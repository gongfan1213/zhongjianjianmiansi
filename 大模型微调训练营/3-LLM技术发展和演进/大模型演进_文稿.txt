	大家可以听见声音吗？可以的话，这个写一个一。可以OK有同学很好，有同学问可不可以回顾一下上节课的知识点？不知道是不是有个上节课没有没有参与的，没有参与我们直播的同学，我们简单一两分钟时间回顾一下上节课讲的内容。
	上节课其实我们主要讲了两个大的部分。一个是AI发展的四轮浪潮，分别从技术的角度，应用的角度，讲了这个四轮浪潮之间的这些技术是主要有哪些技术点在演变，应用的话主要是哪些参与主体，以尤其是在应用这一块，以美国的几个高校和硅谷的这些创新企业为主。一直到最近十多年，互联网移动互联网和大模型出现之后，中国的团队包括华人，在美国的这些华人也深度参与了AI的发展。最后落脚点到我们个人怎么样能够借助大模型来帮助我们自己成为一个超级个体，或者说帮助我们的小团队提升我们的生产力力。也举了几个例子，比如说刚刚成立半年，就有将近几亿美金估值的一个小团队皮卡。然后还有咱们看到的mid july，包括像其他的在国内的一些小团队，都在大模型这轮浪潮里面，正在快速的决心和找到自己的发展方向，同时我们在上节课也讲到了AI大模型的四阶技术。这四阶技术里面我们讲了前两个，一个是提示工程，一个是AI的智能体，也就是现在最火热的基于AI大模型开发的应用形态agents。
	这两部分我们上节课花了比较多的精力也跟大家做了分享，尤其是这个提示工程，我们有提到如果咱们没有写过代码，不是程序员，不是这个深度研发的岗位，怎么样能够享受到大模型的红利，其实我们有提到，整个大语言模型里面，提示工程是一定需要去研究和使用的。即使我们没有去做AI agents，也没有资源，或者说不能长期的去做大模型微调。但提示工程是一个门槛低并且非常容易上手，然后它的ROI也很高的一种技术。如果我们掌握了提示工程，其实我们对于不管是ChatGPT，还是说这种纹身图的stable diffusion也好，未来的纹身视频，纹身3D之类的应用，短期来看，至少最近这几年prompt仍然是一个跟大模型沟通的主流的技术手段。
	那如果咱们掌握了怎么样去使用prompt，其实能帮助我们在很多场景里面都能提升自己的生产效率，不管是写写日报，我们举的这个小的例子，还是说真正的在工作当中，我们去生成给客户的方案，给汇报的方案。PPT里写的，word里写的各种各样的paperwork都可以通过ChatGPT来生成。甚至我们在课后有同学在问，各种各样的日志报错应该怎么样处理？包括我们要去用拍上写一些脚本语言的这些胶水代码，怎么样能够用ChatGPT来帮我们写。这些其实都属于prompt engineering的范畴。
	而AI智能体agents其实它更多的是目前在我们刚刚有大模型，面向公众的这样的一个大环境下面，所谋发的谋生出来的一种暂时的一种AI应用的形态。而A目前我们看到像以南欠，或者说类似的这种框架为主，有很多的应用都基于南欠，包括GPT s在进行开发。而这些开发出来的AI agents其实是充分利用了大模型本身的推理能力，以及他去调度第三方的一些能力，这个就是我们提到的agents里面的最重要的一个范式，叫做react，就是我们的reasoning action范式，我们划到这一页，这里reasoning action的范式，reasoning action非常重要，大家如果想要掌握agents，一定要把这个记在心里面。因为整个react现在是不管是我们的alt GPT这种自主智能体，还是说这个stanford小镇这种角色扮演类的，还是像function call这种调用第三方，ChatGPT的plug in这种调用第三方的这种模式。其它的本质都是react这样的一个核心的范式在起作用。
	因为大模型通过大量的语料的训练，已经具有了大部分的语义理解的能力。这个语义理解既能体现在他能听懂你说什么，也能帮你把你要完成的这个大的目标够去做拆分理解。这里就体现到了我们chal thought类似的这种思维链的技术。这个技术现在大模型的服务商也在内化到自己的模型服务里。这些思维链的应用使得大模型能够理解复杂目标，并且逐步的把这个复杂目标的上限拉高。那么通过拆解复杂目标，大模型就知道你的这个目标要如何去完成。如果能够通过推理完成的内容，那么就在RE也就是reasoning这一部分推理就能够做好。但如果推理仅仅是靠推理无法完成的工作，就会涉及到我们看到的action，就是调用外部的一些工具资源和API，整体组成的叫做act这样的一个范式，这个其实就是我们在上节课讲到的一些主要内容，然后我们在上节课也有一些简单的示例。
	比如说我们要用能欠去实现一个react，然后还能够对接谷歌的这个搜索引擎。那只需要通过这个十行左右的一个代码。因为现在的工具链已经非常成熟了。那能欠上面开发的各种tools和agents，使得我们可以两三行的代码调用我们谷歌的搜索引擎。
	然后再用一两行的代码去拉起一个OpenAI的GPT API，就能够完成一个基于这个GPT加上搜索引擎的一种react模式，以及这种更通用的react这种形式。就是我们直接通过能劝的agent这个模块，去调用它自己实现的各种各样的图，这里就会有各种各样的这这个agent类型。像我们这看到zero shot react description，它其实对应的这个agent type的背后是一个特定的prom template，或者说叫做prompt strategy，就是我们的提示词策略。这个提示词策略大家可以想象一下，它其实就是我们第一阶技术提示工程的一个更加系统化的一种设计，它跟我们具体的大模型的应用开发框架和对应的具体的大模型去做了一些适配，所以它的效果相对来说就会比较好一些。同样的像我们提到的在南泉里面，在Q3末Q4初的时候已经实现了大量的tools，包括这个RAG这样的一些应用，都是在我们现在看得到的非常广泛应用的一种air agent的形态，然后要去实现它的话也不复杂。
	好，这个是对上节课的一个简单总结。我们接着来看一看四阶技术的后面两阶阶技术的一个总览，主要是抛砖引玉。因为整个课其实讲的是大模型微调，所以我们不太可能会在今天两三个小时就把完全讲讲透，讲讲的完全明白。但更多的是让大家逐步的去理解它，由浅入深，先有一个总体性的认知，然后有一个历史发展的一个演进。能够看得到不管是今天的我们，还是计算机科学家和行业的这些工程师们，他们是如何把语言模型这个事儿逐步玩明白的。
	好，我们先看看大模型微调，这个其实是开课的时候讲过的一小部分内容，我看到有些同学也没有听，我们再简单的跟大家分享一下，引出这个大模型微调这个概念，就是首先在讲这个大模型的时候，很多同学可能都没有去训练过模型，也不知道什么是模型。我们都经常把这个大语言模型和AI当成一个黑盒子，或者说有的人把它两极化的去思考。有的人认为AI好像明天就要战胜人类了，人类就可以解放了，不需要工作了，或者说就没有工作了。还有一类认为AI是个骗子，就像有经典的一些AI创业的段子被戳破了，就类似于有一幅很搞笑的漫画，就有个ATM机器，或者说一个类似的AI的机器背后站了一个人在帮你数钱，类似有这样的一种想法。
	但其实我们回归到本质，模型回归到数学或者形式化的定义里面，模型它在干嘛呢？模型其实它就只是一堆我们数学里面的，你可以认为数学里面的公式或者符号。如果到这个层面来理解，其实就没有那么复杂。那什么是模型？模型被造出来的意义是什么？我们上节课已经讲了AI的几轮浪潮，从最开始的基于规则的，后来到数据驱动的，有机器学习、深度学习，以及到现在的大语言模型。但我们今天的重点会来讲大语言模型的技术发展。
	但在这个大模型微调这个总览这一部分，我们会简单跟大家讲一讲什么是模型。模型核心就是我们这里看到的一组模型权重，或者说模型权重的矩阵。它就是一个高维的一个矩阵。我们假设有一个模型，它很简单就是Y等于WX这么一个很经典的。我们在TensorFlow的这个预习的课里面，给大家讲的视频课里面也有提到，比如说Y等于WX大家想象一下这样的一个数学函数的公式我们学的这个线性回归或者逻辑斯谛回归里面都有这样的一些函数。W就是这个权重参数，X是我们的输入，Y是我们的输出。整个模型被定义或者说被设计出来的核心是希望有这么一个模型，通过不断有数据的学习，能够学习出适合这个模式的一种分布。这个分布未来能够在同样的分布下面，你有新的X新的输入进来之后，能拿到我预期的一些输出。
	大部分的有监督的模型训练其实都是。基于这样的一个思路在运行的，所以我们才会有梯度下降，有目标函数，有损失值。然后通过损失值的降低，我们经常看训练的时候，loss会逐渐降低，通过loss的逐渐降低，使得我们的当前训练的这个模型输出的值和我们有监督的这个标记值能够越来越近，越来越相似，或者说最终接近于无限小它们的差值。这个时候我们认为这个模型在训练集上的分布就学的比较到位了，这个是模型的意义和它的定义，它其实就只是一个数学上面的一个高维的矩阵，里面充满了矩阵里面的值。简单来说是这样。
	那如何要去定义一个模型？目前我们有很多的深度学习的这些框架。比如说主流的PITOCH TensorFlow以及google的jack，TensorFlow也是google主导的一个深度学习的一个框架。这些框架可以使得我们把这一堆抽象的Y等于WX，当然实际的模型比它复杂得多这些抽象的概念变成一个的神经网络的参数框架代码，这个是咱们下面看到的py touch和TensorFlow的价值。但是我们的课程里面不会涉及到自己去新定义一个模型，目前大家也通常不会这么干，大家都是基于主流的transformer的网络架构，再去做一些网络层次参数上面的一些调整，所以大家不用担心自己不会排torch或者不会TensorFlow，没有关系。
	因为整个微调技术的核心是对数据的理解，对于分布的理解，对于我们模型不同模型之间什么参数代表什么含义。我们在用有限的资源怎么样去达到我们的目的，这个是微调要关注的核心。有了这样的一个初步的概念，Y等于WX的概念之后，为什么会有一个大模型的概念？这个其实我们也有提到，整个大语言模型和深度学习的这个为什么是第四波的浪潮？它是有一些技术特点的，它不是说我们都在用神经网络，所以我们都是同一波技术。其实神经网络可以追到非常早的一个时期。就像机器学习和深度学习的细分也是类似的一些原因。它的一些技术特点发生了变化。大语言模型这个大字就是它最大的一个技术特点。
	我们看一下一个典型的深度学习网络，它被广泛的应用于学术界和工业界，叫ret net 50，也是一个sota网络。它的模型参数我们刚刚讲到是一个矩阵，那这个矩阵其实就是一堆浮点数存下来了。比如说0.312某一个W对吧？那么它存到了一个高维的矩阵里面，它存了多少呢？我们可以有一个量化它的标准，像renee t50是2500万模型参数，那么nama的65B其实是一个650亿的一个模型参数。我们知道在2020年，也就是三年前，GPT3发布的时候已经有175B了，有1750亿。
	然后到GPT4的时候，有一些OpenAI的员工，工程研发的团队，有对外披露过，当时有提到GPT4是一个混合专家模型，像一个大的GPT4下面可能有八个不同的大语言模型。每个单元模型都是两千多亿的一个参数规模。所以大家可以简单算个账，一个650亿的模型的参数，需要780GB，那我们初算一下，比如说1000亿可能需要1000GB，那么一万亿就是更大的一个规模。甚至根本就无法这样线性的直接去增长。大家想象一下，在以前我们可以在自己的这个GPU上面去跑一跑的net 50。
	到今天为止，真正能够运行，我们不说训练，只是运行加载一个大模型就已经变成了一个极高的门槛。而这个门槛不再是什么个人研发，或者说甚至连高校都很难触及的一个门槛。所以我们能看到在深度学习阶段，高校还能参与一些网络结构的设计。但是到了大元模型阶段，几乎我们看不见高校的身影了。所有的大模型都来自于顶级的前沿的科技企业。他们有足够的资源，他们也有足够的数据，能够去运行和训练这样的一个大模型。这个是大模型阶段一个最重要的特点。
	那么为什么需要微调大模型？这个答案就很明显了。因为首先我们没有足够的资源来从头到一从0到1的去预训练一个大模型。待会我们还会讲一些客观的预训练的成本。预训练的成本是极高的，哪怕是一个650亿的一个lama模型，它也需要780GB的显存。我们大概大部分的同学都知道，我们这个课的要求只要16GB的显存，可以量化的去做一些微调，量化的去预训练一些小模型。
	预训练的成本极高，这个是大部分的一个客观现实，所以真正能够完成完整的去做一个大模型，千亿级的大模型的预训练的公司，就在全球也不会有这个十家公司。这也是为什么国内的很多大语言模型公司，它不太会从0到1的去做预训练。更多的是在已有的预训练模型的框架上面再去做微调的本质原因，这个成本实在太高了。
	第二就是说呃我们往后讲没法预训练，但是往前讲提示工程它也有它的天花板。我们刚刚有看到的那些示例，不管是用一个谷歌搜索引擎加一个GPT，还是说我们对接各种各样的tools造出来的AI eggins，它都有一个很大的局限。这个局限就在于所有的提示工程，或者说所有的from the learning之类的词，它都不会去改变大语言模型本身。换句话说，我们刚刚的Y等于WX里面的这个W它是不变的。那么当W不变的时候，我们就只能在外围做一些工作了。在外围做工作的时候，如果这个语言模型本身对于某一个特定领域数据，它是没有这块知识的。他就没有训练过，或者说他对某一个小语言，特我说人类语言，特人类的特殊的某一种语言，他就没有训练过。那它肯定是无法理解的，文本是一个方面，如果考虑到这个多模态，那就是更明显了，各种图像的信息它都无法识别。
	尤其是为什么中文的大模型有一些独特的特点，因为英语和中文本身就有很多特点。大家如果了解这个中文系或者中文相关的一些历史，汉语的历史是整个汉字是一个象形文字，是从图像演变过来的一种到今天的非常简化的一个文字一个文字。但是这个文字本身如果我们像英语那样去学习，它会比较简单。我们后面会去讲in bedding。
	但像中文，为什么中文同一个字有无数个含义，并且在不同的上下文，它里面的含义又不太一样，在不同的语境里面又不太一样，这就说明本身中文这个语言系统就是要比英文的这个语言系统难很多。那怎么样去把一个更难的语言系统学会，单单去靠这个呃原来的提示工程是无法做到的这也是到今天为止，大家写这个提示词，做这个提示工程，做这个提示是策略都要拿英文来做的一个本质原因。因为中文他学的就是还不够好。这也是中国有这么多大元模型公司，未来能够存在的一个底层的一个价值逻辑。因为中文现在就是没有被大模型给学好。所以如果哪家公司真的把中文的大元模型做到了一个非常高的高度，那它的战略价值是非常大的，这个是前三个部分，我们讲为什么需要微调大模型。
	最后还有两个原因，就是到应用层面来讲，数据安全和隐私。And musk就是这个space和这个特斯拉的公司的老板，马斯克曾经提过，就他他讲到这个大元模型其实是一个比核弹，比原子弹还要危险的一个重器，为什么这么讲？第一是因为首先我们讲前面那种大规模杀伤性武器，它通常是不会使用的，在很多年以来，其实人类都把它当成一种威慑力，不会作为一个真正使用的一种武器。
	但是大语言模型它天然具有一些隐秘，就是隐秘性，就是它使用了其实你不知道的。当然今天可能中国的这个广告推荐做的非常离谱，你会明显感知到它有广告，这个是广告推荐的事儿。但如果是大语言模型，它在背后去运行，给你推一些东西，其实你不知道的。就比如说ChatGPT，你在使用过程当中他的回复你给你埋了一些所谓的广告推荐，其实你不一定感觉得到，因为他没有那么生硬了。并且他如果能够把你的这个交流沟通的信息变成他训练的一部分，他的训练数据，那其实对于你来说也是一种数据安全和隐私泄露的问题，所以从这个视角来看，我们有自己去部署和微调一个大模型的实际的一个场景和诉求。
	当然如果我们最终大模型AI agents或者AI的应用，AI大模型的应用变成了一个像今天互联网一样的服务，那肯定就需要各种各样私有化的这种大模型了。它可能是针对你的个人数据。这就会牵扯到隐私计算、边缘计算、联邦计算以及各种边缘侧的算力的一个同步的一个迭代和成长。这个其实是往长远来看，大模型取得广泛应用一定会存在的一个发展路径，也就是微调大模型。
	从一个最佳实践的角度，OpenAI这家公司其实他们也有一个类似的发展过程。我们知道今天来看大模型这件事儿做的最好的一定是OpenAI这家公司。我相信。全球应该都是没有疑义的，这也是为什么它的最近的八卦这么引人注目。OpenAI其实也是经历了一个从预训练到微调的过程，这个过程其实今天我们讲的这个下半节课也会涉及到。
	GPT本身它的这个模型迭代跟AI的技术发展是一个非常顺其自然发生的过程。首先OpenAI这家公司，我们可以在今天很负责任的讲，它没有非常大的学术上的原创性的贡献。但是open a这家公司绝对是一个，尤其是sam奥特曼进入之后，绝对是一个把商业化市场研究、用户研究和AI的工程化做到极致的一家公司。并且他也探索出了一条新的发展思路，也就是现在在中国互联网，包括像中文中国的创投圈会讲这个所谓的AGI native或者AI native。其实它的核心都变成了跟我们微调很像的一个状态。就是可能我们的操作系统，我们的云设施不太会再有一个短期内天翻地覆的结构性的变化了。
	但是我们这20年来积累了大量的互联网数据，这个互联网数据的积累速度是每年都在翻番的。这么多的互联网数据放在那儿怎么用起来？其实以前我们都没有用起来，包括到今天为止，中国的很多互联网数据是没有用起来的。
	说一个最常见的随处可见的摄像头数据每天都在硬盘里面存着。然后这些存在硬盘里面的视频，可能三个月或者更短的时间就会被刷新掉。这么多的数据其实放着没有用起来。在赛文奥特曼去做出ChatGPT之前，其实这些数据我们不说视频数据，类似的这些文本数据也是一个同样的状态，这些数据没有用起来。
	但是GPT首先利用了transformer这个架构，把这些数据先存进来了。大家可以理解成我有一个更智能的硬盘，它不是单纯的把数据记在那儿，而是初步的消化了一下，放到了这个transformer的架构里面。也就是这个GPT的架构里面，叫general retrained transformer，通用的预训练的transformer。
	放进去之后，一直到了GPT3这一代的时候，他发现不能再持续这么玩了。第一就是数据已经消化的差不多了，就是我第一遍消化已经差不多了，我现在需要进一步的吸收了，因为数据没了。那么进一步的吸收过程当中，相当于预训练阶段该干的事儿都干完了，我也不知道要再怎么去大调能够获得更好的效果了。在预训练的网络架构上，但是微调是从2020年开始一个非常重要的课题了。
	从2020年开始我们看到，第一新增加了一些代码的预训练，这个是当时的一个很很厉害的一个想法，就是从学人类说的话，到人类和计算机交流的一个中间语言。有时候我们天天研发同学都在写的C语言，C加加java这些代码，把代码作为了预训练的一个语料，加到了这个former的预训练模型里。同时把它加进来之后诞生了，或者说促进了思维链在大模型上的一个诞生，就思维链开始有效了。
	然后接着从下面这条线开始，大家可以看到，从codex有了代码预训练的这个分叉路口，和下面这条线开始了各种各样的微调。从他的指令微调到他的人类价值观的对齐，这都是我们下周的各种微调里面要讲的一些细节。人类价值观的对齐到增强他的对话的这个能力。
	我们要知道ChatGPT和GPT最大的区别是啊下面这条线。他们用了很多的基座模型，但这也是他商业化产品化做的成功的一点。为什么ChatGPT的迭代可以这么快，因为他把很多训练的过程工程化、模块化了。当我去换它的基座模型，当我去在基座模型上加新数据，比如说我们看到今年3月份GPT4发布的时候，它使用的这个GPT4的模型的预训练的数据仍然是2021年的。但是到了dev day，也就是我们半个月前，三奥特曼开的这个dep，上面已经把GPT4的预训练数据，迭代到了今年的上半年。
	但是整个现在GPT仍然是稳定的，这里其实是有OpenAI做出的大量贡献的，也是我们讲AI native或者说AGI native这类公司一定要去学习的。就是大的一些基础设施，包括网络，写网络的这个框架都没变了。但是你怎么把这个数据用好，怎么做好这个清洗的工作，并且把这个过程能够工程化模块化。这个是OpenAI带给我们的一些启发和探索出来的一些成功之路。
	我们再回到这个最佳实践到技术这一侧，OpenAI既然做了这么多的探索，我们不可能一个人打败OpenAI。但是我们至少能从一个大的巨头身上学到一些技术。那这些技术，我们认为从微调的技术切入来看的话，微调的技术路线一共有两个。一个叫做全量微调，一个叫做高效微调。全量微调顾名思义就是我们把整个W全部加载到GPU里，然后这个GPU里的这个W全部都要去做可以去在训练过程当中去做调整，不会被冻结。
	大家如果训练过的net的话，就会知道像internet这种网络结构，或者说类似的这种计算机视觉的深度学习模型或深度神经网络。它的微调可能都会体现在冻结主干网络backbone，最后去微调这个全连接网络或者最后几层网络。因为主干网络里面主要去学习了这个卷积核里面，关于我们人类的RGB，各种图像的一些基础的一些能力。最后几层更多的是这个label，就你把这个image net几千个或者说上万个标签的大模型，在视觉的这个大模型训练完之后，要去识别一些特定的物体了。这个物体不在imaging net或者原来的这个大数据里，你会去只调整最后的全连接网络。这个是在CV这个时代微调的一个常见状态。
	但是在大语言模型这边会略微有不同。第一它不是一个简单的深度神经网络了。所以它不太会像以前，比如说我们学VGG net inception internet，retina net之类的视觉网络的时候，它可能是卷积，最后套几个全连接网络这样的一种典型范式。但是在大模型里面它不太会这样分层。那怎么样去微调，其实就是我们接下来要去研究的一个重点。但是从微调的范围来看，全量微调就是全部都调整。还有一类叫做高效微调，这个高效微调就是各种八仙过海的技术在里面去做研究了。
	高效微调里面从效果和主要的技术手段上来看有三种。一种叫做有监督的微调，也就是我们说的有标签，然后这个标签就是这个监督，其对应的就是这个标签有一些人类的标注。然后这种方式，其实是现在大部分的云厂商，比如说国内的这个文心，包括这个通义，他们都会去提供的一种功他们的大模型服务里面都会有，只不过他可能不一定会展开这个有监督微调具体使用的微调技术，还有一种就是基于人类反馈的这个强化学习。也是非常多的，公司现在都再去搞的一个研究方向，也是ChatGPT最早提出来在应用的一个方向。
	更进一步的有把人类的反馈改成AI反馈，让AI来自己反馈的一种强化学习方案，叫做RLAIF，这个其实就是为了解决人类反馈慢的问题，因为人类反馈始终需要派活标注，打标记或者排序，完了之后再给你一些反馈。这个ILF是一个比较新的研究方向，但这个方向其实技术路线上很好，但它还会有很多的问题需要解决。因为本身这个LLHF就是因为原来的那个模型需要去做一些更符合人类的一些习惯的反馈。你用AI来反馈，这里会出现一些不可控的问题。
	但这个方向很好啊，这个是从大的技术路线，我们可以分成这几类，刚刚已经讲到了全量微调有很多问题，首先预训练有很多问题。全量微调一样，它需要把整个大语言模型加载到显存里面，所以它的训练成本依然很高，但比起预训练肯定要好一点。因为预训练他需要把所有的数据全部都丢给这个模型，并且很多轮每个epoch就是把把我们的这个训练数据跑一遍。大家应该训练过都知道，但你实际训练的时候可能要跑N遍，那没跑一遍的这个成本都非常高。因为所有的训练语料都需要嵌入in bedding之后再丢给大模型，那么全量微调可能不需要，它训练数据没有那么大，所以这部分它相对预训练要少一点。但是它仍然需要把模型全部加载进去，这个是它训练成本高的原因。
	第二个就是说灾难性的遗忘，因为本身要把一个大模型预训练好是很难的。那么预训练好一个大模型之后，它的模型权重就固定在那儿了。固定好之后，咱们要去做全量的微调的时候，如果本身技术手段不是特别的熟练，就容易造成一部分的权重进行了不必要的更改。这个不必要的更改就自然会导致一些能力的丢失，或者说一些知识的遗忘。这个是全量微调带来的显著问题。所以这个是全量微调，我们能看得到的两点。
	那么PFT落地到一个具体的微调技术上，不再是路线上，其实现在也有一些很多的论文都在做研究，今天我们列一下，这些都是我们课程里面会涉及到的，也就是下一周也都会覆盖到的一些主流的技术方案，就是我们的怎么样去做微调，又围绕这个token去做文章的，这个token就是我们的训练数据，最终都要变成token，也是大家去用提示工程的时候，或者说去用ChatGPT的时候，都会去算的这个计费单位token。Token做文章的好处是说，语言模型它本身是不变的。就相当于我不用把语言模型加载到显存里面去做各种各样的调整，我在这个外围去做一些微调，用小模型去撬动这个大模型。这里有一些比较典型的像prompt，prefix和P2I这样的一些技术。
	第二个就是我们的这个特定场景的一些任务，简单来说就是一个大模型的一个分解。大家都做过上过大学的线性代数，或者高等数学，或者数学分析。不同学校不一样，都有一个低质分解的一个类似的一个数学训练。在这个数学场景里面，或者在这个数学课里面，大家应该会知道，一个高维矩阵它不一定是一个非常你可以认为不是一个非常稠密，或者不需要那么高维度就能表达的一个状态。那么Laura这一类技术手段，这一类技术方案，其实就是围绕着这个角度去搞的。他知道我们在训练的过程当中，那个大模型其实没有被塞得那么满，有些部分是稀疏的。这些稀疏的就能用两个小模型相乘的方式去表达出这个大模型的绝大部分内容了。
	Ora是这样的一种方案，那q lora就是它的量化版本，还有这个自适应的版本，还有一些新的思路，像IA3和这个uni pilate，这些都是一些现在PFT的一些主流方案了，就是大家都在五花八门的造微调方案。有没有一些统一性的框架，或者说更少的数据就能做微调的方案，都是从降成本或者说训练的框架更加的规范化，系统化的思路角度去延展的。这个其实是我们整个课里面会覆盖到的一些主流的技术方案。
	好，这个是大模型微调，那什么是预训练技术，其实我们刚刚已经涉及到了一部分，预训练是什么？其实预训练是相对于微调的上一个阶段来说的。预训练的核心它是怎么来的？其实是因为我们的整个互联网数据的积累和算力的积累，支撑我们敢去做这么一个事儿了。并且我们会去讲这个大语言模型，它有一个天然的优势。相比于以前我们做这个有监督训练的时候，需要给所有的数据打上标记。而大语言模型尤其是像这个GPT，包括bert这样的一些retrain的transformer，他们不需要标注，他们直接把人类的语言丢进去，我们叫做语料，large coffers，像这个维基百科，包括一些书籍，把这个语料丢给我们的这个神经网络transformer，它就能够学习。
	那他学的是什么呢？其实就两个东西，一个是学的语法，一个是在提取语义说人话就这两个东西。然后这两个东西学完之后，其实我们会发现，在GPT ChatGPT出现之前，其实整个语言模型在AI这个圈子里的地位是不高的，至少不是一等公民，只能算是一个有人在研究的方向，不像现在有一个想要重写整个AI研究范式的这样的一个状态。那会儿的语言模型为什么会有这样的一个状态？就是因为语言模型本身不是一个最终交付物。
	你可以理解成语言模型学出来之后，它还需要去适配一些下游的具体任务。它才能够跟最终的交付的，不管是产品还是成果搭上关系。因为它本身只是一个中间结果，它能够理解你告诉我的内容，然后告诉下游可能要做什么样的事情，但他做不完。因为下游的这些具体知识他也没法学，因为它是一个无监督的未标注的这么一个东西。你可以理解成就是有一个中学生，这个中学生能听懂人话了。但是你让他去写java，写python，让他出这个解决方案去投标，他不会，他得再找一个你们这个前辈，这个前辈讳这些活，但这个前辈不想听这些甲方唠叨，或者不想听谁谁谁唠叨，这个是早期的语言模型，后来的大元模型就厉害在把后面这部分事儿也给干了。我们会看到今天的下半部分课程会去讲。
	从GPT1到GPT3一直到GPT4，其实就是这么一个过程。从一个中间中间状态变成一个端到端的交服务了，这个就很厉害。早期的预训练语言模型其实还没有，尤其是像这个GPT e和bert那会我还没做到这一点。所以那会儿的预训练语言模型需要一个大的语料，然后在中间会有一些具体任务。Task specific data set, 其实就是一些具体下游任务的一些训练集。但它规模可能只有这个语料的1‰甚至更少。然后在这些特定的任务上面去做微调，调整之后才会在一个具体任务的测试集上面去做测试。这样的一张图就跟我们看到的像renee t这个视觉模型里面的微调比较像了，不过它无法直接指出，这是最后的几层，因为它不是这样的一个CNN的一个这种垂直纵深的结构。
	比如说GPT3，它的训练语料就非常大。这个训练语料是没有怎么样经过标注的，它最多经过了一些筛选。比如说这个common co这样一个中立的公益的，或者说不收费非盈利性的一个组织，一直在迭代数据。这个数据怎么来的？就是他们用爬虫在全网去爬下来的数据，4100亿的这个tokens，这个是GPT3，也就是四年前他们的一个训练语料。当然现在肯定超过这个了，但他没有再公布了。GPT3之后就没有论文的发表了，他们只会告诉你数据更新到什么节点了，但至于里面的成分是什么样的，我们就不太清楚了。
	GPT3我们能看得到，其实它的训练的数据已经非常大了。包括30亿的微机百科，然后它也有一些结构化的数据。然后左下角是这个common coral的一个数据集里面的一些简单的一个分类，包括它的原数据等等，包括在GT3里面也有去训练一些人类的经典书籍和像editor这样的一些论坛类的数据，就是在web text 2里面有包含。
	这个是GPT3在四年前就已经做到了一个水平了，我们既然讲到预训练的语言模型，待会儿也会讲这个transformer。其实整个预训练语言模型现在来看仍然是以transformer为主，但有一些新的架构在提出，只是目前还没有成为主流，或者说跟transformer能够在同等体量上去讨论的一个方案。那么基于transformer的这个预训练语言模型主要有3种架构。从18年开始到2020年那会儿，一种是以这个encoders编码器为主的，这种像bert为代表的编码器。还有一种是以GPT为主的decoder为主的，主要用于生成的解码器，还有一类就是比较综合的，这个也是google搞出来的，这个叫T5，就是encoder decoder都有的这样的一种结构。所以我们简单来看，所有的预训练语言模型，或者说这种基于transformer的语言模型，大部分就是这三条技术路线了，我们今天也会讲到这个encoder和decoder，就是bert和GPT这两条路线上的一些模型。
	好，我们讲了这个微调，讲了预训练，最后再来讲一讲它到底贵在哪儿。有没有人去算过这笔账，对吧？其实有的，而且大家要知道，google本身也在做硬件，就它的TPU当然英伟达的这个G有可能市场份额更多。
	在2020年的时候，其实google自己发布了一个他们优化算力成本的一些报告，其中就有提到这个renee t50，这是一个非常好的sota网络，也是各种benchmark的一个经常会出现的网络，recent to be。他有提到在red nir的五行的训练成本的比较，研究方面，这个八块V100的这个GPU去训练90次，全量数据训练90次需要216分钟，然后它的成本是75美金以上。然后一块满负载的云端的TPU，第二代的TPUV2，去训练同样的90次迭代只需要7点9分钟，所以它的时间是快了非常多，7点9分钟和216分钟，将近30倍的一个速度。然后成本只要50美元，所以训练成本下降了38%，速度快了27倍。所以从2020年的时候，其实大家都在研究，但那会儿大模型还没有像今天如日中天，那会儿的大模型就跟我刚刚看到那个图一样，还在GPT123，大家还在做探索，只不过弯曲已经有一些。AI的大模型公司出现了，国内可能都没人关注到，国内可能有一些bert的相关研究，因为那会儿bert的开源做得好，但是在2020年的时候，大家还在用race net 50来做对比，并且确实训练成本，训练速度都在做优化然后大家谈的这个价格，也都是训练一这个result 50需要75美金，对吧？那么这个成本还在降，我相信到今天的时候，这个成本肯定更低了。
	但是基于transformer的语言模型，这个总成本却非常的高。在2020年的时候，那会儿我们还没有看到很多万亿的大模型，可能还都是百亿的模型。但是即使是在这个百亿的模型上，我们看到这个总结有一个很有意思的一个标题，叫做当我们讨论NLP的时候，everything is big and getting bigger。我相信这个话在2020年看的AIAI21 labs这家公司也很有名，自己也在大模型后面，一直在到今天为止还很活跃，发了这样的一个文章。
	然后这个文章里面的统计主要统计了什么呢？数据集的规模，模型的大小和这个训练量。这个训练量就是我刚刚讲到的，我们在训练这个模型的时候，你要用到的数据转换成token的数量是远远超过这个模型的。整个这三部分都在不断的增加，包括具体来看这个transformer里面的一些结构。就待会儿我们会去讲transformer的这个理论基础里面它的层数在增加，像GPT那会儿很很智能的GPT1只用了12层的transformer，到了第三代的时候就基本上干到快100层了。然后像那会儿的GPT2这边有写是48层，然后那会儿还有很多的基于bert的一些衍生品，整个规模其实是在不断的增长，并且今天还增长了几个数量级。
	当时在2020年的时候，其实AI21 lab就根据google发布的这个信息统计了一下，如果要训练一个110亿参数的一个T5的变体。我们刚刚还看过六百多亿参数的一个nama，110亿参数的一个T5。T5是一个encoder，decoder都有的一个结构的一个大模型。它的单次运行成本就已经超过130万美金了。当然今天可能这个数字会下降一些，因为它的单位算力成本在下降。然后如果把这个T5大模型和它的各种小模型运行2到3次，一个项目的成本就是1000万美金。这也是为什么现在说没有10亿美金就不要去搞大模型一样。因为整个算力的这个硬成本摆在这儿，并且是一个大家都需要算力的状态，短期内也很难降价。所以关于异性恋这个大模型的成本是非常高的。
	我们从模型规模就是一个3个到4个数量级的一个增长。数据的规模可能就是7到8，甚至10个数量级的一个增长。那么它的成本自然也会从我们刚刚看到reason 50是70亿美金，现在变成了130万美金，甚至更高，这个就是大模型跟我们深度学习这一波AI浪潮有一个最大的本质上的一个区别。就数据的体量，模型的规模，包括我们运行它的成本都有一个非常巨大的一个变化。
	讲了这么多，为什么还有这么多公司在搞预训练？除了中文以外，除了对中文汉语的理解以外，其实还有很多的局限。就比如说在做第一节这个课的课件的时候，当时找这个GPT4和这个W3，想要做一个微调的这么一幅图，就纹身图其实效果还没有做的那么好，而且差强人意挺多的。
	第一个就是说我们都知道刚刚有表达微调，它其实只训练大模型的一部分的参数，然后我们其实对于模型的理解不要太死板，包括我看有的同学在问微调如果不是调W那是调什么？调X？首先咱们不要理解大模型，就是那么简单的数据结构，Y等于WX一会儿我们讲讲到NNNNNLM就神经网络语言模型，二十多年前的20十几年前，20年前的成果，30年前的成果的时候，可能你就会知道真正的语言模型没有那么简单，不是Y等于WX。然后这里面有大量的模型参数可以去调，甚至可以在模型的外部的in bedding这一层去调，甚至在transformer里面加一些前缀去调，这个其实都是W这个W是一个抽象的，或者我们在数学里面叫data。
	但我们这里回归到这幅图想要表达的内容就是模型微调。其实它真的只是训练一个大模型这个复杂的一个矩阵里面的一部分参数。当时想让他找一幅图，因为我在google也没有搜出非常好的这个图去表达这个含义然后他跟这个反应中一个renee又不太一样，所以我想让他表示只训练模型一部分参数，它当时出现了一个小的bug，就它显示出他在为我创建这个图了。
	然后要表达的这个过程是一个机器人正在调整自己的零件，其他零件保持不变，其实它没有生成，它卡在那儿了，然后我是有这个W3的权限的，然后我就向他确认你没有生成图，让他重新生成了一个图。但这两个图显然挺奇怪的，他没有理解到反应to这个词本质在神经网络里面的意思，右边的这个也是一个他要生成的图，但不行，对，还是差很多意思。所以通过这样的一个简单的，其实我相信通过这一会儿这么一个解答，大家应该能够在脑海里面有一个大致的理解了。就是一个高维的矩阵，每一个值每一个矩阵里面的值都不一样。然后我们冻结了一大部分，只调整一小部分。我确实也很难想象出一幅画面能把它画出来，但肯定不是这里展示的这样的一个内容。但是其实最新的这个GPT4加上w three还没有完全get到我们想要表达的含义。
	所以整个多模态，不管是图像还是视频，还有很长的路要去走。这也是最新很多的人都在讨论OPI这个八卦是不是因为HI突破了，其实不可能的，因为这里面还有太多的技术的问题需要去解决了，这也是现在最顶尖的这些硅谷的科技公司的这些研究学者们一直在努力解决的一些内容，所以大家不用有担心，但是一定要把他现在有的能力给用好。因为他确实多模态不强，这个也不是他之前十年积累的内容。但是我相信就目前全球人民资源的集中，很可能也不会太长的时间，就能有一些突破，这个是我们第一节课给大家讲的内容，其实就是四阶的技术的一个总览。
	再给大家总结一下，微调不一定是把这个大语言模型本身的这个值全部都要去给它做调整，它可以只调整一部分，甚至结构性的去调整一部分。就我们这里提到的结构性的去做一些调整，包括像这个prom 2W就完全不变，只是去额外训练一个小模型，这个小模型能够把chrome的做好，再喂给大模型，prefix 20，它可能都不用去动这个本身。在transformer的这个网络前面再叠加一点点前缀，然后拼到一起变成一个新的transformer，更适应下游的任务。然后Laura不一定是训练这个W本身，而是去训练两个小矩阵，这两个小矩阵的和能够去替代原来的大模型。这些其实都是可能出现的微调的手段。因为微调的本质还是说把你的原来的模型的成果用起来之后，能够适应我的具体的场景或者说新的任务，完成我的一个具体工作。
	这个是微调本质的一个概念，至于它怎么去实现的都可以。只要不是大费周章的把整个模型去倒腾一遍，其实都可以叫做微调。而预训练是一个从0到1的一个过程。它更多的是一个怎么样把一些原来完全没有的知识或者结构或者领域能够学到一个模型里面去。然后早期是需要在对接下游的任务去做翻译。
	二像现在我们看到的这个大型的GPT4，包括一些国内的可能有这种千亿的模型，都已经把下游任务内化到这个大模型里面了，给他的模型足够大，然后训练集足够丰富。好，这个是我们的四阶技术的一个总览。看大家有什么问题，我们回答四分钟的问题，五分钟的问题，然后就开始第二节课。
	大家有什么问题吗？
	老师说大语言模型的中文学的不好，能举个例子吗？很简单的，你就把如果你用过南茜，或者说用过类似的一些工具。比如说你用过OpenAI的GPT的function call，类似的一些主要是想要用AI agents的技术。你把你的提示词换成中文，你去试试，你就知道它有多差劲了对。指令微调是哪一种微调？这个分类我觉得大家不用去太纠结这个细节，我们后面会逐步讲到这些技术名词是怎么来的，大家也不用纠结，就关键是抓住他的这个本质。
	可以再讲一下Laura和突然的区别吗？这个其实刚刚讲的比较多了。Laura是通过小矩阵来替代大矩阵，然后处理，不太会有这样的一个技术路线微调方式带来的效果有明显的区别吗？评价效果的时候通常不看这个方式本身，而是用一些下游任务或者说一些benchmark来做比较。就比如说我们在hugin face上面看到的大模型的leader board，我们在质谱上面看到的这个agent bench等等，包括这个long bench，就长上下文，他一定是因为他最终我们要忘记这个语言模型是中间过程了。现在我们把语言模型，尤其是大语言模型当成一个端到端的技术手段技术方案的时候，我们就要看端到端的另一头，你的终端或者说你解决问题那一端到底需要什么样的能力。然后从这个能力去评价这个模型。然后assistance可以维护这个文件，跟我们后续的微调的区别点在哪儿没有什么关系，这个同学就没有直接关系。
	对，就是assessment这个产品它可以维护文件，它只是能够上传文件，就相当于举个什么例子让你能理解，就是OpenAI是一家大饭店。你是他的客户，现在你可以把你喜欢吃的一些东西，首先能让它记下来，因为它可以翻译to，然后它它可以有一个你高级客户经理专门服务你，然后你只要去了，你跟他报个ID，他就按照你的口味来给你提供餐饮。然后assistance file，其实就是说你甚至可以提交一个小纸条，这个小纸条交给OpenAI。然后下次你去的时候，你甚至有专门门的卡座，有专门的服务员和厨师，都有可能。
	但微调是什么呢？微调是教你开饭店的，这是两件事儿对吧？我不知道这个概念你理解没有，这是完全两个事儿。对，现在我们学微调是为了开饭店，不是为了去消费，不是为了当高级客户，是这个区别。然后没有最好的微调效果，这个同学就是你一定要理解微调的方式，不决定微调的效果。
	我是一个我再举个例子让大家理解，就是金庸的小说大家都看过对吧？我练的降龙十八掌，他练的蛤蟆功，对吧？你说降龙十八掌和蛤蟆功谁牛逼，他不知道，对吧？你说如果是郭靖使的这个降龙十八掌，那肯定牛逼。但你说如果郭靖在用蛤蟆功，然后你让那个段王爷去做用这个降龙十八掌，你说这俩武功谁牛逼都不知道，这完全看你学的怎么样，你把这个武功练的怎么样，能怎么样去用它。对，就不是说我念出降龙十八掌这个几个字我就牛逼了。他是要学的，学完之后每个人学出来水平也不一样，是这个概念。对。
	对，这个有个同学很很好提的，就是中文难就难在很多地方，英语天然有词的风格，中文没有，中文需要分词。对，然后有很多中文的经典分词的这个段子，就是什么长长什么就是给你整一堆。我们课程会讲到全量微调，但是是量化的全量微调，然后会讲主要讲高效的微调，然后还有一些国产的一些大模型和国产硬件上下文窗口扩展吗？不太会讲这个对这个上下文窗口的扩展是一个底层的预训练技术。模型参数是指训练数据的总token数吗？不是，待会儿我们就会讲到这个模型参数是什么了，每个模型都不一样。
	如何能够学好这门课程？这个我回答不了你，因为可能每个人都不一样。但我能给我能给的一些客观的建议是，第一如果你直播过程当中没有看明白的，一定要去看录播，录播都看不明白的一定要去问同学和老师和助教。第二就是理论的部分，我们更多的是开拓视野，提升你的上限，了解整个技术的发展脉络。然后这些发展脉络能够帮助你回过头来在这个课程结束之后没也许在你的工作过程当中，再次去看他的时候有新的体会。就像我记得07的第零期的应用开发的课程的同学，还会有同学在群里讨论。今天说我要重新去看老师讲的transformer。因为我最近在怎么样的时候，好像想起了当时讲的一个技术，尤其是理论部分的，让他有好的思路，这个是我讲理论部分，并且一定要讲理论部分最重要的一个原因。
	就不想把这个课程变成一个java培训班。我希望这个课程变成一个让大家真的能够对大语言模型有一个系统性的了解，然后对它的发展脉络有认知。最后就算学完了这个课程，咱们还能够进一步自己有能力去沿着这个大语言模型的新技术再去做跟进，这个是我的目的。
	我看看大家问题挺多的。有哪些好的衡量微调效果的实践？Benchmark benchmark。然后下游任务各种各样的bench，我刚刚说了好几个了，agent bench、non bench、leader board都是啊。然后数据量完全是看任务来的对，有可能你的任务就是需要那几个词，或者说那一百个单词，那可能都不需要微调，用REG就够了。对，多模态应该不会涉及太太多。对，中文分词，我先不讲中文分词了，开源的大模型支持function calling。这个小同学应该是想说function calling，这个我也不太清楚，我没有去跟进所有的开源大模型，但据我了解可能不多，像GOM好像还没有支持。
	评估模型指标是什么？跟着任务来的对，跟着任务来的。怎么判断向量库搞不定，需要做微调。
	你拿向量库搞一遍，你搞不定不就知道搞不定了吗？好，我看了一下大家在问的一些问题，已经跟接下来的内容有关了。我们就直接开始今天的内容。上节课我们讲了AI，更大的一个词就AI它有四轮的一个浪潮，这四轮的浪潮甚至可以回到1956年达特茅斯会之前，生物科学、脑科学的发展，神经突触，信号传递，我们就知道原来神人的或者说动物的这个神经信号是这么释放的。我们搞了这个sign moy的这么一个神经网络出来，感知机出来。
	大语言模型其实也有一个自己的发展脉络，在AI的这个大的范畴里面。大语言模型它本身是怎么发展的，又是如何技术演进的？为什么图灵奖的三巨头会变成三巨头？他们在整个深度学习和大语言模型发展里面是一个什么样的角色，这个是我们今天想要教给大家的。跟之前大家看AI发展的时候，那些巨头又不一样了。这三位还仍旧活跃在在一线，跟我们去了解什么图灵、香龙、马文不一样，我们看看他们三位怎么回事。
	首先我们把整个语言模型可以分成这三个大的阶段，但你要分成四个也可以把预训练模型和大语言模型，或者说把这个基于transformer的和未来的，或者说更大规模的都可以。但我觉得现在用transformer来把它整体框进来，没有太大问题。因为大部分的现在大语言模型仍然是基于transformer的这个网络架构在做，但是前面两个是毋庸置疑可以划分清楚的，一个叫做统计语言模型，一个叫神经网络的这个语言模型。接下来可能这个重点会放在基于transformer的这个大语言模型是怎么回事，里面就会提到很重要的一些概念，就大家都在讲的这个注意力机制attention，然后包括transformer这篇论文叫做attention is oil need，也在提attention。那么attention是什么？我们要讲清楚，为什么要attention也要讲清楚。
	接下来有了transformer这个网络架构，google发了这个网络架构。Google是非常擅长创新的，他有这个创新的企业文化和土壤。但他自己没有把这个GPT1搞出来，对吧？他就搞了bert，这个也有很多背后的大企业的原因，OpenAI搞了GPT，并且它的这个我叫做暴力美学，就是所谓的大力出奇迹，这个GPT系列的模型，怎么把这个暴力美学在大语言模型上用到极致，这个是我们今天想要分享给大家的一些知识和一些很有趣的观点。
	首先看看这几个阶段的对比，也是一个总览的图，方便大家去进一步的去做研究。首先统计语言模型就是我们刚刚看到的第一个阶段。它其实是非常早期，应该是在2000年前，就是一九他的最后的一个比较重要的成果，并且能够算是推荐阅读论文，是在96年的这篇最大熵的模型。但更早其实在76年的时候就有用统计学来做机器翻译的。大家想象一下翻译是什么样的一个工作，这个是我们开始了解语言模型的本质，就是语言到底是怎么回事？AI是怎么在学习语言的，就我们人是怎么学习语言的。
	其实就回到这样的一个本质问题，大家想象一下婴儿是怎么在学语言。我们很多讲小朋友学语言最早期的阶段是0到3岁。因为那个时候人的大脑发展发育是最快的，就是人的大脑那会儿是飞速发展，比后面学的这个速度要快得多。然后在一个好的语言环境里面，很多小婴儿他就自动学会说话了，就是你我们教这个小朋友说爸爸妈妈、爷爷奶奶的时候，很少会给他拉一个公式，或者让他做个完形填空，对吧？甜甜在旁边说说的多了，他好像就会说了。并且他知道在什么场景下应该叫谁爸爸，什么场景下应该叫谁妈妈。
	那这个是怎么回事呢？其实它背后是符合一些统计学规律的。简单来说就是你在他面前出现每天出现三次或者十次，然后你都跟他说爸爸爸爸爸爸，他就知道你他你其实是想让他叫你爸爸，或者说这样的场景里面，你是爸爸这两个字对应的一个生物，其实就这么一个模式，通过不断的提高这个频率和场景，让他能够理解。
	说到这个层面上，其实就跟香浓最早提出信息论和很早期的时候，大家都知道统计学在计算机领域里面是早期是非常牛逼的。包括现在有这个统计学的这个分支的人，还经常嘲讽神经网络这个分支的。就是说你们都没搞清楚这个里面发生了什么，可解释性一塌糊涂，还可能在这儿搞模型，但是人家有效果，对吧？那你的统计学，因为这个统计学本身需要足够的形式化，能够需要需要人类的专家知识，能够把它梳理出来做特征工程。因为它的天花板还是有很明显的，因为它受限于那个大佬本身的水平。但是神经网络数据驱动，靠算力直接就突破了人的上限。这也是为什么我们上节课有讲视觉和自然语言，人类的这个human performance都已经被计算机突破的原因。就是我用我质量不行，我用数量来替代，我靠算力来堆，然后我是能解决问题的。
	回到语言模型早期，其实统计语言模型就是基于分布和频率来预测单词。他做翻译就是说我有足够多的双文语料，然后我在双文语料里面我去标注好这段话，比如说这段中文对应的是这段英语，然后我刷到的这个语料足够多的时候，我就能够去统计分布频率了。我就知道这个词对应的是另一个词，中英是怎么互对的，但是它有限制对吧？因为简单的分布和频率，第一它需要特征工程。这个特征工程就是人得去干活，人得去做标记，人得做很多事情。第二它很难捕捉长期依赖性。这个问题一直到大语言模型出现才解决的，算是比较好啊。神经网络语言模型也没有解决这个长期依赖性问题。
	简单来说就是大家想象一下，就是你读金庸的小说，开篇讲了这个谁谁谁，然后又过了十章之后没讲，讲了另一条这个故事故事剧情线了，然后突然在第11章的时候又去回溯了第一章的那一位人。那他谁怎么样？你说一个语言模型怎么样去统计，你计算机也装不下，或者说你装得下它这种子代词关系其实是很远的，你也不知道。这个其实当然我举的有点夸张，可能没有十章那么长。可能在那个阶段你跨了几句话都很难能够捕捉到了。
	这个是统计语言模型阶段的一个特点，有一些推荐论文主要就是对应着里程碑成果的几篇论文，这个统计机器翻译最早的一篇76年的论文，这篇论文应该需要一定的访问权限才能够下载，它不在ACC b上面，因为太早了。然后后面两篇是在的，然后在的只要能够我下载到的论文，我都会放到平台上，大家应该就能够直接下载了。到时候看跟我记得上上一门课也可以，就把论文放到平台上。大家看回放录播课的一个地方，像这个n gram和这个最大熵这两篇论文都可以。
	然后第二个阶段叫做神经网络语言模型，其实简单来说就是把神经网络开始用到语言模型上了。神经网络或者说机器学习深度学习带给我们最大的价值，在上节课我们讲的就是数据驱动，通过算力去学习数据分布，来解决我们人的特征工程的瓶颈。这个是神经网络语言模型。
	大家也能看到这个bengel 2003年发布的这篇文章，neural probabilistic language model，就是神经网络的这个概率的语言模型，这篇文章其实是非常重要的一篇文章，我们待会儿也会深度的去解读。它第一能够去捕捉一些所谓的复杂的模式了，因为大家可以想象那个简单的统计，那那就是你有这个模板就有这个模板，能对上号我是学不到隐藏的这个含义的。这个有一定基础的同学应该能理解，就是是one hot encoding和后面我们学的这种词向量最大的一个区别。One hot它学不到这个更深层次的语义信息了。但是所有的这种，这里像早期的hinton的一篇文章，是我们图灵奖的另一位得者获得者，有一个叫做怎么样去学习distributed的representation，其实就是去学习不同语言之间的深层次的含义，这个我们待会也会去讲，相当于我能学习一定的语义了，那这个语义就能让我去捕捉一些复杂的模式。
	同时，他提的这个NNLM这篇文章也没有限制，是说你必须要用什么样的一个网络结构。在那篇文章里面本久也提到可以使用前馈神经网络，或者说类似的一些循环各种各样的神经网络，循环神经网络等等。都可以去用到这个神经网络语言模型里面。但是它也有它的局限性，它的局限性在哪儿呢？
	就是大家都知道RNN，就卷积神经网络是我们在视觉里面用的比较多的。那么循环神经网络这个recurrent neural network，2010年马可夫他是把这个RNN用到了语言模型上。RN更早的时候就被提出来了，像LSTM其实是97年就提出来了，只不过没有在语言模型当中去用而已。
	RNN它天然是一个。我们按照电路，大家学过这个中学电路就知道有串联和并联。那么INN是串联的一个网络模型，然后不好意思，这个猫叫声比较大，一个串联的模型，然后这个串联的网络模型天然带来一个缺陷，就是他要把前一个序列里面的这个神经元处理掉之后，才能去计算下一个。就像我们流水线，像这个电路的串联一样。所以它会带来一个计算效率的问题，就是它没法并行的去做计算。这个问题在早期的attention的这个网络里面也有，有attention的这个机制在里面也有提这个问题。
	因为它本身早期也是一个RNN的网络，那同时它还有有一个什么问题呢？就是INN我可以计算很长的就是我的这个序列当中的依赖关系。比起我单纯的去像模板的去统计，就这种统计语言模型它有优势。但是它它捕捉的这个依赖关系也不能特别长，就比如说统计语言模型可能他只能统计这个词的前面两三个词。那么神经网络的语言模型可能能够统计这个十个词或者这个20个词。但是你上一段的话可能我就捕捉不到了。为什么捕捉不到？就是因为RN本身会有这个梯度消失的问题，这个词离他太远了，没办法。
	像LSTM这样的一些长短期G网络，能够一定程度上解决这个梯度消失带来的依赖不做不到的问题。但也不不能本质上解决，但LSTM本身是非常好的一种网络结构，到现在为止也仍然被广泛使用。这个是第二类神经网络的语言模型。
	第三类是基于transformer的大语言模型，也是我们今天最热门的架构。它其实核心是通过一个叫做自注意力机制，就self attention，是在attention的基础上做的一个更通用的一种模式。自注意力机制改进了一个长距离依赖问题，就是我们提到的很长的距离，有这个问题，这个是为什么我们后面会去讲，简单来说就是关注重点。以前我给你十个词，十个词我都得记住，好像你说的的话都很重要。现在我知道你说的十个词里面可能只有两个词重要，那我可能就可以听50个词或者100个词，我只关注重要的那十个词或者20个词，这个是attention带给我们的价值。也有一定的并行化处理的效率，但不完全并行。因为我们知道这个循环神经网网络刚刚有提到，它是要前面算了才能算后面。
	Transformer的结构的好处是说它的decoder部分是它的几层decoder部分，可以跟encoder的最后一层直接相连，是有一定的并行化的，但也没有完全并行化，这也是很多人吐槽transformer架构，以及现在我们去部署一个训练好的基于transformer的大元模型推理成本高的原因。因为你生成的token，你用decoder去生成一个token的成本，它的长度，就你这个token生成的长度和它的算力成本是一个平方的关系。所以你生成的越长，其实部署这个大元模型的公司的成本越高。
	在整个基于transformer大语言模型的这个阶段，我认为有几篇论文是非常值得读的，也是很有代表性的。包括这个transformer本身的这篇论文，以及这个dirt就是google的这个bert这个语言模型和GPT1。当然GPT2、GPT3也可以去读一读，但GPT1是一定要去读的，这几篇论文是非常有价值的。然后也因为我们知道transformer的单元模型没有标注了预训练的阶段，那么如果你的训练数据本身有很多的偏见，那么它就会放大这个偏见。这个也是现在的一个热门的研究方向。
	为什么现在大语言模型说会有一些像人类类似的偏见，比如说什么，我们开玩笑，因为咱们应该观众里面没有黑皮肤的同学，就经常像几十年前在美国nig o这样的词是不能被讲的，而且到今天来说也是政治不正确的。这种词为什么在大语言模型里面会被学出来？其实就是因为训练数据里面充满了这样的偏见，然后这个偏见我也没法把它摘出来。从训练数据里他就会把这个数据分布学进去。学进去之后自然就有这样的一些偏见了。包括什么word to left，经典的man woman和king和queen之类的这些东西。然后包括整个整整个研究方向都会发现有很多的偏见。这个底层原因其实是因为大量的语料，人类产生的语料里面有这样的一些问题。同时它的计算资源消耗非常大，这个我们已经反复提过了。
	好，那么接下来就一个一个来看，怎么怎么从这个统计语言模型一步到了这个大语言模型一步一步过来的，统计语言模型这个我们会很简单的给他讲清楚，整个统计语言模型其实是非常早期，那会儿计算机也不强。大家可以想象统计语言模型对应着它的研究时期。在国内来看就是刚刚恢复高考，那会儿就是这个阶段。所以没有什么算力的，其实也没有多少数据积累，都是一些经典的数学家和统计学家们在做研究。那他要怎么把这个语言给用计算机表达出来，当时其实都是以概率的方式为主。比如说我们有一段话叫做统计语言模型是什么？这么一句话，它是中文的，然后我们要统计这样一句话，在整个中文的知识体系里，或者说整个中文互联网，出现这句话的概率，应该怎么样去给它形式化定义呢？
	那会儿其实非常简单，我们先做一个分词，假设就是统计语言模型是什么，分成了123455个单词，那它就对应着我们有一个句子叫S，这个S就是统计今年模型是什么？有这个几个词，分别是这个W一对应的统计，W2对应的语言，W3对应的模型，一直到这个WLW这个L对应的是什么这么一个概率。这个概率概率模型其实就是最早期的统计语言模型。所以说统计语言模型首先它是一个概率模型，它被设计出来是用来描述一个字符串，它的一个概率分布。不好意思，我去把我的猫关到房间里了，太吵。
	好，所以统计语言模型的核心它是一个概率模型，是用统计学的方法来统计一个句子在一个大的范围内出现的概率。大家都知道什么是贝叶斯的公司，对吧？贝叶斯公司，贝叶斯说说这个词真难受，贝叶斯公司公式转变为这样的一个条件概率。因为我们知道你去统计这段话出现的频率，这段话可能就没怎么出现过，对吧？然后你统计他可能最后的概率都是0.000。因为整个中文的知识体系是非常大的，那么你如果去统计完整这个句子的概率，几乎就全部都是接近于零了。那么条件概率是用来解决它的一个法宝，所以通常我们用贝叶斯的公式来转变它，变成一个PS等于这样的一个的概率来做计算。就是当出现这个W2的时候，W一出现的概率是多少，然后这么乘起来就等于上面的这个公式，大家如果连这个都不知道，需要去查一查什么是公司了，有了这个东西之后就好好玩了。
	就是怎么样让大家理解它的本质呢？一个所有人都做过的东西叫完形填空，对吧？之前的课程里面也有提到过完形填空，就是人是怎么学英语的。我不知道完形填空是不是一个学英语的好的手段，但至少完形填空这种学习英语的形式，是特别像这个统计语言模型的这个形式的。我们都知道完形填空在干嘛，就是我们把一篇完整的文章掏出很多空，比如说这里掏了应该有15个空，没比更多，20个空这里应该掏了都没解完。
	某一年好像是19年的某个高考题，我找到的。他是怎么做这个题呢？大家都懂对吧？就是找到一个空，比如说这个36号这个空，36题这里到底应该填submarket ending keeping还是preventing，有四个选项可以让你填这个事儿就跟统计语言模型极其的像。假设你现在正在做这道题，你说这个地方应该填什么？其实这四个东西就是概率，对吧？就选A的概率是多少，选B的概率是多少，选C的概率是多少，选D的概率是多少。
	学习好的同学为什么能填对呢？因为人家的那个概率模型学的好啊，他知道那个地方应该是什么。那么学习差的同学可能他压根就没学过，他都不知道这个英文的这个概率分布是怎么样的。他在蒙，蒙的话就是25%，对吧？蒙蒙几回就一回。但如果他真的学会了，那么他是知道这个概率分布的，而且他这个条件概率他是能算得出来的，因为放在那儿更合理。
	只不过这个形式上是这么回事，在人的脑子里面可能不是这么简单的，不是单纯去统计了磁屏。但是是这个逻辑，就是当我的前面出现了for ten years，I wrote, 我写了十年这五个词的时候，那么此刻这个条件概率是多少，它就能用起来了，这个是统计语言模型的一个现实意义，在统计语言模型里面它的参数是什么呢？其实就是这些条件概率，我们在聊W是什么对吧？那么你说在统计语言模型阶段有没有W呢？有WW就是这些条件概率，但这些条件概率是直接统计出来的，它其实也不需要神经网络来学。
	那么通过我们把一堆的语料标注之后，给到我们的这个统计语言模型之后，其实这个语言模型学出来之后，它就有一个很大的或者说它有一个很重要的价值的。这个价值就是只要你给我一个句子，一个S我能给你一个就所有的这个条件概率都都有了之后，当然如果你你可以设置一些初始值，比如初始值是零，统计才会增加等等。然后我就可以给你一个句子它的一个概率，相当于说这句话靠不靠谱，说这句话符不符合这个语法，符不符合这个背景等等等等。这完全取决于你的语料是什么了，因为你的语料决定了这个条件概率。
	这个是早期的统计语言模型，就比如说这里的这个第一句话。I first started writing in the summer of nineteen nineteen eight。那么它这个地方我们可以把给套料写tipe，那这个时候可能比如说我们的这个语料非常的丰富。我们就知道可能98年的时候不一定会用这个typing，可能更多的是用的writing等等，就这么一个意思，然后它的条件概率就这么回事儿，但是我们刚刚知道两个问题，就是统计语言模型带来的。第一就是它的模型太稀疏了，因为首先统计语言模型大家看到这W是什么？是一个一个具体的words，一个具体的单词或者字，那这些字大家都知道有多少字，这个W就有多少个。然后它的这个W是不能合并同类项的，我打引号的合并同类项，所以这个模型里面的这个W会特别多，也就是这个L会特别大。因为可以排列组合，是一个很庞大的一个数字。
	知道GPT4的这个emlin模型的维度才1536维，我不知道大家知不知道在1500多位。但是如果你要把一本书，它的所有的W分词之后的W它可能都不止1536位，可能是几十万维度，或者说这个一万维度。因为它有1万个不同的W，有它的模型非常稀疏，参数空间非常大。这个是统计语言模型的最大的两个问题，也没有使得它成为一个广泛应用的模型。
	统计语言模型刚刚那个那个展示大家应该搞明白了。我们再来看一个很重要的，就是在统计语言模型阶段的一个重要的发展是什么？就是刚刚那个甚至都不能应用，因为它太复杂了，有一个有一个很大的问题就是它的前面的词太多了。就是你但凡哪怕一个完形填空，它都是几百个词，那几百个词你算不过来的。在这样的一个排列组合里面，大家可以自己去捋一下，你就知道这个参数量有多大了。
	有一个很重要的马可夫假设，包括马可夫链，整个马可夫在统计学里的地位是挺高的。马可夫假设是什么意思？其实它很简单，就是我假设一个词，它出现的概率只和它前面出现的一个或者有限的几个词有关。最大的区别就是我们看刚刚的那个条件概率是什么？是从我这句话的第一个词开始，一直到当前的前一个词，全部都要算算一遍。那么马尔可夫的假设就是说当前这个词只跟前面的K个词或者N个词有关系，到WI减K就可以了。那这个时候我的K的取值就可以做文章了。
	这里就衍生出了一个很有名的叫n gram的一个语法模型，这个语法模型大家应该在各种聊语言模型的时候都会听到。那这个n gram的N什么意思？其实N就是指我这个词，词跟前面的N个词有关系，就叫N个人。比如说我N等于一，那就是我这个词本身，就是我我说的每一个词之间都没关系，你不要去揣测我前面说了什么，有可能后面就会说什么。当N等于一的时候，其实就是等于我自己，其实就相当于P等于WI了，就等于我这个词自身，这个时候叫做uni gram，叫一元语法模型，那么这个时候就相当于我自己的这个概率直接相乘就好了，这没有条件概率，就无关。
	那么N也可以取2，可以取3，取任何数都可以，但通常不会取太大，不会超过。我在那个年代，资源有限，在当它取2或者取3的时候，就是这个by gram或者叫tride gram，那么它也可以对应的把这个值带进去，其实就跟前面的一个词相当于这里我还专门找了一个图，就是两个单词凑一起组成了一个条件概率的分布。然后这个是by gram，那么tree gram只有三个，像这里我们看到uni gram，它就是每一个都是单独的一个单词，this is a sentence。那比如说N等于2的时候，这个background就是this is is AA sentence有三组。比如说我是N等于三的这个tree gram，那就是this is a is a sentence就取三个，那么这个是这么一个逻辑，那么怎么样去算呢？
	就是我要怎么最终把它算出来，把条件概率最大自然估计带给我们的一个很大的帮助，就是把我们的这个条件概率去变成一个统计上的活，那么就能够去直接统计这些词出现的一个概率。那么在当时的这个class base的n gram models of natural language。九年这篇推荐论文里面，也是一个应该是扫描的这个手写体，或者扫描的这个印刷体，那个论文质量不高，就是打印的质量不高。但是简单来说就是当我们取这个uni gram background m和tree gram的时候，大家可以看到它的计算量是非常夸张的一个增长。所以你可以想象当你取到这个pana gram，pen gram就是N等于5的时候，那这个计算量是很难承受的。
	这个是咱们的这个统计语言模型，简单来说总结一下，统计语言模型两篇论文值得阅读，一个是最大自然估计最大熵模型。一个是这个n gram模型，都是在NLP这个领域上面非常有影响力的。在当时那个阶段的一些工作，然后n gram要感谢IBM沃森，大家还记得我们上节课有提到沃森这家公司在上个世纪末的时候还是做出了非常大的贡献的。IBM Watson提出来这个n gram这个模型到今天也仍然有用。因为n gram这个模型它的最大好处就是它就是一个统计。然后如果我们要去做一些离线的这个应用，离线的一些统计的时候，一旦我把条件概率确定之后，我去训练它，统计它的成本很高，因为W比较多。但是当我训练好之后，我只是去乘一下这个sentence的概率。其实它就是一个乘法运算，它的计算成本是很低的，所以它在一些特定场景里面仍然被广泛在应用。
	这个n gram OK这个是统计语言模型，它难以捕捉它的长期依赖性。我们刚刚讲到了N的增长，每增长一个数量级的增长是一个指数级的增长。然后他的训练本身需要比较复杂的一些特征工程，这个是统计语言模型阶段。
	那么神经网络语言模型，讲到神经网络语言模型，我们就提一提这个机器学习，这个也是上次直播的时候，我看有人在评论区去问机器学习与深度学习这是什么关系？简单来说，其实机器学习所有的这个learning，我们讲learning到底在learning什么，包括像这个机器学习，其实它都属于我们按真正学术圈的一些，就是不是AI圈，是这个更大范畴，计算机科学这个领域，或者说更general更通用的一种说法，都叫叫表示学习，叫叫representation learning，表示学习。这个表示就跟我们刚刚讲到的概率分布很像了，就是他在学习的是一个数据的表征，表示的一个特征，学习它的概率分布，学习这个数据本身它表达了一个什么样的含义。所以很多人说深度神经网络，深度学习最终学出来的拟合出来是一个函数F，这个F就是同样的数据分布，丢过来能给出你一个符合这个数据分布的Y，也是这个输出，这表示学习。
	那么机器学习是什么意思呢？其实机器学习是它的一部分，机器学习就是有一个机器，有一个计算机，有一个GPU，有一个CPU，用这么一个机器来学习这些表示的特征，这个是很早期的martian learning的概念，机器学习。但后来发现我考全都是机器在学，也没什么人在学了，因为以前还有人来做特征工程，对吧？现在全是march learning了，那好像讲march这里讲不清楚了，那现在我们才开始有分类桨深度学习，因为有深度神经网络。
	我记得是本酒还是hinton在2011年左右的时候发了一篇综述性的文章，讲的就是这个DNN，应该就叫swell DNN。可以去搜一下这篇文章，就讲这个DNA的综述，就讲深度神经网络。因为神经网络的发展非常久远了，卷积神经网络乐坤应该是90年代就有了，然后安也是9几年就有了，IOSTM也是，只是应用慢慢才应用起来，因为力增长起来才能用NN。
	有了深度神经网络之后，使用深度神经网络来学习数据的特征的这一类模型，被叫做深度学习，它当然是属于机器学习的一个小的分支了。因为它都在用算力和数据在学习，所以它属于机器学习。好，这个是从网络的层面上，就是从我们用了什么样的网络结构，neural active ture，用了这样的一个网络结构，我们叫深度学习。
	当然还有什么方法？就是从这个所谓的learning这个层面上去做分类，就是我用我刚用了一个特定的词叫网络，我用这个网络结构在学，我没有像以前的机器学习或者说经典的机器学习，用这个决策树、随机森林之类的，它没有，它的这个结构是稳定的，它的超参数也很少。但是我们从学习本身对于数据的要求来说。因为我们从这个学习的角度来说，是从输入里面学数据分布。
	那从这个学习的角度来讲，又会分为有监督和无监督的，这个是最常见的强化学习，都是最近10年火起来的，就阿尔法狗带起来的。那么有监督和无监督最大的区别是什么呢？简单的第一个最直观的分类就是有监督有标签，无监督没标签，这个是最通俗的一种说法。就是有监督需要人去给他打上一些label，打上一些标记。这个标记通常是跟你最终的用途是有直接关系的，就是跟你最终的任务是有直接关系的。就比如说我们的fine two，最后也需要有监督，一些特定的有监督的训练集来做这个SFT1样的。
	无监督更多的是说我可能由算法自己来找出它里面的一些特征，然后这个特征可能是比如说典型的无监督学习的方法，这个聚类的方法，分类的方法。他就说我们包括没有学习的方法，也有一些做分类的方法。但比如说我们一个分类或者聚类的方法，就是咱们有很多的特征，然后我们看到这个特征之后，我们把它分成了几类。然后这个类别墅可以是一个超参数。你去说这有一堆人，你把这堆人分成三类，或者你把这堆人分成两类，这个类是你去打的，然后通过你打这个类别标签，你打这个类别标签的数量，他能去通过算法帮你去做一个分类。
	做个最简单的例子，就是这里说的这个人人口分布按每十年为一个坎。为什么讲老龄化？那也是人先规定了多少岁以后算老龄了。然后把全中国的人或者全世界的人拉过来之后，看了一下年龄这个标签，然后用年龄给他砍成几类，这是一个分类，用性别也可以砍成几类。当然以前性别可以只砍成两类，现在可能要砍成很多类，具体几类我也不知道。然后就类似这个意思，那就是无监督的学习。
	那强化学习是什么呢？强化学习的特点不是在这个数据本身，就所有知道强化学习的同学应该都知道，强化学习最难的事情是对于这个环境需要去做定义。简单来说就是我要模拟一个环境，这个环境是真是我真实应用它的时候的这个环境。那为什么强化学习在游戏里面应用的非常快，就是因为游戏的这个环境本身就已经造好了，就是人造了这个游戏的环境。星际争霸，什么魔兽、dota等等，包括像这个吃鸡这个环境就是人造的。所以我很清楚这个环境里面发生的一切。
	但是为什么在现实生活当中用强化学习很难？因为这个世界不是人造的对吧？所以你不知道这个环境里面的这个变量到底有多少，就这么简单。
	那为什么强化学习在围棋里面运用的好呢？因为围棋这个环境足够纯粹，它是一个封闭式的环境，这个封闭式的环境里面环境确定了。第二个难的事情就是我一个特定的动作应该给我怎么样的一个奖励。就这个reward word和这个policy，就是给real words的这个policy这个策略，这两个是第二重要的。那么在围棋里面，因为有这么多的棋谱，所以我能设计一些策略，通过各种策略方法算出奖励。这个是强化学习的特点，这个是机器学习的分类对吧？那有了这三大类作为基础的铺垫和这个知识的结构之后，神经网络的这个语言模型干了些什么事儿呢？就是我们的图灵奖获得者本就在20年前发表的这篇论文，有非常大的深远的影响，是具体怎么干的，我觉得一个最大的一句话来讲，就是把语言模型从概率分布的统计变成了我们各种learning要干的事儿。
	就是目标函数的优化，这个应该是目标怎么去优化目标函数，这是所有的叉叉哪里都需要去解决的问题。因为它涉及到第一，你要找到目标函数，要设计一个目标函数。第二，函数当中有哪些模型参数。第三怎么样去优化它。这个是三个本质问题，那这三个本质问题整明白了，你的叉叉learning就能够搞好了。整个NNLM就是把语言模型这个客观的问题，用我们的基于学习的方法能够开始去做进一步的研究了。这样的话简单来说就是未来算力增长，数据增长，人只要还能够去迭代它的认知，我们的语言模型就会越做越好啊，这个是非常有奠基性的一个工作。
	那么怎么样变化的，我们可以看到我们简写一下刚刚的这个公式，我们把此刻当前的这个W变成一个条件概率。然后这个条件概率它的前文我们就不再写W1WW23了，我们就写一个上下文context w。因为我看刚刚还有同学在问，是不是只能跟上文有关系，能不能跟下文有关系？
	那当然也可以，所以我们写个上下文，context w，这个是之前的概率分布统的这么一种模式，我们把它变成目标函数优化之后，其实想变成右边这个形式。右边这个形式就是我刚刚说的三件套F是这个函数，也是我们用的神经。神经网络简单来说就是要学的这个玩意儿，然后它是一个整体。这个F包含了它的这个W模型的权重，这个西塔模型的权重W这个单词和这个contest w它的上下文，西塔是模型权重，W是这个word，这个跟我们之前的缩写with不太一样，这是单词。然后那么简单来说，NNLM是实现了这个模型F的一个首次的尝试，这个是我对它的一个评价，然后它的一个简写，在这个通用的一个写法，就把这个F展开的话，就是FI是第I个词，然后这个T减一直到T减N加1，可以写成右边这个函数的形式，这个鸡是一个神经网络，就是我们可以用的神经网络。比如说我们用一个简单的全连接网络，或者我们用一个INN都可以，这个G是一个可以替被替代掉的一个神经网络。然后这个I是指第二个词，然后这个CWT减1，或者说CI是指这个第I个词的特征向量，也就是我们词向量第一次被用到语言模型里，这个也是一个非常重要的贡献。就是他把概率分布统计变成了一个基于数据驱动的一个目标函数优化的一个事情。
	第二他把简单的基于统计单词变成了基于词向量来做learning。这两个是他非常重要的贡献，那这两个贡献我们就看一看它的模型训练方法就好了，不用深究，就是造了一个最大似然估计，但是因为太太难算了，所以对它的这个对数去做运算。这边的这个R西塔是它的这个正则画像如果训练过模型就知道这个正则化，我们在特色flow的视频课里讲过，然后这个地方是对它模型训练过程当中去优化这个模型参数，在做优化，做梯度下降对吧？这个模型参数我们在这儿先简单写一下，就是这个C和这个W，那么梯度下降，大家如果不知道的这幅图取自于我这个TensorFlow那个课程，也是他应该最早是在吴恩达的这个machine learning的公开课里也用过这张图，就是用马用这个meta LAB画的一个梯度下降的图。其实整个过程，所有的这种神经网络就是基于这个梯度下降在优化我们的这个模型参数。
	模型参数现在先写到这儿，下一页我们看看它具体是怎么玩的，绝对不是一个Y等于WX这么简单。首先NLM20年前的这篇神经网络语言模型的论文，他写的非常细。他用这个log的probabilities去代表每一个输出的Y，最终的我要预测的这个单词是什么，它的形式化的写法其实是下面讲的对，里面有很多的模型参数，有这个B小B大的这个W然后U，还有这个DH。
	当然X是我们的输入，Y是我们的这个输出，具体是什么概念呢？其实我们先把这个X展开看啊，就是这个X其实它是一个我们在这幅图里面能看到的，就是这里有这个图的最下面输入的这么一个X，然后它会有去做一个index去表示每一个X。因为它本身在神经网络里面用的不再是这个单词本身，而是一个向量。然后这个向量其实是能够被表达出来的。然后这个句子本身它又由多个单词组成。所以你看这里的这个X其实它是把每一个位置上的单词的这个vector组合在一起，变成了这样的一句话。然后这一堆单词BWUDH是什么意思？其实对应的这幅图来看就并不复杂了。
	然后这也是论文当中的一个原文，我把它call过来让大家有一个理解。其实读论文也没有这么难。首先这个H是什么？H这个大家如果看的多的话，H通常表示的是这个隐藏层，就神经网络隐藏层的这个units，隐藏层的神经元个数，就我们的这个小H然后M是我们的每个单词的feature的数量，就这个特征的数量。
	然后这里涉及到一个初始化的一个过程，就是我们怎么样把这个NLM的初始值设计好啊。简单来说其实就是我们看到这里有一个单词，每一个下面的小方块都是一个单词和它对应的这个向量。然后这个向量也可以直接连到最后的这个单词softmax这边。但是我们知道在去学习这个数据的时候，有的这个X是会直接接着你这个Y的那就相当于它的训练数据里面出现了前面是X一后面是Y但是还有一些它是没有出现，它从来没有被出现过。那这个时候就直接把这个matrix w设置为零就好了，就是它没有直连的这么一个状态，它的这个词向量就设置为零就好了。
	然后还有一些需要去调的参数，包括这个输出层的偏置，就我们在讲这个基础课Y的Y等于WX加B，这就是一个经典的，我们做这个逻辑斯谛回归或者线性回归都有的一个函数。那么我们只看前面这个公式的话，就是Y等于B加WX那这个B就是它最终输出的这个偏置，然后这个小弟是他隐藏成的这个偏置，然后因为它中间这一层有一个隐藏层，这个隐藏层需要有一个偏置，然后这个大H是它隐藏层的权重。所以我们拆解来看，前面这一部分Y等于B加WX，其实最终的这个输出的或者说直连的这么一个典型的一个模型设置。然后后边这部分其实你可以直接把tangent这一层给它设置为这个。你可以把它像递归一样的，把它变成内部的隐藏层的一个偏置和它的一个权重。这么去理解，应该就很好理解了。然后这个U是隐藏层到output，就最终输出层的一个权重值。所以其实整体来看就套娃套了一层，把里面整个套到一起，又变成了外面这样的一个结构。
	是的，然后这里你看完之后，可能这个参数很多，对吧？但是不用太纠结。因为这些东西在最后的大元模型阶段都变成了一个极小的一个小模块了。但它里面其实就长成这样的一个结构，然后通过这个NNLM，其实它需要训练的参数非常多，这个是第一个认知。第二个它引入了什么呢？它不再通过word本身来做训练了，而是让这些不同的word之间可以share，share这个参数就是这个metrics c，share这些参数简单来说就是假设我有1000万个words，但是可能我最终这个矩阵C它只是一个两千维的一个矩阵，不再是one hot的编码。这个我们待会讲one hot。
	然后这个是我们刚刚看到的这个迭代迭代好啊，有个同学问需要有隐藏层来连接，为什么还有直连？这个是非常常见的一种网络结构设计，read net也有这样类似的设计，然后我们再讲一下所谓的matrix c为什么能够share parameters across worlds？就是为什么在不同的单词之前能够share共享这个权重，为什么？这个就涉及到一个很有意思的概念，我尽量用一些普通人都能听懂的方法来教会大家。就是有一个很重要的表示学习的编码方式，叫做one hot representation，或者叫one hot encoding。这个东西就跟大家背单词一样。现在可能大家不这么背了，所有人应该都看过右上角这本书，对吧？
	因为在应该在去年以前还是在今年以前，中国的这个全日制大学生毕业的话，必须要过英语四级。我印象当中是有这个要求的。如果你是个大学生，你得过四级的考试你才能毕业，不然你拿不到证书。
	好像是这么回事，应该大家都看过这本书，我理解。那么什么呢？就是我们知道什么？就是单词表是长什么样的。单词表大家想象一下单词表包括我们这个听写单词的时候，就是你这本书有多少个单词。那么每个单词都是一个单独的一个标题也好，或者单独的一列也好，它是摆在那儿的那当我们要去记录一个四级词汇，这本书有多少个单词的时候，或者说去记录它，要把做到计算机里的时候，其实就是如果我有这个四级词汇有5000个单词，那么你就需要有一个长度为5000的这么一个向量。这个向量里面，就放的是每一个单词。
	因为每个单词都不一样，所以你需要用一来表示，就像记这个ID或者记位置一样。比如说这个罗马，就记在第一号位置，巴黎就记在第二号位置，意大利和法国类似的就记到这样的一个位置。如果你有1万个单词，那么这个长度就是1万，这个叫做one hot的一个，那么这个概念我相信大家应该理解了，对吧？就是你单词越多，你的这个长度就越长。然后你现在看到的只是一个单词。那假设我们四级词汇出了一个四级短语，对吧？
	那可能就不是几千个单词了，它可能变成几十万甚至更长的一个规模，那对于我们的开销是非常大的，因为它的长度是直接增加了非常多的数量级。这种one hot repenting它的好处是一定给你记下来，坏处就是说它消耗的空间非常大，非常稀疏。因为整个向量里面只有一个只有一个维度，只有一个数字是一，这个就是one hot的那个one的意思，只有一个是热激活的。
	并且带来的第二个坏处是什么呢？就是如果我们想要去做向量间的一些计算，比如说我们看到这个经典的world to work里面，这个man和这就男人、女人啊，国王和皇后之间，它们的这个差值关系是能有一些语义的。这个就简单来说，就向量去做运算的时候，是能推测出一些语义关系的，那这个其实在one hot里面是无法实现的。大家去简单回想一下为什么无法实现，因为他们都在不同的维度上，对吧？他们不太会出现在能做加减。因为他们自己的那个维度上只有他自己是一，一做加减之后，one hot向量就不成立了，所以one hot的这个向量是没法去做语义计算的。这个是带来的一个巨大的问题，并且很浪费。
	其实1986年的时候，hinton就是我们图灵奖的得主，也是最近很热的伊利亚的博士导师，也是alex net的博士导师。陈老师86年的时候就已经发表了一篇论文，叫做learning distributed representations of concepts。简单来说就是为什么叫distributed representation？其实跟one hot一起来理解就非常好了。就是我们有一个单词表，每个单词都是单独放在那儿的，然后只有他自己那一列是一。那distributed的就是指我现在有一个向量。这个向量我的每每一个单词，它不是单独在一个维度上的，而是分开的分散在不同的这个维度上的，它在一个高维向量空间里面不同的位置，然后甚至大家的这个不同的维度上，是能去做加减的。
	就像我们现在左边看到这幅图一样，有单词的这个in bedding，当然也可以去做降维。那么不做降维的话，这个就在很高的维度，你看不出来，就像人不能理解三维以上的维度一样。但是我做完降维之后，比如说这个是七维的，我降到二维你就能看出来这个关系。然后这里这个man和这个woman，包括queen和king的关系在二维也就看得很清楚了。你也可以把它降到三维，三维也能看得很清楚，这个是distributed repented带来的一个巨大价值，就对应着one hot的不好的两个点，能做语义计算了，同时降维了，这个其实就把这个词变成了一个可以去做运算的一个状态。
	同时也为后来的基于深度学习的这种representation提供了非常好的一个发展思路，在NNLM里面也用了这个思路，就是我们刚刚看到的这个matrix c，他把所有的单词都放到了一个矩阵X矩阵C里面。然后这个矩阵C就能够表示出我们这里的这个矩阵了。这里比如说有七维，就有一个七维的矩阵表示了这些单词，然后最后可以降维。那么在NLM里面那个矩阵C大家也可以去看，它有取不同的值去表达不同的不同规模的语义。然后这是work wake的一个经典的一个历史。然后我们看到NNLM2003年发表之后，其实2013年的时候，word to vex发表了，然后直接推进了很多的工作，就是这个直降量的这个工具。然后14年紧接着发了这个global vector，然后这俩其实是对我们后续的整个大语言模型的发展起到非常重要的一个作用。然后work well也是一个非常好用的工具。
	最后再提一下这个安N，就是我们刚刚提到一个语言模型，一定要捕获咱们学习的这个训练数据，也是我们的自然语言里面很重要的特征。一个叫做语法的特性，一个叫做语义的特性。为什么在大语言模型出来之前，很多人都讲这个NLP，最大的问题在语义理解，就是因为它语理解不了。那会儿的大语言模型出来之前，即使是像NNLM这样的模型，他也没法去把语义理解的很好啊，他只能把一些语法特性学得很好，就是一些偏就是比较少见的一些语法用法，它能理解到位。但是你说他能把你的语义像今天的GPT1样，给你整的特别明白不行，但是他能去有一些针对性的场景，能做生成任务，但是理解不行，生成就在于，因为生成就是人类的本质，是复读机，只要我能把任务描述清楚，他一定能把他学过的各种套路用出来。所以那会儿我们能看到在七八年前、五六年前的时候，各种基于LSTM的这种诗歌生成，小说生成，包括这个小小兵都在做类似的事情。
	但语义理解有问题，然后与理解有问题的两个原因，我们从网络结构上能看到一些比较明显的特点。第一个就是典型的IN网络，这个是INN网络用到自然语言处理上面。当时的一篇论文，我们也在开头有写他的论文标题，大家可以去有兴趣读一读。那么这个IN的结构就导致这个隐藏层。对于比如说这个HT加1，假设这里已经有十几个20个单词了，那么通过这个梯度去做这个梯度下降的时候，其实如果我们的精度，比如说只有16位的精度或者32位的精度，一一正相乘之后，到这儿可能都已经反馈不过来了。所以我们这个X0位置对应的这些隐藏层的参数就无法被更新。
	这个是第一个梯度消失带来的长距离依赖的问题，第二个就是因为就算我的算力队的比较多了，但是因为它没法做并行，就他时间要等很久，那么这个时间等很久之后，就导致我无法去训练一个长距离非常长的这么一个网络出来。并且就算我做了这样的算力，刚刚说的网络结构上的问题也会导致他没法去做更新，除非我在用高精度，但高精度这个成本就太大了，这个是RNN带来的一些问题。像LSTM一定程度上解决了这个网络结构上的问题，就是我遗忘的问题，但是还是没法去做并行。
	所以核心来说就两个问题，长距离依赖计算效率，那么推荐给大家的文章，除了刚刚提到的，还有就是我们重点看到的这个NNLM，就本久的这篇文章和world web这篇文章。这俩文章是非常值得一看的，而且写的也不长，很很值得研究。那么我们终于到这个基于transformer的大语言模型了。其实一路过来，大家发现从统计分布到目标函数的优化，目标函数的优化就离我们开始有一些近了。我们知道要用数据来学习，用机器来用队算力的方式，用我们的数量去换取高质量的一个结果。然后我们在transformer这个阶段，其实把这件事儿做到了极致。我先留五个问题的这个机会大家提一提，我正好接杯水。我们接着开始讲这个基于transformer的大型模型。
	有个同学问，每个词在向量空间当中的位置是事先人为定义好的，然后在不同的问题场景拿来用的吗？这个不是的，这个是学出来的，就是这个embedding的模型也是需要训练的，这个同学问的挺好的，我们看到后面的微调技术里面也有在embeds模型里面去做文章的。然后work wake有现成的向量表示结果可用吗？他是这样的同学，首先我们现在的大语言模型，这个大语言模型对应的invading模型，我们知道他们都属于embedding，word wear也属于ebdon了，现在都叫这个词了。它都是配套的，跟它的训练集和它最终要用的这个内容。因为你如果不配套，它的向量空间不一样，你没法把这个embedding的vector变成一个对应的自然语言。然后如果你要用现成的，也有就是有一些经典的数据集上面，然后用word file算出来的一些embedding的向量，这个是有的。在github上面有大量这样的一些库，包括google自己也开源了这个库，然后CPU就能跑。
	还有个同学问这个16和32精度的问题，这个是一个典型的计算机的一个知识。就是我们学计算机的这个数据表示的时候，什么16位浮点数、32位浮点数、64位浮点数，这些不同精度的浮点数按照ARROE的标准，它的有效位数是不一样的。就有效数字小数点后多少位是不一样的。虽然它已经有32位的浮点数了，但是他可能只能表示小数点后几十位是它的有效精度。那么我们的网络的层数或者RNN的这个序列长度异常之后，你可以想象一下这个模型权重的迭代。这个梯度下降是0.1乘0.1，那你是不是乘个十个就变成小数点后这个十个零了。但是实际情况可能是0.01乘上0.02乘上0.06，那么你这个可能就十几层就已经达到了这个浮点数的精度上限了，那么梯度就消失了，这是梯度消失的本质原因。
	然后我再看看embedding跟词表的关系是什么，这个同学问的很好啊，就是one hot的这个编码也是一种embeds ging。Embedding是一种技术，首先然后evidence这个技术理论上来说，它就是有两个特点。一个特点是它能够降维，所以one hot勉强算是一种in padding。但是很勉强，因为他其实没有做降维，但他把自然语言变成了一个向量第二个就是evading希望，他就是这个技术被造出来的一个价值，就是既能降维还能保持原来的语义。是一个好的embedding。就比如说我们经常用到的一些world rect，把几十万字的小说变成了一个512维的一个向量，比如说我们在OpenAI用到的embedding的API，比如说tex ADA002这么一个embedding模型，把整个全世界的语言变成了1536维的一个向量，这些都是好的evading模型。
	NNLNNLM作为transformer的一个小部件是在哪里？这个同学可能理解的这个有歧义，或者说我表达的有歧义，就是这个小部件确实是要打引号的。因为我们这个小部件的背景说这个词的背景是说，一开始我们讲Y等于WX的通用的这个说法一个模型就是Y等于WX，然后这个同学问W如果不调整的话要调什么？那么我们在NNLM里面有给大家看到要调的很多。除了跟X直接去发生关系的各种隐藏层或者神经网络层的这个参数以外，我们还会有什么呢？还会有一些偏执、BIOS，当然还会有一些其他的一些，包括正则画像，都是它的一些参数。这些东西看起来现在看起来这么复杂，但是其实你把它放到这个注意力机制里面，它也不算复杂了，所以是这个意思，不是说它跟transformer有直接关系，而是说神经网络的这种设计方式是非常常见的啊不要简单理解为一个线性方程。
	这个同学问全世界的语言装进了这个巴拉巴拉。是的，就是这个意思。你现在把全世界的语言交给GPT，它都能够把它变成一个向量。至于准不准那是另一回事，但至少在西方语言世界体系里面还是准的。中文大部分他也能够理解你的意思，对吧？所以他做的还挺好的。
	好，那我们就继续开始了。还有1个小时时间我们讲这个transformer了，这个就是一个更硬的部分，会有一些数学的东西，希望大家能够就算这节课上没有听明白，下来也得再花点功夫。就是我们基于transformer的大型模型，还是回到这个界面上，我们讲一讲这个很厉害的汾酒老爷子，很厉害。他们在NNLM2003年的这篇神经网络语言模型发表之后，又过了11年，带着他的高徒叫banana，这位应该是现在加拿大的mac林，还是叫什么加拿大的一个大学里面在做教授，现在在研究这个自然语言方面的一些研究，叫bad now，跟他的这位博士生一起发表了很著名的这篇文章。这篇文章其实现在就是大家称之为注意力机制。这篇文章叫做neural machine translation by jointly learning to align and translates，这篇文章就我们现在图里看到的很厉害。
	2014年，一举把大家停滞的神经网络语言模型的研究达到了一个新的高度。这个是这篇文章的一个里程碑的。这篇文章过了三年之后，谷歌的现在叫做谷歌八君子是吧？跟当年的搞芯片那会儿很像，当年的硅谷的那那八君子，其中有几个就参加过达特茅斯会议的。然后17年的这篇attention is a列的，其实这个attention指的就是bin，就14年的这个attention。不过当时他在标题里面没有写这个attention，在内容里面有。那么为什么要用attention？当然是要解决问题，对吧？我们刚刚看到了神经网络语言模型有什么问题，两个问题，效率问题，长依赖问题。第一个要解决的就是这个编码器解码器，这个叫sequence to sequence或者叫encoder decoder这个网络架构的一些问题，导致信息损失和这个对齐的问题，这个是这篇文章要解决的第一个问题，也就是我们现在经常讲的alia对齐，到底要怎么对齐？
	那会儿的自然语言处理最重要的任务就是翻译，自然语言那会儿还没有把翻译这件事情搞得很好啊。你看那会儿还有什么各种翻译软件，你都知道吗？有道翻译、google translate. 
	就因为翻译还是一个难的事儿，还能支撑商业，所以翻译对于自然语言来说，那会儿是一个很难的事情，现在不行了，现在翻译没那么难了。现在有了大模型之后，我们几乎可以说翻译这个问题被人类解决了。基本上所以那会儿所有的类似的NLP的研究，语言模型的研究，都是在各种翻译的benchmark上面去做比较。这个是腾讯选要解决的第一个问题。
	第二个就是说以前我们都知道因为他没法因为精度，因为这个梯度消失的问题，他没法去访问前面的所有的依赖。就比如说你这个序列长度是1万，或者说太夸张了，100万或者1000，那你最后的这个位置的这个序列这个值要去访问开头的那个很难。第一可能是访问它没有价值，你存不下来，精度消失了。第二个就是说你存下来可能也用不好，就各种原因。
	那么注意力要解决什么问题呢？我们开始举个例子了，抓重点，就是你全部都丢给他，但他知道重点是什么，它可以直连的，把这个重点连过去，这个是attention要解决的核心问题。但是这个注意力怎么样去抓重点，本身就是attention这个注意力机制的题眼所在。就是他训练了一个网络来抓重点，然后因为他训练了一个网络来抓重点，所以这个注意力去权重的这个学习是自动的，因为这个网络本身就在学这个权重。然后他做的这个事儿是在一个机器翻译的问题上，机器翻译的这个问题使用的这个结构就是一个encoder。Decoder就2个RNN然后对齐的这么一个结构，也是我们常见的sequence to sequence这个结构。所以它要捕捉它的相关性，同时能够构建一个新的新概念，叫上下文向量，是我们的context vector，然后能够让我们的解码器全面的去访问这个输入序列，这个是它具体实现上的一个手段了。而同时能够提高一些模型性能，这个是整个注意力机制带来的问题。
	我们刚刚提到的这个encoder decoder的架构就长这样子的，就在没有注意力网络之前，这个encoder decoder的架构是上面就不多，我们可以看一眼上半部分的encoding stage就是它的编码器，是一个典型的IN网络。这有一个法语单词，有一个INN的一个神经元，隐藏成状态，给到下一个单词的这个隐藏层的这个hidden units，然后去做一个合并的运算。在这么这个击鼓传花式的往下传传完之后整体把整个法语的这段句这个句子一起存到一个hidden state 3号里面，这里面存了这一段话，那你就知道如果这个date state 3要是没整好，那么这段话就直接就拜拜了。就效果不好对吧？所以这个IN很很考验训练的水平，如果这个中间的黑的没搞好，这个decoder拿到的就是一个坏结果。就相当于你们在玩游戏，在这个你画我猜。我不知道大家看过这个综艺节目王牌对王牌没有，这个你画我猜里面就是经常很搞笑的。一开始的这段话传到最后就完全就啼笑皆非的一个结果。那么RN的风险就在这儿，所以要解决这个风险就是让最后的人去看第一个人说了什么，也是大家每次在节目里耍赖的时候会玩的一种手段，这注意力机制的核心逻辑就干这点。
	其实我们接着回到这个学术的说法上来说，就是我有一个hidden state 3，然后decoding会把它解码出来，然后在我解码器的这个神经元里逐步把它还原到对应的这个英语单词。这个attention network大家就看到了，我们之前无法去传递的这个hidden state一也被放到这儿来了。相当于解码器能够看看一遍所有的这个编码器里面的这个状态，这是attention的一个核心架构，那具体来看它怎么样实现的呢？这个稍微有点公式，跟刚刚一样，我们快速的去理解一下。首先这幅图怎么看，我们先不看左边的这个表，这幅图要看的话，其实就是把刚刚我们看到encoder decoder的这个架构倒过来，左边是before，右边是after，就是右边是有attention的网络，左边是没有然后这里的X和Y不变，X还是输入，Y是输出，H是输入。就是我们的编码器encoding stage，编码器里面的隐藏层神经元，S是我们解码器里面的神经元。那这些都是原来的sequence to sequence网络要训练的模型参数不变。那么有了attention之后，就是在这俩之间加了一个新的网络，这个也是非常常见的神经网络的搞法。包括我们做微调的时候，大元模型不变，外面再加一个新的网络prom tuning，这个新的网络就是用来学习怎么样说好听的prompt给大模型听，让它能够按我的心里办事儿，其实就这么套路。
	Attention其实也是一样，植入一个新的attention的network，这个network干什么呢？这attention模型，attention的这个model要做的事情就是首先咱们这有一个新的模型了，那这个新的模型就对应着一堆新的模型权重。模型我们假设这里有一个矩阵，大家能看到这个矩阵里面有一堆的阿尔法，这个阿尔法它连接的是我们的输入和输出的隐藏层，所以这个矩阵其实是转置了一下。就大家看我现在鼠标这个矩阵其实是转置了一下，会让大家看着有点别扭。它的H是输入层的神经元，输入的这个隐藏层的神经元，S是输出的隐藏层的神经元。然后这个矩阵其实就来自于左边的这个网络，这个网络其实就是加到了原来的这个sequence to sequence里面的一个网络。
	好，这个attention加进去之后的一个新的产物是什么？其实我们看到右边这个有attention model的机器翻译的这种序列到序列的模型，它的不同就在于之前都一样，这条线从XX2X3到Y1Y2，然后Y一给这个S2，这些也都一样。但是这里的S二多了一条线，相当于我的attention model或者我的注意力机制的这个注意力网络多了一个输入给它。这个输入是什么呢？是在这里的这个CA2，这个C2是阿尔法21H1，阿尔法22H2，阿尔法23H3，什么意思？就是说大家能看到这个阿尔法都是2，就前面这个下标都是二是指这里是输出，阿尔法二是输出的第二号位置。然后这个阿尔法212223，这个后面的下标就是指前面我输入的123，这么说应该就好了解了，所以它对应的也是前面输入的H1、H2和H3，所以是这么一个意思，所以它简单来说就是这里高亮的这一部分S2对应着输入的H1、H2、H三分别有一个权重。然后H1、H2、H3其实就代表的是我输入的X1、X2、X3。
	这个大家能理解了对吧？因为我们刚才讲神经网络语言模型的时候就讲过了，神经网络能够把我的这个单词变成一个词向量，自然也能把我这个单词变成我神经元里面的一个权重。好，那么这个阿尔法就是我哪个权重高，我就把它的阿尔法调高一点。
	反正我只要保证我的阿尔法2加起来等于一就好了，或者说我做规划就好了。那么这个C2其实就干这么个事儿，这个C本身就是我的上下文向量，我的context vector。我这里的一个阿尔法的矩阵就能造出一个C的矩阵，这个context的矩阵就能为我的整个sequence to sequence的网络服务，所以我不知道这个解释够不够清楚了，就对应在这里。所以我有一个C2，我就能我枚举我的所有的X和所有的Y，就可以去枚举他们。这个I等于一到TT是序列长度，然后就可以去把上下文的向量给算出来。
	那么这里通过一个上下文的向量context vector，使得我们解决了一个什么老大难问题。那就是我们的每一个输出我们每一个输出层，我们的或者说我们每一个解码器decoder这边的解码器的序列上面的这些神经元都能够跨过。原来有一个代理，对吧？就是最后一个H的代理直接去访问输入的每一个隐藏层的变量，相当于我们能直接对话了。我不会再像以前这个你画我猜一样，我只能看见最后一个人比划了什么，我是能看见前面所有人比划的内容，这个是非常关键的，那这个解码器就可以改写成一个三元组，既有原来的S它的上一个S1，这里的SJ假设把它当成S2，那么SJ减一就是S1。S一它从原来的只能有它的上一个S和上一个Y，同时还增加了一个新的CJ，这个CJ就是它的这个context vector对应的这个向量，所以这个是我们刚刚讲到的这个注意力机制，没这么复杂对吧？其实就是让我们的解码层，让我们的输出层能够跟输入编码层直连，然后有一个注意力的权重，这个注意力权重是学出来的那具体怎么学呢？这里就会有一个这里是它的每一个阿尔法，叫做它的attention位置，捕捉的就是H和S之间的一个关联性。
	然后它的这个P可以用各种各样的激活，包括我们刚刚提到的这个sigmoid，然后我们把这个SJ减一和HI整体，我们把它叫做一个attention model，我们看到左边这幅图叫做一个attention model。这是一个模型，很通俗很通用的一种说法，什么东西都可以叫模型。那我们给它取一个具体的名字，就是这里的这个红框框框的这个内容，我们叫什么呢？我们叫alignment function，叫做对齐的这个函数alignment function。那他要怎么样去学习这个alignment function，也就是所谓的注意力模型的这个权重呢？啊，其实这个过程也很简单，就是alliant function。其实它就是在捕捉我们的输入，整个输入叫一个query。然后这个输入里面有很多权重不一样，每个单词对应的隐藏层的神经元它的权重不一样，这里有一些高权重的或者说我们认为重要的叫做key free references，就是这个key关键的references。
	然后我们最终为了把这个计算，因为最后可能这个阿尔法H，这个西格玛求出来的这个值，它可能不是一个规划的值，尤其是在高维的时候，我们可以用soft max来做这些规划。所以整体我们可以把这个注意力机制，注意力模型简写成一个三元组，看起来很复杂对吧？但是大家课后或者现在在脑子里再过一过也没那么复杂。
	它的这个QKV是核心，Q就是它的query key，就是它的输入的这些关键的这些有有权重值高的这些输入key。然后这个V然后它的这个A就是我们这里的alignment function，然后这里的P是softmax，为了去做做这个规划，然后乘上这个V，就我们输入的这里的值，就可以组合出一个这样的注意力模型，就我们这里这一个红框框里的内容，大家自己去推导一下，就会发现这个逻辑其实没那么复杂。这是时间关系，我们就不浪费大家时间了。
	然后这个attention的mechanism，这个注意力机制，其实核心就是这么一个公式，这个公式QQV这里我们要整明白，就这俩人，bbn a和这个benjy，这个attention也有的地方也叫Better attention。然后这个QQV我们都知道，这个alignment function是这个红框框。然后这个alignment function它是一个高维的一个模型。那这个模型我们是不是也可以做文章，我们现在跳出来看，我们不再是简单的理解这么一个向量的一个sigma加法权重，这么一个加权平均了。这个A本身的function本身其实是有很多文章可做的，事实上也是，我们看到有一篇应该是中枢性的文章，关于注意力机制的，我在右下角也有贴，这里叫做attentive survey of attention models，就注意力模型的一个综述。
	就关于这个alignment function本身，是可以去做。比如说这里做这个similarity，做点击，做这个scale的这个电机，然后去做BIOS general等等等等，包括做这个拼接。所有的这些操作其实都是为了去在整个AQQV这个attention通用的注意力模型的范式下去调整aligned function的一种搞法。所以大家整明白注意力机制核心是为了解决我们的输出能够跟输入直连，然后同时在直连的过程当中，用一个注意力模型学出来了这些注意力的权重。而这个注意力模型本身，我们把它叫做整个叫做注意力模型。
	那这个注意力模型本身核心的这一部分，就核心里面的这个A，这个alignment function，它是可以去做调整的，可以调整各种各样的表达我们的key和这个query之间的关系，这个其实就是我们的alignment function这个A和整个最近模型之间的一个关系。这个P就是我们刚刚看到的，可以用softmax等等。然后这样看就很清晰。这幅图就我们整个输入层有各种各样的输入的X然后encoder里面是它的序号JJ加1，J加2，J加3。然后encoder有它的隐藏层，然后隐藏层之间要跟我们输出的这一层直接去做关联，那怎么关联呢？有一个对应的我们叫注意力权重，注意力权重是后面这个值，0.9、0.010.05、0.04。
	因为这个注意力权重我们希望它是一个权重，那权重最好是能够归一化的，所以前面会用这个softmax来对它进行规划，不然这个alignment score可能就会超过一。那权重如果超过一算起来就不好看，对吧？通过softmax来实现这样的一个方法。所以这里很多同学会经常疑惑，怎么又有aligned score，又有这个attention element score取多少完全是取决于你的alignment function，对吧？你是用的相似度，你是用的点击，那算出来这里都不一样。但是通过softmax可以去做这个规划，做完规划就变成了一个权重值。所以是两个阶段的事儿，最终把它们汇总变成了这个context vector。
	好，注意力机制我们讲完了，注意力机制的特点和优势我们再总结一下。它第一能够帮助我们克服RNN当中的一些挑战。比如说它的序列长度增加的时候，性能会下降，然后计算效率比较低。第二就是注意力机制不仅能够用在语言模型上，这个是他第二牛逼的地方。
	为什么？我们回顾一下刚刚的注意力机制，它解决了什么问题？第一，他把这个长距离依赖，让我们的INN的这个sequence to sequence的网络，它的decoder层能够直连所有的encoder里的隐藏层，这是它的第一个好处。第二个就是说这个结构本身就sequence to sequence。这个结构本身，它也不只是能够应用于机器翻译，它也能够应用于其他的领域。比如说这个计算机视觉，比如说这个推荐系统等等。然后第三个就是说注意力机制，它还能够第一次把他简简单简单来说，我想个简单一点的方式让大家理解，就是我们的机器翻译和这个对齐。所谓的对齐就是decoder里面的每一个词跟我们的这个encoder里面的每一个词，谁有谁谁跟谁的关联度高。
	这个权重这个事儿，这个alignment这个事儿，在一个神经网络里面去做了统一，就是在一个大的架构里面去做了统一，而不再使用两个网络，它是直接把attention的这个网络或者说这个模型加到sequence里面，然后把它一个模型干了两个事儿，一次训练就能完成。那这个也是它的一个非常重要的贡献，也是后面transformer再把这个attention机制不断扩展的一个很重要的一个灵感，就是相当于以前是一个神经网络训练出来干一个任务，现在是一个神经网络通过注意力机制可以干好多任务。我们后面讲transformer结构说可以跟大家讲明白怎么回事。
	然后还有一个原因就是attention的这个机制还可以去一定程度上回应这个黑盒问题。就是我们看到计算机视觉里面，有一些中间卷积层，可以把它的这个激活。激活打印出来就能看到这个背景里面哪一块高亮，哪块没有高亮。然后在这个自然语言里面也是一样的，机器翻译的这个对齐可以看出哪个单词哪个英语单词和哪一个法语单词或者中文单词之间的注意力机制作用之后，它之间的attention with高，这个也能表达出它的含义。
	好，我们这就讲完这个注意力机制之后，我们再来看看transformer。Transformer是什么？Transformer首先这篇这篇transformer这篇论文其实写的很有意思，叫attention is all you need。然后整个transformer要理解的话，其实把它先拆开来理解是比较简单的。我们知道一个注意力模型或者说一个注意力模型，它可以被分成三个重要的部分。这三个部分分别是注意力机制的这个类型，他所使用的这个神经网络的架构，以及它最终被用来解决什么样的问题，这三大块通过这样的方式来做拆解。
	好，我们刚刚看到的最早的这篇论文，在这个红框里面是它的一个定位。第一，它解决的是机器翻译的问题，就是它的application是在machine translation，它使用的神经网络的架构叫encode decode。因为注意力机制其实它最终变成了一个捕捉两个关联的一个模型。所以你能用在encode decode，自然也能用在别的网络。比如说这个图神经网络图，包括这个图的注意力网络，那么encoder decoder加上Martin translation，加上最简单的注意力机制的这个类型，其实就构成了我们刚刚看到的那篇14年的这个论文的一个技能的一个分类，一个组合。
	那么transformer干了个什么事儿呢？其实transformer我们先不看它最终的应用，他第一换了一个新的网络架构，叫transformer，他自己发明的。第二，他用了一种新的注意力的类型。这里的不同种类的注意力类型，大家回头也可以搜一搜，也没有那么复杂。你想象一下我们刚刚讲到注意力模型里面，什么东西是可变的，什么东西是不可变的那他变的其实核心就是那个alignment function。所以这些不同的注意力机制的类型有很多都是在变这个element function，包括transformer也变了。其实就这么回事，就能理解什么是transformer了，如果从拆解它的这个角度来理解的话，那么attention is oil类的。
	其实这篇论文的摘要也说的很清楚，他这篇文章八位的作者有提到在encoder decoder这种序列翻译模型里面，使用一些很复杂的这种循环神经网络或者说卷积神经网络。但是是带一个encode decoder这种sequence to sequence的模型是很不错的。但是他们发明了一个更简单的网络架构，叫做transformer，它能够在已有的这个基准测试上取得更好的结果。其实这个摘要写的很清楚，就是2017年机器翻译这个很难的自然语言处理问题上面序列模型很好啊，但是我们发明了一个很简单的网络结构，比sequence to sequence这种结构还好，这是他们干的事儿，非常简单直接。当时也没那么多想法，说要去整个大模型就干这么一个事儿。
	然后这个transformer为什么是一个叫做变革者？这个game changer其实很有意思，看这幅图能看得出来。第一就是我们看到左边这个是我们刚刚学习的最古早通用版本的这个序列对齐的一个INN的这么一个attention的一个网络结构。然后右边是这个transformer的新结构，然后这个新结构里面的这个小的小框框，就是N乘上小框框，在当时的论文里面这个N取的是6，就这个小框框里面的东西，它取了一个名字叫做self attention的。
	这个mechanical整体的网络结构，它叫做transformer，那我们就来拆解看看它是如何从这种序列对齐的RNN的这种网络结构变成了一个self attention的叫做transformer的新的网络结构。刚刚我们说三件套，之前那个叫序列对齐、序列网络或者叫编码器解码器的这个网络结构，神经网络结构，这个是新的网络结构，google自己提出来的transformer，然后这个attention的这个机制没有变，但具体的这个alignment变化了，怎么变的？揉眼，这个是我们看到在序列对序列的原生的对齐里面的一个效果。就是在机器翻译里面，我们看到竖着的这一条和横着的这一条单词，竖着的是法语，横着的是英语。有一个这个单词应该所有人都听过，就是这个area，这个空间区域这个词对应的法语的这个zone，就是中国移动，最早叫重是要这个单词，这个其实是一个法语单词，这两个之间是高亮的。这是因为他们的注意力权重是最大的在这个IJ上，所以他们是用这个sequence align这个RNN能够表达出这么一个含义，然后这也是他学习到的重点内容，在机器翻译任务上。而这个self transformer他要学的东西是什么？大家看到右边这个两列分别表示的是这个不同，你可以理解是就跟这儿的输入输出一样，这其实the law will never be perfect，右边也是the law will never be perfect。
	很奇怪对吧？它并不是两种语言，不是一个英语一个法语。它整个self attention，包括transformer，它想要解决的问题是说所谓叫自助毅力机制。
	就是说我这句话里面，这个具体的单词yes到底是跟这段话里面的什么单词有关系？这个想象力就很大了。它不再是应用到一个机器翻译里，而是说用来理解语义。就是给你足够多的内容，然后这些内容让你能够去学完之后理解人类的语言。就比如说他学完之后，我是知道这个is到底指的是law，还是指的这个application。然后它的不同层，我们刚刚看那个N层对吧？不同层它的学到的内容也不太一样。
	但最终的目标是为了把这个关联关系学出来，这是要和腾讯的使命，那么self attention它最终的这个形式，如果我们把它的这个展开，它的这个表达式是长这样的，这个softmax就是我们看到的P，这个V就是最后的那个V这里面是他用的alignment function。熟悉数学和熟悉计算机的同学就知道这个lemon function是一个什么？是一个dot product。Scale的dot product就是一个可伸缩的一个电机，待会儿丢进来看看。这个scale的dot product attention，这个是它一个具体的一个出的模块，然后我们可以看一下它的这个element function，选择了这个element function之后，在transformer里面它的结构怎么做的呢？第一里面有一个具体的scale dot product attention，就是具体的A这个模型，就左边组织的这个形式，q query和key去做一个矩阵相乘，然后再做一个scale，做一个掩码，做一个soft max。这就等于我们看到的这个前半部分再乘上一个V，做一个矩阵相乘乘上一个V，然后就是完整的一个attention QKV对吧？
	然后marty head就是我们经常会提到的在transformer里面的另一个词，什么叫muti head？多头？这个多头跟这个炒股里面的多头不太一样，它是指什么呢？它其实是指这里我们看到右边有一个H，这个H就是指我有多个scale dot product attention，我训练了多个attention的这个你可以叫多个天线的模型，或者多个对齐的函数，这不同的对齐的函数并列在这儿，然后把它们拼接在一起。Contract就是拼接在一起，把这些向量再在外面乘上一个权重，这个权重就是用来到时候去取哪个头说了算，这个就跟他的in simple这个摘要也说的很像，就是我相当于一个通俗一点的话来说，就是我有多个参谋。三个臭皮匠，顶个诸葛亮，我这H个臭皮匠，顶很多个诸葛亮，就这么个意思。那至于我这个人什么时候用哪个臭皮匠，我再训练一个W，然后我就知道在什么样的场景下，我用什么样的臭皮匠，这么个逻辑。
	然后这个muti head attention对应的transformer结构里面，就是这里的这个小框框黄颜色的部分了，所以你这么去看，好像transformer又没有那么复杂了，因为这就是一个黄框框，再加上这里的一个Normalization，再加上一个全连接的网络，就构成了整个transformer的encoder的部分，或者说叫它的前半部分输入的部分。我们不叫encoder，这个容易引起奇，输入这一侧的处理部分，输出的这一部分，其实相对于输入，我们看它是三个块电池块，三个模块。不看第一个，看后面两个。后面两个其实跟左边这个encoding的部分，这个输入的部分是一样的，它唯一的不同是右边这儿有一个叫做mask muti head attention。这个是什么意思？简单来说就是我们都知道我们学了天选，知道所有的S这个S能看见所有的H然后S跟S之间也有关联关系。那么mask就是像人看书一样，从左往右看啊，我不是把所有的都能看到，我只是看到我以前的所有的这个内容，就是output这一侧，我看不到我后面的，我只看前面的，相当于我在output这一侧只看上文不看下文。通过这样的一个方式做了一个叫做mask marty head attention，有这么一个区别而已。
	这个FN是一个典型的一个神经网络，W1加上B一乘上W2加上这个B2，这个就是取一个要么取这个零，要么取这个相当于当它小于零的时候，我就不影响它，只加上一个偏置就好了。这一个常见的一个神经网络，那么把这个transformer我们整体缩小之后，就我们刚一个一个把它庖丁解牛的理解之后再来看，其实可以把整个模块或者说transformer的网络架构，其实也就这几类了。一个叫做attention，就对应着我们这儿的这个muti head。Attention加上Normalization，就组成了我们刚刚看到那个黄色的self后面这个就是一个神经网络，叫做它的feed forward的一个神经网络。其实就是一个单纯的一个神经网络，它取了一个词而已，然后就对应着我们左边encoder的这一部分。而右边跟刚刚一样，就是self attention，不过它加了一个掩码，然后对应的一个encode decode的attention，后面是一个fit over，这个就是transformer的网络结构了，没有很复杂。这个网络结构你在这个论文里面我们能看到6层的一个网络结构，那这个六层的网络结构我们把它展开，其实这个网络就长这样的那为什么说transformer一定层面上解决了并行的问题？我们看这个网络就知道，当我们算出第六个encoder的时候，所有的decoder都能计算了。
	它不像最早的这个sequence to sequence，我的这个地的也得一个一个算，至少我现在并行了一半，我没有全部并行了一半。这个是它在一定层面上并行化的一个原理，然后当然transformer也能够被应用到这个机器翻译里面，所以我在input里面如果输入这个在out to put里面也能输出对应的这个英语，这个是没有问题的，这个是transformer的一个结构。然后我们把刚刚那个视角再回过头来看，其实再看这些图就很简单了。包括我的这个输入这一侧怎么样去做encoding，了解encoding。经过了这个self attention，然后又到不同的feedwater里面，最终走到了这个decoder。最终也还可以在transformer外面去对接一些线性层和这个softmax，去做一些具体的下游任务。这也是bert之类的大语言模型和GPT都在做的这个工作。
	整体这里我们看到其实他的这个输入还会涉及到一个什么问题呢？就是这个X需要有一个位置编码，因为他不知道这个X1X2谁是在前面，谁在后面，所以他自己做了一个position的一个encoding。就这么一个事儿，没那么复杂。
	我们刚刚提到transformer每一层，它学到的这个东西不一样，对吧？那么学到的东西有什么不一样呢？在论文里面其实有提到，就像红色的和绿色的。首先这两个是在不同的这个层，就不同的抵扣的这个层。然后不同的层里面，比如说我们看到刚刚说的这个application，它是有关联到这个yes，也有关联到这个application。然后绿色的这一层，它就不只是关联到了its和这个application了，它甚至跟这个B关联的更多，这是为什么？就是因为我们看到了它多个臭皮匠，对吧？
	这个臭皮匠为什么要搞muti head？其实很简单，就是术业有专攻，就不同的attention去搞不同的注意力。左边这个红色的你可以简单理解，就是我们拼接在一起之后，左边的这些注意力机制，他可能学的是这个application，具体在这段话里面，哪些名词是跟它有关系的。这个右边可能学的是有一些，比如说动词或者介词跟它是有关系的，在这个事例里面大家可以浅显的这样理解。但这个机制是可以被运用到很多地方的，包括多模态，就是我们用不同的mark head的attention去训练这个transformer类似结构的时候，其实他就是干这么一个事情，通过你去设置不同的decoder，或者说最终输出层的标记，可以让他去学到不同的注意力，这不同的注意力自然给你的关联关系，因为他是捕捉这个关联关系就会不太一样。
	然后他也做了一个示例，把这个making，不同的multiple的腾讯全部都打印出来。然后看到这个making和他自己的关联最多，然后和这个年份2009的法律，包括more difficult关联是最多的，尤其是下面这个。因为整个它的decoder的训练部分，都是为了更多的去找出他下一个是什么。因为他把这个decoder的输入这一侧做了掩码，所以更多的是方便于他去获取下一个是什么。所以它的more和difficult会显示的多一些。
	然后他的最终的实验结果也是明显用这样的一个更简单的网络结构训练速度更快。在BLEU这个英语到法语的这个测试集上面，以及英语到德语的这个测试集上面，获得了最好的结果。就28.4 41.8，更大的这个transformer，这个base model应该就是它的六层的encode 6层的这个decoder。它这个encoder和decoder跟最早说的这个sequence又有点不同，网络结构上，所以它叫transformer的base model。
	好，刚刚我们讲完了这个transformer，什么叫预训练的transformer时代？就是所有的这个GPT也好，berk也好，其实都是基于transformer在做文章。那么预训练的transformer时代，我认为可以从18年OpenAI发布GPT1这篇论文开始，可以看到这篇文章叫做improving language understanding by generative programing。然后bert其实是18年的十月份左右发的。但是这个网站收录的是19年，可能是在19年做过一次编辑和更新。也许这个具体原因我没有去深究，所以bert被标注成了19年，我就按照他这个网站的结果写了一个19，bert是一个pre training of deep by directional transformer for language understanding大家看这两个非常有时代意义的大模型，或者说现在叫大模型，以前就叫预训练的这个transformer他们目标都是一致的，都是想要提升什么呢？Language understanding就是语义理解，其实是啊就想提升语义理解的能力。
	这两篇文章的作者也很有意思，重要的bert这篇文章的作者，现在还在google。然后当时的这个GPT1的这篇作者的小哥，当时跟他的这个合作者里面，有最近的热门。其实当时我们都没有想过伊利亚会成为这个暴风口，但现在确实一个首席科学家在OpenAI的，其实他非常有学术方面的贡献，我们也不知道背后到底发生了什么，但是他很厉害，从hinton这里，他应该是PHD是在hinton这边和alex一起发表了anif net深度学习最有影响力的这篇文章。然后当时也是跨时代的提升了十几个点，在这个对应的比赛上面，奔驰化上面，同时也在google的时候参与了TensorFlow相关的一些论文。它有一个很重要的文章的成果，应该所有人都用过，叫做dropout。就是我们在训练神经网络的时候，可以概率性的关闭掉一定的神经元连接，dropout也是伊利亚的作品，所以很多人评价伊利亚应该是未来的图灵奖，只不过是一个时间早晚的问题。
	这里聊了一个科技圈的一个八卦和这个背景，这两个大模型具体来看我们是怎么样去理解他们，我们今天花一点时间快速的认知一下，这里的小红圈是banana和这个bengel发布的attention mechanical这篇文章。14年，然后然后这里还有一些小圈圈，分别代表我们看到的transformer。在这个最大的被引用的这个圈圈里面，STM、word web和这个global vector，其实大家都是紧密连接的，圈圈越大表示引用它的内容的论文越多。那么所有的刚刚看到的这些内容里面都逃不开一个词叫做neural network，就是神经网络，包括LSTM这个by LSTM双向的LSTM这个双向的操作也被bert借鉴过去了。Bert使用了这个双向的深度的transformer，然后evading也是一样的，像water wet global vector，也是用的神经网络。然后这个attention mechanical发展到了self attention，也就是我们的transformer，后面基于transformer延展出来了这个bert的GPT。
	所以所有的这些为什么大家都在搞什么神经网络，都能用tensor pro，都能用patch h，就这么个道理。因为它背后底层实现它的时候都是个神经网络，只不过写法不同，用到的神经元不同，用到的这个层不同there不同，那GPT1是怎么做的呢？是GPT，我们看到整个GPT e，它相对于我们的transformer的改造没有特别多。
	第一我们看到这幅图里面左边这个masked marty self attention，their nominalists ation fade forward layer longoria ation, 是不是有点似曾相识？这个东西其实就是我们刚刚看到的transformer里面的右半部分，大家有印象吗？就是有掩码的marty head attention，只不过他娶了别的名字而已，master much self attention, 所以没有左边部分，右边部分，然后把原来的六层的decoder改成了12层。然后同样的这里需要做文本和位置的编码，然后结局就是这里。
	最后会在这个下游去训练一些特定任务。比如说文本预测、文本分类，其实GPT就是这么朴实无华。对，就是把transformer拿过来改了改。因为本来也就是在transformer发布之后没多久，做了这么一篇文章，然后他怎么理解为什么他会这么做？其实简单来说就是把transformer当成了一个语言模型，预训练的一个模型，然后就是我们这里写的预训练的语言模型，retrain的LM也是我们现在经常在微调里会看到的一个缩写PLM，pretend LM预训练的语言模型。
	在预训练的语言模型后面去增加一些具体的任务，是我们这里看到的文本预测和文本分类和这个任务的分类器。通过这样一个模式，就能把整个这个架构GPT1变成一个可以跟下游任务去做对接的一种结构了，然后整个这个事儿就能够往后去滚雪球一样的去运行了。然后GPT就这么做出来了，然后看起来没有什么新的idea，也当时没有引起什么太多的人关注。
	这个是当年的GPT1，然后GPT1的当时他自己就叫GPT，GPT的这个generative free transformer，当时在一些自然语言的在benchmark上也拿到了一些还不错的结果。然后他当时很朴实无华，他也没有给自己搞很多名字在论文里面，到现在都还能够挂在ACP上面。他当时有提到在这里的六个不同的基准测试上面，这个叫fine tune的transformer LM就OpenAI自己写的，就是经过微调的transformer的语言模型，其实就是GPT1，确实取得了很好的结果，这也是后面有暴力美学的原因，就是吃到了这个螃蟹。就是这former这个架构好处无穷，可以有很多的玩法，并且有很多可以去深入研究的地方。当年这个比赛上除了这个RTE不是sota以外，这五项都是索塔。这六个基准测试我这边就不再念了。
	简单来说就是都是关于自然语言推理的一些任务。主要就是用来理解这个模型它的语言的语义理解能力强不强。所以它里面会去判断一些逻辑关系，比如说两句话之间是包含关系还是矛盾的关系，还是说完全无关，然后这些benchmark的设置都是为了用来推测这个模型的水平，这些模型如果好不好好的话就能用到一些像问答系统，包括翻译之类的这个下游任务里面，这个是当时的一个背景，在18年，这个我们刚才已经讲过了，就不讲了。
	那再讲一下bert，刚刚那个PPT其实很朴实无华。那么bert做了什么事情呢？我们都知道google的这个同学一定是有想法的，他总要做一点不一样的，对吧？那么当时这个bert解决了一些当时的所有做transformer或者做语言模型的人，都没有去解决的另一个一个方向或者说一个问题。第一它这个B就开头的这个B很关键，这个B就是指这个双向by directional，然后这个by directional具体怎么体现的呢？其实当然首先从结果的角度来说，他考虑的这些问题，解决了这些问题确实带来了非常好的结果。
	在摘要里面他也提到了，像这个ELMO是一个我印象中这个ELMO好像就是这个AI2e lab的作品。我不知道，我不确定，大家可以帮忙确认一下。然后这个GPT1，这两个都是他当时在这个摘要当中有提到的，之前的一些sota。
	那么就bert本身来说，当它推出的那一刻，就是屠榜的一个存在，也符合谷歌的一项的特点，直接在11个自然语言处理的任务上拿到了最佳结果。这个sota是自家人用自家的这个网络结构达到了一个新高度。也直接导致了后来一年多的时间，也是从18年底到2020年中GPT3出来的时候，所有的开源社区和高校公司几乎都在基于bert在做进一步的研究，因为它确实太强了，但是bert它牛在哪儿？
	它到底解决什么问题？第一个就是说我们看到GPT1它用了掩码，它沿用了transformer的decoder结构，让它的这个mask的这个self attention只能看见到当前这个单词以前的内容，看不见后面的内容。然后这个是bert这个团队就提了一个很大的问号，就是说为什么语言模型它它不能是双向的呢？如果是双向的是不是更好理解？我觉得这个事情是我自己的认知是说，第一双向的更好理解是在于有的时候人的语料就是有问题的，就是他本身训练语料就有问题。第二就是说作为一个人，人类你去看乱序的这个中文和英文，你也能看懂，说明这是一种能力，这个能力就语序不再是那么重要的一个卡点。也许因为你没有学这个反着读，倒背如流，你没有去去学这个，从右往左你可能还损失了一部分能力。从结果来看，这个双向在当时确实是比单向强。
	然后第二个就是说我为什么非要去搞抵扣的，因为在当时我有提到，语言模型都被认为是一个中间产物。这个中间产物就像是说我训练了一个大模型，训练了一个语言模型。这个语言模型它的最大的能力就是充分理解人，能够听懂你要说什么，你的语言是什么意思，这是它的最大价值。然后他没有说必须要去生成一点什么，他不是要去生成一个下游任务，所以当时bert就走了。
	这个主要是by directional encoder这条路，就是去双向的，以encoder为主的这条路。Encoder的核心就是去理解你的这个输入，去训练这部分的参数，encoder成的这些参数，这个是当时的bert解决的一些主要问题，然后我们就能看到很有意思，我们叫做uni这个directional就单向的，uni directional和这个by directional训练过程就有点不同。简单来说就一个只训练从左往右读，一个是两边都都训练，就这么一个区别。
	然后实际上怎么训练的呢？这个就涉及到当年bert的一些预训练技术，就谷歌的一些巧思，简单来说跟我们最早讲完形填空有点像，怎么怎么训练？就是第一我要训练他对语言的理解，是不是就可以用完形填空的思路来教语言模型。
	那怎么填空呢？其实他就随机的去把他的语料里面掏一些空出来，就像这里有段话叫the man went to the store to buy a gallon of milk。一个男人去一个商店买一加仑的牛奶，他把这个商店和一加仑的加仑单位抛掉了。抛掉之后变成那个完形填空的空，然后他掏多少的单词出来呢？这个是一个超参数可以设置，这就是典型的数据增强的技术掏15%涛10%都可以。那他就会有一个思考告诉大家，如果你这个涛的太少，训练成本就特别高，因为你得准备一堆的原文才能掏出一点点空。
	但如果你掏的太多，上下文可能就不够了。比如说这段话，你把这个man掏掉了，把这个went掏掉了，然后把buy掏掉了，把milk掏掉了，最后只留下了the to a of，啥都没有，学不到对吧？没有张小文超多了，那这个就是K需要去设置，在从这一个超参数里就能看出来，要去预训练好一个大语言模型，或者说那会儿就叫预训练好一个transformer。其实有各种各样的超参数需要去调整，针对不同的数据应该怎么样去设置，这个是真正的核心技术。
	然后他实际去掏的时候，这个空要怎么填也很有讲究。就假设我现在滔好了，我掏好了之后，15%都是我掏的，mask涛的是空，那我要往里怎么填？这个相当于是一个标注，就是正确答案是什么，或者说把它掏完之后，留个什么东西让他去学。80%的时候，他会去把那个地方就留成一个空空一个空。然后10%那会儿随便放一个词，随便放一个单词，然后还有10%是就保持原文。因为你要知道的是说它的训练语料没有大量的像这个基于下游任务去做标注。它只是为了提升语义理解能力，所以他没有办法去做标注。所以他也没有办法去确认那个原文里面他抛掉那个词有可能原来就是错的，这个也是有可能的，所以他就直接用这种方式去做，并且还达到了非常好的效果。
	因为相当于就是让这个bert去掏掉一个特定的单词之后，通过他的前文和后文，比如说win to the。我记得对面一个store，下面是to buy a gallon，to buy a和when to the去预测中间这个就跟人学习很像了，这个是他的对数据的一个处理和训练的手段。然后他对下游任务的一个设计，包括这个单词蕴含关系也是一样的，就打标签，这个就需要打标签，就是我不再是语义理解能力了，而是我要就我们刚刚看到的要接一个下游的具体任务了。
	比如说我要去做一些这个句子之间的关系的一个判断，这个也是一个典型的benchmark。刚刚我们在。GPT1的这个基准测试里面也有看到，那他判断这个关系其实有几种关系。有的是说我之间有没有关联，有的是说有没有包含关系，有的是有没有矛盾关系。
	这里我们举个简单例子，就是两个句子之间是不是上下文的关系，通过一个标签叫，比如说是上下文叫is next sentence，如果不是的话就not next sentence，通过这种方式来打标签。比如说这个sentence a和b the man went to the store。He boat a gentle milk, 这个label就是is next sentence。通过打这种标签，你的语言模型就不只是能够理解，就不只是能完全填空。他还能在你给两个句子的时候，他给你输出一个标签，这叫有监督，对吧？学过这个训练过模型同学都懂了，那像这里也是一样，the man to the store penguins，flight less，就是这个企鹅不会飞，这俩不是上下文关系，打一个对应的标签。如果你打了只打这两种标签，至少这个模型能够训练这个标签的任务。最终就可以你给两个句子它来判断是不是上下文，这个能力它是有的。
	如果你给别的标签，然后它就能具备别的能力，这就是反映这种下游任务的一个逻辑，那么在bird的这个论文里面，他也有提到各种各样的benchmark，尤其是这个glue是非常有名的，就各种自然语言理解任务的这个benchmark，以及这个score。这俩其实是出现在我们周三那个课程，就是人类的能力，就human performance里面其实是参与了这个，包括红杉的这个文章里面都有引用。这两个基准测试也很重要，然后bert是超过他们了，然后类似的包括NER这个NLP最重要的基础任务，还有这个多选问答任务，都拿到了非常好的成绩，都是sota。
	然后整个bert其实是开启了这种新的范式，就是我们用一个没有标注过的生成A和B，我们大家记得刚刚我们去训练这个but的过程当中，可以没有label的，label是为了下游任务考虑的。没有label的时候，我只需要把它这个mask掉就好了，就操控就好了，就可以训练一个bert。然后训练出来的这个bird可以再去反映这种下游的任务，就是加这个标签，去训练这个下游的任务。这种新的范式其实到今天仍然有效包括我们提到的prompt的这个fine tune，就是我们的PEFT里面有个prom 2I也是类似的。其实你去理解它的核心逻辑也是有个大模型，大模型不用变，然后搞一个小模型。这个小模型去生成输入一个prompt，经过小模型再输出成一个比如说是bird或者说GPT4喜欢的prompt一样的逻辑。只不过在那个流程里面，你的小模型变成了中间一环。然后你的小模型的上游是人类，下游是大模型，然后大模型的输出才是最终给到人类的结果。
	然后bird的这个价值就是非常在当年引起了非常多的关注，有很多原因。第一，encoder为主，它的上下文理解能力非常强，语义理解能力很强。然后它是一个预训练加微调这种范式的一个开启者，然后它的跨任务的泛化能力很强，因为它就是一个强调语义理解能力的模型。下游是单独训练的那它的核心就是予以理解，简单来说就是它是一个更会沟通的模型，它更能听懂你的话。那么和一个怎么理解？就是一个职业技术学院毕业的学生，假设是GPT1的话，那可能bert就是一个经过高等教育的比较好的一个大学本科生，所以他们两个人可能职业毕业的学生，职业技校毕业学生没有任何歧视的意思，他手上的功夫，他有一些职业技能，他能干活。但是当他去干一些，可能需要一定的，比如说高等数学、微积分这样的知识才能够理解的任务的时候，他干不好。因为他他这方面能力弱，所以他可能起步快，他能马上干一点小活，但它就很难天花板很低，大概这个意思，我不知道能不能给大家做一个类比，就是它的跨任务泛泛化能力的一个点。
	那多语言的支持性能也很好，然后开源做的非常好啊，它的这个开源其实是非常早，包括hugging face的transformers这个库，就哈根face有个库叫transformers，也是我们第三周要讲的主要内容，现在也算是整个大元模型当中用到最多的一个SDK，很早就用py touch实现了bert的这个模型，所以有很多人就基于他去做各种各样的进一步研究。But和GPT的差异，我们刚刚有提到了，一个是auto encoding，一个是叫做auto regressive，然后他们的预测目标不同。然后bird我们刚刚通过预测的这个训练的过程就知道它是完形填空套了一个词。它能够给定上下文预测一个或多个缺失单词，因为它就这么训练的，他训练有80%都是把单词空在那儿，他就这么训练，他自然预测目标就是这么干的。
	而GPT不是，GPT是一个只有这个transformer的decoder部分的一个网络结构。所以他一开始训练的时候就是只给前文，然后让你搞下文。所以他更好能够去生成一些内容，这个跟他的训练方式是直接相关的。然后对于训练或者说输入的处理，一个是双向的，一个是单向的，适用场景自然有不同了，but适合去作为一个大的系统里面的一个核心模块。而GPT更像是一个终端应用，它能够各种深层次任务去搞。然后语言模型，包括它的这个优点缺点也各有优劣，这边就不再展开了。大家去回头去好好理解一下它的训练方法，它的模型结构、模型架构，就能够理解它们各自的差异了。
	那么他们的共识是什么呢？就是我们能看到首先他们都在用transformer，然后他们的数据预处理都需要用token ization也是我们后面我都会做的。然后他们的预训练过程基本上都没有用带标签的数据，直接能够用无监督的方法，无标签的方法去预训练，然后都可以通过fine home来进行任务的迁移，GPT虽然是一个职业技能还不错的，这个非不一定是这个高等毕大学这高等教育的大学本科生，那他也能学习，所以他也是能翻译to的。他不是说不能翻译to，只是说他的这个语义理解能力在网络结构上就天然比这个bert有一些缺陷，但特指GPT1，然后训练目标上都是为了提升语义理解能力。大家还记得刚刚这两篇论文的标题都叫improving这个language understanding，然后都支持多语言模型的训练，这个是他们的一些共识，最后我们再花一点时间讲讲GPT的这个系列模型，为什么叫大力出奇迹的暴力美学。我们看到18年GPT，在当时这些这个评价是来自于stanford的自然语言的课程的原文的评价。我这边不做更多评论，当时这个课件里面有提到stanford的这个NLP课程，提到18年的GPT是一个巨大的成功。这个其实是没有太大问题的，因为它特指的是在预训练一个decoder这个领域，而不是在预训练语言模型这个领域。
	所以这两条路线是非常明晰的，就是GPT走的是free train一个decoder，transformer里面砍一半decoder。而这个bert就是预训练一个encoder，主要是encoder，而且是by directional的这个transformer，在GPT我们能看到它一第一代的时候使用了768维的一个hidden states这个隐藏层和3072位的这个fate forward的隐藏层。这个两个参数你可以理解成就是我们刚刚还记得transformer结构里面，下面是一个mask self attention，上面是一个feed forward，就这俩。然后它的这个bad pair encoding是有这个4万对，然后训练语料上面7000本独立的书籍，这个是GPT1的训练，然后这个训练过程就是我刚刚说的这个包含关系，就是说什么是蕴含的，什么是矛盾的，这个是他的训练过程，我就不再展开了。然后他的训练的这个结果我们能看到，这个是还不错的。但是到了GPT two，我们会发现这个是GPT two。
	GPT two有一个很有意思的点，就是首先它没有在网络结构上真的有一个什么所谓的双向的，或者说encoder owning或者之类的这样的提法，他不会这么干。但他做了一个很有意思的事情，就是他在想既然我一开始是decoder为主的那我可能语义理解能力弱。那我能不能一开始训练的时候，就把我应该烦痛的这些下游任务训练进去。
	简单来说就是你想象一下，这个就像小说里的这个人物一样，这个bert是一个家境不错，然后一来就是要走这个学术路线的。我要先把自己的这些很符合谷歌的调性，我要把自己的语义理解修炼到足够高。最好是一个某个什么中文系大师或者历史系大师了。然后我再去行业里面去找一些应用场景解决问题。
	但是GPT想的是说好，我这个是实用主义。我一来我是先到某个职业学校，我先学了一门技术。那我能不能变成那个小说里面的那种什么男主角，我学东西都很快，然后我在这个职业学校里面把所有职业技能全学会了。然后我出生的时候，我就已经带着这个非常好的技能了，这个是GPT的一个思路。并且其实你看现在GPT也做的差不多了，是这个思路的一个很好的最终结局。
	当时的GPT two的论文也很有意思，他提的这个模式叫做language models，是一个on suprise martita none，就是我们要做一个语言模型，它是无监督的，并且它还能把很多任务都学会。你看现在多模态其实也是一样的，简单来说就是我给你足够多的算力，给你足够多的数据，然后给你足够多的任务。你全部都给我一锅炖了，然后都学好了。
	事实上其实在我们这儿看到这个GBT two它自己的这个版本有多个版本，有他所谓的larger的版本。15亿那会儿就算非常大了，然后大家还记得我们看到的这个race net 50也就2500万，在这个地方都排不上号，所以那会儿认为这个15亿就是非常大的。那会儿的大模型都是用百万来做这个单位的，因为大家很少有超过十个亿的。这个一点一点5B就是15亿的GPT two，在很多的多个基准测试上拿到了非常好的结果，并且是使用的这个zero shot的这个为什么叫nero shots results？那会儿还没提这个prompt，也是因为其实那会儿给没有参考事例的学习也是一个很有也是一个很重要的研究方向，并不是说zero shot这个词是open I发明的，是一种learning的方法。然后GPT3我们之前也看过了，它的这个训练集就更夸张了，几乎把人类历史上那会儿能搞到的好搞的公开的数据都搞进去了。
	训练之后取得了更好的结果，只不过它的模型参数其实是整的比较大的，已经有1750亿了，然后相比于当时的最大的T5，我们讲过T5这个模型，google发布的这个encoder decoder都有的。这个模型其实训练一次，当时在2020年的数据也需要150万美金了。但是他当时是11B，就是110亿的一个模型。GPT31下干到1750亿，你就知道它需要多少钱。所以那会儿OKI其实是在GPT3搞出来的时候，是一个几乎快破产开不下去的一个状态。后来3M奥特曼进来之后，给了很多的资源，包括拿到了微软的这个支持，然后整个GPT3的这个训练方法，也已经吸取了很多其他大模型的一些经验了，包括他在这个训练过程当中的一些小的技巧，在论文里面也有，我这边就不再展开了。
	但核心来看，其实还是去垒这个transformer，这个是他在训练过程当中训练出来的一些，相当于是说把一堆大的语料给到大模型之后，给到GPT3之后，他自己学会到的一些技能，这个技能就有点像我们现在的prom，就是给一些前缀，给一个简单的，他自己叫做，有一个简单的transformer的decoder。然后给他一个上下文前缀，他就知道你要干什么活。现在我们来看这个事儿，就是你没有给这个任务描述，但是你给了这个feel short，他就知道你其实是想做翻译。
	然后GPT3也是首次提出在上下文中学习，in context learning的一个很重要的，其实就是prompt这个词的前身的一个概念，上下文中学习。但是当时这篇文章2020年出来之后，他还提到一个前置条件，就是要能够让in context learning成有效果的一个前提，是要足够大的大模型，有千亿级别的大模型才有这个效果。这边是他举的一些事例，就是同样一个大模型给他不同的上下文，他就知道要干什么活。这个就有点像把GPT2许的愿在这儿实现了。就是我们的这个GPT，我们的transformer是一个unsupervised的，是corner，对吧？我没有给他任何的有监督的标签，他就是足够多的训练语料。训练完之后你给他上下文，他就知道我要干嘛。很厉害。
	就像学了这个高等教对这个研究生，他虽然好像什么技能都不会，但是你给他一些参考示例。这个新人好像学的还挺快的那其实也能做到。对，然后有提到这个在上下文中学习，也就是这个prompt zero one和这个few shot带来的一个收益，使用了这个prompt的这个收益是超过没有prompt的，然后前提条件是要足够大规模的一个大模型才有效果这个是他给的一个参考示例，我们之前开始讲过，我这边就不再赘述了。大家可以看一看，也是论文当中提到的一些内容包括这个模型的一个表现。在不同的benchmark上，显然是足够大的模型能拉开这个差距。如果是小模型，像这个一个亿的，或者四个亿的，或者13亿的，使用这个prompt其实并没有拉开这个差距然后我们最后再对比一下，就是三代GPT，为什么叫暴力美学？
	我们能看到模型规模是真的是快速在增长，从一个一个亿的一个GPT1这么一个模型到15亿，直接干到1750亿。现在GPT4据说是几万亿，对吧？2万亿或者是一万多亿，反正这个谁也没数。有可能他不同的这个时期，实际部署的也不一样。但是能想得到肯定是超过1750亿了。那么整个这个模型规模是数量级的增长，然后transformer的层数也在增加，但是这个transform数没有数量级的增长。所以你能想象得到就是他要么把muti head的这个H变大了，就是我们看到它有多头的注意力机制，要把那个变大了。要么就是把单个muti head tension的hidden的神经元的数量变多了，这个layer的神经元数量变多了，不然对不上这个模型规模数对吧？
	那第二就是说它的数据变得越来越多，它不需要那么深的层让它数据变得越来越多，因为太深的层本身训练也是一个问题。然后这个过程当中，其实从GPT3开始，互联网的数据，人类产生的各种这20年的积累都加进去了，以及GPT4把ChatGPT用户的反馈也加进去了。然后这个是非常能看得到的，就是OpenAI的这个套路，就是我的transformer架构不变。然后我就是靠数据，靠AI的工程化，能够把我的模型直线的这个性能拉伸，这个是非常夸张的。
	然后他们的主要贡献点也有不同，虽然说没有提出新的模型架构，但是他其实思路非常好。在GPT1的时候，他应该算是首先提出了基于生成式的预训练的一个语言或者说语义理解方法。就是他第一个提出improving language的understanding，用这个transformer，并且也是第一个去把pre train的这个decoder做的非常成功的模型也展示了这样的一种pre train的transformer，可以去跟fine today结合起来做各种下游任务。然后GPT two有一个很重要的思想，就是说我提出了一个观点，就是只要给足够的数据，足够的算力，我可以用一个无监督的方式来学习多任务的这个语言模型。这个也是现在很多大模型都在研究的一个思路了。然后把模型规模和训练数据集的规模都提升了。
	然后GPT3很重要的事情是提出了prompt概念，那会儿叫in context learning，又叫小样本学习，就是说我甚至都不改变大模型，因为大模型训练成本太高了，我们刚刚算过，T51 100多万，那么训练一个GT3可能是上千万的一个成本。那么训练出来之后模型别去调了，怎么样用这个in context learning的方法，用prompt的手段去把大模型的结果变好啊，这个是我们的GT3提出来的，也是非常重要。到后面今天为止一直是成为大模型沟通技巧prompt的一个起步价。然后也当然就更进一步增大了这个模型规模和这个数据集的规模，然后也增加了一些新的任务，然后时间也是一年一个更新，我们能看得到到今年为止，其实OpenAI又有了非常长远的进步，包括它的这个GPT4和所谓的GPT4.5这三大套件，也就是assistant API的三个主要组成部分。其实OKI这几年一直有非常强的商业化和工程化的体现，最后这三篇论文我也会都放到这个平台上，欢迎大家去阅读。GPT123。然后因为这个GPT3到ChatGPT这一段，其实是相对来说比较没有官方的论文指导的，然后也是它的微调手段。所以我们会放在下一周的在讲微调技术的时候穿插着讲进去。
	我们也是以GPT为作为这个最佳实践，看看这些微调技术到底都是怎么发生作用，又是怎么样从2020年走到了2022年，好吧，那么今天的分享的这些知识就到这儿，看看大家有什么问题。因为时间比较晚了，我们就快速回答，就回答到10点20。看大家有什么问题，现阶段著名的基于bert的大模型有哪些？这个同学你可以写一下注明是什么意思。对，就是这个注明具体是指什么注明。然后有很多这个大模型的，这个bird的大模型的。我主要是我不知道这个著名怎么好去评价，因为这个比较容易惹起争论。
	对。我看看有没有那个图。好像没有放对，就制服有总结对视频怎么做embedding，用什么模型？就看这个同学你的视频做embedding想干嘛？如果你的视频用了embedding之后是用来做什么标题检索，那其实有很多办法，就是你想象一下那些视频网站是怎么打标签的，然后那个标签如果你只要标签主题这一集的话，是有办法做的。然后如果你要更细的把这个视频的每一秒每一帧都要去做in bin，那得具体讨论。
	Benchmark是有标准答案的，同学就是大模型的输出存在一定随机性，benchmark是有标准答案的。Benchmark基准测试人情万分，一定是有答案的。Bert还有必要学习吗？是不是没有翻身的可能？我们没有在学习bert，我们在学习的是bert的思路。所以大家一定就我开始这节课之前我就在讲，大家不要不要陷入一个这样的怪圈，就是bert的这个思路很重要，就是怎么样能够把双向的思路用到这里面来。然后encode和decode的区别是什么？这个是我讲birth的关键。然后有没有翻身的可能我不好讲。
	什么样的场景使用bert的bert更合适？这个其实有提的，有对比对它的语义理解各方面能力会很强。但是确实现在google的大语言模型也不是倍的，它有自己的单元模型。对，但是GPT的大语言模型你拿不到，是吧？所以这个问题我不知道你对比的是什么。
	Transformer的隐藏层的神经元个数怎么计算？这个同学你回看一下明天的录像，就是transformer的网络结构里面刚刚有讲过，就是他的这个我一步一步的从aligned方向开始讲的，讲到最后的这个讲到最后的这个transformer的结构的，这个同学会看一下，可能当时听的这个内容比较晕了，就这里，从这儿开始讲的，一路到这里。好，我们再看一下。
	曾经用到的技术栈有些已经过时了，有些在大模型时代还是非常重要的。能举个例子吗？例如evidence的技术非常重要了，但是贝叶斯已经不怎么用了，有没有这样的一个技术栈的集合？我觉得技术战可能不一定是能能概括这个词的，但我觉得方法论是可以的。就是我们在看刚刚的有一幅图，就是这个为什么都在讲都是神经网络？
	大家如果去看这个LSTM什么时候提出来的，30年前，然后by LSTM什么时候提出来的，LLSTM是怎么用到语言模型上的？然后LSTM的思想或者说by LSTM的思想又是怎么用在bert上的。然后transformer是17年提出来的，然后为什么到今天还有人在用？我觉得这个是关键，包括这个attention的机制，学attention要抓住它在捕捉这个输入跟输出的关系，然后query和这个key的关系它能去算。然后完了之后它里面的aligned function又变成了关键。这些其实是方法论，这些方法论真的学够了，是一通百通的。
	为什么encoder only？为什么decoder only？这个同学你你看看我们刚刚讲他那个训练过程，就他的训练过程里面或者说也不一定叫分类任务。就是说他的训练过程让他更适合去能够填一个完形填空这样的场景，因为它训练过程就是这样子的，而这个穿GPT它的训练过程就是只给上文，让你弄下文来对比，这是他的训练过程决定的。然后transformer可以用于时间序列分析和预测吗？可以。
	这个同学问benchmark怎么做的，建议去看一下benchmark的一些网站，我尽量回复一些我没有回复过问题的同学。LLM训练时的限制序列长度和整体的上下文长度是啥关系？对于超长文本如何处理？这是两个问题，就训练时的限制序列的长度。这个我们其实刚刚今天的课程一直在讲。就是你的训练的时候，你长度太长会被各种限制，导致他没法被训练到，比如说梯度消失，比如说各种各样原因都有可能，这个是训练的时候的长度限制。然后如果你说这个推理的时候，就比如说你给GPT发的时候，它的这个上下文限制，我觉得可能原因就比较多了，有的是成本原因，就比如说我刚刚提到了它生成这个内容的成本是呈平方关系，是不是超过它的这个资源上线了，或者这个就不太能支撑了它的架构。第二就是说有可能是因为这个上下文它预测不出来，就像你提到的，在训练过程当中没有那么长的序列，所以他没法生成那么长的序。
	然后第二个就是说这个超长文本处理方法有很多。比如说你在丢给大模型的时候，是不是可以自己截断自己去sweet，或者说你在丢给他之前判断一下哪些是不需要丢给他的，甚至在这个缓存，或者在记忆网络，或者在向量数据库里就已经有了。要想学透基础部分，必须去看论文，而且还不止于论文，对吗？我觉得这个同学问的问题很好啊，就是这些基础我的核心还是讲学会方法论，然后能够理解这些一个一个的词，以及这些背后的论文到底它的核心贡献价值是什么。不一定一次搞明白，可以每天搞明白一点，或者每个月花一点时间搞明白一点。这样的话你的上限是很高的，你不会是天天焦虑。
	又有东新的东西出来了，因为太阳底下的新鲜事没有那么多。你一定要知道今天这个新鲜事它新在哪儿。等你整明白这些东西之后，你会知道它新的东西也没那么多。就像我们都知道GPT迭代了这么多，网络架构有迭代吗？没有，那它迭代的是什么？你就去找那个特定的切片就好了。
	Encode和decode解决的是什么问题？我可能是漏听了，不知道讲没讲。这个跟网络结构有关系。同学首先encode decode这两个词的含义是这样的，encode是指我把原始输入变成一个神经元的隐藏层的一个值。Decode是把神经元里的就神经网络里面的值变回成我一个人类能看懂的这个输入。比如说特定的文字，或者说特定的图图，这个是encode decode这个架构的通用的解释。
	然后这个架构本身它的这个应用就跟它的具体网络结构有关了。比如说注意力机制里面用来做机器翻译的这个encoder decoder和transformer用来做自注意力，用来做语义理解的这个encode decode就不一样。因为encode decode的本身就是我刚刚说的这个含义，就是原始数据或者说人类数据和神经元里面的神经元的这个值之间的关系。
	好，我们今天就先到这儿，10点22了，大家有什么问题我们群里再提问和沟通，谢谢大家。然后我们下周会正式开始大模型微调，然后以也会借助OpenAI的迭代，我们来讲讲这些微调技术。好，谢谢大家。