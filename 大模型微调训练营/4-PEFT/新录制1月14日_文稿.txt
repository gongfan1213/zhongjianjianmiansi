	Hello, 大家好，能听见吗？OK可以看见。好，那我们就直接开始今天的内容。好，我们今天其实要讲的内容已经跟我们的整个课程的主题紧密相关了。然后在这个目录里面，我也把咱们的这个时间线给捋了出来，让大家了解一下。其实大模型微调这个技术是很新的一个技术。我们可以看得到就我们主流的目前主流怎么评价，就以现在开源实现并且被大家广泛使用，也在学术圈有论文在引用的一些技术，我们把它列了出来，当然可能列不完，我们列一些代表性的技术。如果大家对其他的一些跟微调相关的这个。
	电相关的技术感兴趣，包括像lora或者说这个多任务，多模态相关的一些技术感兴趣，我们也可以在群里面提出来。然后我记得当时有跟这个浩哥沟通，我们会在这周填一个算是一个表单，让大家关于我们的实战和其他的一些知识点，有想听的可以提交上来，我们可以在课程里面再去做补充。好，那么我们就回到正题，今天主要讲的是一个其实是一个论文的解读，也是一个技术演变的一个过程，当然我们这个技术到最后还是要落地的。所以我们能看得到从2019年google发布的adapter tuning，一直到2021年22年。从清华质谱这边的P2，这三四年间的一个迭代其实也时间不是很长。但是技术上也有一些不断的一些新的思考，并且从实验结果的角度也取得了一些进展。我们会逐步看一看他们是如何从最早期的19年的技术到22年的技术，以及我们其实在实战里面就会用到这个P20v two来微调我们的chat GM36B，所以我们有必要去了解它的来龙去脉，才知道它好在哪儿，为什么不去搞这个早期的技术。
	第二个就是说除了单纯的这个PFT以外，其实还有一条技术路线。我们在之前的课程有提过就是这个Laura LORA。Laura其实也是一个比较新的，在大模型这一侧也算是一个比较新的技术在2021年的时候，由微软提出来的一个技术方案，并且微软也有自己的这个开源实现在github。当然现在可能大家更多使用的是hugin face上面PFT这个库里面实现的。Laura在微软自己的github的这个主页上也有提这样的一个关联链接，以及后面有今年我们才看到的这个q lora和这个艾达罗尔是什么样的一个技术，可能我们今天主要的内容就这些。好，我们先来讲一讲什么叫这个PFT，就大模型高效微调的技术。在讲这个PFD之前，我还是喜欢把这个来龙去脉给大家交代清楚。
	首先讲PFT之前，我们要知道PFT是在一个什么样的背景下提出来的。在GPT3提出这个in context learning的时候，其实我们会知道，那会儿要提高效微调也好，提微调也好，有一个比较本质的原因就是大模型的训练成本，微调成本都太高了。我们在之前的课程里面也反复说过，所以才需要做这种高效的微调，换句话说也就是不是全量参数的微调，这种非全量参数的微调，最开始其实都没想过微调。我们现在好像听起来微调是一个很自然的过程，但是在更早的时候，其实我们都不知道大模型怎么微调，因为它和我们以前遇到的模型都不一样，这个我在上节课里面也曾经讲过，像基于视觉的这些模型，千万或者百万级别的参数，它是一个典型的深度神经网络。所以它的层数一层一层加深的，或者说再往前倒就是这种卷积神经网络RNN，它是一个序列，越来越长的一个状态，比较难训练的。像这个图神经网络可能本来也不是一个主流，像强化学习本身也比较难训练，这都是比较难训练的那至于大模型那就更难训练了，因为第一它的成本很高，你没有足够大的算力能去把它加载进来。第二，就算加载进来之后，它参数太多了，我应该微调哪些，我不知道。
	对于预训练来说，其实更像一个乱炖的过程，就是我把足够多的数据清洗好之后给到大模型，他先去学学一个六七十分之后我们再做一些精巧。但是本来现在微调就是要精调的状态了，就是到这个阶段了。那怎么样去微调？其实在三四年前，大部分的AI的研究学者或者说科学家面对的是这样的一个问题，就是大模型到底怎么样去做微调，我不知道，所以GPT3当时提出来的这个in context learning才会有这么大的影响力。因为大家发现我靠原来不用微调，我先不去调整模型，我先单纯的让这个大语言模型自己去响应不同的prompt，就能拿到很好的生存结果。这个是大家当时没有想到的，也就是很多同学在讲的我的模型参数没有变，我到底在调什么，我这个in context learning到底在学什么？这个learning的主体其实是大语言模型，或者说我们用大语言模型的这个prompt。我们通过调整给大语言模型的，就能够取得更好的结果。
	这个是2020年的时候，我们绝大部分的大语言模型的使用者和研究人员发现的一个很好的一个事情。这个事情也就延展出后面的这个词，也就是prompt。我相信很多同学应该都都是在一个不是在ChatGPT，更多的同学应该是在纹身图的时候，第一次了解到这个prompt这个词的。
	那会儿其实在有GPT3出现之后，学术界也开始了解m from这是一个什么的东西。直到像硅谷的一些公司开始做出一些类似的产品，比如说这个Midjourney或者说开源的stable diffusion。那这一类纹身图的产品或者服务，其实是引爆这个prompt，以及prompt技巧from t工程的一个很重要的一个点燃的一个产品。
	类似的这些工具和网站也就变得很多了，像prom hero或者说类似的一些网站，他们干什么呢？他们其实就是收集一些用prompt生成的，用prompt的，然后和AI一起生成的一些AI的GC的产品，或者说AIGC的一些图像，把这些内容放在这个平台上，同时把它生成的prompt也放在平台上。当然如果我用的是这个纹身图的，比如说stable diffusion或者说Midjourney，它还会有一堆的参数。那这些参数我也会放在这儿，这些其实变成了一个你可以认为算是最佳实践的一个收集地，这些其实都是在我们能够做微调之前，大家群策群力发挥出来的一些想法。大家都在像这个地图探索一样，不知道大模型有多长多大的边界，所以我就各种尝试prompt，然后我有一段神奇的prot复制给别人，好像就显得很厉害，这个是很早期的状态。除了这种硬编码的这个prom的网站里面，我们就能看到有很多类似的像我刚刚提到的这样的一些产品。比如说这个是由这个stable diffusion的新版本生成出来的一个图片，它里面就会写这个是我们典型的prompt。并且我们会知道，不管是这个ChatGPT还是其他的大语言模型，或者说基于这个diffusion技术的这种生成类的文生图的模型，都能接受这个prompt。
	这个prompt本身的写法也各种各样。你像纹身图里面会有正向的prompt，也有反向的，包括一些其他的参数。在大语言模型里面，尤其是这个GPT API，它也在不断的去拓展文身纹，就是聊天室的这种大模型的这个prom的输入的类型，除了正向的以外有不同的角色，还有function calling等等，其实是一个逻辑，都是让我们的大语言模型的输入变得更多样，然后让他能够理解我们的需求，然后把我们的结果生成的质量更高，本质上是这样的一个逻辑。
	这种硬编码的prompt，除了stable diffusion，包括像人的生成也很多，并且会出现非常多的prompt，很长一串，像我们左边跟右边都是非常长的，然后里面还会有一些各种各样的tricks。比如说这个括号，这个括号其实是他跟他训练集有关，包括中括号，小括号等等。这些中括号、小括号，然后标点符号，其实我们写过年欠的同学就会发现，它其实是属于另一个层面上的东西。就是我们提示词模板就已经开始把硬编码的提示词模板化，然后开始做一些初次加工的这么一个prom的设计。我这边就给大家简单展示一下，大家有兴趣也可以去研究。
	刚刚是开源的这个stable diffusion，也有商业化的像media journey，生成的一些图像，像OpenAI的dw three，他可能野心更大，他在他自己的介绍里面会把整个纹身图做的更加的语义化一些。因为它最终的一个终点是想要去做跨模态多模态的一个生成。那在整个OpenAI的架构和产品规划里面，像这幅图，我们就能够看得到它不同的一些提示词，它带来的一些作用和效果。但这个是他的一个介绍，实际上整个大力税背后是不是按照他想象的这样，把这个提示词里面的内容就直接还原到这个图当中的某一部分，这个不太一定，就像这个sidewalks，包括这个corner里面有一个年轻的女人等等，这些是不是刚好就能按照这样的一个方式去生？
	当然是不一定的。因为我们都如果用过类似的这个纹身图或者说AIGC的产品，就知道里面还有一个很重要的随机化的一个种子等等。其实里面的随机性特别强，我们单纯能靠prompt想要把一个AIGC的模型或者产品玩的特别熟，其实是不太现实的。可能短期内你能拿到一些好的结果，但当大模型它的训练方法，训练语料发生了一个比较大的变化之后，其实很多你积累的print就没有那么。那么好的效果，这个逻辑也很好理解。
	就跟刀耕火种的年代，你积累了很多比如说你积累的这个锄头或者镰刀的使用方法，然后你也非常熟练了，苦练了十年，突然这个联合收割机来了，对吧？大家都开始用这个工业时代的新的产品了。显然这种硬编码的prompt，它的生存的生命周期就会慢慢受到一些消解。
	还有一种类似的，我们刚刚看的都是纹身图的。如果是纹身纹或者说大语言模型，AI agents类似的也是有很多的这种模板化的出现。就比如说能欠里面使用到的各种提示词模板，就很典型。比如说我们这里看到的这个auto GPT的prom template和这个auto GPT的class里面，关于prompt的一个组装就非常明显。
	在左边这一部分其实是这个能欠版本的auto GPT做的一个prompt的一个类。这个类里面的最开头部分很有意思，也值得跟大家讲一讲，就比如说这个from star这边有提到，your decisions must always be made independent。这里就是告诉这个大元模型，如果这个o GPT用的是GPT，那么这一段prompt就会发给GPT。如果用的是这个ChatGLM，那就会发给ChatGLM。但这个prompt本身在不同的大语言模型上，它的作用效果是不同的。这个我们刚刚解释过了，跟每个大语言模型的训练方式有关，也跟我们今天后面会讲的，因为它自己的PFT不同，所以它对于同样的一段prompt，不同的大语言模型，它的响应机制，响应的效果结果都不一样。
	那么回到这个auto GPT这里，它主要是通过这个开头的prompt，告诉这个大语言模型，因为要做的是一个auto GPT的应用，它是一个自主智能体。所以对于一个自主智能体来说，它的主要使命是，第一完成用户交给他的复杂任务。完成的方式就是第一就是首先把他的这个大的任务拆成这个小的目标。比如说我有一个大任务是今年要挣十万。那么这个10万可能把拆解成每个月挣多少钱。比如说每个月挣八千，那可能就变成每天要挣多少钱等等类似的一个意思。
	去做一个任务的参与者，然后拆解之后再去逐个查看每个任务他自己是否能完成。如果不能完成，应该需要借助什么样的第三方的能力。最后就是他需要去检查整个大目标拆成了一个一个的小任务，这些小任务有没有被完成掉，如果全部都完成了，这个aut GPT当前接收到的任务就完成了。所以这个开头其实主要有这样的一个目的。并且大家往后看能看得到有一个注释写的construct full prompt，这里其实就有写，真正对于他的RTGPT的设想。
	除了这一段prom start以外，这个是一个python的组装它前面还会写它有AI的名称，AI的肉。就是假设我有多个auto GPT的智能体，他也希望能够做好。但这一段prom的对大语言模型的要求很高。目前我们感觉如果一个单一的AI智能体能做到auto GPT，宣称的那样的任务就已经很好了。
	要到后面，其实整个prompt是一个不断组装的过程，到后面我们还能看得到，这里有一个goals，他把这个goals逐步的去做了一个拆解格式化，然后整个最后生成了一个完整的一个full prompt给到这边的右边的alt GPT去使用，这个alt GPT这边又会去给一些额外的指令。就比如说启动的时候会去判断下一个指令应该做什么事情。然后返回的时候要用一些特定的格式，这个特定的返回格式也是它自己有一些定义的，这个定义方便它把大语言模型生成的内容变成一个类似于这个拉姆达表达式，比较适合用于function call的一种自然语言的形态。它这样就能够去做一些处理，包括把最终的这个结果存到这个memory的系统里面，去判断当前的目标有没有完成。完成了我们就结束整个循环，大家看到这写个y two的死循环，那如果他没有结束，他就会去判断接下来应该干什么。
	其实auto GPT的底层逻辑听下来并不复杂，实际上也是如此，整个OTGPT的实现就是一个把prompt用到极致，把大语言模型的能力尽可能挖掘到边界的一个设想。至于他哪一天能真正达到这个像终结者一样的实现的状态，我觉得可能还很遥远。第一个是因为大元模型本身能力还需要不断的去提升，我们很多现在看到的大语言模型能够生成图像，但它和自己的这个或者说纹身图的和纹身纹的单元模型还没有整合好啊。第二就是说现在虽然能调用很多的第三方的API，但他的语义理解能力还没有提升到一个特别高的一个地步。这个我们从PFT的技术迭代后面我们也能看得出来，所以这些都是未来这些前沿的科学家还要去填的坑。但至少从这个auto GPT的实现形式上，我们能够理解通过模板加大语言模型，加上合适的一个实现，可能也就1 200行的一个代码，就能做一个alt GPT这样的一个产品或者demo了。
	好，刚刚我们看的其实都很原始，很手工。不管是纹身图，我们自己记下了各种各样好用的prompt，然后我们在网站上去找很多很好的prompt，还是说我们学会了能欠能嵌，可以有自己的prompt template，然后from temple ate可以用来开发一些应用。但是深度的能欠用户就会发现你同样的一个from template换了一个大模型就不好用了。或者说你同样的from template换了一个语言，从英语换到法语或者换到中文就不好用了，这些都有可能。这就是我说的这个prompt本身它还没有那么好，它还不是一个跟大语言模型的一个交互的终极形态的本质原因。
	既然如此，现在又不可能把prompt的立即干掉，我们就是得造各种各样的prompt。现在就是大语言模型太贵了，人还比较便宜。因为大语言模型训练一次就几百万，你换一个换十个人，可能一年的工资也才没多少钱。那么怎么办？那这个时候就只能去把prompt生成的质量更高一点。现在目前就说这个方法是第一时间我们能想到的方法，也是在GPT3当时提出来的方法。
	那怎么办呢？我们都知道我们学了AI都很，尤其是机器学习和深度学习，都很理解有一个词叫做data driven，就是数据驱动的，用数据大量的数据加上算力的叠加，我们能去学习出一些很好的特征分布。这个特征分布能使得我们去让AI学会做一个特定的任务或者特定的事情。这个是一个很重要的思维模式。回到这个prompt这件事情上来也是一样的。但这个学习让大语言模型去学习下游任务本身它的思想来源，其实也不是一下蹦出来的一个想法。
	这个应该学过机器学习的同学都知道，transfer learning，就迁移学习是一个已经存在很多年的一种做AI学习的一种思路了，在数据当中学习的思路，它的主要方式是什么样的呢？其实就跟这个图里面看到一样，以前的最早的machine learning，就比如说20年前大家搞的这些超参数很少的这些机器学习的传统模型。可能就是一个特定的任务。然后学一个特定的数据集，然后这个特定的模型就拿去做这个特定的任务。但是transfer learning想要告诉大家，就是在大数据集上面学出一个基本能力，然后把这个大数据集上面的基本能力记下来。就像经常我举的一个例子，这个大数据集学出来了一个大学本科生，小数据集上面学的是这个研究生2到3年的知识。然后你就变成了一个领域里面的研究生，那你就可以在那个领域里面去深造，要么是去继续进修，变成一个PCD，要么就是你到这个工作岗位上去学习一些工作岗位的技能，工作岗位的技能可能就是更小的data fed 3，就是这个数据集3。然后让你学会一些新的技能，你就可以把你的这个把人当成一个模型的话，他就能去干很多工作了，以前的task一你还能干，现在的task 2以及未来的这个task 3你也都能干。
	这个是transfer learning的一个核心，就是提升训练的效率，并且能够复用训练的成果，用更少的数据训练数据去使得一个模型能够迁移到不同的任务上。这个其实跟在大语言模型之前的机器学习时代就一直有。因为迁移学习本身就是这样的一个思维模式。
	那迁移学习在我们刚刚提到的，比如说像传统的CNN这样的网络里面，其实是非常好去实现的。尤其是在最近10年，有很多的工具，很多的论文，包括一些经典的backbone一些网络结构提出来之后，它都很好实现。就比如说这里是一个典型的CNN的一个网络，前面有三层的卷积，然后接了一个全连接层，然后又接了一个全年阶层，加上这个softmax去做一些这个后面可能就会接一些分类器，去做一些分类的一些任务。就这样的一个网络来说，其实我们要怎么样去做fine two呢？就像刚刚讲到的前面的卷积层和这个全连接层的任务。
	就今天我们来重新理解什么是深度神经网络，什么是卷积神经网络来说的话，因为有一些可解释性学习的进展，我们知道可能卷积更多的是去感知，它里面有很多感受。也更多的通过不同的这个层次的卷积，我能够去理解一个图像里面不同的位置里面的一些具体的目标。有的可能是区分出了颜色，有的可能是区分出了边缘和非边缘的部分。有的人可能是能够对一些特定的物体它能够激活。就像我们前面讲的这个注意力机制，后来被用到这个卷积里面也是一样的，它的可解释性比较强了。然后我们的全年阶层可能更多的是对一些文全局性的，或者说文本摘要的一些东西再做一些学习。
	因为有这样的一个分层，所以我们会发现，我们现在要做的一个新任务。比如说就计算机视觉的任务来说。一开始在image net上面学到了1000类不同的各种各样的物体的类别，我能够做图像识别了。然后现在我的这个应用场景可能是一个具体的公司，或者说一个学校里面的场景。这里面出现了新的十个或者20个不同的物体类别，这个类别不在原来的image net或者大的数据激励，那我要做的事情可能就是让他能够知道这些新的10到20个类别，它经过卷积之后，它的特征是长什么样的这就那个feature的那个vector这个特征向量是长什么样的，它的处理模式是不变的。所以在CNN领域里面，可能我通常是把卷积层给它冻结了，卷积层的参数给它冻结了。然后我去微调我的全连接层，就find two上面这部分，包括这两层的这个全连接层，然后通过我的这10到20个类别的小数据集，然后通过它的这个反应处，让我的新的这个网络，主要是变更了后面的全连接层的网络，能够认识新的类别。下面的卷积层不动，这个是深度神经网络阶段，我们很好去做微调的一个网络结构上面能够支持的一个情况，但是这个LR是learning rate的意思，就这个学习率的意思。然后这样的一个结构是方便我们能够去做微调的。
	但我们刚刚也提到大元模型，它就不太一样了，2018年的时候，这个bert就google的这个bert发布之后，你会发现整个bert的这个网络它不太像是一个深度，我们叫DNN深度神经网络，不太像是一个逐渐加深的一个网络，它又宽又深。跟早期可能在我印象中是1617年的时候，也是google当时出了一篇论文叫wide and deep，如果大家有印象的话，可以去搜一搜这篇论文。当时就是把宽把神经网络的这个宽度和这个深度结合起来的一篇网络，想要在广告推荐领域里面做一些迭代，但是这个最终没有落到生产环境里面，没有在工业界得到广泛的应用，有两个原因。第一个是说本来广告推荐要可解释性很强，要可以调，要为用户服务，所以它天然就不能能用这个可解释性比较弱的模型。第二就是它的运行成本比广告推荐，经典使用的这些逻辑斯谛回归，或者说多重的这种线性回归要高得多，它成本很高。然后运行一个深度神经网络，那大语言模型要运行起来，显然比我们刚刚提到的wide and deep的模型还要大上百倍甚至千倍。这样的一个模型它就不太能捋得清楚它到底不同的你说叫神经元也好，或者说不同的这个模块之间到底是什么样的一个关联关系，哪一块学到了什么？
	到今天为止还是一个非常热的研究话题，研究课题，就是我的大元模型，这个千亿级别的大语言模型，哪些部分的参数干了什么样的事儿，然后我应该去微调哪部分的参数，冻结哪部分的参数，这个是大家都不知道的那像bert，他的做法就是说我训练一个，这也是为什么bert跟GPT走了不一样的路。并且bert当时受到这么多人的喜爱和推崇。因为bert把自己摘出来了，就是我先不做一个端到端的一个大模型，我做一个语义理解能力很强的模型，并且他找的这个切入点也很好。因为到今天为止，其实语义理解能力也都是一个大模型的一个决定大模型上线的一个能力。因为很多大模型其实它的语义能力，语义理解的能力并不强。包括像P20，也都在尝试解决这个NLU的问题，就这个自然语言理解的问题。
	Bert当时是说我训练一个，大家还记得怎么样去训练的，这里也有写mask的sentence，我看还有同学在问，就是像人学完形填空一样的去学习这个知识，更好的去理解上下文。然后把这些上下文理解清楚之后，在下游的具体任务上再逐个的去微调这个模型。所以首先这条技路技术上是通的，但这条路它并不好走。是因为你训练一个bird成本很高，你可以训练好把模型的参数开源，然后大家都可以用了。但是如果我要用它，我首先需要把bert整体加载到我的GPU显存里，然后同时我还要去造一些新的下游任务的标注数据，然后再把这些标注数据跟这个bert一起去做训练。
	这个模式首先验证是可行的，但是它的成本非常的高，所以显然这个模式现在不是大家推崇的，因为不是每个人都能运行起这么大的模型。但是在18年的那个时刻是可行的，它和GPT3是一条并行的路，因为google发布了bert这个大语言模型，后面我们会看到其实很早期的这个adapter的toi也是google发布的。所以我们总结一下，bert最早期的应该跟GPT1同时代的大语言模型，它的这个模式预训练大语言模型就retrained language model加上fine tune，下游的这个downstream的task，这样的一个范式是可行的。但它最大的两个问题就是首先预训练的成本太高了，第二个就是说每一个下游的新任务，你其实都需要重新微调。而且这个重新微调是需要把bert完全加载回来，还需要去做数据。就这两个问题其实如果无法解决，这个饭是很难大规模的推开，那怎么办呢？总要解决问题。
	19年的时候，也就是bert发布一年，google发布了这个很很有意思的。大家其实看我们刚刚为什么要讲trans for learning，因为transfer learning这个思想其实被他们引用到这个领域里面来了。并且跟我们现在提到的这个parameter fiction ency，其实也是一个很重要的他们提到的一个词其实主要的问题是什么呢？就这边我标红的在他的摘要里面，高量的这些部分。
	第一就是说traf learning是一个很好的思想。但是在NLP这个领域，尤其是NLP走到了大时代，大模型这个时代，这个阶段，需要一些transfer arn，并且是高效的transfer learning。这篇论文主要解决这个问题。然后在这篇论文的右边这幅图里面，其实也有一个很强的一个对比他有把这个adapter，就是他这篇论文提出出来的这么一个方法。
	和这个top player，就是所谓的大语言模型。它虽然是说不清楚哪一块是干嘛的，但我们都学过上节课，知道GPT transformer的一个叠加，从这个十几层干到了GP3的将近100层。然后我们的bert也是双向的，by directional的transformer。
	然后其实像former也是一个神经网络，里面是由自注意力加上前馈网络叠出来的这么一个网络。那这个网络，始终还是有层的，这个层它不像简单的这个DNN或者那么窄，它又宽又高，它也可以去逐步的去反映出从top到这个from top down这样的一个过程，所以他也是能够去接触的。然后这个过程当中他这个冻结的越少，反触的这个层次从顶到底越多，就是下面这个X轴你能看到的就是它需要find two的越来越多，然后这里有一个X轴的说明，叫做我需要这个训练或者说反冲的这个模型参数比上这个任务的一个比值，而不是单独的需要去训练的这个参数的值。因为这个更简单来说，就是我如果要搞要让他做十个下游的任务，然后我需要去训练的这个模型参数可能是不平均的。因为有的任务多，有的任务少。然后它其实是把很多个不同的任务，做了一个算术平均，这样相对来说比较公平一点，也没有说哪个任务特别的难，或者说调的这个参数多，就权重大等等。然后这上面这根红色的这个线呢，其实是这个adapter自己的一个比例。然后他几乎把自己的这个adapter的表现水平，这个ACC波动做成了一个基准值。
	从这个数据来看，其实他想要说明的就是说通过这个adapter tuning这个技术。可以使得我们的训练成本，或者说我们的在大语言模型上面的迁移学习的成本能够大大的降低。一个最直观的感受就是说，我如果要使用fine phone去追上我的adapter tuning的这个效果，这个准确率，我需要繁重的参数会变得越来越多。而这个参数的增加其实就是训练成本的增加，就是我需要加载到显存里面的这个模型参数的量在增加，并且是数量级的增加。这里其实是100倍的一个差距，就这里列出来的一直到这儿，是一个一千倍的一个参数规模的差距，那在这个过程里面，他其实就干了这么一个事儿。并且他这里有一个比较，就是说在glue这个比较有权威性的一个基准测试里面，他从这个adapter的这个性能的角度，其实也就准确率这个角度跟完全的fine to full find to，就是说我没有任何冻结，我把所有的模型参数全部都拿来做调整微调比起来，这个只差了0.4%的一个差距。但是它使用了3.6%的模型参数，相对于每一个任务来说，因为最终是要在下游任务上面去看大家的性能高低的。
	这个应该还记得，bert本身不是端到端的，要微调到glue的各种下游的基准测试上去做比较。他只调了3.6%的模型参数，但是性能只差0.4%。这个trade off是非常夸张的，就是相当于成本只有原来的3%，那么性能还跟原来差不多，只差了0.4%。所以整个我们认为2019年这篇论文其实是有很多跨时代的意义的，也推动了PFT的一个研究，虽然他现在不是最好的途径方法，那他具体怎么做呢？
	我们展开看一看。就首先他是提出来了这个adapter，adapter最终其实也就是一个神经网络当中的一个小的模块。那这个小的模块在哪儿呢？在我们这个图里面我画了一个红框，我不知道大家能不能看见，就整个论文当中的这个截图，就是它的adapter的这个tuning的一个核心的一个说明。
	在传统的transformer layer里面，我们都知道transformer layer是encoder decoder两部分，encoder有两个模块比较重要。大家如果还记得，我们才刚刚讲讲过的一个叫做muti head self attention，然后接了一个fade forward的network，就是一个传统的经典的神经网络。然后如果我是decoder的话，是在这个基础上还接了一个mask。这个Martin had attention，这个是我们看到的经典的transformer layer。那在这个经典的网络结构上，我们看到这个multiply的attention加上feed forward network后面接了一个adapter，就是在原来的这个encoder decoder两个模块后面再加了一个模块，这样的这个模块就叫做adapter，然后我们知道这个transformer layer的encoder部分是前面部分是attention加上这个FFN，第二部分就layer nominalists，ation之后是只有一个FF的。这个如果大家不记得，可以回头再去看一看transformer的这个network picture。然后它其实就是在这个部分加了两个adapter，就这么简单。
	这个adapter展开来看是个什么东西呢？就adapter layer里面做了一个什么事儿？内部其实是有一个你可以简单理解成有一个高维的一个特征向量，这个高维的特征向量是这个FFN的，就是我们看到这里有2个FFN全连接网络，这两个全连接网络可能是假设随便说个数是一千维的，然后它可以把它变成20位或者30位的这么一个维度。那这个降维之后就变成了我们这里看到的adapt layer里面的更小的这么一个矩阵。那这个矩阵通过这个非线性，然后最后又会给它重新映射回这个高纬度。
	其实这个思路大家现在想想，跟na跟很多东西，其实都是这个思路。就是我在这个高维空间上面学，然后他很大，然后我学习的成本很高。那我有没有可能用一个更小的尺寸或者更低维度的这个特征空间去把它能用到的这些东西都学到手。这个其实是一个很很典型的一种解决问题的方案，在数学的这个思想上比较划归，就把很多你不能解决的问题，然后把它划到一个你能够解决的问题上，然后就能解决问题了，对吧？Adapter其实就这样的那通过这一步其实可以大大的减少参数，怎么理解呢？就是本来我可能整个FFN都要去做调整，甚至我的这个注意力层都要去做调整。那adapter tuning的point这个点就是说我不用去动这些FFN和attention的这些参数。
	这些参数很大，主要的计算量都在这儿。我只去改什么呢？我会改这个little organza，会改这两个，就是降维和升维，就做这个前馈神经网络到这个adapter这个模块，就相当于降维那adapter模块。回到这个高维度的前馈神经网络需要升为up project，就做这么个事儿，把这几个绿色的部分拿来做训练，所以它的参数大大的减少了。这里还有一个重点，就是我这么干会不会导致过拟合或者其他的一些问题，他就做了一个就是我刚刚讲的划归思想，就是以前的一些sota或者说经典的设计怎么样能够引入进来，这也是很好的一个设计。我们看到除了刚刚我们在右边这部分，看到的从pade forward到这个down project，到这个adapter这部分，再上去有一个非线性到up project，最后又回到fed forward的大的之外，还连了一条线就是旁路，这个旁路有同学在问有一种残差的感觉，这很好。其实他就是利用了这个残差的思想，就是使用这个step connection，就短链接。
	因为我们都知道transformer，大家都说大力出奇迹，暴力美学。你的renee t大家都知道经典的renee t也就五十多层，对吧？大家还记得GPT3把transformer干到多少层？把transformer干到了九十多层，那这个九十多层的transformer难道不比你当年的renee浅，对吧？那因为它太深了。
	我们都知道现在的大语言模型也好，或者说原来的深度神经网络也好。当这种深层次的神经网络需要训练的时候，一定会遇到一个挑战，就是梯度消失。然后梯度消失我们也讲过是它的有效精度问题，就是一个大元模型，它用这个浮点数来存储它的模型参数，也就是我们这里看到的所有的这些矩阵里面要存的这些模型参数。他通过这个back propagation就是反向传播去做这个迭代的时候，我会通过链式不断的去直接求导，然后把这个delta给它改回去。但因为乘的这个乘数太多之后，一直在小数点后很多位相乘，乘着就超过这个浮点数的有效精进度了。所以一定要解决这个问题，这个梯度消失的问题。
	这个梯度消失的问题，regnet提出了一个很经典的方案，就是这个skype connection就是直接连接。直接连接从数学意义的证明上，其实rs NET也做出了非常优美的证明，大家有兴趣可以去看一看，然后我也专门把这个截图放在了右边，简单来说就是如果我这一层大家可以理解成整个深度的神经网络，它就是在做各种学习拟合。然后可能这一层的时候它就是跳过去会比绕过这一段复杂的计算会更好。
	或者说他们俩的这个和就是FX加上X这个FX是指中间这一个小部分review，这个小部分就是你看这有一个权重，加上入这个激活，加上这个权重层，就跟我们这儿其实是类似的。然后这个add layer内部其实就可以当成一个小的FX，然后外面是一个X本身，相当于我啥也没干，我直接把它传到下一层去。这样的一个思想可以解决梯度消失，梯度爆炸的问题。同时也能把我们的这个训练保证它的一个你可以认为是一个兜底。如果我最后什么都没学出来，我还能保证我没有变得更差，我可以直接通过短连接连接回去，就算我这边的权重经过一顿操作都变成零了也没关系。这个是一个这个是一个很经典的一个引用了。
	除了这样的一个设计以外，其实还有一点是通过实验结果我们能看得到的。因为整个adapter 2它是在跟什么都没有，只有fine 2和这个全量fine 2的1个当时环境下去做的比较。我们能看到它还跟这个find top player过程当中，既有这个模型参数逐步增加，也会比较。
	还有一个就是这个learning rate，就我们开始提到的这个学习率的一个比较。我们都知道去真正去完成这个繁训或者预训练的过程当中，学习率是一个非常重要的超参数。这个超参数如果设计的不好，容易遇到很多问题。包括这个超参数的初始值搭配着什么样的优化器，都有一些小的讲究。但有的优化器是自适应的，整个我们看到右边这幅图能看得到的是adapters他自己对于learning rate相对来说是比较鲁棒比较稳定的。而当时的fine true，其实它针对不同的learning rate还会容易掉到一些局部最优解里面，这个也是他当时提出来很有意思，在这rate上面达到的一些成果。
	好，那么adapter tuning它的一些实验结果也表明确实很好啊，这幅图就是他选了不同的一些下游任务，这里有不同的下游任务，然后这些下游任务以bert的反应二作为这个baseline。所以我们能看到第二行这有一个bert base，这个反应two。然后它有一个叫做total number of parameters，有一个17倍，然后trained parameters per test，就是每个任务需要训练的这个parameter，它是百分之百，第一列这个是没有find的，bert就拿了一个bert过来，然后没有做过任任何的微调，就在各种任务上面去跑。这个是得的一个分数，所以它是相对来说最低的在各项任务上。而我们看到这个adapters，它有一个总量和每个任务的一个平均的这么一个量。从最终最下面这一行trained parameter ter protest可以看出来，其实只用了1%的训练参数，但是达到的这个效果其实已经很好了。
	我们看这个average就跟我们现在看大语言模型的leader board一样。就是把不同的下游任务都有一个得分，然后再做一个算术平均。其实是跟这个繁重的birth分数没差多少，就他说的这个0.4%这么一个差距。甚至在有一些任务上还超过了bert，比如说这个i line，比如说这个corporate messaging等等。所以其实adapter tuning当时是非常强的一个给大家相当于一个指路明灯，让大家理解其实大元模型也能够微调，然后也能用这个迁移学习的思路来做很多事情。他也贴出了更多的实验结果。
	这glue我们其实应该上节课讲这个大元模型的时候有也有介绍过这个基准测试就是一个评估，我们自然语言理解能力，就语义理解能力的一个系统性的一个benchmark。里面有很多个不同的小的benchmark，然后大家有兴趣可以去看一看。然后在这个glue的基准测试上，我们能看得到find home，整个大元模型和这个adf比起来，其实adapter处理有蛮多的优势。然后包括在这个具体的任务上，我们能看到这个adapter明显是在训练的总的模型参数上面是有数量级上的优势。我们大概理解了，其实18年有了bert 19年有了adapter tuning。接着2020年其实有了这个GPT3。因为中间这个过程当中，其实我们会知道要去做adapter tuning，要去做这个vert的研究人，那会儿还没有那么热，所以并不多。
	2021年的时候，stanford发了一篇很有意思的文章，prefix tuning其实是一个新的，相比于我们刚刚看到的这个adapter tuning比起来的话，是一个新的思路。这个新的思路我觉得是后续也引发了很多不同的研究，包括跟他的一些对比，也算是一个标志性的一个论文。包括stanford的这位lisa，也在后续有一些研究。
	整个prefix tuning其实要解决的问题还是怎么样能够把大语言模型微调的成本给打下来，就干这么一个事儿。要打下来，他自己提了一个方式，原文叫做轻量级的去微调大模型的方法，然后怎么样去微调，其实跟我们刚刚adapter不同，是在他的transformer网络里面欠了一个小的layer。这个layer放进去之后，让这个新的小数据集里面去微调的时候，只调整这个deter层的这些，我们刚刚看到那个绿色的方块。然后transformer的经典的注意力机制和前馈网络是不调整的。那这里其实也是跟他加入的这个方式有点不一样。
	我们看到一个transformer，他在find two过程当中，不管是bird还是GPT，通常都需要把这个全量的参数加载进来。就我们刚刚讲，这里他在transformer前面加了一个任务。你可以认为就是特定任务有一个特定的prefix，然后它它就是一个特定的特征向量，跟刚刚的adapter比较像，只不过它是加在了这个transformer的这个网络的前面，并且它的适用的就是我们这儿看到它的适用方式，或者说他最终实验里面用到的这些单元模型也略微不同。然后它的任务也有一些不一样，我们待会儿可以看一看，他选择了这个GPT two和这个bar这两个模型。
	他第一是讲我们把这个网络展开看啊，第一就是说它同样是冻结这个transformer的全部参数，并且比我们刚刚看到的这个adapter tuning还要夸张，因为adapter tuning其实还会动到一些，我们看到一些law layer的nominalists ation，会会其实会把transformer里面的一些计算结果会有一些调整。但他其实是说我transformer这部分的结果，我计算什么都不会变，我直接在这个transformer的这个网络层的前面再增加一部分的前缀，让它去生成一些新的token，然后这些token就能够去适配特定的任务。这个有点像什么呢？就是我们看到刚刚的这些手工的这些人造的hard prompt，或者说能欠的这些提示词模板，其实都是人在干perfect turning的这个活。你可以理解成以前前我们在一开始使用这个纹身图或者说南茜的这个提示词模板的时候，我们也不知道怎么样去写prompt，它效果好。所以人会怎么干呢？人会不断的人来去换不同的prompt，然后去跟大语言模型去交流。
	这个应该是ChatGPT刚刚发布前三个月，全球人民都在干的一个活。就是我跟他怎么聊，他能得出一些很有意思的结果。不管是让他去生成小说，还是帮我完成特定的任务，或者是调侃他。但这个事情其实很在21年的时候，stanford的这个研究其实就希望说我不是我这么傻，我人在花时间一条一条的去试。而是我能我直接把这个事儿用prefix tuning这种自动化的手段来去做。然后让它去生成一些面向特定任务的一些指令集，相当于我能造出一些特定的指令集，然后我就能在一些特定的任务上面，让模型生成一些我想要的一些结果。
	第一它同样是不需要去训练transformer本身的这些参数的。所以跟adapt ti一样，它肯定能降低我们的这个GPU算力和训练的时间成本。不过相比adapter tuning，它更好的一点是它都不需要去加载整个大模型。这一点是跟刚刚19年的这个版本比起来，非常好的一个优势了。
	大家想象一下刚刚的这个adam处理，虽然我把他们冻结了，但因为计算过程里面我需要涉及到，我们再回到这个图，这个是还是一个蛮关键的技术点。我们这个图里面因为需要计算adf的这些这些绿色的部分是我要训练的参数，因为我要训练他们，所以这些值会变。然后这些值它又不是孤立计算的，他会和我的这个transformer本身的注意力，和我的这个feed forward加在一起。如果我想实现的简单粗暴一点，可能我就得把整个模型加载进来，并且大概率也会得这么做。因为你不太可能是说把把绿色的这些部分放到显存里，然后再把这个呃transformer这个大模型再甩到一块这个CPU或者别的地方，那它的训练效率就会极低。你肯定是把它们都放到显存里面去做计算效率是比较高的。
	所以adapter其实是需要把整个大模型加载进来的，只不过它不需要微调那么多参数，这个是一个很大的技术点的一个区别。像prefix，因为它本身不需要，所以它可以大大的降低GPU的算力开销。然后就比较适合去调整那些千亿级别的大模型的。
	因为bird其实跟GT3还是有差距的，就相当于有了perfect tuning之后，大家会发现因为GPT3特别大，所以没法微调。那会儿跟19年的apter的场景又不太一样了，因为又变成了一个1000倍的增长。大家有有印象的话，GPT3的模型参数是GPT1的1 1000倍。
	那么GPT3怎么微调？不知道，OpenAI自己的论文是说的是你别微调了，你就搞in context learning。你就自己去造各种各样的提示词，让我的大语言模型去在上下文当中学习你想要干什么。这个其实是当时的时代背景，也是我们今天这一节的开篇，但是perfect turning使得我们可以开始去微调了。因为我不需要全部加载进去，我还是只需要加载这个prefix的模块，它的模块化的去加载，这个其实是prep IX的额外带来一个非常好的一个进步，这个就是prefix，那它具体的这个训练过程，这可能是复制了一个奇怪的图案在这儿。这不影响对他在这个训练过程当中，其实我们能看得到，原来的整个transformer的部分是这里的X和Y，就我们上图看到这个X和Y，它这里这里这个截图，论文当中这个截图是一行一行的看啊。那么上面这一行是一个GPT two上面做的一个summarizing的一个任务，下面是在BRT这个encode decode模型上去做的一个table to text这么一个示例。
	然后选了两个不同的网络架构，是为了证明这个auto，或者叫自回归auto regressive这个GPT这种decoder only，或者就叫自回归这种类型的网络架构和这种encoder架构，或者说google的T5也都属于这种架构。都能在这个perfect to I这种tony手段上获得比较好的收益，但是它具体要怎么训练，我这儿不展开了。简单来说就是我们看到前面有一个prefix，然后这个prefix它的这个取值怎么样去取的。其实这里就是在前面又套了一个神经网络，然后这个神经网络根据下游的这个特定任务去训练这个神经网络，所以第一跟我们刚才讲bert一样，技术上一定是可行的。只要你的训练技巧足够高超，然后你能够很好的去调整这个过程当中的loss值，包括这个优化手段。这个prefix是能够被训练出来的，并且论文里面也都提到了能够被训练出来。但是他没有那么好训练，就他没有那么适合没有那么多经验的人就训练不出来。
	简单来说，所以这个mlp其实就是一个神经网络，整个prefix 20，在这个过程当中，首先我们总结一下，它使得我们的大语言模型，千亿级别的大语言模型可以被微调了，因为它不需要加载这个大语言模型的全量参数，只需要坏化的去加载一些内容。第二，它很难被训练出来，即使它能够同时作用于这种智回归和这个encoder decoder的网络，但它是可以被训练出来的。不过它很难被训练出来，但它如果能够被训练出来，就像stanford的这些基准测试上面的结果，它的效果还是很强的。就比如说不管是端到端的这种基准测试，还是其他类型的基准测试我们看到整个这个表里面有对比哪些技术，比如说fine 2，就完整的去微调模型。
	Adapter有一个adapter 3%和这个adapter 0.1，就是我们刚刚讲到的这个adapt的技术和这个prefix，黑色加粗的就是它的基准，这是指表现是最好的。我们可以明显的看到prefix就是把这些比完之后，下面有一个这个prefix和这个find 2以及prefix tuning发布之前的sota就是最好表现。所有下面这一行加粗的都可以直接说明，这个prefix tuning其实刷新了N个很多个sota。
	所以其实你会发现，通过这样一个手段，一定是能训练的，尤其是在我们叫表格识别也好，或者叫table to text也好，或者是这种语义理解，这种文本摘要的特定实践上也好。都打败了当时的很多需要更高成本去微调模型的微调的技术，包括这个全量微调的技术。那么perfect tuning其实是非常强的一种手段了，但它也很难，这里是举了一些例子，就是怎么样去设置这个perfect tuning。我们可以具体看一下实验结果，实验时间原因，大家有兴趣可以去细读一下，从这个实验结果来看，在不同的基准测试上，我们通过不同的训练数据的规模。下面这根线是by 2，上面这根线是啊perfect ti都比较好，甚至是超过了当时的这个fine 2的技术。所以其实全量微调本身就很难，就是说大语言模型的全量微调本身就很难。
	这个事儿是我们在开营和第一节课时都讲过的。但是很多同学可能不知道他有这个多难，或者说它的成本开销有多大。也是为什么经常有同学一来就说我要去预训练或者微调大模型的时候，我会劝退的原因。因为这里的坑太多了。不管是数据的处理，还是说你需要的算力，以及你要投入的时间和精力的成本都太高了。
	我们能看得到这些PFT的技术在一遍又一遍的刷新全量微调的实验结果。所以其实怎么样去微调大元模型，就是一个在不断热门研究的课题。包括现在一些新的框架，在研究怎么样系统性的统一框架，少数据量去去把我们的大元模型更适应我们的下游任务或者某几类任务。这是一个非常新的研究课题。所以不太可能有大家想象的一招鲜，这个还是比较少的。
	然后包括这个perfect money，其实也是两年前的一个benchmark的结果了。但大家比较关注的重点，第一是我们一直在提的模型参数。第二就是我们的训练数据，能不能在更少的训练数据上达到更好的效果。在至少在prefix上面，我们看到在经典的benchmark上面，不管是小的训练集，小小的训练数据，规模还是更大的。其实当时的perfect turn都是比这个反应二还要好的以及他还对比了一个很有意思的事情，也是他自己的prefix的稳定性的一个表现。就是我们知道prefix，我们刚刚都讲了他的大概的网络结构是什么样的，然后训练出来的效果是什么样的。但最终要怎么去用它，就是我们从基准测试的结果，这个结果本身我们想象一下它怎么被测出来的话，就会有一个这就不得不提到prefix的另一个使用它的一个局限就是因为我们知道prefix是在你本来想干的这个任务的prom的基础上又加了一个前缀。那这个前缀也是要占token的，就是它是要占你的prompt，它会变成你prompt它的一部分。
	那那如果你现在这个prefix搞得特别长，你想象一下你的这个prefix，本来你的这个大模型只支持早期，可能21年只支持2000个2K大家不要觉得2K现在听起来特别小，其实ChatGPT发布的时候，它的API就只支持2K的这个token上线。假设它就只支持2K的这个token，然后大家看到上面这个右上角的这个prefix的长度，已经可以达到300了。如果要训练它的话，那如果我的perfect tuning搞的这个前缀占用的token特别多，其实是影响我自己的主要生成任务的。所以长度本身是一个影响，然后这个是摘要的生成，下面这个是表格识别的。显然摘要的生成，因为它涉及到的文本本身正文就很长，所以它需要的这个prefix很长，下面是这个表格识别，所以它本身需要的这个prefix还好，没有占用特别多。但无论如何prefix我们看到这个文本摘要在这个任务上，它不同的这个长度其实对于它的效果没有太大的影响。但是从当时的这个局限性来说，它还是会占用一定的token长度的。不过它的效果是相对来说比较稳定的。
	然后还有一个比较，他在论文当中比较就是说我可以在我们都知道这个transformer，它一层一层叠加起来的，然后最终那一层有一个embedding的一层。如果我在做这个prefect tony的时候，我本身其实我我大家还记得这个transformer的这个perfect 2是怎么加的，加在前面。那么如果我只加embedding的那一层transformer去加一个prefix的模块，其他的伸缩mer都不改，这个是一种可以突破的方式，我当然也可以去改很多层，这个是这种设计后面也会有，大家可以在我们看这个突然的技术演变。所有如果我只去改这个embedding这一层的这个transformer前面加一个前缀，和我这个层数越来越深比起来，其实能看得到，只是改embedding层的效果肯定没有后面的这些深层次的transformer这个prefix加上效果好啊，这个我们能看得到。如果我去加了这个in fix，那就在中间去做这个调整，和这个prefix比起来也是完整的。这个prefix它的效果会比较好啊，这个其实是一个实验的最终结果，尤其是在端到端的这个。基准测试上面的一个结果也很有意思。我觉得从直觉上能够判断的一点就是可能只改这个embedding层，不能让它整个transformer下面这些层的prefix被响应到，就相当于你只在最终的这个embedding这儿适配了，生成了一些好的prompt。
	但里面其实没理解到，没有这个prefix去承接，所以就没法去把它的最终的这个值改过来，这个是很有意思，包括他还做了这个初始化的一些比较，就我要去训练这个prefix这个模块，就跟我们开始讲的in rate有这个初始值一样。我如果随机的去设计一些这个prompt肯定不好，那最好是我有一个特定的开头，这个就跟大家说的所谓的prompt黑魔法有点像，如果我的初始化里面设计了一些很好，举个简单例子，你要让这个ChatGPT帮你做一个翻译的任务，你直接输给他一段话和你写了一个翻译冒号，肯定写了一个翻译冒号会更直接。这个就像他的prefix的初始化前缀是一个逻辑。如果我们给这个大语言模型也好，或者说给他这边用到的不同的单元模型都行，给他去做prom的时候，如果你的这个前缀你的这个前缀是一些特定的词，带有明确含义的，一定是好过一些随机词的。这个也很直觉上能够感觉得到，这个是一个对比。
	刚刚我们其实把perfect to讲了，但prefix to听下来就感觉很复杂。虽然它的效果很好啊，但是他他确实挺复杂的。我自己在看他的整个训练过程，包括一些网上研究，也没有特别多的人把他这个整的特别透。但是google在21年，其实也是同时期的就发了一篇这个文章就挺好的，就很优雅。这个优雅就体现在其实是把刚刚我们讲的这个很复杂的perfect ti做了一个简化。然后这个简化就是指我们刚刚知道如果我要用prefix 20这个技术，我的大模型有多复杂，有多少层transformer。我理论上按照他刚刚的实验结果，我都需要在对应的transformer层上面去加上一些prefix的模块，prefix的block然后再去做训练，然后还要去构造一些。
	因为我的初始化池对它也有影响，所以其实刚刚看到的初始化这部分，我是相当于还是有一定的手工设计的部分在的。就是你有一个特定的任务，那这个特定任务我要找到一些特定的初始化的prefix的词，对它响应会更好。这里有一些人工的部分。虽然整个这个过程当中训练prefix参数是自动化的，但是它的初始化值的一些设计，包括它的prefix是在哪些层，其实都还是有很多训练技巧在里面。
	但是21年的这个prom tuning其实很有意思，他提了一个新的概念叫做soft prompt，跟我们前面提到这种人硬编码的这些prompts有一个对比，这个soft proms也用到了它的T5这个模型上面。那他自己其实在这个摘要里面就写的很明显，我这边左下角也写了，就是他自己写到，他就是最近有人提出来的，就这个丽lisa提出来的这个prefix tuning的这个简化版本。所以其实这篇研究就某种层面上覆盖了大家去看perfect tuning的一部分这个原因了。
	Prom tuning它本身其实只是在输入层里面去加一些这个prom token就可以了。它最大的一个好处就是刚刚我们看到的那个prefix doing效果什么看着很爽。但它其实每一层的transformer前面加的那一部分都是一个神经网络。那这个神经网络要怎么样去训练？其实非常难。我们看到这个部分我再给大家回顾一下，今天可能会有一些硬核，就这里的每一个下游任务的prefix，这里其实都是一个复杂的多层神经网络，这个也是需要训练的，并且这个不是特别好训练，那怎么办呢？
	这个prom 2想了一个好办法，就是说我不并不需要加入太多mlp来解决这个来来解决突尼的问题。我不用加那么多mlp，我在输入层加一些token，然后就可以解决更好的去造出能让大语言模型响应特定任务prompt这样的一个模型，其实就干这么一个事儿。并且虽然他没有说我全面超越了fine two，但是他基本上已经逼近了这个find的结果。这个逻辑就跟我们刚刚听adapt处理有点像，就是我用一个就就跟我们写软件开发有时候也比较像。我用更低的软件开发成本，然后解决了一个可能需要比我高十倍甚至20倍的开发成本的任务。虽然可能他是100分，我是95分。
	这个是from tony的一个很重要的思想。然后这个思想有一个很重要的高亮的词就是这个scale，the power of scale for PEFT，他进一步的把这个词提出来了。PEPT parameter efficiency from ti，其实整个from tuning提供了一个非常好的思路，并且他也回应了当时OpenAI举的一个例子，就OpenAI当时在这个GPT3里面提到了。就是我去造一些自然语言的prompt一定会比没有造prompt好。我又不能老是来一个任务，我就在那抠脑袋的去想我应该造什么prompt，包括刚刚写的prefix 2I它的初始化也需要抠脑袋的去想。那有没有办法我可能就能够相对自动化的，连给他的这个prompt也能够被学出来的。这个其实是托尼当时提的一个非常好的思路，我们如果要总结来讲，prom two的这个主要贡献就是第一它能够以一个比较直观的这种自然语言来提示和引导这个大禹模型。第二就是它比较适用于那些已经掌握了大量通用知识的大语言模型，这个也就是他论文当中提到的这个the scale，就是一定要模型足够大，然后它本身的微调成本也比较低，因为它也不需要加载这个全量的大语言模型。
	这个比起adapter to do有非常大的一个进步，我们先把这个观点抛在这儿，接着来看一下怎么做到的，他要怎么样去做这个prom turing，其实跟他跟之前的这个翻译two，就完整的模型的微调做了一个对比，这个对比也跟我们开始看到的有一幅图。就是traditional machine learning，就这个传统的machine learning去解决不同任务的这个图很像，就是传统的机器学习没有这个transfer learning的时候，其实我是每一个不同的任务有不同的训练集。将这里的task a批量的3种不同的task就训练出不同的三个模型，全量的三个模型。你们能看到这上面有一个预训练的模型，110亿的参数，然后task ABC也都是全量的110亿参数的模型，所以你有多少任务就得训练多少个这样的模型。并且bert其实也是这个模式，我们讲到的这个adapter也是这样的模式，然后包括像刚刚的这个prefix，其实也是这样的模式。只不过它训练的时候不用把这个全部加载进来，它这个前缀是单独训练的，但我要用的时候还是得加载进来。
	那么我们看到的这个prom处理是怎么干的，他比较有意思。第一他搞了一个新的一个外部的模型，就跟我们刚刚看到的pre fix还要更进一步了。就是我们刚看到prefix是在transformer里面加了一个prefix的前缀的一个模块，那它直接是在预训练模型外部又加了一个新的模型，跟我们的预训练模型是隔开的一个新的模型。并且它的训练过程是可以把不同的任务放到一起的，这个是很牛逼的。就是我们看到刚刚的perfect tuning，包括adapt tony，其实它还是要不同的任务在同样的模型上面去做反应送的，只是说我不用动那么多参数。
	现在是说好你有三个不同的任务类型，你们都拿过来，然后我一起来做这个prom的图案来训练，然后这个过程怎么做的呢？其实简单来说就是他自己需要去设计一些提示。当然这个ABC还是要手工设计的，这个ABC需要手工设计。但这个ABC手工设计之后，你要在新的这个场景里去用的时候就不太需要了。任务是ABC3的任务里面有一些最佳实践的A1A2B1、C1C2，通通通放进来，当然你也可以用一些别的方式来做这个A1A2的生成，然后把这些东西都放进来之后，他直接去学习这个就相当于任务A应该是哪些这个prom我举个大家好理解的例，就相当于咱们要去做这个PPT，做课件，然后这个课件不同的领导或者说不同的场景，他可能喜欢看的这个模板什么的是不一样的。他把这个大的类别任务类别区分出来之后，然后他再去学一些case study，一些最佳实践，但是都是由一个人在学，然后最终能学出这样的一个模型来，这样的一个模型差不多就是这个两万这个parameters就可以足够了。
	那么这样的一个模型训练完之后，其实。它可以有一个最大的好处是什么？第一，它不用动原来的那个大禹模型。第二就是说这个混合的新的from to出来的小模型，它可以解决各种各样的任务。你这三类任务可以，四类任务也可以，五类任务也可以，他不再需要再从头来过了。甚至如果你有一个A心或者AP是这个任务的小的变种，它如果训练的够好，说不定也可以。
	那这种技术其实是可以往更通用的下游任务去走的一种模式，并且这个跟我们周日要讲的一个instruction tuning其实是啊有一定重叠了。就是他开始往这个指令微调这个方向上去走了。然后指令微调更多的其实就是开始让大语言模型去更多的去提升和关注这个语义理解层面的一些工作了。那么from还没有from还是更多的是怎么样让一个自回归或者一个生成类的模型按我的需求来输出。
	然后这个prom tuning，它的一些比较是什么会影响prom tuning呢？它自己的一些对比在prompt的这个长度上面很有意思。就是如果我们有这个prompt，然后我们的prompt只生成了一个token，只有一个。就比如说翻翻译可能都会占到2个。比如说这个转换convert，或者说这个revert，或者说delete remove之类的这样的一些prompt，它都能够达到一些还不错的效果。
	就是我们左上角看到这幅图，我们能看到这个是一，然后长一点的是这里有个像这个加号，是五个proof的这个nse当它是20个的时候就表现的非常好了，在super glue这个benchmark上面。所以prompt一也还行，有一定效果。然后如果它的长度是20的话，性价比贼高。你因为你看到这个100甚至150的这个prompt，也就那么回事。然后第二个就是它的初始化，当然跟刚才一样，你随便随机给的东西肯定一般。那么你如果去有样的去从这个字典里面去抽样，或者说你干脆给一些这个类别的标签，那它的效果肯定是挺好的。
	但是比较有意思的事情是什么呢？就是当我们的模型规模到10的10次方，这个random的uniform好像也就跟大家一样了。并且大家注意到没有这个prompt nance也是一样的，然后预训练的方法也是同样的，预训练的方法和这个微调，我们微调到底要选要选什么样的这个step。最终你们会发现这个图里面最有意思的一点是十的10次方。
	这个X这一列几乎无视我们所有之前对于托尼的理解。就是我们不管是from nance要怎么调整，还是我们的这个initialization，还是我们的预训练的方法，只要我的模型足够大，我几乎就能够让我的这个prom turing达到一个差不多的效果。这个是很有意思的一个结论，也是后面我们会发现我不知道google的这个palm搞了五千多亿有没有这个原因，但至少这篇论文让大家发现，我靠就是大力出奇迹是存在的。就是我的很多原来的所谓的在经典的深度学习领域，CV领域的一些fine tune的这些技术，到这个足够大模型上面就失效了，就没有用了，都能够达到类似的效果。这个是prom turing很有意思的一个点。好，我们先稍微休息一下，然后大家有什么问题我们回答五分钟的问题，然后我们接着再去讲这个P20的这个V一和V2。
	看大家有什么问题。
	我正好接杯水。
	好，我们来回答一下那个问题。前面有同学说那个残差就是adapter tuning那边是有引用这个残差。然后大模型的垂直微调领域是未来的方向，这个肯定的。因为大模型整体要去调整太贵了，肯定是精雕细琢，尤其是针对特定任务来处理是比较好的。然后不需要每那个perfect doing，应该不需要每一层都设置一个loss。我看还有什么问题。
	有个同学问，这里说的翻译出来调模型是指全量吗？其实我整个今天目前为止讲的这几篇论文里面都有去比较，尤其是像adapter里面就有比较，它有一个特定的词，大家回看课件的时候可以看啊，就是那个find这个top player，其实就是指它这个反冲也是从顶层开始往下调，简单来说就是跟最终输出层比较近的位置开始做反冲。下面的不动逐步的往下调，一直调到整个模型。然后它的这个X轴有几幅图，就是指这个过程，它的效果怎么样。当然在比较早期的时候，像19年、20年、21年的时候，这个翻译two还是说调的越多可能效果越好，因为大家也不知道怎么样去做金条。尤其是他这个翻译本身也没有去做各种各样的金条的手段，就是拿着这个数据去刷这些模型参数而已。
	然后这个from tuning还是会增加执行任务的模型token数。是的，它会有一些占用，它会生成一些这个模式固定模式的token。因为它本身就是一个简化版的prefix的处理，它只是简化了这个过程，但它的这个实现方式上，最终达到效果的方式上还是一样的。它会跟就像你训练的时候，它会有这个nars的一些区别。像我们刚刚看到这一页会有这个nars的区别，包括它初始化的选取上也会有一些区别。但他可以用class label和抽样的这个vocation ary来做了也不用手工的去造各种各样的词，然后这个大元模型的微调的部署，它也能做一些调整。我们再来看看。
	然后prom turning是在大元模型前面，再再增加一个模型吗？如果是的话，它的输出是什么？是的，是再增加一个是token对。有没有办法将还凑合的大模型针对某个层垂直领域做微调以后，形成一个比较小的模型，然后私有化部署。这个属于模型蒸馏和压缩。
	就有个同学问，包括量化都是实现你说的这个效果。就比如说有个大模型，它是千亿的。然后你把它做成这个int 4的量化了，可能它就只占原来的10分之1了，那它就变成相对来说的小模型了。Int 4的这个模型参数在有一些硬件上其实是反而不一定有这个float算的快。比如说一些NPU. 
	之类的。
	前面讲的这些微调的方法很多，需要构建额外的神经网络模型。这些神经网络的构建有什么讲究吗？只知道模式，想要浮现出效果感觉也不容易。第一就是说这些神经网络很多都是经典的神经网络，更多的是他训练的时候一些超参数和数据处理。然后你要复现也挺简单的，就是今天讲的为什么选了这几个？是因为这几个都在hugin face的PFT上面有复现的，是可以直接用的。是，所以咱们不用担心怎么实现这几篇论文都有实现的。就在这个PFT也是我们后面会去讲的，怎么用这个PFT的库，用这个P2的V2来这个高效微调TGM36B也是用的这个库，也会用它官方的一些一些相关的内容。
	非fix可以用来训练非开源的模型吗吗？要加在每个transworld前面的话，只能针对网络架构开源的模型。这个非开源的模型这个同学是指什么？是指像GPT吗？就我们这儿讲的find two肯定都是指你能拿到模型文件和模型的，不然你没有这个fine tone的意义。目前除了GPT的这个fine tune的服务以外，应该绝大部分的fine都是你自己能够拿着模型部署然后翻译的。然后bert擅长理解，GPT擅长生成，两个结合起来的效果如何呢？下面有同学回答了，我就不回答了。
	然后不懂不是很懂prom 20是在做什么，输入是什么，输出是什么？可以举一个具体的例子吗？可以，这个同学问prom tony，就比如说task a是翻译，或者说task a是英语翻译成中文这样的一个task a。我们看到这个proto，这个task a是音译中，然后这个AE可能就是或者叫中译英。中译英中文翻译成英语，那这个AE可能就是叫做翻译成英语，这个A2可能叫做译成英文，A3可能叫做translate into english，这个就是task a batch里面的这个设定。
	那么task b可能是生成python代码，或者就叫生成代码。因为这个就是我说的，你的task本身的设计会决定最终的通用性。假设你的task b是这个task b是生成python代码，那你的B一可能就是叫做写一段python代码，或者这个B2叫做生成一段python代码。如果你的这个task b是生成代码，那你的B一可能是生成java，第二这个B2可能是生成python，b3可能是生成这个。谢大家。
	当然生成这三种代码本身要用到的能力不一样，哪种好得得看你用的什么样的预训练的模型，以及这个预训练模型在代码生成方面的能力如何。我不知道这个例子举清楚没有，就这么个意思。然后接着你要去做不同的task的时候，因为你最终你要用这个大模型，你要应用的场景是，你知道现在要生成的这个是这个活是大的A还是大的B还是大的C这个任务类型你是知道的我们是有类别标签的，这下游要做什么任务？
	然后prefix的方式，目前实际项目当中用的多吗？不多。因为lisa她自己也迭代了新的论文了，大家有兴趣可以去跟进一下stanford这一位的研究。但是他的这个思想很重要，而且他也是通过prefix tuning干翻了这个翻译2，对吧？就说明单纯大力出奇迹队算力的3Q全量3Q不一定干得过这个有巧思设计的这个发音图，各种各样的ti，prompt tuning，这个是一个很重要的结论。
	然后prom 2这篇论文最大的结论就是scale很重要，scale也是OU need对吧？像腾讯也是OU need，scale也是OU need。所以palm干到了5000亿对吧？快1万亿的参数。后面我们会发现像LORA出来之后，这个模型参数虽然很大，可以以量换质，但是罗尔也可以以质换量。
	我们最后再回答一个问题，马上九点半了，大的ABC指的是大的分类，小的A1V1C1指的是具体的细分类。不是，大的ABC指的是你的任务类型，小的A1B1CE这些东西是指你给大语言模型的prompt，你设计的这些prompt，这些prompt可以是手工设计的，也可以是让大元模型来生成的，都可以。就是那些小的A1、A二是喂进去给它它用的prompt。未来它也会针对你的特定任务去生成这些A1、A2、A3，不过这个是生成的一些A1撇AA21撇，不一定是跟你训练经理一样的。但是因为你训练了这个任5和A一的这种数据，所以未来针对不同的任务它能生成比较好的结果。
	好，我们在剩下半个小时来讲讲这个P20以及Laura，可能今天也就只能讲到Laura。好，那我们先讲讲到那儿我们大家再来提问。P20是2021年的跟这个prefix和这个prom同一年发的一篇paper，是清华和MIT一起发的一篇paper。也是唐杰老师团队的一个作品，还有杨梓琳这两个大家关注大模型的应该都知道。杨紫琳月之暗面，然后也是当年在谷歌做了很多bert相关研究的一个华人，很厉害。然后唐杰老师，他们都是姚班的，清华叉院的。所以有些连接，然后整个p tuning其实都是中国这边团队主导的一个tone技术。
	好，然后我们看到这个P20V它要解决什么问题？就是我自己的打的这个标注，首先它是要解决人工设计prom的问题，这个是我对他的一个远大目标的一个理解，包括他论文当中自己也说了，我们看到这个摘要里面说的很清楚。对于一个预训练的语言模型来说，给他一些prompt，让它识别一些自然语言的模式，是对于它来理解自然语言是很有用的。但是但是比较关键，但是可能你给了他一个prompt，有十个十个的十个词，只要有一个词没有搞好，可能对它的性能影响就是灾难性的。他写的亲近。A single word in the prompt might result in substantial performance. 
	Job, 这个其实我也挺好理解的。大家想象一下，为什么说在这个饭桌上有的人一开口这个场子就凉了，对吧？可能他也没说错什么，他就那一两个词没说好，大家接不住，对吧？其实就这意思，就是有时候就那一两个词，它权重不一样，它位置很关键，它就影响了最终的这个结果。确实如此，因为整个自然语言人类的表达就是这样的那那既然如此之关键，这么重要的一个活儿交给人手工来做。因为训练这个，刚刚我们看到prom 2其实已经简化了很多prefix 20要做的mlp训练的工作了，然后也不需要训练那么多层，但是他仍然需要去造一些手工皂，一些task和这个task对应的prompt，来做预训练，来做这个fine to做这个from two 0，这个是第一件事儿。
	第二个事就是说刚刚的那些技术还有一个缺点，也是p two你想要解决的。就是我们看到prom ti也好，还是perfect ti也好，他们其实都是按照叫做frozen broken这个language model。就是把大语言模型本身是冻结的，就是我干这个perfect 2或者干from的，我就是不去调大模型的，我就固定了，那边不动的，我只调我这边的事儿，大家都知道，训练过的都知道，这样会带来一种风险就是过拟合，对吧？因为你这个小模型挺小的，如果你兑了一堆的数据在你这个小模型上，那你有没有可能就过拟合了。这也是为什么也可能动刀一件的利益，就是这个打榜搞这个benchmark，后来在大模型这件事儿上，其实是挺挺值得需要去客观深入去考察的。就是这一点。
	你想象一下，你要去刷榜，然后这个榜里面的这些训练集、测试集你是不是都能拿到，然后你就用from ti的手段，把这个榜单里面所有的prompt都拿去给他做prom tuning了。那你说你在这个测试集上表现能不好吗？但凡你搞了一个千亿级别的大模型，然后你做一个pro tuning，你在这个leader board上面你就分数能挣很高。这个没啥好说的，这个原理就是这样的，scale足够大了，它的大元模型针对你特定的就是能响应了，那响应的效果就是好。那这有什么好说的呢？但是这里就会发现benchmark也在迭代。
	为什么现在有的benchmark只是靠响应是做不到的？因为他这也是什么instruction tuning这条路线后来能够发展起来。因为即使它的这个scale再大，如果有一些基础能力它是缺失的，你就算给他搞from他能力也是搞不定的。就比如说你要让他去做复杂的数学运算，他就算把这个题理解的再好，他做不来。他他变了几个符号，或者说需要更复杂的多层次的推理之后，他就做不好了。像现在一些比较常见的benchmark，也就是做个小学数学应用题，你做个高等数学的题还挺恼火的对，很难做，必须要人跟他多轮对话才能去做出来。那这个是展开来说了一点点不多了。然后我们回到这个P20，他要解决什么问题呢？就是第一我不在人来造这些东西了，我能够把这个提示词本身变成一个可以学习的一个新的layer，它叫做invading layer。
	然后这么做这个思路是可以的，但是这么搞之后也会带来两个新的挑战。第一个已经通过预训练优化过的这些正常语料的嵌入层，也就是我们所谓的预训练模型的embedding layer，和我们即将要去学习，就把这个prompt放到这个embedding layer之后的这个新的layer去一起训练的话会怎么样？这个学习过程当中能不能调整好啊？这里的这个离散性主要就是指因为预训练模型的这个语料太大了，而我们现在要做P20的这个语料很小。然后我们现在要去做这个invading layer的这个微调的时候，会导致一个问题是可能我的语料丰富度太低。然后过拟合之后，原来本来这个大语言模型的in bedding layer，它的这个知识是很丰富的，它能把各种各样的语义invading出来。但因为你过几何了，导致可能预训练模型本身有一些能力还被你削弱了。这个是有可能的会导致陷入一些局部最优。
	第二就是说提示这个嵌入之间的这个相关关系比较难去捕捉，这个我们可以回头再细讲，但是第一点大家应该是很好理解的。好，那我们具体来看一下他怎么做的，一个例子来说明，让大家比较好理解。上面这种叫做prompt search，简单来说就是比较野生原始的搞法，就是我要去搜一个比较好的出来，不管是人造的还是怎么样的，反正就是人或者说一些其他的手段来做的，不是我自动去学出来的。这个from都可以当成上面这一类，叫做prom的设计，一些离散的。因为它不是一个连续变量，也不是连续可微在学习，而不是在learning出来的。而下面的这个叫做prompt encoder，也就是大家在这儿看到的，它有一个叫做伪代码一样的这个prompt跟上面的这个离散的一些，就是你像就相当于你拍脑袋，不管是你人拍的还是谁拍的，反正上面的这个from generator都是一些离散的一些值给你生成出来的。但下面这个是连续可微的。是可以去做这个back propagation去学习的，放到我自己的整个大模型里面去做learning的。这个是他们的一个大的区别。
	好，那么怎么样去区分他们，首先我们看这样的一个例子，这个例子也是论文当中的一个例，叫做the capital of britain is mask。这个完形填空又来了这里要干什么呢？其实就是我们这里三个不同的颜色代表不同的意思。首先红色的这个东西是要填的，就是要让单元模型。去生成，去填这里是什么，然后通过上文给下文。这个蓝颜色的这个是关键的这个context。因为其他的都是一些你可以叫给他的一些prompt，一些task，一些任务。但英国如果大家用过门前就知道，这肯定是那个变量了，是那个variable，这个是很重要的。剩下这些都是template from time plate。
	然后通过这样的一个事例，让我们来理解怎么样去生成这个，或者说让大语言模型得到这个区域，就是橙色或者说红色这个区域这个词应该是什么？如果是在上面这个流程里面，他只能接受一些离散的奖励。因为他是额外去做的一些训练，他跟整个大模型之间的没有什么关系。但是我们的这个P20，我们刚刚有讲它是在input embedded ing这一层，就是我们原来的这个模型的这一层，加了一个新的你可以简单理解成就是把我们需要训练的这些p tuning的参数加到evading里面来了。然后加进来之后，它可以跟着我们这个任务任务的输入，然后任务的输出一起去训练这个H本身。
	那这个其实是跟原来的prefix和这个prom 2I一个很大的区别。第一他们还是在模仿的去生成一些指令，这个是一样的。但是他加了一些额外的embedding，这个跟原来是有一个本质不同的，你可以理解成原来的prom和prefix，其实整个大语言模型的embedding层它是没动的，当然prefix可能在前面有加一些前缀但是是加了一个mlp需要去训练。P20其实是直接在embedding层里面去整体去调这个embedding ing里面的这些模型参数了，然后prefix它它也会加，但是它的训练过程很复杂，需要用多层感知机，就mlp也就神经网络来进行初始化，然后再各种各种搞。然后只有在这个过程当中，你还很难的去把那个mlp调整好。但P2Y只需要去把这个in bedding加新的一些参数，很简单的一个套路来做整体性的训练，就能去调整这个encoder了。
	其实就是他自己造的一个词一个概念，叫做prompt的encoder，就是把我们的原来尾的这个prompt，就这里的P0PI变成一个新的evading的结果。大家知道这个encode的这个过程，其实就是把prompts变成这个神经网络的参数。所以它取了一个名字叫encoder这么一个逻辑。而generator这边其实是靠一些各种各样的手段直接生成一个特定的词，这个是他们的一个区别，然后这个区别在当时的这个实验结果上来看，取得了非常好的一个成果。第一个就是说我们看到在这个bird，这个109M也就是10亿和bert large 3亿的大语言模型上面，其实它的P20是取得了非常高的加分，你可以理解成就是他的这个benchmark上面得的这个分数是非常高碾压型的一个存在。然后这个micro应该是微软当时比较有名的一个大模型。
	我们有技说的话，包括在GPT2上面也获得了一些非常好的out perform，其实就是把原来的很多的得分都干赢了，包括这个准确率，这个其实是一个非常夸张的一个结果。简单来说就是大家没有想过用一个这么简单直接的一个手段去改造这个evading层，就能获得这么好的一个收益。并且这个训练过程和思路并不复杂，就能达到一个这么好的一个结果，包括他在其他的一些跟全量微调的和大规模的全量微调的大语言模型的对比上面，我们也能看得到，它p two 77.8，这个全量微调的77点点2。然后在这个GPT two上面，刚刚那个是bert的这个large，在GPT two的这个中号版本不最大号版本上。也还获得了很好的一个成绩，甚至超过了他的一些繁重的成绩。这个其实是挺让大家觉得匪夷所思。但是又又这个结果挺好的，就是相当于一个很巧妙的方式，让大语言模型的inviting适应了新的你的具体任务。
	这个逻辑有点像什么呢？有点像我们开始讲的计算机视觉里面全连接层的这个反应。好像一下让我们的一些具体的新类别，那个新类别里面的特定最后卷积层输出的这个feature map应该长什么样的一个排列组合，它识别出这个pattern了。识别出那个pattern之后，他就真的认识了这个类别在像素层面上是长什么样的，这个P2也有点类似，就是我有一些特定的这个task，然后这个特定的task我有一些prompt可以去引导它。然后我把这个proms直接豹变到它的这个invading层之后，它其实是理解了这个evening本身，而不再是在某一个特定的单词上面。其实已经开始朝这个语义的方向去走了。
	为什么？就我们讲emb ign有一个很大的点，就是它它有这个统一语义的功能。我们在上节课讲word White时候也有讲类似的，就是中文英文的word vest，你去做这个什么的king queen，然后man woman的这个向量操作，它得出来的这个等式是差不多的。就是因为evading其实本身就有一定的语义提取的能力，而你把这个prompt不再做到纯自然语言层面，因为自然语言层面你要把它变成一个token。这个toga ization做的好不好跟它的编码有关。但如果你直接在invading层面上面去做一些操作，那其实是绕过了一定的问题，提取了一些更本质的语义信息，那自然它的表现肯定就更好一点。
	因为相当于你把茴香豆的4种写法都整明白了，你知道他在写茴香豆，而不是不只是说这个茴香豆到底有N种写法，还是几种写法都无所谓。因为最终是那个特定的实体是最重要的，那个实体有几种写法，最终都表达的是那一个实体的含义，这个是我个人的理解。我觉得可能是这方面达到了一些很好的效果，然后在跟这个prom 2I也做了一些对比，就是跟刚刚我们上一篇讲到的google的这个prompt 20，显然在很多的基准测试上，尤其是RTE，CB等等这几个典型的基准测试上都取得了很好的一个成绩。甚至他后面都不跟这个from two 0比了，这个其实是很很好的一个结果，也是纯中国的团队研发的一个结果。包括跟这个future learning去做比较。因为我们知道few shot是比这个server shot的效果要好的，但是跟fuel shot这个fine tune去做比较的话，也没有差太多，甚至有的还更好。这个其实是挺强的。
	然后接着就过了一年，这个P20V2出现了，进一步的去提升了这个P20唯一的一些或者说解决了一些它的局限性，什么局限？这边我一开始就写了，就是prom toi其实说了一句很重要的话，叫做scale很重要对吧？Scale is all you need. 
	就是你只要规模足够大，然后哪怕我是手工设计的各种模板，我只要设计，我花点心思它在特定任务上就是能响应的。好，因为大模型本身太强了，它的十的10次方的这个模型参数能干任何事情了，几乎在benchmark这个事情上。如果模型没那么大怎么办？就模型没有那么大的时候，你会发现这个prom tuning就没那么好使了。你那四个它的这个prom的长度，初始化的这个词的选取，包括你模型微调的这个step等等，这些东西都会影响from tuning的效果。
	类似的其实P20V1也是在小模型上效果不好。PV21来就讲了这个问题，就是我们看到这里有一幅图，就是330M这个应该是2B10B不同尺寸，这个在我们今天看来都小模型，在当年还挺大的，但22年就不大了，2022年的时候，十币的这个100亿两这个100亿、20亿这个规模的模型有3种不同的手段来比较他们在各自的基准测试上面得到的一个平均分。我们明显看得到这个P20中间这个蓝色的在越小的这个规模上，它其实表现是很一般的。在十币的这个规模上就百亿级别，他才能够跟大家的这个通灵技术差不多，跟F2跟P2的V2差不多。但是P20的V2其实是不care这个模型的大小的，在一些小模型上它仍然能达到跟fine two类似的效果。所以即使到22年的这个P20v two，我们都能发现大家都没有说我能随便干一翻一听然后他也只是说跟樊新闻差不多，但是成本会降很多。
	所以整个P200的这个V2版本，第二代就是为了解决很多问题。具体就体现在小模型我能解决了，然后多任务的微调的质量我也能解决了。所以从这个论文的标题我们也都能看到到，就是我们的prom能够在不同规模和各种下游任务上，都能达到find 0的这个效果。然后之前的P20V1主要就是刚刚讲到的这两个环节上做的不够好啊，那他具体怎么搞的？
	就是为什么P2的V2也就是我们课程的实战里面会用到的一个通灵技术，我们会用这个P20V2来微调这个chat GM3，那它有一些什么样的特定的技术点？这幅图跟刚刚那幅又有点像了。大家左边是我们上一篇论文P20唯一的这个图，大家有印象的话可以看一看。下面是一个大元模型，然后optimize，这边有一个叫做prompt encoder，这个prompt encoder下面这一层是它的embedding layer，然后他干了个什么事儿呢？第一，他干了一个叫做the parameter ization，叫从参说话。在这个prefix和P2当中都用了这个神经网络来构造这个embedding ing。我们看到这里在prefix里面也有，只不过可能prefix的这个mlp那个神经网络整的特别复杂。然后p two 0也许稍微简单一点，但是都要用来构造这个输入。然后在这个P20v two的一些实验结果里面，他们会发现针对不同的任务和数据集，用这种手段可能会有一些适得其反的效果，尤其是在NLU这个领域，就是这个语义理解这个领域，所以这里做了一些从参数化的一些操作，就不是是直接去做这个调训练微调，然后在每一层这里的每一层。然后第二个就是它的这个提示时的长度，就它针对不同的任务对应的这个最优提示长度是不一样的。
	这个肯定很好理解，就是我们刚刚讲的，我让他做一个翻译的活，其实你就写一个翻译，或者说英译中，或者这个translate，但是后面输了一堆中文，大家可以去试一试。这些提示词，就手工皂的，但是能得到很好效果的就是你要translate，然后你后面跟一堆中文，大概率ChatGPT会帮你翻译成英文。然后你说翻译，后面跟一堆英文，它大概率会给你弄成中文，就这些肯定都是优化过的，但是这就一个词就够了。如果你要让他帮你去什么生成一个日报，就像我们上次讲的，生成一篇日报，那你是不是给提供更多的信息？因为它本身就是一个相对更复杂的任务，不是一个那么简单的任务。比如说你要让它生成一个代码，帮你去第bug，那都不一样。那它的这个prop ince的最优值肯定是不一样的。然后这个我就不用再过多解释了，这肯定是大家能理解的。
	然后关于这个marty task的这个多任务的学习，就是它的这个架构设计里面，使得我可以去选择我要不要去做多任务。我可以一开始去做这个单任务的学习，那如果做单任务的学习，也就一定程度上解决了prominence，可以由一个最优值来决定，而不需要在多任务学习里面有不同的最优的prominences，然后来导致我的两个任务或者多个任务的值都没有取好啊。这个是关于这个P20V2他做的一些optional的一些设计一些巧思。
	然后还有一个就是他的这个classification head，这个东西其实就是在from two当中使用这个我们开始看到from to没有细讲，他要预测这个动词的一个核心点。因为我们知道给的这个提示词里面有很多词，其实它的权重没那么高。但有些词是比较重要的。就像我们刚刚比如说的这个翻译，生成，然后第八个这些词都很重要。然后在这个p two v two里面，其实他会发现，因为所有的刚刚讲的这些秃顶技术，都有一类任务做的不是特别好，就是这个序列标记任务。然后在序列标记任务上面，如果我搞了一堆的这个动词，把动词的优先级提升，或者把这个动词在prompt里面的这个权重提升，也许是对这个任务有不一定有起到正向作用的。所以做了一个类似跟prom 20不一样的设计，把LM这个预测动词的这个事情给它简单的简单化处理了一下，不要把它当成一个第一优先级来处理的方式，而是直接去用一些随机初始化的一些classification he，也就是我们最开始看到的在初始化我给大家放到那页，可能大家不一定读过这个原文，会有点遗忘。我们在这个地方有看到这个地方有一个叫做prompt initialization，这个地方有一个叫做random uniform和simple的vocabulary和class label，这就是去初始化prompt的时候，有不同的手段。
	然后我们在P2V2里面其实没有再强调这些class label了，而是把这个class label跟这个in your head直接能够去直接去做初始化。没有再说，因为本身通过那个实验也能看得到，我用随机还是用这个class label，还是用这个词表里面的抽样。最终在足够大规模的模型上它没有什么区别。甚至当我的模型足够大的时候，刚刚那幅图里面它的random uniform其实还超过了。大家可以看到这幅图里面random的这个uniform甚至还更高，这个稍微高一点点，没有高太多，甚至还更高。因为它可能这个多样性得到了一定的保证，所以他又回归到了这个初始化，跟这个bert类似。Bert我们记得当时这个mask就是80%是随机的。
	我不清楚大家还记不记得这个bert的这个训练方法，所以其实就搞了这四个不同的策略。你总结一下，第一个把原来人这个主观上认为的一些，就是人在不断测试这个prom的怎么写的过程当中的一些经验拿掉了，就像我刚刚讲的动词，我们认为人在去手造prompt hard prompt的时候，好像动词很重要，但其实没有。在你真正去做自动化的去噪prompt去tuning的时候，其实大家是一样的，随机化就可以了。第二就是说在这个过程当中，不同的任务它的prompt的长度肯定是不一样的。
	如果我们要去做多任务的学习，就像from ti的时候要去做多任务的学习，那这个时候你的from他可能就这个最优值就只能去折中去trade off。那能不能就让他一开始去做单任务学习，然后就能让这个单任务学的更好。然后我本身训练成本也没有这么高，那它就可以在各个单任务上做的非常好。但是如果你要做多任务学习，它的参数配置会更复杂，然后在整个从参数化的过程当中中，不同的任务和数据集，就像我们刚刚讲的，因为简单来说就是不同的任务它里面的这个数据集首先会不一样。但是有可能同样的词，他要在这个任务里面干的事儿是不一样的，或者说它的意义是不同的那在这种场景里面，如果你能够去增加这个重参数化，那就跟我们刚刚讲单任务学习搞到最优。不要把一些可能会有冲突或者相似的一些事情放在一个marty task learning里面去做会好一点。
	这个其实是P20V2的核心，就是它论文里面提到的四个重要的技术点。其实我自己的总结下来就是不断的去把一些人为的设计给挪走，然后让这个data driven这件事儿，就是数据驱动这件事儿回归它的本质。就是用足够多的数据，然后用比较好的网络结构去学出来。然后在一些我们看得到的可能会明显有冲突的这个任务和数据里面，能够人为的把这个冲突尽可能减少。
	这个是他的一些很有意思的一些设定。然后和这个prom tony和p tony相比，它还有一些好处，这个是它本身四个具体的特点。还有一些好处就是第一它的可学习的参数变多了，就我们刚才讲的数据驱动，增加了更多的可学习的一些参数。第二就是它的深层结构的设计，就是我们看到的每一层layer都有prompt。这个跟我们看到的prom图灵来说是一个新的一个设计。Prom图灵是在外部有一个模型，而它能够做到每一层都有。这个其实是借鉴了一些prefix 20的一些优点。
	Prom图其实把这部分简化掉了，但P20V2把它剪过来了，并且拿到了更好的一个效果，所以自然这么多好的功能的加成，其实使得它在各种各样的，尤其是像GLM这个质谱自己推出的大约模型里面，去取得了非常好的一个成绩。大家能看到这个图里面bert和这个GLM的20亿和100亿的这个成绩比起来，其实GM表现挺好的。这个335M应该是3亿的，就3D的一个单元模型，跟这个两B的这个GOM比起来，其实并没有什么优势，甚至很多比分都是比他低的。这也说明了P20v two本身带来的一些好的关于特定下游任务的一些微调的效果。
	好，我们这里预告一下，大家如果没有下载和安装体验过这个chat GM36B的同学，可以去github上面clone然后玩一玩。我们很快就会走到这个实战的部分来，用这个chat GM36B这个模型去做P20V2的微调。然后这个网站应该大家都能搜得到了，github上面很全，然后不好意思进入锁屏了。然后我们看到的这个github上面很全，然后我们的也有它的可以运行起来的实例。只要你有一个符合我们课程要求的16GB的这么一个显存，就能够加载起它的版本，当然可能不是全参数版本。好，那么十点钟我们看到目前为止看关于p tuning有没有什么问题，没有的话我们可以或者我们可能周日再来讲的话，也是OK的。先回答大家的问题。
	Embedding还有语义理解的效果，embedding有语义提取的一些这个点在里面。是的，是增量训练和微调。增量训练和微调有什么区别？这个同学对我们助教老师有回答。大语言模型是否可以增量训练后再微调？就看这个同学你最终微调下游任务是什么。其实我今天2个小时一直想告诉大家，咱们微调是下游任务，就是作为第一件要考虑的事儿，这么多实验结果摆在这里，对吧？
	首先大语言模型它自己不是到端的，它会有下游任务需要去做。那你在学这个课程，学这个技术的过程当中，你的下游任务是什么？你搞清楚。如果你都没有下个任务，你只是想要掌握这个技术，那我们可以看一下一些经典的benchmark，这个是可以的，这个也比较重要。
	大家还有什么问题吗？不会都已经下线没人了吧？
	输入的token和embedding有啥区别？我之前理解是把输入的文字转换成embedding，就是token。P20的训练成本比five tone少在哪里？没听明白。皮托尼不需要训练那个大模型本身，皮托尼那就是整个都没听明白吗？这个同学就between就从prefix开始，这个就在做教大家这个大语言模型的，大语言模型是冻结的，你不需要加载它们，你就加载，你要调那部分参数就好了。然后prefix如此，这个prompt tuning就完全是一个新的小模型也是如此。然后P20也是一样的。对，这个我们看看是大家哪没听明白。
	如果是这幅图，我们现在看到这幅图来看，我给大家捋一下。如果是这幅图，你们想一想P20V1跟P20V2的区别在哪儿？V一是只调整我们看到的input embedding。看见没input in bedding这一层，下面这个retrain language model是不动的，他他把我要调的，我要训练的，我tuning的这些参数就藏在input in bedding里面。大家看一下，这儿有一个prompt encoder，所以他在embedding层去做了一些新参数，然后去调整，使得它能够响应我的特定任务。跟prompt比起来，prompt是把它的这些参数甩到外面去。
	作为一个小模型，它是直接甩到这个大模型本身的embedding层，这个是我们的P20V1做的事情，所以才会提到这两个问题，就离散性和关联性的问题。我们因为甩到了这个嵌入层，就和原来的大模型的evading layer共享了整个嵌入层。那有可能会导致它陷入局部最优。也就是说它能够对我这个P20的这些数据集响应的非常好。但可能使得原来有一些更通用的benchmark和数据响应的不够好了，这个是有可能的这是它的局部最优解带来的问题。
	下游任务是指垂直领域的业务需求。是这样的，同学就是你要理解自然语言处理，它有很多经典任务，然后语言模型它的下游任务，我们大家如果不知道，关于下游任务这点不知道，去搜一下GLUE，这个也是每一个大元模型的benchmark，都基本上会涉及到的。包括super glue就是它的扩展版，我看看我们哪一页有放了。我早已有的。
	BLEU, 这端到端的一些测试。这些都是一些经典的benchmark。然后我们在上节课或者说应该在应用开发课，应该都基本上介绍过各种各样的基准测试是用来干什么的。
	然后这些基准测试简单来说，其实无非就是能够去体现一下大元模型的能力。这个能力要么是语义理解的能力，要么是一些常识推理的能力，要么就是一些比如说还有能不能去理解一些语义，做一些小学数学应用题，这个也是现在很火，像NSM8K这样的一些基准测试，就是他能理解你的需求，就比如说我们上次举的那个例子，一个我手上有五个网球，我又买了两罐网球。一个罐子里装三个网球，我现在手上几个网球？11个。这种就是小学数学应用题，二三年级的学生做的。但他得理解这个语义，并且还能知道一个罐子里三个网球这个知识，然后他还能把它转换成一个和数学的公式，这些都是属于基准测试。
	这些任务很重要，因为这些任务组成了我们现实生活场景当中更复杂的一些任务。大的分类我刚刚有举那几类，大家可以关注一下。然后GLUE可以去搜一搜，然后包括像thread，就是这个stanford的这个QUAD，也是很经典的测试，包括像这里写的，这个都是一些非常经典的。这里的这个课件里的，大家如果看着就一脸懵就去搜一搜，没有那么复杂，也就那么几个。相对于SQUAD对吧，这个stanford的经典的这么一个问答测试，也是第一次上课。我们讲计算机超过了人类，其中就有这个SQAD这么一个经典的基准测试的数据集。
	然后我们再来看看还有哪些问题。下海，看着P图你就简单一些。是，这个设计的还是挺巧妙的对大家再看这里的区别，黄色的部分是我们看到这个部分是P20V1，P20V2做了更深层次的一些模型参数的调整。然后。我们再来看看。
	P20V2的这些参数是随机初始化的吗？可以，可以做随机初始化。对，V一和V2的差别是啥？这还没讲明白吗？这个同学问的，我再说一遍，就V一把你的所有的托尼要训练的模型参数就放在了in bedding这一层，然后让我所有的这个模型参数就训练in bedding这一层就好了。然后这一层相当于原来的embedding新增加了一些我20的这个参数，这些参数是为了响应我的特定的prompt，然后生成一些特定的prompt，就干这么个事儿。然后我的V二是为了能够在整个单元模型里面去更深层次的去调整我的这个prompt，能响应我的prompt，这个是第一第二，同时把这个多任务学习和不同任务之间的最优提示长度去把这个事儿提出来了。
	提出来之后就让大家能够更方便的，因为它配置变多了，你就可以通过配置来做单任务学习和单任务的最优长度的设置。然后甚至在不同的任务上，比如说你需要做的是序列标记任务，你的这个分类头还可以去做这个随机的初始化。但如果你做的是一些特定任务，你也可以选择一些特定的class label去做这个class location head的初始化等等。
	Embedding层没有那么大的算力。对一个大模型到底是由哪几层组成的？回想回去看看上节课，从GPT1到GPT3都讲了是怎么组成的对，上节课有讲这个大模型是怎么来的，transformer是什么样的，然后从transformer到GPT e是怎么样的，从transformer到bert是怎么样的对。
	预训练的显存消耗以及find tuning p20等各种方式微调的显存消耗的差异，以及显存消耗的计算公式吗？现在知道预训练模型的显存占用是12加2加2乘参数量。这个我们后面实战的时候会讲。对我觉得这个不是一个非常难的一个技术点，这只是一个相当于你知道99乘法表是怎么算一样的东西。我们后面实战会讲这个东西。对。我的理解prefix tuning prom tuning是新增模型层，prom turing是一个新的模型，它都不是模型层了。但你要说它整体是一个大模型，一个新的更大的模型也OK。
	对，但是它的运行逻辑有点不一样。因为prom turing它其实相当于相当于有一个怎么讲？就是这个prom ti的手段更像是有一个大堂经理，他能够给你提供更优质的服务。但是最终他能让你心情变好啊，他同时能让给你提供服务的这个炒菜的厨师心情变好。不会因为你老去雕这个菜做咸了太冷了，然后厨师心情也不好，厨师做的菜也不好。
	可能中天这个prom图他他要做的事情就是安抚厨师说你今天做的很棒了，但是这个客人很挑剔。对你这个客人就是想要吃的咸一点，口味重。然后厨师说那我要把它做重一点。然后同时他还会告诉你，你就按照你想要的来，你不需要适应我们的厨师和我们这个饭店，你平时怎么点菜你就怎么点菜，我来帮你搞定。
	这个是from tony这个小模型干的事儿，他没有改变给你提供服务的那个大模型，他也没有改变使用大模型的你，他只是说他默默努力，在家苦练沟通技巧。就是那个task a有哪些特定的prompt，task BB有哪些特定的prompts，task a可能是这一类难搞的客户喜欢什么，task b可能是那一类难搞的客户喜欢什么，我不知道这个例子举明白没有然后p two的核心是什么呢？P two是说你现在有一个你还是去吃饭对吧？但是吃饭的这个embedding就是image这一层，其实就是给你提供服务的那个大模型，给你服务的这个人员，他本身因为他很刻苦，他提前学习过，他进修过，或者说这个给你剪头发的tony老师tony老师。
	这个皮托尼这么举例子，就是他是一个tony老师，你想要告诉他你要剪一个什么样的发型。但是我们都会有一个困境，就是你永远说不清楚你要剪一个什么样的发型给tony老师。然后tony老师总会有一个他认为很好看的发型给你剪出来，然后你很不满意。然后P托尼就是说tony老师，他是一个有心的托尼老师。你每一次跟他的沟通都能让他更懂你一点点。然后现在把但是你没有那么多时间给他去试对吧？所以他会自觉的去学习，他把他的in bedding层学的越来越好。他知道有哪几类发型，有哪些类型的描述，他就能整明白了。
	因为我们不专业，我们说不出这个叫空气刘海，我只能说这个地方留三根毛就好了，或者这里留五根毛就好了，然后煎些什么说了一大堆，其实这个东西就是空气刘海的意思。但是如果这个tony老师他不有他不是一个有心人，他就不知道你说的是空气刘海，他的embedding这一层就不理解你，所以他怎么都剪不出你想要的空气刘海。但P20就是一个有形的老师，他去剪了，然后他剪出来了，这个例子我觉得举得挺好的。
	然后P20V2是什么呢？就是tony老师自己水平有限，他他会剪空气刘海，但他不会烫头。他烫头技术很差，但是你又很想烫个头，而且你烫头的时候你要染发。
	他只如果有一个P20V1的技术，他不管怎么理解你的需求，他也做不出来。因为他不会，他就得深度进修，还得去学一个月进修一个月把这个剪三根毛，三根毛里面怎么样，屡成什么样，扎个麻花头什么说的一大堆，他都整明白了，他还知道怎么做了。然后回过头来，你跟他聊的时候，他把你的需求服务的服服帖帖的，甚至来了不同的人。有的顾客他说的这个顺序是我要洗剪吹，然后再烫个头，然后再给我洗个脸。另一个客户来了之后就说剪一下，这两个客户其实任务是一样的。但因为他学的很多，他他理解了。对，然后甚至因为不同的这个任务，他的这个他因为你学了不同的这个任务，他的最优长度不一样，他还能够理解了。
	这个例子我觉得应该举得比较熟了，因为P20改变了托尼老师，而prom托尼没有改变那个做饭的厨师。他只是一个大堂经理，他知道怎么服务好顾客，他不需要顾客对他这个店来做适应它来适应顾客。同时他还能安抚好服务的厨师的情绪，因为他知道厨师太难请了，请一个厨师要几百万美金才能训练出来，这就区别。
	然后perfect twin你可以理解成就是有一个可能像这个国务卿这样的一个角色，他太厉害了，他他把这个大模型理解的服服帖帖的，然后他训练手不断有机器高超，但是平时你搞不出这样的一个国务卿来，所以他甚至超过了这个反正他超过了让这个总统自己去训练的这个水平。他跟总统的配合大于这个总统自己去训练，所以他很牛逼。但是你要搞出一个perfect tuning来就是很难，是这么个意思。Adapter tuning的意思就是说，你现在要这个你自己要进修，你你你的这个你自己要进修，但是你又理解不了这个概念。然后我现在就在把这个复杂的概念给你简化了让你理解。那这个过程就是adapter tuning，让你简化的理解了这个概念了。至少现在99%的场景，你能说清楚这几个突然的区别。对了，但现在有一点，比如说别人问这个模型到底是有几层lair，多少个参数你还说不出来。因为你简化了，但是就是有那么百分之几的东西你还没学到，我不知道说清楚没有。这几个徒弟。
	还有个同学问P20v two是在embedding层之前新增了一层带参数的网络吗？没有，你看就是这一层，就我们现在这一页，就是这个p two 0v two，右下角就这一层，跟它这一层evading这一层它有加参数。下面它也有，就是它共享了那个embedding层，并且扩展的这个evading，其他的layer也是一样的。
	In bedding层也是反向传播的对，因为它可微，就是它刚刚讲到的可薇很重要的一点。对，可微就能够反向传播去更新，可以走这个optimization的这个流程。P two的v two每一层的是如何更新的这个反向传播，同学这个是back propagation基础知识，它怎么样做的正向的推理，怎么样去做反向的传播？对如果你实在感兴趣，就像我刚刚讲的，他这个论文里面写的挺细的那个公式，可以再去深入看一看。但对于我们微调的实操影响不大了。我希望大家把这个演变过程整明白，就是为什么要做一个有心人，还能够自己去进修服务好大家，然后把这个P20V2用好啊，就是这么个逻辑，看大家还有没有别的问题。没有的话，我们今天就到这里，然后我再把Laura部分的资料再整理好，我们周日把这个罗A讲清楚，然后把ChatGPT训练过程当中使用到的这个instruction tuning，包括RLHF，可以给大家讲清楚。然后可以略微带一点点prom tuning和instruction tuning的一些新技术都是一些啥，比如说IA3，这个PLT等等。