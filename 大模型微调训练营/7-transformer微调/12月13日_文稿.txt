	Hello, 大家好，不好意思，最近天气变化比较大，就感冒了。所以上周日的课程我们做了一个顺延。现在声音和画面正常吗？大家能不能看到屏幕？
	我看很多同学写了一，应该是可以的。好，那我们今天就开始，今天是一节实战课，所以课件比较简单，更多的是实战部分的代码。好，那我们就正式开始。我看有的同学说一切正常，挺好的。
	稍等，我把这个手机放置好。好，那我们今天开始这个实战transformers的这个模型微调因为有很多同学我看上次统计没有用过transformers。其实我们的PFT包括后面讲的这些做分布式模型加速之类的应用，都会基于transformers的一些基础的训练模块再去做扩展。今天我们就来第一次使用transformers来进行微调，分别微调了两个模型。一个是这个bert，我们在pipeline ine的时候就用过的一个bert的模型，我们的bert base case的这个模型。第二个是训练一个由hugin face这家公司，他们做的一个轻量化的birt版本叫dist bert base on case这个模型，这俩模型在github的这个开源项目上，我都已经把相关的代码刚刚推上去了，同学有的可以，现在就可以动手拉取一下代码就能看到。然后今天的整个实战部分的代码，其实也就围绕着这两个来展开。
	但是在讲transformers的实战之前，我们还是先把一些基础的它需要用到的依赖给大家做一个简介。当然它的依赖本身也很复杂，我们不可能像这个工具书一样的，把它用到的依赖全部都给大家全部介绍一遍，这不太现实。所以我们按照我们学习的这个由浅入深，循序渐进的这个过程，逐步的给大家深入的去讲，data sets有哪些功能，trainer有哪些功能，甚至还有不同的trainer，data sets还可以自己去做一些私有化数据的一些改造，模型训练的评估，还有一些更深层次的用法，分别怎么做。今天主要是带大家能够从0到1的去走一遍模型微调。我们首先来讲一讲这个数据集的处理库，叫hugin face的data sets，这个库的名字就叫data sets。我知道用过tensor pro的同学应该很早就能感受到，其实TE sor FOW的数据处理也有一个对应的名字，叫TF到data sets，hugin face也沿用了这个名字，包括ten TensorFlow后面的这个patch都有data sets的库，为什么需要data sets？
	我们在上节课其实跟大家讲过pipeline的这个流程，不管是模型的推理还是模型的训练，训练就是在推理的基础上做了这个反向传播。这个反向传播是什么？大家应该都应该知道。如果不知道的同学需要去再预习TensorFlow的这个视频课，或者前面我们讲这个大模型微调和训练原理，有简单提过模型是什么，不管你做训练还是做推理，都有这样的一个拍拍案。那在这个pipeline里面，假设我们需要做训练，那训练在transformers的pipeline里面，我们知道有三个重要的模块，分别是together model和后处理。因为大部分的模型输出的可能都是概率，这个概率不能直接变成结果。在我们今天的实战里面，我们能看到要怎么样把概率又转换成结果，有一个映射的过程。但是如果我们从数据要进行训练，要进行模型微调的角度来说，data sets首先解决的其实就是我们的数据来源问题。
	就是我们知道有token nizar的技术可以对数据进行各种各样的处理，包括对它进行编码做映射，然后再把它进行今天要讲的填充截断等。但这个原始数据怎么来？Data sets，有大量的库开源的数据集能够支持我们去获取这些数据。所以简单来说，data size本身是一个库，是一个python的库。这个库可以让我们去访问很多类型的数据集，包括音频的，计算机视觉的、自然语言处理，也就是我们的文本类的这些数据集，一个python的库让我们能够去访问库这些数据集，只需要一行的代码就可以加载这些数据集，就跟我们上节课用pipeline去加载这个token IDE加载模型一样。当时有一个方法叫from pre train，不知道大家还有没有印象。
	类似的数据集，它跟face也用了一行代码的一个方法，叫做node dataset。那下面这个就是hugin face的hub，上面有模型数据集，包括已经可以部署好的，可以直接使用的这个influence API，这些其实都在一个统一的hub上面。Dataset也是一样，我们现在这个截图其实就是dataset。今天来看已经有8万将近88000个不同的数据集在这个hugin face上面是可以被访问的。
	那怎么样加载呢？其实很简单，我们今天的第一个实战就加载了一个叫做yp，一个美国的大众点评，也是大众点评抄的这个原型，美国的药物它有一个评论的数据集，这个数据集里面有65万条训练集和5万条测试集，一共70万条的用户评论。那这70万条的用户评论怎么样去下载呢？
	做过模型训练的同学对于数据的访问也好，清洗也好，是一个很头疼的事儿。做数据这一部分的工作。那么hugin face它厉害就厉害在它用一个统一的平台hugging face hub把你要处理的数据，你要访问的模型都放在了这个平台上。并且通过一个统一的transformers，或者说transformers生态的这些库，比如说data set，能够让你很轻松的把这些数据模型下载到本地，然后来进行进一步的训练处理部署，这个是它厉害的地方。所以我们能看到通过一个node data set，你可以去加载一个yp review，然后我们直接去去访问这个data set。这个是我们加载出来的一个数据集，我们直接去把它打印出来，可以看到里面是一个类似字典的这么一个数据结构，然后他帮你区分了训练集和测试集。然后训练集里面嵌套了是真正的一个完整的dataset，里面有它的这个features，还有它的这个number rose。
	这个number rose和features对于文本类型的数据来看，就像一个典型的excel的表一样，有多少行，有65万行，然后有哪些列，每每一列有不同的这个类型，待会我们都会去实际看的。那么我们通过这个，因为它像一个字典，dataset，dictionary这样的一个数据结构，所以我们也很方便的能够去访问训练集、测试集，然后通过这个下标索引的方式去访问每一条数据。在这个transformers的这个或者说在hugging face的data sets这个库里面，它有具体的一些抽象，待会我也会简单给大家讲一讲。这个其实就是访问了一个具体的一条数据，训练集里面的第一条数据，这个label是它的这个评分，四星，通过这一行就能搞定。那我们刚刚讲到的，通过这个神奇的一行node dataset，就可以去把hugin face hub上面的，就像一个一个的github上面的代码一样。这个数据集的card，大家能用过hugging NFCE的hub就知道，它会有这个model card dataset card，就像这个主页名片一样的。那这个dataset card明明是网页上面的一些数据介绍，怎么就变成咱们可以直接使用的数据集呢？
	其实这里很重要的两个抽象简单跟大家介绍一下。核心其实就是在data sets这个库内部有一个很重要的抽象类叫做dataset builder，就是去构造数据集的这么一个类。它里面有几个重要的方法，包括info split generator和这个generate example。那么要去构造出dataset的builder这么一个类，它也需要一些配置项。它需要有一些相当于原信息或者说配置信息一样的这个数据。那么这个时候我们就会引入到另一个配置项，叫做builder的conf。就我们左边看到的这个builder，它有五个比较重要的字段，构成了一个数据集的基础要素。
	所以是一个通过builder config这样一些配置项加上这些数据本身，可以去构造出一个完整的数据集。通过builder conflict我们也能看到这里有一些比较重要的参数。比如说我们看到的这里的name，version data的DIR files和它的description，分别就是我们的这个数据集的一个简要的名字short name，包括它的版本。因为我们都知道不同的数据集有不同的版本。像第一个时代里面用到的这个yp review for，它就一个版本，或者说主要就一个版本。第二个实战项目里面我们用的这个score，就这个stanford这个question answer的dataset，它其实会有很多版本，比较主要的版本一个是1.1，一个是2.0。我们在理论篇在讲这个大模型理论的时候，已经无数次的出现了score这个数据集了。
	今天我们就会用这个数据集来做微调，version很重要，包括它的目录，就是存储我们本地的这些数据集的这些文件，它的目录在哪？以及具体的这些文件它的路径是什么？然后描述这个数据集，就是我有一个简要的名称，但是我对这个数据集本身还有一个描述。这个我们待会儿都会看到，比如说这个医药review for它的这些关键的这些内容有哪些。当然这些在我们的higden face的dataset的这个主页上面也都能看得到。
	假设我们现在自己想要构造这个数据集。因为说到这儿，其实我们就已经发现你自己就能造数据集，并且还给in face的这个data sets的库也支持你把你的本地的数据打包成一个标准的data sets的这个数据集，然后上传到hugin face，不然也不会有这么多。88000个这个注意器，也很方便能够去push到它的这个hub里面。那怎么样去构造这里，就是通过我们的这个build config来构造。并且如果我们现在想要基于一个已有的数据集再去做一些改造，比如说你有一个开源的数据集，就跟我们以前做视觉的时候，你在一个imaging net 1000类的这个图像识别的标签里面再增加个十几类，怎么加？这个时候其实也是通过build conflict这样的一个配置项来实现的。
	这个build config这个类，它是一个python的一个class，可以通过继承这个类的实现。我们知道应该大家写过这个代码，做过面向对象的都知道，这个build config可以作为一个鸡肋，让你去实现它的子类。然后这个子类，你既可以通过这个子类或者它这个类本身的实例化的实例，就把这个实例注入进去，来实现它的这个dataset默认值的复写over right，也可以直接在加载node dataset这个方法加载的时候，去手动的去在node dataset这个方法里面去修改它的这个值，而不是让他去取默认值。
	这两种方式都是可以去改造这个，或者说去在构造data builder这个类的实例的时候，去实例化这个类的实例的时候，去修改它原生从这个hug in face hub上面拉下来的这个数据集的方法。然后你修改好之后，这个data set的实例其实就在你的这个内存里了，然后你再把它保存下来，再push到这个hugin face的hub上，就变成了你自己的这个data set。但要符合一定的这个开源协议和规范，那整整体来说，整个dataset这些数据都可以放在这个内存里。然后以一个我们刚刚看到的这种dataset dictionary这样的一个自定义的形式。然后这个形式能够被加载，能够被保存，也能够被复写，是这样的一个逻辑。那么data set这个类，它具体的这三个方法，其实名字上也很简单，就我们能看到info，就是关于这个dataset里面的一些原信息可以去访问。
	Split generator，就是用来这个generator是一个生成器，那它的这一块第二个这个方法它的主要的功能其实就是帮助我们去把一开始的这些存在硬盘上或者这个网盘上，云服云硬盘上面的各种各样的数据文件下载下来。下载下来之后，能够去按照我们的需求去把它分成不同比例的。比如说训练集、验证集、测试集，去做这样的一些组织和下载的工作，然后真正去具体生成它。
	我们用过python generator同学就知道，写一个generator其实是把generate的逻辑给写出来了。但真正要去生成它的时候，是generate这个操作再去做的。真正的这个生成一个我们我刚刚访问的像这个一行这个data set训练集第一行这个数据真正去生成的是这个generate example这样的一些方法，它会具体的去按照generator的这个逻辑去读取数据，然后去生成一个的example。然后我们知道dataset真正在使用的时候会分被分成不同的用途，训练集、验证集、测试集。然后我们使用刚刚的三个方法，就可以去在构造自己的数据集的时候，去划分不同的比例，那这个划分不同的比例具体怎么做，我们在真正需要去自己构造数据集的时候，我们再给大家做详细的介绍。
	现在大家有这样的一个初步的概念，data sets这个库，帮助我们去从hugging face hub上面获取各种各样的数据集，并且通过node dataset把它加载到了我们的内存里。加载到内存之后，我们可以去使用它。使用的时候，因为任何的数据集上传的时候就已经划分了不同的比例，所以我们下载下来的时候它就已经分好了，我们不需要再去做额外的一些划分了。但有的数据集可能做的不够好，它没有划分。你需要按照你的这个比例再去重新划一道也行，也能去做处理，这个都不是很难的事情。
	然后如果我们要自己的去把这个data sets去再进一步去改造，我们包括我们在加载的时候还会遇遇到一些别的问题。比如说特别大规模的数据集，我的内存都不够，没法一次性加载，我可能需要进行这个streaming流式的加载等等。这些其实data SaaS库也有提供一些帮助。包括跟各个云服务厂商的对接，跟各种各样的云服务厂商的云硬盘对象存储去做对接，它也都有啊。那我们到需要用到它的时候，我们再进一步去做这个延展。现在不去把各种各样的API给大家做一遍介绍了。
	然后有了这个数据之后，我们刚刚看到这个流程里面有row text或叫row data。我们有了原始数据了，这个原始数据通过node data sets跑到我们内存里来了，变成一条我们可以用的数据了。但是我们在上节课讲pipeline的时候，有有讲到token ized干什么？Top either把我们的原始数据分词、映射、编码，然后最后变成一个向量，我们上节课应该就只讲到这一步，但是没有去讲这个向量怎么样处理。因为我们在influence这个状态下，通常不需要对这个数据本身进行太多的处理，就直接用就好了。但如果我们现在要进行微调和训练，那我们就得对我们输入的数据进行处理。并且给到我们的这个大语言模型，或者说语言模型，甚至任何的模型都会有这样的数据预处理的诉求。
	而这个数据预处理的这个诉求或者说策略，主要还是来源于这个神经网络。就大家看过我们的这个理论课的都会知道，这个神经网络它其实最后就是一个矩阵运算，在矩阵相乘的过程当中，我们的维度必须得满足它的要求才能够进行矩阵运算。所以既然token是我们一开始输入的这个就input的部分，那这些input的这些token或者说这些embedding的token的向量，它的维度一定要符合要求。
	如果有一些token或者说token ID它转换过去之后，它组成的这一句话他就不满足我们的这个长度要求，那怎么办？那这个时候通常有两种策略，一种就是这句话它确实太短了。就是本身我们可能要求输入的这个长度是384，这个384个token或者说384的这个维度组成的，那么你这句话太短了，有一种办法就是我直接给你填充，补上一些没有实际意义的内容。就像我们之前在处理视觉的时候，有一些图片它的分辨率跟我们要求的分辨率不一样。那就补充一些不必要的像素，比如说那个灰度为零的，或者说255的灰度的等等，把它填起来填。这样你可以理解成就是有一个输入的管道，然后这个管道挺大的，我们本来都应该要求刚好这个尺寸过去，那现在我太小了，那我就补充一些空的内容，就可以送进去了。这个是用填充的方式来进行数据预处理。
	还有一种方式是截断，简单来说就是跟他刚好截然相反，它的输入要求就是384。你的这一段话太长了，四百多了。那这个四百多，你不可能全部输进去，怎么办呢？就截断，我没有找到一个特别好的去表达向量截断的这个图我就简单取了一个英语当中的含义，其实是一样的。就比如说我们这个cycle这个C这个cycle是我们七个字符，character这种编码的话，七个字符是我们要求的输入的最大值了。那现在你所有的都超过它了，那怎么办呢？一个最简单粗暴的方式就是直接给它截断了，右边的都不要了。就比如说像现在我们看到的，把右边的这些OGY，然后logical，然后logic都给它干掉，包括这个environment ments mental都干掉，强度就是七个，剩下都不要。
	当然显然这种阶段策略太粗暴了，而且实际应用的时候也不太会说就直接阶段不要了，一定还会有一些更细致的一些截断的这个手段，我们待会儿在实战里面也会提到，就比如说剩下的这一段我虽然不要了，我能不能放到后面去，就把它一砍2，变成两条数据，当然可以。但变成两条数据之后，又会有一些额外的问题，就是你要映射的这个关系就变成了这两条其实在原始文本里面是一条，那怎么样又去把它映射回去，就有两层的映射，那就更麻烦，但是也可以处理。这个是数据的预处理，我们通过cocoa ize可以实现padding，可以实现traction，两种策略最常见的。但是我们都知道这个token ized它是一条一条在处理。虽然上节课我们讲pipeline的时候也给大家讲过这个token ither可以处理一个列表，可以处理多个输入，但是好像也不是很很智能。就假设你有整个data size，我们现在不是说inference是要做fine tune的，是要做微调了。那你处理的是整个数据集，65万条训练集，对吧？你把65万的这个数据整到一个list里面，那也不太现实。那应该有更科学更轻松的方法来处理，那这里其实就是data set有这样的方法，这个方法其实就是map的方法，这个也是一个在nmda表达式或者说nuda。这个运算都非常常用的一个方法。
	这个map方法简单来说就是你可以理解成我们可以把刚刚定义好的所有的这些处理手段，都把它应用到我们这个map所。你可以理解成就是我们这个代码应该能看得清楚，还是比较大的截的这个屏，就是我们的这个data set的map，接受了一个函数，这个函数叫做token nice function，这是非常典型的一种londa表达式的这种使用方法。那么把coconut function，也就是我们的填充加上阶段，填充就是不够补齐，traction这是最粗暴的一种方式。
	不是说只能这样处理，如果我超过了我就截断，剩下都不要了，只要对于我输入的内容，每一个example我都进行这样的处理，然后最终作用在这个dataset上面。这里的dataset是一个我们在前面的课件，你看到的从hugin face hub上加载进来的一个完整的一个数据集，然后在这个数据集上全量的去使用这样的一个took next function。他原来的这个65万条数据就会被这样洗一遍。你可以列成，就把我们的一开始设计好的预处理策略，应用到了全量的数据集上。然后处理完之后也可以把它可视化出来，通过一些pandas这个库里面的一些data frame的可视化方法就可以看到了。好，我们待会儿具体到实战的时候再跟大家看啊。
	刚刚其实讲到这个是data sets，我们能够把数据集很轻松的方式从hugin face ub上面搂下来。搂下来之后能处理结合的tokenizer，结合着map方法就把数据都能够清洗一遍了。那么trainer也很关键，那么transformers的trainer模块，这个是transformers这个库里的要怎么用？首先其实就两步，就是要完成一个模型微调需要怎么做？就两步你非要掰细了讲就三步。第一步是定义这个trainer这个对象，这样的一个实例。我们能看到这个trainer的对象里面有这么几个必要的非常重要的参数是在实例化的时候要传进来的。第一个是这个model，第二个是这个arguments，就是我们训练的这个参数配置。后面两个是数据集，训练的数据集和评估的数据集。
	就在训练过程当中我要不断的去做模型评估这种训练是很通用的。不管是大语言模型还是传统的深度学习机器学习都这么干的，只要是基于这个监督的，还有一个叫做compute这个matrix就是去评估这个模型的一些关键指标，有什么这个关键指标呢？其实也在data sets，就是我们刚刚讲的这个data sets这个库里面可以做进去。因为我们既然这个数据已经被构造成了一个数据集，这个数据集又构造成了训练集和测试集，还有验证集。那这个测试集验证集被划出来了之后，我总得用他们那用的时候就得评估他们，那评估的时候就会有一些指标。所以在dataset里面还实现了一个方法，跟node dataset是啊，你可以认为像这个两兄弟一样的，一个叫node dataset，一个叫node metrics。就像如果你在造构造这个数据集的时候，你把这个matrix也做进去了。那么别人在使用这个data size的时候也能加载回来，那他就会更方便的能够用你的数据集去做训练和模型评估。
	这个是最外层来看，要去实例化一个trainer，那么要去实例化一个trainer。为什么说分成三步，就是因为其实这里面的这些参数也需要被实例化出来。Model我们已经知道了，就是模型在上节课讲过，可以通过from这个pre train，可以加载一个预训练的模型，它就代表着有预训练的权重。然后这个training arguments是我们待会儿要讲的，就是把我们的这个大于把这个transformer拿来做模型微调的时候，要配置的各种各样的训练参数。在这个training arguments里面，剩下的这两我们刚才讲了，就数据集，这个metrics也讲了，就是这个用来做模型评估的一些指标。这个是我认为是第二步，如果一定要说的话，就把这些需要在trainer识别化过程当中传进去的这些对象，也要实例化出来，提前做好准备工作。
	第三步其实就是直接通过这个train方法，trainer点train这样的一个方法就能够完成模型微调。这个train方法也跟paras、TensorFlow，包括patron是类似的。甚至他们的这些接口名称也都是能够跟上一个时代搞深度学习是非常相像的。这个方法一value方法，predict方法等等。
	好，那么training arguments它跟我们刚刚看到trainer又不一样了。你可以认为trainer这个类他就想要简单一点，就让我们把模型微调，搞得非常简单，一个实例化再加一个train就搞定了。但模型训练哪有这么简单，对吧？真正要去做好一个模型的训练，有各种各样训练微调它的方法，包括但不限于不同的微调的手段对数据集的划分。然后在训练过程当中，我的各种超参数，我的best set设置成多大。然后我在训练过程当中我的步长怎么设置，learning rate怎么设置，decay怎么设置，这全部都放在了这个training arguments里面。然后这个training arguments的参数非常之长，我这边只展示了一部分，其实有很多，待会儿我们在实战的时候也能看到，这个其实复杂都被包在这个里面了。但如果你是一个纯新人小白，素人大模型微调的这个同学，没关系，因为training arguments它也有这个默认值，你可以就把刚刚那五个设置好，它就能够开始训练，甚至你的这个compute matrix不输入也行。
	因为有的模型它去在训练过程当中去实时做模型评估是很贵的，它的成本很高，可能会选择不一定在每一步都去做这个evaluation等等。好，我们就大概给大家讲了一下trainer这个模块，更多的还是在实战里面去看啊。然后模型的这个评估也有一个单独的库，跟data sets是类似的。它更多的是干什么呢？其实跟data set一样，它同样是一个python库，也是希望简单一点，能够一行代码就能够让大家访问。我们的不同的各种各样的评估方法，你可以理解评估是干什么事情。然后刚刚看看到有同学在问这个computer matter是什么意思，正好就讲到这儿了，简单来说就是我们都知道这个大语言模型也好，机器学习也好，这个强化学习也好。只要是基于这种有标签的，有这个label的，可以去比较你的这个模型输出的结果和我最终的这个或者说我的这个数据集里面一开始预划分好的这个训练集里面的标注和验证集里面的标注能够去做计算，那么我都可以对他进行一些特定的评估。
	那这个评估有两种方式，或者说去计算它的训练的模型好与坏有两种方式。一种方式就是直接去通过你的目标函数和这个loss function可以去算出一个损失值。这样我们这看到有一个叫做training north，就是我们去要这个美食评论的数据集上面去进行这个微调的训练。训练了三个epoch之后，它得出来的一个在训练集上的一个loss值。然后这个loss值其实理论上来说，它应该随着训练过程的变化，它应该变得越来越越来越趋近于0，是比较好的一个状态。当然你可能在非常大规模的训练集上，一开始它的这个loss变化是不太稳定的，甚至有可能还会变大，然后又变小，或者说因为你的处理不当，你的learning rate的各种超参数的设置不太正确，可能就陷入了一个局部最优解就不动了。但它其实不是最终的最好的一个模型参数的配置。
	这个是一种方式，就是通过loss function可以算出一个评估你的模型在这个数据上面，它的数据分布有没有跟训练集训练出来的比较像的一个数据分布了，这是一种方式。第二种方式，就是这个myrick，那就是我们的这个评估指标。常见的一些评估指标，大家可能耳熟能详的，什么准确率，F1，F1值等等，这些都是一些非常常见的评估指标。它其实就是以一个比较符合概率学，或者说比较符合传统统计机器学习的角度，去给你算出一个有特定含义的一个指标的值。那这个指标的值要算出来，它不就得跑一整批这个数据。那它跟这个算validation loss还不一样。因为你算loss可以只抽样一部分，算是一个值。但你要算一个matrix，通常需要跑全量的数据，这也是为什么不一定需要在训练过程当中加入compute matrix的一个原因。
	因为如果你的训练集的这个数据规模特别大，然后你还要在每一个epoch或者说多少个step的过程当中就去算一遍matrix，那可能就会导致我去，不好意思，我这个猫过来了。它可能就会导致什么问题？就会导致你的训练速度被计算matrix的时间给拖慢了。
	因为理论上loss已经有这个价值了，loss的这个减小就是标志着你的训练方向是对的。但如果你还要在每一次训练过程当中都去上这个matrix，去跑一遍全量的数据，去得出一个指标来，那就很慢很低效。所以有的时候会选择不在这个训练过程当中去算matrix，是这个意思。
	然后我们再往后就是实际操作了，那么在实际操作之前，先再跟大家同步讲一下关于环境的问题。因为有很多同学在群里问这个GPU等等的事情，这里我正好也更新了read me，我们来快速讲一讲。大家能看见这个github的这个页面对吧？这个大小是合适的吗？
	这个大小应该可以了，假设大家都能看清楚。首先我们在这个read me里面更新了一些内容，然后好，然后这个里面更新了一些内容。第一个就是增加了这个python的具体版本，希望是3.10加的。我再把之前说的可能没有听过的说一遍。然后用mini contra来进行python的环境管理，用Q拍AAB来做交互式的开发的环境。虽然我们后面的一些训练可能会通过脚本的方式，但如果我们要做课程的分享，就hdl lab是一个比较好的方法，或者说这个环境，让大家能够体会到怎么去用。
	然后更多的其实是下面这部分，就是我们看到GPU驱动和CUDA的这个版本。因为上节课其实我们的那些pipeline是可以不用GPU也能跑起来的。我相信很多同学也发现了，但是现在我们要去做模型微调了，那肯定得用GPU了。尤其是我们的第二个实战，如果你用CPU然后拿内存去跑，可能会特别的慢。我今天用这个T4的这块卡，跑第二个实战项目，跑三个e poke的这个微调，大概是将近3个小时的时间，就三个，但他肯定还没有完全收敛，所以其实其实也只是一个最低的要求这个也是很多同学一直在问要什么才够，其实他没有一个上限。我在这个群里有回复过，我们只能说这个课程里面为了让大家能把这个技术学会，我们能提一个下限的要求。当然你有更好的卡，更高的这个显存肯定是非常好的。并且我们在教这个技术过程当中也会告诉大家，如果你有高于这个最低要求的配置，你可以通过改哪些超参数让你的训练效率更高，这些我们也都会讲。
	言归正传，怎么样去装这个GPU驱动和扩大？我的建议是这样，就是按照官方的要求来是最棒的。我们为什么需要关关心这个GPU驱动和扩大的版本？其实说到头还是因为它底层依赖的这个patch ch和TensorFlow，他们需要使用酷达。那他们使用酷达的时候，我们能看到比如说py touch这个FAQ，它的这个跳转链接做的不是很好，过来之后没跳这儿。其实他自己的官方就是pat touch的这个官方网站的FAQ，里面有回复。
	首先2.0跟1.0兼容性也没有太高，TF也是。那么关于这个扩大的版本，其中这个问题上有写，就是有没有安装py touch 2.0一些额外的需求？有啊，比如说酷大的11.8，这是他当时的回复。2.0的版本，我相信现在大部分的同学都用到了更高的这个版本，我在新的这个上传里面应该也加了一个requirements，没有传上来吗？我看一下。
	一。
	这个文件怎么没有提交上来？没事，这应该大家也能看见。因为它在更上一层的目录，刚刚艾特的时候没加上，把这个放大一点，在这个项目里面新增加了一个requirements点TXT，这是一个python的用来装各种各样依赖包的时候，通常用这个方式去指定是一种比较常见的行为。在这些包里面我主要指定了一下这个python的版本，最好是大于2.1.2。
	然后transformers是我们在讲的这两节课讲的主要的一个hugin face开源的库，除此以外，这节课我们会涉及到data sets和evaluate。然后因为evaluate是做模型评估的，它里面又会借助一些SK learn的这个库，所以把它加上了，为了去把data sets的这个数据，在就拍的lab里面能够展示出来，我们用pandas来实现这个data frame的一些展示。这几个是目前一些必要的库，当然可能还会有一些漏掉的。大家有同学如果知道的话，也可以提一些PR把它补充进来。我看现在已经有PR了，有三个挺好好，因为py touch有这个的要求，官方讲2.0版本以后至少是这个11.8，但他有写11.7因为每一个酷大的版本安装都会造成一个什么问题呢？就是大家要知道，我们现在已经装好的同学也都能够使用这个NVIDIA SMI这样一条指令来查看自己的GPU的情况。作为一块GPU，它有两个包是最重要的。
	除了扩大以外，更重要的是驱动，就是硬件需要驱动才能跟我们用的软件一样，才能被这个CPU也好，被电脑里面的其他的主要的软件，核心操作系统能够去访问到这块硬件要通过驱动。而通常来说，英伟达的CUDA版本和它的GPU驱动版本是匹配有一定匹配关系的那假设如果你现在装了一个11.8，在未来的某一天这个拍照器或者tensor pro又升级了，对古达有了新的要求，那你可能就会需要同时去更新哭的和GPU的driver了。所以我的建议就是如果你现在能装新的，最好就干到这个最新的版本，那么最新的版本在NVIDIA的这个网站里面其实有写，通过我的这个超链接，大家应该都能访问。然后最新的版本应该是这个CUDA的two kit 12.3 update一这样的一个版本。
	然后大家要怎么样去选适合自己的这个CUDA？比如说你是一个linux的服务器，选择linux叉86的对吧？然后假设你是这个开源爱好者，你用了乌邦图的，用了20.04的。你看其实酷达现在对于这个18点12、10.04之前的这些版本，16、十八这些非常常见的乌帮兔都已经没有作为官方支持了。所以其实整个迭代是很快的，然后这里有三种不同的安装包的选择，一种是直接选择这个run file，简单来说run file就是直接把整个安装打包成一个文件。这个文件最后下载下来之后直接运行，它就会安装了。当然也有通过网络的方式去安装的。
	在不同的操作系统里面都会有这个操作系统级别的包管理工具，你可以给这个包管理工具的这个软件源，就它的这个source增加一个扩大的reports。然后增加之后，你就可以通过你这个操作系统对应的包管理工具去直接安装它，这样也行。当然也可以通过这个下载的方式，把这个下载下来，然后通过它来进行安装。
	这里我们就不再详细的去讲怎么去装CUDA了，当然库达和GPU driver我们开始讲过，是两个不一样的玩意儿。有的比如说这个run方法，它可能会直接下载到本地就都带上了。有的是没有都带上的，或者说一开始你的这个电脑里面的驱动是对的，你只是需要更新酷的。这些其实都可以在安装过程当中，如果有什么问题，在网上搜索或者说在群里去提问。但是古达本身不应该是一个很复杂的这个事情，也不应该是一个很复杂的阻碍这儿大应该没什么问题，对吧？安装库的好，那我们就看一下具体的这个实战的部分了。
	好，这个大小可以吗？还是需要再放大一格。正好接杯水。
	我再放大一点。好。
	这样可以了吗？
	还要再大一个吗？还要再大一个，看不了多少。
	东西了。
	现这样也看不清楚了。好，可以是吧？好，很有意思。我今天其实没有还没想这么快把提交上来了，但手抖了一下就把这个提上来了。但也没事，正好就可以给大家用，用来做一个测试，就是看看你自己的这个GPU驱动和这个库达到底有没有装。对，当然本身这个ChatGLM它也是基于，或者说ChatGLM它也支持了transformers，所以你能看到chat GM36B，它也是可以通过这个transformers的tokenizer和model去加载的。
	这个是跟我们上节课承接起来的。不过因为它还要涉及到一些它的这个微调，还涉及到一些更多的内容。所以我们今天先讲这个简单的微调，再逐步加深，让大家学会怎么样去做这个更复杂的微调，这我就不再做过多的介绍了，反正大家看到了这个notebook可以去试一试。
	一定是通过这样一个简单的方法，就能够去验证你的GPU有没有装。对，因为它这个half苦打这两个参数，一个是加载它的量化的权重，一个是使用这个GPU，简单来说这两个这俩就是干这事儿的。所以如果你只要运行了，能够运行起来，那至少你是满足了16GB，大概16GB好像12到13GB也能加载起来，然后你能够用这个哭的，那就说明装对了，驱动没有问题，我先把它关掉了。
	那么剩下的两个notebook，今天新提交的是我们这节课要的主要内容，都是以fine to one开头的，一个叫fine tune的这个quick star，一个叫fine tune的QA，区别是什么呢？就是这个quick star是主要让大家去以一个要review for这个数据集，让大家去走完一遍这个流程。就是从数据集的下载到预处理，超参数配置，然后评估指标的设置，以及这个trainer，然后怎么样去实际train和最终去完之后的保存。这个因为数据不大，我们是抽样了100条数据，所以是可以直接给大家跑的，这个没问题。
	然后QA就会复杂一些，它是基于这个thread，就是我们讲过的这个stanford stands，斯坦福的这个数据集，然后去做了一个训练。这个训练相对来说比较耗时，可能就没有办法在直播里面给大家训练完了。好，那我们一个一个来先看一下这个要这样的一个数据集，这个数据集我这边也有给这个对应链接，大家可以去回头有兴趣的可以去详细看一看。我这儿就不再去给大家讲这个datasets在hug face hub上面的这个事儿，我们就着发这个翻译成来讲，简单来说这个数据集它就是来自于yelp的这个评论。真实的评论是从这个yp data chAllenge它一个挑战赛里面提取的这个数据。
	然后这个数据集任何一个数据集它都会支持一些特定的下游任务，那在这个数据集里面主要就是一个文本分类，文本分类什么意思？就是给你一个文本，你给他分个类，怎么分类呢？因为它是评论级，所以无非就是打分，就跟你经常打这个打车，去这个餐厅吃饭，都会有这个好评这个频道五星的打分没有更细致，不像现在这个3.6、3.7、4.9这种滴滴的打分，他当时就做了五个级别的打分，所以就这么一个事儿，给一段文本你打一个评级，就这么一个数据集。
	这个数据集里面它的这个示例也比较简单，分别有两个key标志出它不同的数据集里面的内容。一个是我的这个用户评论，一个是这个评级，0到4代表的是由差到好的评论，level 0就是一星，level 4就是这个五星，在它的这个原始的label里面，这就是这两个字段的含义。他还做了一个数据的拆分，就是通过一些随机的方式选取了这个评论，然后最终构成了65万个训练集和5万个测试测试题，然后它是来自于最开始的这个挑战赛里面的抽样，这儿是它的数据集的一个背景，那我们看怎么样去玩它？我看有没有，我们重新启动一下这个notebook，这样能够让他比较。他的这个演示就比较顺畅，是从0到1来完成的，现应该重新加载了。好，那么序号变成一又重新开始了哈那我们通过这个data size这个库，然后加载了这个数据集，yp review for，然后我们去运行一下。能看到其实就是我们刚刚讲到的65万条训练集训练集，然后5万条测试集假设我们要去看一下这个训练集，随机看一下这个训练集里面的内容，比如说这个doctor，goldberg offer everything I look for，不说一大堆，he is nice and easy to talk to without，说一大堆，这个是一个比较好的一个评级，我们再随机抽一个，这个就是一个比较差的一个评级。
	A driving range inside the city，living like a license to print money. I don't think I ask much out of a driving range。Desent出来的一些抱怨的话，这个就是一个比较负面的情感，打了一个比较低的分。其实就是这么样的一个数据集，没有那么复杂，跟大家经常用的各种点评类的网站是一样的。因为药本身也不只是餐馆，各种各样的评价都可以做好。
	我们有这样的一个数据集了，这样一条一条的抽取非常的傻对吧？也就很麻烦。那我们有没有一些什么办法呢？这里两个实战都构造了一个这样的方法，叫修random elements。其实就是去取一些，就把我们刚才做这个事儿给它自动化一下。从我们的这个数据集里面去随机的抽一些样本出来，这样本在这个dataset里面叫example，随机抽一些这个example出来，然后去抽完之后看看我们的分别这个数据有哪些维度，长什么样子，定义一下这个show random elements，然后去运行一下，默认的是抽十个，当然你也可以选择不同的抽取的总数，这里有一个断言，就是如果你抽的太多比dataset的总量还大，那肯定不行，就不能抽出这么多。所以我们能看到通过这个方式，我们能有不同的数据被拎出来。
	我们这儿比较好看的是这个，比如说这个两星的去描述这个地方。Short and suit great, 这个service beautiful inside。说了一大堆note was the money。这个其实就挺有意思的，就是他的这个服务还不错，但是它不值这个价，就是他有点太贵了，这个就两星的，四星的。Great place for the is great and good value. 
	这个其实就是这个函数还是挺实用的。然后大家如果要自己去处理各种各样的文本数据，也能够通过这个方式去处理。并且因为data sets是一个抽象的类的实现，所以他用这个class label能比较方便的把整个文本类型的数据集都抽样成这样的一个维表。然后里面有哪些feature就可以在这儿展示出来，通过一个pandas as的data frame就能很轻松的展示出来，最终转换成了这个pandas的data frame。Pandas是一个很基础的数据分析库，这是我也不再花更多时间去赘述了不没有用过这个的同学，也不用去深入研究，简单来说就是做数据处理的，然后我们也就用到这个层次就够了。如果后面要用的更多我们再讲，所以能通过这个方式大概看一下你的这个数据是什么情况。但从这儿其实就已经能看到，这个评论有长有短，是我们一会儿需要去做预处理的。
	那么预处理怎么做？其实预处理分成两步，一个是具体的处理手段，我们通常都是基于这个token niza来实现的。不管是我们从上节课讲到的，用一个out total anozer，然后从预训练的这个模型里面加载出它对应的token iser，然后来进行处理，还是可能还会有一些别的token。Er但无论如何，这个数据具体的一条一条的一个ample的处理，是它来进行处理的。因为它的功能就是把原始输入变成一个的token vector。那么具体要把这些处理完了之后，批量的应用到所有的数据集上的时候，我们会使用这个data sets的这个map方法。
	那我们看这行这个部分的代码块也就很简单了，我们预处理数据开始有讲过两种策略，填充和截断。那么填充就是不够的，我给它补上，所以能看到这个penny方法有一个这个max然后这个traction是指截断，我设置为true，那就是超过它的话我把它截断。然后这个examples其实就是一批样本，就是我们这里看到的每一行一个一个的一个samples，一批样本。然后这批样本因为我们已经可视化出来了，所以我们知道每个样本其实它不止，它不是一个单纯的key value，它是一个字典，就是我们这里看到的这种结构，有label，有text。那我们的tok anither要处理的其实是这个text，不是这个label，对吧？
	所以我们把这个text丢进去，通过这个方式我们来处理每一条example，然后把它定义成了一个token nice function。这个token nice function定义好了，但它实际没有去处理任何一条example，对吧？真正去处理的时候，真正作用于整个数据的时候，是通过这个token set的mac方法。这个token set是我们开始加载的这个token set，它不是token set，是我们的数据集要数据集。那么这个token set这个数据集加载到内存里了，它的map方法接受一个我们用来处理这个数据集的方法，然后batch的等于true是指它还能加速，能批量的去进行处理。然后通过这个方法我们得到了一个tokenizer data sets。
	大家还有印象我们在pipeline的时候也讲过，原始的输入和token nice之后的输入有什么区别，增加了三个维度对吧？也是下面我们这儿能看到的。Input ID，这儿我把它改成了只输入只抽取一个样本，也比较好看一点，只抽取一个，随机抽一个，刚好抽到一个五星好评的。Not in the best neighbor d，but IT would be worth risking your life for this stuff. 
	然后这个是他input ID，这个是它的token type ID这个是它的attention mask，这一段就明显应用了什么这个策略呢？用了这个pending的策略，就是填充的策略也短，然后其实不够，不需要截断，只需要把它的不够的这个长度补齐就好了。那么整个token nice除了刚刚说的今天讲的填充策略以外，更重要的是把原始输入的文本变成我们的这个token vector，这个是它的本质工作。这个只是因为数据各种各样的情况都有，而需要做的一些额外处理。所以这三个大家别忘了，然后再随机抽样一下，能看到有些不同，这个填充的就能看得到这个填充就少一点。因为它本身正文就很长了，看能不能找到一个阶段的，这显然就截断了。
	大家能看到这个attention mask的变化，就a attention mask这个我们上节课有简单提过，最粗暴的理解就是如果这个attention must是一，说明它原文的，因为我们没有做更复杂的处理。Tok nizar的默认逻辑是，如果我原文不是被填充的无意义的这个值，那么它的attention mask就是一，因为它是正文，它不是填充的V一的这个值。但我们开始有看过有一些填充的无意义的词，它的attention mask是0，我们再来抽一个看看。
	这个抽出来的东西也比较大的。
	after. 
	你看大部分的数据，这里这一条比较明显，这一条就是大部分的attention mask是0。因为这填充的这都是一些填充的内容，所以它的attention mask是0，就这个意思，这个是默认的token nizar的行为。当然你也可以手动的去改造attention mask，跟你最后用的注意力的这个部分的改造有关系，就这么个意思。好，这是预处理的部分，通过这一个简单的代码块，我们做了两件事儿，一件事定义清楚了每一个example我们要怎么样去处理，第二个就是通过dataset的map方法，把这个处理的手段策略应用到整个数据集。然后这个袖random elements方法不影响这个数据集，只是一个抽样，可视化，大家可以去看看这段代码，我就不再赘述了。
	然后我们接着要干什么呢？因为我们要给大家做实时的演示，我们不可能在这等着训练，所以我们抽1000个数据的样本，在这个bird base on case的这个模型上去做小规模的一个训练。基于这个patch的这个trainer这个地方其实它底层使用的pyrr h的这个trainer。但transformer把它的这个trainer的这就patterns的trainer的一些实现给隐藏掉了，直接使用transformers的这个trainer就可以了。但是如果你要去研究，其实transformers s也支持直接去使用排套器的trainer。然后这里我们要进行抽样，那要抽样的话会用到这个，这个是我们token nights的data set，就是上一步处理完了，这抽样完了这个可视化抽样之后，大家别忘了我们处理完之后的这个放在tokenizer data sets里面。
	Token net的data sets里面新增加了三列，这三列有train，有test，那么从train里面我们随机的shafer这个函数就是重新排列，你可以理解成就是什么意思？就是你大家都玩过这个这玩游戏，桌面上全是纸牌对吧？然后我们会随机抽一张比大小sap就是把这个纸牌顺序打乱，就这么一个意思。然后sap既然他要打乱，可以有随机化种子，只要大家用过随机函数的都会有这个概念。那么sharp其实就干这么个事儿，因为本身这个token nice data set它是有顺序的，shafer一下，然后给不同的这个种子然后选，就打乱之后最终要抽抽1000个，抽1000个构成了这个small train的这个data set。
	类似的我们构造出了评估的测试机，都只有长度为1000，大家还记得train本身有65万个，我没有记错的话，65万个5万个，从这里面抽出1000个，然后从下面也抽出1000个，到这儿好，测出来之后，我们数据就准备好了，大家想象一下我们做了哪些事情，加载一个数据集，然后把这个数据集，针对每一个样例都就是全量的70万条，都把它进行一个tending和attraction，做成符合我们要求的输入。然后从这个tokenizer data sets里面再去分别抽取出1000个样本来做训练，就构成了现在这里的small train dataset和small evaluation dataset。好，接着我们才开始加载模型，因为上面都只是针对数据的处理两部分，准备数据，然后定义模型，给模型配置一些参数，真正的开始训练。那么到这儿为止，我们开始需要去碰模型了，这个微调模型训练的那些配置到底有哪些一个一个来，首先需要加载这个bert模型，我们用的but this case的这个模型，那么这行代码其实就是会从hugging face上面去拉取它对应的模型，就我们从这个hugger face。
	其实他就拉取了这个模型，再给大家回忆一下，这个from free train就干这么个事儿，就去拉取了这样的一个模型。这个模型有1亿参数，tensor的type是32位的32位的浮点数，然后它的mask方式是这个，上节课也有一个有也有过一些介绍了。好，那么加载下来之后然后把这个number labels设置为5，因为咱们的这个模型的lab就是5，那就可以把这个模型加载出来了。
	这里会有一些警告，这个警告我也做了一些解释，首先这个警告是说了些什么事情就。Some ways of the model check points没有用它，为什么会没有用它？是因为我们就是不要用它，对吧？我们会丢掉这些with丢掉这些权重，然后给它一些随机化的值，然后再去微调这个模型。然后在这个流程就跟我们上节课还是上节课讲过，我们去微调模型的时候会冻结一些内容。然后会去把这个顶部的一些顶层的top player的一些陈述一些层给它重新训练。是一个逻辑，然后在一亿这个维度的参数是可以这么干的，我们后面看到在这个大几百亿的这个大模型上，可能就不一定方便这么干了，就会用adapter的方法来做了。
	但是在一亿这个维度还是可以的，我们把这个加载进来之后，接着就开始去训练这个下游的任务了，那怎么去训练他们，就要用到这个training arguments，这个是反过来的，要先定义这个trainer实例化的各种各样的要的对象。大家还记得trainer我们需要model，需要这个arguments，需要数据集。那我们先准备了数据集，然后就把模型给拉下来了。然后现在我们去配置超参数，那要配置哪些参数呢？
	这里其实比较最重要的这个配置就是这个output DIR，就是我们的模型权重的保存路径，专门加粗写了一下，就不管你忘记什么了，这个都得配，不然你白训练了，对吧？就找不到了，那它有默认值，然后完整的这个training arguments有哪些参数呢？其实非常多，大家可以看一下，我们刚才在课件里有一个截图，其实只展现了一部分。在这个transformers的这个文档API文档里有讲，这个是transformers到training arguments这个类，它的参数有很多，因为它要兼容很多的不同的场景，所以它会有放很多的参数在里面，各种各样的需求都会在这儿。然后类似的其实大家如果看右边的话，还有一个sequence to sequence的trainer和对应的training arguments。这个我们到合适的时候再跟大家做介绍。简单来说就是trainer是基础的这个模型微调和训练的这个类。然后sequence to sequence主要是服务于这个sequence to sequence的这个网络，对他们的网络结构略有不同，我们就不在这儿去做展开了。
	好，那么我们要去配置它，除了刚刚说到的这个output的DIR以外，也可以去设置这个日志的这个DIR，包括记录日志的这个steps等等。这里有很多的参数可以去设置，包括刚刚这个忘了给大家做介绍了。如果我们要去详细查看，因为刚刚他的这个界面，这个hugging face的transformer这个文档界面看的不是很清楚的话，习惯看代码的同学也可以去github上面去看一看它这个注释，包括它的跳转就很清楚了。在这个github的上面的具体实现，源代码层面上有很多注释，包括它的具体使用，这个是我更喜欢看的文档的方式，所以大家在这儿其实都能看得到。像这个deep speed也是跟trainer有一些集成的。所以为什么要讲trainer不是一来就跟大家过各种各样的库，是因为trainer是这些的核心，都会用它，包括跟hugin face hub的一些交互等等，都在这个trainer这个类里面，算是一个非常重要的核心的一个类，就跟pipeline是应用它的一个很重要的类。甚至这个pipeline对于没有搞过大模型的同学来说，可能看的很fancy，很很有意思。两三行代码就能跑起一个模型了。
	但真正如果你要做训练的话，其实trainer是绝大部分的时候你会接触到的一个对象和他的实力。因为大部分的其他的开源项目要用transformers来做训练的话，也是基于trainer去做文章。不管是我们的课程里面的notebook，还是说他写了一个什么python的脚本，最终都是通过去调用这个trainer来实现的。
	好，那我们回到这儿，我们设置好了这个trading arguments。这个是模型的路径，在models下面大家自己跑完就会有了，我不我就不把这个传上去了也不太现实。上节课的中文的bert和这节课的两个birt。
	对，然后我们把这个定义好之后，可以打印一下，这里就能看到它完整的超参数的配置。比如说这个NGPU等于一是它的一个默认值，因为检测到应该也不智能检测，它默认直到我有GPU，然后默认设置成了这个一就一张卡。包括其他的关于optimized的一些配置，数据类型的，包括这个评估的等等，都在这里。其实可以通过这个方式看到你现在使用的这个training的arguments。
	You过去。好，我们把这个收起来。因为我们只用了1000个样本，所以可以照顾到整个完整的流程，就可以把evaluate给加进来了。我们刚刚有讲过，如果你真实要去训练，比如说要训练70万行数据的时候，你加了在训练过程当中的这个compute matrix可能会比较慢。一千就还行，所以我们加了这个equate。
	正好介绍一下evacuate这个库，evaluate这个库，这边已经点开了。Event这个库也是哈根face开源的。然后这个库也有很多的内容，我觉得重点要看的就是第一它支持哪些评估的指标，比如说在。
	Tutorials里面应该有一个。各种各样的metrics，有哪些metrics可以去？比如说准确率等等，IOU做视觉的，然后他有一个具体的指标是写到哪儿去了？Reference, man class。
	How to? 有一个他已支持的所有指标，choosing a metric。Do you using the IT? 应该是在某一页，我之前有翻到过，回头我发到群里。简单来说就是他会有一页去讲他现在支持了哪些的这个指标，但这个也不重要，因为其实跟你的这个具体任务有关系。
	然后我们在这儿使用一个什么指标呢？用一个最简单的指标，就这个准确率就可以了。然后这个指标通过我们这个event这个库直接去加载就好了，跟数据集的这个使用方式很像。然后这是我自己写的，我靠。被猫给整烦了。对，就是这个invidia metric这里有写它支持哪些指标，然后也有一些动态的space里面去放的，就像这个leader board一样，写的各种各样的指标，包括这个glue等等。这些都是一些大语言模型的指标，包括像IO的reliability等等。
	首先这些指标大家。
	都可以直接去网上再去看一看，这就不再赘述了。然后我们再往下加载了一个叫做准确率的一个指标。当然这个加载之后，我们需要开始有看到去算这个准确率，我们知道这个准确率这个指标加载进来了，但是我们的模型开始有一个课件里面有一页写了的模模型输出的内容和最后我们要去比较的真实的值，不管是label还是什么东西，它都有一段距离。因为模型输出的是logic，是这个概率。那么这个概率要怎么最后变成我们要的那个label，其实是需要再做一步转化的。那通常这个compute matrix这个方法里就干的这个活，那这个compute metrics里面的输入是模型的原始输出，然后拿着模型的原始输出之后，其实这个方法就是囊派的一个取这个。
	简单来说就是我我的模型输出无非就是五个不同的label，会有一个logic，加起来可能等于一这个一。然后我直接去五个里面取最大的logic作为我的这个label，就这行代码的意思。那么取出来之后，我再去跟这个标准的去比较一下，就跟我的真实的标签去比较一下，就能算出这个ACC了，这是最简单的一种指标。好，那么获取到指标之后，我们就可以实实际的来定义一下这个training arguments了，我们看到。这个training arguments里面，这应该是我后面加了一行，就这个地方，我们稍等，but test china。
	可以把这个加上。
	好，这样定一个更多配置的这么一个arguments，然后开始来做这个训练，这个就是定义最后的这个trainer，trainer就是把我们从hugging face上面拉下来的模型，刚刚定好这个arguments，包括抽取出来的两个数据集，再加上我们定义好的算准确率的这个函数，全部传进去。定义好了这么一个。我之前这里还占用的这个GPU给我报没有显存了，把它关掉。很多同学可能没有用过这个，用的不熟。这个就拍lab这里就可以像关这个管理我们的这个就拍摄其他的这个tab。好，这就成功加载进来了。
	加载进来之后我们可以看一下它的这个GPU有没有占用。一种方式是我看有同学也会用，就直接在这儿，其实是可以通过感叹号来执行命令行级别的一些指令的。就比如说这里trainer默认会占用一部分的显存，有一个默认值也是一个参数。他现在默认占了五百多兆的一个显存。但如果你想实时的去查看，就比如说你想要一直看它的这个显存到底占了多少，动态的去查看的话，把这些干掉，我们也可以用。这个。
	可以通过有一个叫做watch的指令，这也是老子。Watch杠N是一个循环去执行的，或者说查看一些指标，非常常用的一种命令行指令。Watch杠N1就是指每一秒执行一条后面的指令循环的。那么。
	今天。
	网有点卡。
	好，那么能看到这个屏幕上面写的LV每一秒执行一次英伟达的这个SMI这个指令，所以你能看到它每秒这里都在变化，就这个地方。卡了，理论上这个远程的服务器应该每秒钟都跳一下。对，卡了，现在是几秒跳一下。然后这里其实就跟我们刚刚在这里看到的一样，输出了一个568兆的一个占用，然后现在我们实际的来做一下训练，刚刚这个指令我也写到这儿了，还有同学可以在这用我们实际的来训练一下。Trainer、trink，这儿会跑375个steps，预计的这个训练时间可能四分多钟。然后ebook 3个ebook这个是trainer的training arguments. 
	的这个默认值。
	然后在这边右边就能看到已经起来了这个六千多兆的这么一个显存的占用。如果我们把抽样的样本再增加一些，这里可能会变得更大一些。那这里在实际训练，我去把我的猫关进房间，稍等过这。
	有个同学有的同学说用VDIACMI本地执行疫苗也执行不完。其实可以的，单纯是因为今天好像我的这个服务器不是很很稳定，有的时候是比较慢。也还行。对，然后我们看一下这个地方有一些不一样的细节。
	我们回到这个训练的页面，大家发现这里到126、375这个时候停下来了，下面多了一个进度条，看见没有？这个进度条为什么会出现呢？是因为我们在这儿加了一个evaluation strategy，就这里就我们这儿看到有一个evaluation的strategy这个strategy就是能够让他在训练过程当中去做对应的评估这个评估什么样的频率来做？这个strategy里面写了每个epoch做一次，那什么叫epoch？就是指1000个样本跑完就叫一个ebook然后我们每一我们这一千个样本没有一次性丢到我们的这个显存里，它也是分批去丢的，这个取决于你的big size。然后目前我们看到很好算，375 3个e poke，然后一个一poke 125 1000个样本，那么125个step跑完，那best side是不是就等于8，很多同学都不知道这个怎么算，其实也就是这个属于非常简单的这一个计算方式。就你的batch size乘上你的step，然后就可以算出来你的这个，然后你有一个总的数量，你就能算得出来了，没有那么复杂。然后刚刚那个输出里面这个training loss这里写的是no，这没有数据。
	如果有印象的话，或者大家在github上面看到我传上去的那个版本，这是no。为什么呢？是因为另一个参数，就是我这儿加的这个参数，就是它的这个logging steps，默认它是500，我们刚才这其实有有看到，然后因为我们375个step就跑完了，所以它不会有这个training的loss。然后你设置为100，自然它也就有了。好吧，这行就可以注释掉，然后他会继续训练。那我们接着往下看代码，它应该也很快了，一分多钟就训练完了。
	然后这个training loss和这个validation loss就分别对应着这个training loss，对应着上面这个进度条出来的loss，这个validation loss是对应着我们在上上面的这一条进展过程当中，我们还有一个验证集，就是我们传进去的这个small evaluation dataset的这个loss。这个是一个做深度学习和机器学习的一个前置的知识，基础知识就是训练集，是我们刚才讲到的会一批一批的丢到显存里去训练，然后算loss。然后算到这个一个阶段，他会拿验证集再去跑一下，得到一个validation的loss。然后下面还有一条去算这个compute matrix，是算这个ACC的，就是我们这里看到这个ACC的这个频率。所以因为我们的evaluation的strategy用的是每一个epoch去算一次matrix，所以我们有三个epoch，这里就会显示出三条分别对应着三个computer matrix的值。
	这俩就是如果我不去设置这个computer matrix，他也会去算这俩loss的，这俩是都有的。这个就是我刚刚说的，我们去评估一个模型在训练过程当中有没有变好，收敛的怎么样。就是两个事儿，两个维度，一个是loss，一个是metrics，就这个意思，然后你就能看得到，其实我们这每个一poke都去算一遍，这个是很麻烦的。因为我们才一千，所以best set设置为8，然后125步，125个steps就能完成一次这个matrix的计算。但假设你的这个训练样本特别大，你从1000干到了1万，那这就是1250对吧？1250的steps。然后假设你是10万，就是这个12500的steps。假设你全量的数据70万，那你就差不多是将近10万次的steps才能完成一个准确率的计算是很慢的。
	然后实际的训练的这个ebo x可能你不是三步，对吧？你可以搞成50步，那就会又进一步拓慢你的这个训练速度，然后我们看这个训练完了之后，它输出的一些结果有全局的这个step数量，375。然后这个loss值训练的loss值1.10，然后每一个这个simple percent就是每秒可以跑八个symbols，然后每秒可以跑1.085步，总共的这个flows和他这个算力，包括他跑了多少个跑了多少遍训练集等等这些数据都会在这儿，大家有兴趣可以去深入研究研究。
	那我们再看一下，我们假设再从这个测试集里随便以另一个shaffer的方式抽取1000个来做一个evaluate。看看它的这个模型的准确率怎么样，100个sorry，说错了100个，那么能看到会略微有不同，比如说我们这儿看到它是0.569，就56.9%的一个准确率，那么在这儿其实是55%是不一样的。这个也很正常，因为我们才训练了三个ebooks，然后准确率本身也还没有特别高。然后你现在去跑这个验证也好，或者拿新的数据去跑也好，肯定还没有完全收敛。所以这个事例放在这儿，就是希望大家把它当下来之后，因为它不需要特别贵的这个硬件资源就能跑起来，可以把这个e poke放大一点，然后看看这个准确率最高能干到多少。也不要用1000个样本了，因为其实这里有65万个。看看比如说你在1万个或者10万个样本上去训练，看看这个准确率最高能干到多少，那这个其实就完成了整个流程。
	当然还有最后一步，就是我们的保存，保存我们之前用auto model可以进行加载保存。这里也是一样，我们都知道用model可以去save model，用trainer当然也可以save model。我们我们用model来自于model，这个在pipeline里面讲过，看大家还有没有印象，再调整一下。
	应该在这儿我们展示过。这些概念比较多，我们尽量让大家都捋明白，就是有模型，有cocooning zer，有pipeline。这是我们上节课讲的这节课我们讲了有data sets，然后有trainer，还可以做模型评估，重要的是data sets和这个trainer，那么作为一个模型来说，它当然可以保存在这儿对吧？我们可以通过这个save free train把我们的模型保存下来，这个是没问题的，保存下来，保存一个模型，我们也确实保存下来了。在这儿这个new bert base chinese保存了这些模型，六天前，那么除了model以外，我们都知道这个trainer它的实力里面第一个配置就是model，那它自然也能够保存model，这个逻辑很清楚，它自然也能够保存model，这个逻辑很清楚，才能保存模型，保存一下模型。
	刷新一下。
	得给它一个路径对吧？我们选bert base case test trainer，我应该前面定义了这个路径，好的，我们把它加上这里model的DIR。
	为了说明我们这个是新保存的，我们取名叫这个假设叫fine tune的这个。One two winner. 
	就我们刚刚定义好的这个fine tune的trainer保存下来了，8秒前、7秒前保存了什么呢？就我们的这个模型，bird base的case，然后是一个什么样的模型，然后隐藏成768，然后flow 32，然后我们也可以把训练状态给保存下来，也放在这儿。没有。
	它的这个芯片状态默认的使用了开始的这个参数的这个位置，就是我们的定义的那个模型的的位置，沿用了这个值。所以走到了开始那个test trainer那个路径里去，因为它跟着这个model走的，只有model可以跟着这个trainer去走。然后也许应该有一个特定的，这个我就不查了。这个下来我们再看一下，应该是有一个特定的参数值。我记得save state应该有个特定的参数名，可以在这个地方去重写，让它保存到这个新的路径里去。但这个流程大家应该已经整明白了，对吧？
	就是我们的整个使用transformers来进行微调，其实这个流程分成三个大的步骤。第一个步骤是准备数据相关的内容，第二个步骤是准备这个训练模型相关的内容，包括它的超参数评估指标，这个模型本身，第三部分才是真正的训练。训练完之后可以把模型保存下来，包括保存它的这个模型本身和它的训练的状态。
	我们现在看的这个其实算是一个最粗糙最简单的一个流程。但是很多复杂的训练流程其实都是在这上面做了不同程度不同环节上面的一些你可以认为是更深入的一些变化叠加和延展，其实就这么回事。比如说我用了不同的这个我用了更细致的预处理的方法，然后我在这个训练的参数上用了更多不同的超参数，改了不同的预训练的权重，用了不同的预训练的模型，过程当中设置了不同的评估指标，并且在训练的时候，我用了更多的设，我用的单张卡多张卡，多个服务器等等。这些其实都是在这一套流程上面去演变出来的，到这儿为止看看大家有什么问题。我来回答一下大家问题。
	样本这么多，假如每次训练一小部分，保存一个模型，再找另一小部分样本，在之前模型基础上训练。最终将所有训练数据训练完毕，这样可行吗？我理解一下你这个意思。
	每次训练一小部分是这个同学，你是什么意思？你是说你的资源有限，所以每次只能训练一部分吗？这个是通过back size来设置的。然后如果你的这个数据没有办法整体的加载到显存里，可以通过这个streaming的一些方式去加载。这些都是trainer的一些更细致的优化了。
	然后你说技术上肯定是可行的，因为check points和这个python的bing文件就是把模型权重放到硬盘上，然后假设你甚至来了新数据，还不是你的场景。更常见的是说你这模型上线了，然后运行一段时间产生的新数据。新数据基于你现在这个模型权重加载进来再去训练，就比如说GPT每三个月会有一个季度版本，每两周会有一个新版本之类的，这里没有设计反向传播的优化器，是trainer默认设置了吗？是的，因为现在很少去卷优化器了。在五年前大家会去选各种各样的optimize各种各样的论文，现在都不卷这个了。
	怎么自定义数据集？这个不在我们的主线任务上，但是刚刚有讲，所以给了一些脉络可以去研究。通过这个dataset builder和这个builder config可以去玩这个数据集的自定义，这个随机化种子的设置是不是随便一个数，还是设置要求这个参数是随便设置的。
	Training set和evaluation data的这个set要一样吗？现在都是一千。对，这个纯粹是为了演示方便，实际上我们不太会这样的，实际上会可能是一个1比5甚至1比8这样的一个关系。就是这个训练集和评估的测试集1000，因为太小了。对，主要是为了我们这个直播演示方便，不然我们就得等在这儿，这就没必要。对。
	数据准备的过程，超参数的指令等。那肯定的是这样的，其实你说微调就这么回事儿，这个notebook就已经讲完了整个微调的流程了。举个简单例子，我还喜欢举一些比喻让大家理解。就是你如果把模型微调这个技术当成炒菜，当成厨艺，当成一个厨师的技术的话。那现在我们就已经知道了，要当一个厨师有这么几个步骤，你得会买菜，会洗菜、会切菜。好处是说关于买菜、洗菜、切菜这件事儿，hugging face的data sets加上它的hub都干完了。你去hugging face hub上面可以找到一堆已经洗好的菜，通过node data sets弄到你自己的厨房里，这个是node dataset告诉你的。
	Token either要干什么呢？Token either是说我们针对不同的模型和下游任务，需要把它做编码和做预处理。就跟说你的菜洗好了，你要切切的时候，你这个土豆？有的是切片儿，有的是切块，有的切滚刀。为什么呢？做的菜不一样，有的还切丝呢？对吧？那这就是因为你要做的菜不一样，下游任务不一样，你的顾客不一样，你的模型不一样，所以你要改刀。这个token ezer干这事儿的那改完刀之后，你是不是还得最好土豆丝切成都是一样宽的，土豆片都是一样厚的。就是我们为什么要把这个padding跟traction做好，不然顾客吃了不满意，顾客就这模型对那塞牙，你这个维度不一样进不去，人家特别挑，是个机器不是人，大一大一寸都不行，就是得维度一样才能相乘，因为他那儿其实还要做一堆的处理，那么对于我们来说，到这儿为止，我们知道了做出是啊要把这些东西做好，前面的预备工作就做好了。
	那真正的训练这个trainer这里无非就是我需要炒菜，那炒菜炒菜你说有多复杂，没多复杂，对吧？把你刚刚弄好的这堆洗好切好的菜丢到锅里，开个火浇上油，你就能炒出来了，好不好吃呢？不知道，就像我们现在我把这个参数都用的默认的，然后数据也选的比较少。就跟你明明炒一盘菜，我只放了几根菜下去，这盘菜肯定就没炒好。因为数量都不够，他的这个数据样本没给够，这么大个锅就丢了几根菜叶进去，那肯定不行那么现在你把合适的这个数据都丢进去了，然后你也会炒，会开火了，有一堆的超参数需要配置，有一堆的参数需要配置。这个不就跟炒菜过程当中的火候放多少盐、放多少醋、放多少酱油、放多淀粉一样。所以training arguments其实是真正最复杂的部分。
	因为它是见人下菜，看见你用什么样的预训练模型，什么样的下游任务，你应该怎么样去调整它的arguments。甚至根据你的这个下游的任务，你的模型还会去调整token ized，就是我的token ized的技术应该怎么样去叠加，对吧？我的这个改刀改完之后，剩下切下来的部分是扔了，还是说可以继续放到盘里做点别的用处？所以你说这个notebook其实已经讲完一个厨师的这个工作的医生了，就是干这个事，买菜、洗菜、切菜、炒菜、装盘。但是真正复杂的就在炒的过程当中，并且越厉害的人，他通过炒的这个过程，他知道不同的菜，不同的原材料，不同的顾客应该怎么样去设置这些参数和超参数。我不知道这个表达清楚没有，其实就这么回事儿，对模型微调就是这样的流程，就是这个流程，但是里面细节非常多，然后没有哪一个真正的师傅说他精通这个八大菜系的对吧？就像没有哪一个做算法的同学说他精通所有模型微调的一个道理。
	Fine tuning的话，arguments是不是可以直接抄原来模型的参数，就像模仿厨艺大师的手法。再来一遍。是这样的，就是你你的这个说法就很像经典菜，青椒肉丝、麻婆豆腐，他一定是有很多经典的配置的，肯定是能做的对，这个事儿是肯定靠谱的。就是照着已经很成功的这些超参数去配置在固定的这个模型上，是可以的。然后任务又不变，下游任务不变。
	但实际情况你想象一下，更多的实际情况是什么？是你的顾客可能是你的用户或者leader，他他以为他要吃他喜欢吃的是川菜，你也给他做出来了，你按照网上的食谱做了。但其实他不知道他喜欢的是香菜，他以为他喜欢的那个叫川菜，所以最后那个就没有那么适用对吧？因为回锅肉跟这个小炒肉的区别就是回锅肉要先把肉给煮一遍再来炒，对吧？那这个煮一遍的过程就是他得提前做一些数据预处理，你没去做这个预处理，你做出来这个小炒肉怎么都不像那个回锅肉。
	虽然看起来都一样对吧？用的是同一个模型，同样的锅、同样的灶，同样的青椒，就是不一样。可能因为你没加豆瓣酱，对吧？你没有有一些关键的地方你没调整到位，是这么个意思。所以实际情况下，我们很难遇到一个场景或者情况是你的所有的这个模型要适用的场景和某一个经典的情况是一模一样的。
	但是八九不离十是可以的。比如说你的这个用户虽然他要的是这个回锅肉，那他说的是这个小炒肉，但你给他上了一份小炒肉，他觉得也还不错。原来回锅肉还能这么做其实他也能接受这么个意思。
	然后pending和traction的设置对微调的影响是什么？首先为什么要设置他们？是因为我们刚才讲的这个模型它必须要invading vector的维度是固定的那你现在你这个买回来，对，你得改刀，你不改刀没法做。同学就是你要做一份这个，你要炒一份回锅肉，你要用青椒炒，你直接把菜市场的青椒丢进去肯定不行。你不得给人家砍了砍成片儿或者砍成丝。那你要砍成片还是砍成丝，取决于这道菜。那菜是怎么来的，取决于这个客户，那就是下游任务。
	怎么在训练出现异常时保存模型的checking并自动重启训练，这是两个维度的事儿，两个级别的事儿。
	首先异常的时候保存模型的check point，两种方式，一种是也是比较常见的，是定期的去存这个check point，就像我们待会讲第二个，我们看这儿，第二个this distal bert，这个玩意儿你看这个就自动存的，它默认500个step，存一次check point默认存。所以这个是什么意思呢？就是相当于快照一样的，就特定的步数的step就会存一下，所以你不用担心。但如果你的login step设置的特别长，就一万步才存一次，那这个首先这参数就没设置好啊。但如果你的情况比较特殊，你就是得一万步才能存一次，那你就得通过什么手段呢？通过try catch，你去相当于出现了异常，你捕获到这个异常。捕获到这个异常之后，你的trainer，你的整个程序捕获到这个异常之后，你去把这个trainer给它存下来，然后是可以的，但前提是你的异常没有导致这个python程序崩溃。但如果这个python程序都崩溃了，你的内存，你的trainer都已经受到损坏了，或者说你的显存，你的trainer都已经受到损坏了，你也就不好存了。
	最好的方式还是定期存，然后从这个定期的check point里面去取数据比较靠谱。然后自动重新训练，不建议自动重新训练，就是因为一般出现了问题，你需要去看一下出现了什么问题，是不是OOM了，或者是不是你的数据预处理没做对。碰到了某一个example的时候，它的维度有问题，导致你在底层的py touch里面做这个矩阵相乘的时候报错了。如果你不去处理，你直接重新训练他到那儿他还得错。就相当于你你你你在这个训练过程当中，其实你就在练习。你一天要做一千份回锅肉，然后你的出问题就是在于你每次你都不去放这个豆瓣酱，对吧？那你做出来一千份都是错的，因为你就是没放，你得回去看一下到底哪儿出错了，这样比较靠谱。所以第一时间不是自动重启训练，而是写一个什么告警通知，告诉你你的模型训练出现问题了，去看一下。如果他刚好只是一些别的环境导致的，跟你自己的程序没问题，那你继续训练就好了。
	评估过程当中会需要参考ACC是用什么方法计算出来精确度的。刚刚讲过的这同学是不是没仔细听，还专门说了。首先这个准确率是一个数学概念，或者概率上面的概率论方面的一些概念。然后不同的问题它准确率计算方式都不一样。那就我们这个评级来说，刚刚我专门说了模型输出的是每个label对应的logit我们取最大的logical的label作为模型输出的这个label，然后用这个label和真实的这个验证集里面的label去做比较，就能算出这个matrix。一样的话就是一分子就是一，不一样分子就是零。然后做一个sigma对吧？加一下再做一个算术平均就得出来了吗？
	超参数的设置参考哪里模仿哪，这个蛮多的，就是你甚至在cutting face上面都能看到大量的信息。所以每个模型都有，我这儿就不再赘述了，我们到具体的一些这个里面再去看，都有一些经典值。这个同学问的就都有一些经典值。就比如说你的这个adam的这个optimized这个优化器是training trainer默认的这个优化器，它都有一些经典值，甚至是经典值都已经变成了training arguments的这个默认参数。
	截断会不会造成语义丢失？当然会，我们第二个马上就要讲了，时间原因我们直接开始第二个。这个实战需求场景不明确，感觉听懂了又感觉一头雾水。同学这个实战是在实战transformer这个库怎么样做微调训练，不是在实战。你手头的工作就是实战，是实战的这个技术，不是实在你的这个工作。所以我不清楚你的一头雾水，到底是哪儿有雾水。
	如果你现在没整明白训练，你就你完全不知道什么叫模型训练，需要再回顾一下之前的课程，整明白什么叫模型的训练。然后你如果不知道这个模型训练出来有什么用，你就把这个模型训练出来的这个结果，你打印出来看看，或者说直接用这个show random，就我们前面展示的去看一看，就简单来说这个模型就有有一个能力了，这个能力是干嘛的呢？就是你给我一段话，我能给这段话的情感打一个分，分数这个就其实就是他的label，分数越高表明它是越积极的，分数越低表明它是消极的这就是这个模型的价值，这也是这一类自然语言处理的任务，情感分类。如果你之前没有做过自然语言处理的任务，那你就去查看一下相关的资料，这一类任务是一个非常通用的NLP的任务，然后可以用到各种各样的场景里。然后你现在把这个样本数放大，你训练出来的模型就能拿来干这个事儿了。因为它是英文的，所以只能对英文的语料做输入，那你可以找一些中文的数据集，用这段代码去跑一遍也是靠谱的。大样本是不是把整个数据集微调一遍？是的，我们把这个加到这儿，写个家庭作业，homework. 
	呃。
	好，我们把这个homework就写在这里，看大家到时候比1比，看这个ACC最高能到多少，时间原因我们就开始。第二个这个反应通，这个更复杂里面就是从现在我们就开始讲一个厨师的自我修养，就是怎么样把这个各个环节做的越来越好啊，这个是我们整个课要研究的课题。我们也都知道一个厨师的自我修养就是没有上限，对吧？能针对不同的问题，不同的场景，不断的去丰富自己的这个技术战。让你熟练各种炊具，在各种厨房环境下，各种客户的要求下都能做出一道好吃的菜。
	微调出一个好的模型，现在我们就来看看刚刚那个是情感分类的任务。模型是你用不同的语料，最后训练出来都是能去用的，包括现在这个英文的也是能用的。只不过拿他现在的1000个样本和三个一poke可能不够好啊，你把那个训练的再好一点就能用了。
	怎么用pipeline？大家还记得pipeline是可以加载我们刚刚sib的model，然后走那套预设的API的。啊不要把这节课学了，忘了上一节课拍不烂怎么用了，然后我们再来看一下问答类的任务怎么做，这里有一个黑体字的强调，就是大家要知道GPT4或者说这个GPT3.5这种很通用的ChatGPT类型的这种应用大模型应用是很难做的。
	我们现在在一张卡上面去跑的这个模型，就跟之前这个pipeline API1样。它虽然是问答任务，但它需要有这个上下文，需要有context来支撑他去做这个问答，而不能说直接去问答。因为他没有做一个大语言模型，把知识都存进去，那个需要的显存特别大。但是就算是基于context来做问答都很难很复杂了，那我们现在先看看怎么样基于context来做问答来实现。并且就算是ChatGLM3的这个6B，它也不是说所有的版本都是支持这种连续问答的，包括这个function calling的。所以大家不要认为这种AI的聊天对话是一个非常简单的事儿。微软小冰投入了这么多钱，几十亿都没有做到那么好。现在只是因为整个大语言模型的技术起来之后，水涨船高，让大家感觉到这个AI的聊天机器人很简单，但其实这个技术很复杂。
	我们现在先看这个就问答怎么样去微调一个语言模型，预训练的这个模型来支持这个问答任务，示例就这么一个意思，就是有问题，微软阻碍链上下文，我的名字是叫什么？我住在哪儿？然后计算一下计算的结果，就是基于这个context得到的这个结果，然后有一个对应的答案就是brook in，那这个brooking有一个logical自信度这个自信度就是我们从这个模型当中提取出来的logic，然后这个模型使用的这个distil bert base on cast这么一个模型，这个模型我们也同样可以在这个地方看到。就这个模型这个模型6700万的参数，使用这个32位浮点数，然后他就支持这么一个模式，然后支持这个pillow mask，我们往下看啊就不浪费时间了。然后为了适配大家的一些情况，大家可能有自己的这个GPU不同，然后你的这个GPU甚至更强，那么这些都可以去做调整，包括你的模型名称，你想换一换，这都可以去做调整。我就这个比较大，没法实时去运算，但是下午我确实把它这个训出来了，然后大家应该也可以通过，按照我们的这个最低要求，应该是能训出来的。
	在这个地方，最后花了将近两个半小时，总体的这个时间应该是8400秒8450秒，然后跑了4152步，大概训练出来了一个阶段性的结果，当然这个肯定还可以再降低的，那我们就看看代码，然后大家有什么问题我们可以大家实际跑的时候我们再来问。但这个流程我就讲不同，跟刚刚这个流程有什么不同这个代码是肯定能跑的，因为我自己已经跑过了，第一就是这三个参数是可以调的，分别表示你是要用这个standard问答数据集，这数据集很有名，就这个水机SCSS没加载出来，就这个数据集，这数据集已经非常高频的出现在了我的课程里面。也在红山当时做出来的这个所谓的大语言模型，超过了这个自然语言任务上，超过了人类。也是拿着这个score 1.1和score 2.0来做的这个比较，里面有一个human performance，这个score 2.0和1.1有一些不同，那具体关于数据集这个我们就不再展开讲了，不是我们的重点。
	然后下载数据集，一样的使用这个node data set，然后加载这个SQUAD，也就是一个square v two。然后我们这儿有一个参数叫做thread v2等于force，它默认没有加载这个V2，默认的是加载的这个1.1要少一点。印象当中是这样，然后你也可以把这儿设置为true，它就会加载这个v two了。这段代码大家应该能看懂，就是比较取巧的。它如果设置为true，就加载它，不然就加载它，调整了不好意思。加载完了之后，它是一个dataset的一个，刚刚我们都介绍过了，但是它跟我们的yelp的review for data set有点不一样，咱们把它弄过来了。
	这个做实例，大家看到在这个yp的这个review里面就两列label和这个text。在我们的thread里面有ID有title，有context question answers，这很明确，对吧？就是我八万多条这个数据训练集里面的，有上下文有问题有答案，这个几乎就组成了我们这里的这个内容。当然还会有一个ID，就是我这是第几条example，还会有个title，就这么一个意思，然后这个validation也是一样的，然后我们也可以取出来，取出一条，这个里面就会写ID这个意思比较简单，然后university not them，然后这个context是比较长的，就上下文比较长，然后问题和答案，我们可以看一下这个数据集的组成。
	首先问题，to whom did the virgin mary and here不是说了一大堆，然后答案是什么呢？答案是这个santa b什么saw beers那玩意儿，这么一个东西。这个答案里面其实是两部分组成的。大家去细看，这个代码里面对于数据的处理就更多了，这也是我们经常要做的内容。
	你也可以想象一下一个厨师炒菜的时间和洗菜切菜的时间占比，就是我们的就跟我们微调模型一样，如果你是一个能做菜，做过菜、炒过菜的人，你就会知道真正炒菜的时间就那么几分钟。我这个炖菜、烧菜、厨炒菜，我特指真正这个炒菜的时间就那么点，大部分时间在干嘛？再去菜场挑菜、洗菜和这个切菜的过程，就跟我们数据处理一样，就绝大部分时间是在处理数据，然后就跟有个预言故事叫做消除是视力一样。
	因为你的模型定了，你没太多权利去自己创造一个模型，所以你大概率会选择一个模型。就像你选择了一份菜谱，那你选择了一份菜谱，菜谱有要求，你就得按照菜谱去找数据，去处理数据，就这么一个意思。包括你把这个数据造成特定长度的vector不也是一个意思，对吧？
	对于这个数据处理是比较复杂的。在这个里面我们再看一下刚刚的那个情感分类。简单就简单在我模型的输出，有一个label，有一个logical。然后我有五个label，五个logic，五个logical里面选出一个最大的logic对应的label，就是我的这个评级多简单。但是这个问答任务复杂在哪儿呢？它不再是说我输出一个类别标签就够了，我其实是要输出一个什么呢？我要输出的是一句话，一段自然语言。
	在这个训练数据里面，我们首先看到这个answer有一个叫做text，就是这个文本，然后answer start，这个answer start是它的文本当中的一个起始位置，这个起始位置在哪呢？在这个位置，差点误触到这里，在这个位置高亮一下，这就是它的完整的一个训练集的。你可以叫label，也可以叫做这个label的参考。这个是组成了它的这个S，那我们就会看到在这个代码里面，最后要去把它的这个模型评估做出来，要去取出模型输出的这个。因为模型不会直接告诉你标准答案的，模型输出的是概率。那从这个概念里面最后要去组合出这个词，这一句话是比较麻烦的，但是也都是可以捋得清楚的，也不复杂，但是需要做一些处理。
	好，我们看到数据集是长这样子的，有这么一个特点。然后同样的我们可以从这个数据里面去取出一些内容，这个代码也是类似的，就不再赘述了。当然它会比刚刚复杂一点，刚刚只有这个label和text，现在我们有ID，有title，有context，有question，有answer。这个是咱们看到的这个训练集OK然后我们要预处理数据对吧？怎么样预处理呢？这里有加载一个token ized，然后这里的token ized跟我们刚刚用的又略微不同，相当于我们的打下手的切菜的兄弟进步了。
	给大家介绍另一个token niza，也是一个transformers的预实现的token ized，叫pre trained tokonoma er fast，是一个rust实现的zer。简单来说就是他切的更快，他他的帮忙的水平更高，然后可以用这个token either来做实现，然后我们针对这个token ither输入两段话，分别对应的是what is your name？My name is a分别对应的是这个question和这个context。
	因为我们要知道最后我们这个应用场景，这个问答任务的场景，它是一个给一个是问问题，一个是给你一个参考的上下文。然后最后你回复的是答案，所以是输入两个输入两个或者说输入两段话，然后回复一段话这样的一个应用场景，所以你的这个输入就是两段分别对应的问题和这个上下文，然后在这个token nice的过程当中，就是在你去切菜，在你去处理数据的过程当中，我们开始有讲到截断。但是截断就会有一个很大的问题，就像刚才有同学讲的，就是我们几个同学讲的叫做什么截断会不会造成语义丢失，对于长文本有什么好的策略避免这种情况发生？
	来，这就开始了。如果我们不是像刚刚那个问题，刚刚那个问题就是一个评论集。评论集里面我们都知道人的评论大部分时候就是那个车轱辘话反复说。但如果我们现在是上下文加问题这样两组组成的这么一个输入，那么假设你的问题和你的上下文比起来，通常我们在这样的一个场景里，落到这个场景里问答任务，你的上下文大概率是比你的问题要长得多的那我们回到这样的一个查看，这一列是question，这一列是上下文。通常来说肯定是问题长度短，上下文的长度比较长，那么我们要截断无非就是把这个，因为这俩是合在一起输给模型的。大家要记住，不是分别输的。合在一起输给模型的时候我要截断，那你肯定不能把问题给截没了，对吧？那你还怎么训练呢？
	你最多是把上下文给截一段，至于截一段的下来，这个东西还要不要再说。假设你现在不要了，那你至少问题留着上下文砍一点。就跟你要做青椒炒肉对吧？现在这个锅里面炒不下这么多菜，然后你不可能把肉先扔了，对吧？炒了盘青椒给别人，那你这怎么玩呢？我要的是青椒炒肉，重点是肉对吧？不是青椒，因为我青椒炒肉也可以换什么什么木耳炒肉，什么都可以炒肉，重点是那个肉。
	你别最后搞错重点了，然后截完之后只有上下文，没有问题。这个训练不了answer都对应不了问题了。好，这个是一个重点，也是我们看这个代码要整明白的。好，那我们截断的时候就要去理解它怎么截了。好，那我们假设我们就对这个。首先现在这个模型它的输入它要的这个长度就是384，这个是它的模型网络决定的。如果大家不知道可以去看一下这个模型，它的这个主页有介绍，我就不再赘述了。既然它超过了384，我就一定得结。
	那怎么结？就像我刚刚说的，我们要去截那些上下文的部分，而不去截这个模型的部分，具体怎么结的呢？就是我们看到，首先我们通过这个一个循环找到大于384的，找到之后我们把它取出来一看，它超过384了，396，它的token还多了这个12个，怎么办？
	那么我们通过这个token nizar的这个方法，可以去做这个截断，叫做only second这样的。刚刚我们用的是叫什么？叫true，对吧？回想一下我们刚刚处理的策略叫什么？在这个位置叫traction等于two，都是图个neither对吧？那么我们现在用的这个fast token ized，它有一些别的处理手段，其中就包括这个only second，简单来说就是如果我们直接截断这个部分，就用in这个C它就保留了，就把那个就干掉了。
	然后如果我们想要把简单就是你还是举个这个比喻比较好。简单就是你还是要炒菜锅太小，然后你菜都切好了，然后肉留着青椒只能用一半，剩下不还有一些青椒吗？你也别扔，你留下来留下来要怎么样留下来呢？
	通过这个return overflowing tokens等于true留下来，那留下来之后留多少呢？因为有可能当然这个可能不一定用炒菜来来比喻形象了。因为这个青椒他用了就是用了，没用就是没用。但实际上我们截断保留语义的时候，它会有一个重叠的部分，因为如果我把这个上下文硬砍一刀，然后硬砍一刀之后，前面这部分我自然能够去尽可能的去保留到最大长度了。但切下来这一段可能它都不到384，它可能只有12甚至更少。但是切下来这一部分，如果我只就是我这个刀锋特别尖，我切下来了，那他可能就把一段完整的话都切成两句话了，甚至可能把一个短语都切开了。所以我一定会把切下来的这部分，不是只留切下来的这部分，而会再往前，相当于有一个滑动窗口，再往前去多找一部分，相当于第一部分和第二部分有一定重叠，然后这个重叠通过这个stride来设置，这就是这里的两个参数，就是我可以允许有这个overlap，就是我的上下文要被切掉。
	那我的上下文被切掉之后，我的上下文被切下来这部分给他补一些前面部分的，让后面这部分不至于是一个毫无意义的一段，这个大家应该能明白了。然后那么切下来之后，我们能看到切下来的这部分相当于原来是一个超过这个长度的，就变成两段。因为原来我只有一个vector，里面既有相当于原来的这一个384长度的vector。有question，有context。那是因为我现在的这个训练样本太长了，我没办法，我只能把它切成两部分并且给切下来。
	第二部分组装了一些前半部分的内容，那么就变成两个了两个vector，然后长度分别是384和157。这部分的这个技术上上节课教过，就是token nice之后，我是可以decode回去，还原成原来的这个内容的那这段内容就是想给大家看这个逻辑，这个已经拉满了384了，这个就是我们的前半部分有问题，然后也有这个context，那这个问题是什么呢？问题是这都是上节课教过的内容，不懂的再回去看一下bert。COSSEP就是question，然后这个SEP到这个SEP是截断了的context，然后当然还有这个第二段，第二段当然也得保留这个问题，不然我这个上下文都没有对应的问题了，对吧？所以问题第一就是问题还在。但是这个部分是我砍下来的后半部分的context，它跟我的第一段话是有一定重叠的，重叠的部分，我看从这儿能看得出来，the 2010到2011的team concluded its regular season，就是它开头的部分，就是这儿就对应的这一段，其实它就相当于。
	把这部分。
	我看看2010，我确认我看的是正确的，1908，32比6。对，32比6，25-5，就是把后面这一部分又挪到了这里来。大家应该能看到，它这一段的开头应该是到32这儿，就下面这一段，整个第二段一直到这儿，就对应着是前面都有的内容，第一段都有的内容。但是我们不是抄了这个十几个token，抄的其实就是这一段。
	The most by the fighting irish team since a nineteen eight. 就是这一段超了，所以我一个一个vector放不下，我就只能干成两个vector。但我刚才两个vector，我后面这一段不可能只留一个。The most by the fighting average team. 
	对吧？没有意义了。我最后要这个模型实际从这context里面去提取我的语义，在做构造答案的时候就没用了。所以我从前面再拼一些给他，就这个意思，拼多少呢？这120决定的128，这个大家看明白了对吧？洗菜的这个流程说明白了，那这个预处理就这么回事，就这样去处理的那处理完之后，其实这里还会有一个问题，就这脑子里面大家应该都整明白了，就是那我最后怎么回去的？
	因为这儿其实变成一个问题是啥呢？你可以想成什么？这里可以举个例子，就是你锅很小，但是人家客人要的就是一盘菜，对吧？你可以分开炒，你可以把那个这个我不知道这个做做出来好不好吃。就比如说你的青椒放不下了，你先拿这个混沌汤，你你要炖个什么牛腩，然后你翻茄太多了，你先炖了第一锅，然后牛腩在里面炖好了，然后你可以盛出来了。因为番茄再炖就烂了，你把番茄先给它盛出来，再放些番茄进去，因为牛腩它很精炖对吧？然后又炖出来一锅。好，这下好了，你终于把番茄用完了，牛腩也用完了。完整的一个番茄炖牛腩的超大份出现了。
	这个超大份的才是客户点的那一份菜，因为相当于你的装菜的容器是足够大的，但是你的这个锅就这么大，所以最后的问题是什么呢？你分成了这个你是开饭店的，你有十个顾客都点了番茄炖牛奶，你得搞清楚现在这个番茄是属于哪一个客户的，哪一锅，对吧？那这其实是有一个第二步的映射了。还不只是说我的这个token vector decode回来就能找到我的自然语言。而是说我这一堆都不知道是什么的token vector，他还被砍成两截了。这两节最终要归属到一个客户的一个锅里去，这就是这个offset mapping要干的事儿。就是把因为你要知道实际情况，它有可能更惨，他这个要分成三部分的、四部分的、五部分的都有可能。通过这个offset mapping可以找回到我原来他们到底是哪个顾客的哪一锅。
	这就是这个offset mapping，去获取原始的input ID干的活。它相对上面的部分增加了这个呃，就我们上面是通过什么呢？通过return overflow的token和only seconds加上这个实现了这么一个切割，大家有印象对吧？我们现在再增加一个return offices mapping，其实就是再增加一个映射关系。知道我这临时炖出来的番茄先放，它是属于哪一锅的，记下来。然后我们把这个打印出来，相当于就是新增加了一个内容。就是我们能看到现在这个token，在这里面的这俩token，到底属于原来的那个input ID，就保留这样的一个映射关系就可以了，那这部分其实就干这个事儿了，通过这个fast token nizing这个sequence ID可以实现这部分我就跳过了时间关系。然后大家如果这段实在看不懂的，注释也看不懂的，我们回头可以再问。
	然后简单来说，反正就通过这个offsets，能还原到原来等于ID，然后填充也是一样的。这里补充讲一句，就是我们知道现在这两个notebook的填充策略都是往右边补齐，右边补齐。但是并不是所有的这个模型，它都是右边补齐就靠谱的，有的可能是需要左边补齐也是可以的。这个通过painting side来left就可以了，right改成left就可以了。并且如果我是左侧敏感左边补齐的，然后我的顺序可能就变成了什么呢？Padding的空白内容。
	然后这个question或者说我们的这个context之前我们的顺序是什么？大家想象一下，就是先问题上下文补充的部分，如果我们现在倒过来应该是什么？应该是补齐的部分，上下文和问题。这样比较好，不然会出现什么情况，就会出现你的问题被截断了，对吧？因为我现在是以前是砍右边，现在是砍左边。如果你还是把问题放在前放在左边，上下文放在右边，那你砍的不就是问题吗？所以这就是你如果是左侧填充的模型，就把question和context在这个vector里面的位置调转一下，这样就能保证你的question始终是能被找到的。因为我们砍下来之后，都会把这个question补充到这儿，所以如果是左侧填充的话就变成了question可能在最右边，然后前面是这个context被截断的部分，就这么个意思，就跟这个先炒哪个后朝哪个差不多。那上面这些所有的预处理步骤，我们最后还是可以变成一个function，对吧？
	就我们刚刚看到这些步骤，包括这里token iser的部分，我们最终都可以变成一个，包括这个setting和这个offset的部分，然后都可以变成一个函数的方法，就对应着其实就是就干干的事跟他一样，只不过我们处理的更复杂了。为了保留语义，为了保留context的语义，然后为了应对不同的场景，为了能够把offset的input ID找回去，干了这些事儿，然后它变成了map的这个函数，然后这里我们还有一个remove的columns的方法就是因为我们在这个预处理的过程当中，样本的数量做了更改。简单来说就是我们在做预处理，然后在做预处理之后，之前的一条可能会变成多条，甚至样式都不一样了。然后我们把一些不要的这个column name就给它移除掉就好了，然后这样也能提速，然后就这么一个功能。好，然后这个就是他的map要干的活，然后到这儿为止其实就把数据给处理完了。听起来好像这个代码很复杂，但大家一行一行看过来应该也没事，也没那么复杂的对，就是大家要习惯读代码，然后都有注释的。
	然后到这儿我们就要加载模型了，加载模型跟之前的模型不一样。大家如果仔细看啊，上一个任务我们是做情感分类的，所以是加载了一个叫做sequence的到这儿来大家录一模型在。在上面，我们之前叫sequence的classification。这个其实在pipeline n的时候也讲过，就是它有不同的下游任务。这个sequence classification就是我们现在做这个情感分类的任务。我们要做问答的话，会用这个auto model for question answering这样的一个auto model，然后去加载加载就是加载了我这期就是我们要做的这个模型，这个模型我们刚已经看过了，是hugging face开源的，这一段警告也是一样的，这里有些超参数可以调整。
	对于这个16GB的T4这张卡，best size可以做到64，甚至可以稍微再长一点点然后保存的这个模型的路径，就这里我们设置的比起刚才这里多了一些超参数。比如说learning rate，我们选择了这样的一个学习率。然后因为用的这个默认的adam，还有一个超参数是wait decay，就是这个权重衰减，然后这个其实是默认值，写不写都可以。然后如果我们有这个多个，就是我们有这个多张卡的话，可以用这两个参数放在这儿。其实大家如果有多张卡可以实际跑一跑，如果跑不起来，我们可以再把问题报到在githa的项目上，我可以再来帮忙调整，争取让大家单杠多卡也能跑起来，那beside也能设大一点，这个数据整理器也是一个提效的，在模型训练的时候可以去做批次处理，这个大家使用默认的就好了。
	在这个地方，其实trainer也是一样的，我们使用的这个model使用了上面的arguments，传入了两个训练集。但这里我们没有再加compute的matrix了，因为我们用的整个squad v一的数据。你每一个epoch去再再去给我算一遍，这个时间还是挺夸张的。简单来说就是本来我只要两个半小时就要变成五六个小时了，那可能今天就没法给大家演示了。对，所以是这么一个意思。当然你也可以加，你也可以加computer matrix，这个不影响。
	然后token either就使用我们上面的这个token either进行训练，这个是实时的使用this deal。Bert, 这个best side 64 squad这应该是1.1严谨一点一点一。然后实际的一个内存占用几乎是快占满了。因为它实际可用的这个可分配的这个显存是15G多一点点，用了14.5G在这个T4的卡上面。
	然后跑的这个时间刚才也给大家看了，2个小时20分钟，跑了三个ebook，然后训练完成之后，这个很重要，第一时间对对，有人问超参数在哪设置？所有的这些训练参数我刚刚有强调，都在这儿training arguments，然后第一时间一定要把模型给存下来，不然你想搞了这几个小时？那个没存下来很蛋疼。虽然有check points，但是这是个好习惯。然后模型存在这个是存在哪儿呢？
	我这边设置了一个路径，model DIR，model name，然后model name是叫this deal bert on caste。然后为了跟check points区分出来，我加了一个。叫trained model path，叫做train，不一样，这个是训练出来的模型，以及它的这个token ized，包括他的词表等等，这里面就会有写。然后包括它的token nizar的一些配置，以及我们训练的这个sorry，这个不是UTF8的，就pat lab加点错了，这个看不了。这个token ized conflict是可以看的，然后token ized的Jason也是可以看的。这些其实都是大家把这个代码克隆下来，或者破到这个新代码之后，可以去实操去去操作的。这个token能的太大了，我这就不展开了。
	那么训练完成之后，保存下来，用这个save model保存到这个路径，就是我们现在看到这个路径，你也可以去改一改模型评估我们刚才讲了，不在训练的时候评估，因为训练有loss也不会影响它。那如果我训练完了要进行评估，怎么评估呢？这里其实就涉及到我们看这个经典的pipeline里面有讲，就是这个pipeline里面。最终我们开始讲了怎么样去处理从原始数据，然后切割到一个我们能给模型的输入。现在成了从一个问题，就是说我模型输出的logic又怎么样变成一段话呢？这个其实也很不一样，跟前面的这个实例比起来，怎么弄的，看看。
	这儿模型评估简单来说就是模型输出的这个logic，它的这个预测值，我们还要映射回原来的这个上下文，然后映射回去之后，接着我们才能组织起来这个最终的答案。那模型输出的是啥呢？我们看一看，这个地方我是是应该是收起来的对。我看一看模型训练train的model，对，收起来的。这个是我把这个模型保存下来之后，又去加载了一下，加载的这个叫训练好的模型和训练好的trainer，这两个应该被我移到最后了，这个是一个家庭作业，先提前讲一下homework，就是我们把训练好的这个模型，其实是可以加载。
	就是开始有个同学问的问题，训练一部分之后，我要再把这个模型从本地加载回来再训练可以吗？可以，这也是第二个fine to的homework，我们不是一次性像这个yp 1样，一次性用全量的数据了。因为我这个训练时间很长，所以我就是把训练了一段时间的这个模型存到那儿，然后我可以再把它加载回来，通过这个from train，当然你也可以通过trainer去直接一次性加载。那这样就可以有一个trainer是你训练了几个epoch之后的预训练的权重，加载回来之后再训练，然后可以提升它的F1的值和这个exact match的值。这是两个matrix，这其实已经看到了，是至于怎么算出这两个metrics，我们可以看一看。这里是两个问题。
	第一个问题是说我们要去计算它的指标，这样更直观更直观的评估这个模型。但是我们要理解的是因为这个模型它是transformers训练的。所以假设你不管这些问题，你不去做模型的评估，你直接拿着你训练出来的这个DTL bert拿给pipeline去做问答，他是能做的。
	这个大家要理解，就是我们下面整个这一套操作都是为了算这个模型评估的指标。因为模型评估的指标，它的这个验证集里面的这个是自然语言，所以我们通过比较这俩自然语言去算这个F1 score。但是如果你只是为了去生成这个answer，那你使用p yp eland的API直接对接上。你现在预这个微调之后的模型是能完成问答任务的。因为他那一套怎么样去输出出pipeline，针对这个auto model for QA它是能对上的，所以这是两个事儿。大家不要理解成下面这段代码跟pipeline还有什么关系。下面这段代码纯粹是为了评估，然后让大家理解我们是怎么把QA这类问题的模型输出结果还原回人类的而做的这段代码，然后怎么做呢？我们简单看看，那我把这两个就收就就就删除掉了，我们这儿就已经放到最后面去了。
	然后我们看到这个模型评估，其实第一件事情就是看模型输出一个什么东西，对吧？就跟前面一样，输出的是label加上一个这个a journal fell，changed over, right, has change on desk since the last time. All right. 
	然后我们看一下这个模型输出的是啥，怎么怎么看啊。我们trainer，这个是我们的训练的trainer trainer点model就是去获取到这个模型，然后batch是一堆的训练数据，然后我们把这个batch传进去，然后构造出了一个相当于获取到了我们的模型。然后这个模型的输出的具体的结果，每个example输出的结果有key，然后有具体的值，我们把key给提出来。其实模型就输出三个东西，一个loss，一个start logic，一个and logical，分别对应的是损失值。然后它的起它在context里面起始位置的这个logic和结束位置的这个log值。所以比我们刚刚那个模型复杂一点，刚刚那个模型只有一个logo加一个标签。现在其实这个模型它是在预测这个context里面的起始位置和终止位置，然后它的概率是多少，就这样的然后。
	对，然后我们就往下看啊，其实有了这两个，我们就能够去开始做进一步的操作了。我们看看它的output里面的这个start logic和这个and logical，它的这个维度是什么样的，都是啊64 384这个维度的。然后我们简单把这个输出了一下，然后如何就相当于那个逆过程，怎么样把这个模型输出位置的这俩logit变成自然语言呢？
	大家想象一下，没有大家想那么简单，为什么？我跟大家举个例子，就是起始位置的这个logic，它是个什么东西？它是我现在的起始位置有多长，有384个可以选。我不知道这个大家脑子里面去想象一下，这个一段话最长384，然后他现在有384个位置可以选，然后每个位置都有一个概率，所以这个起始位置其实是这样的，那么结束的位置也是一样的。最后我要组合出这个答案，其实是固定这两个，选出一对最佳答案来，然后他就决定了最后这段话是怎么样去弄的。所以其实这样的一个logic那这样的一个logic就不太会出现。
	我们刚刚这种很粗暴的选出一个最大的logic的label，就是我们要的答案了。而是要选出一对儿最好的这个start和结束的end的logit然后他们中间这段内容是我们要的文本对吧？其实这个是我们要处理的问题，那么怎么样去处理呢？这儿其实有一堆介绍跟大家讲，就是因为每一个feature的token都有一个logo。然后如果我们把就简单来说怎么讲，就是贪心的算法。如果我们直接取最大的start这个logic和最大的and loggers，这其实是一个很典型的贪心算法，对吧？那肯定是能得到一个答案的，但这个答案它不一定是最佳答案。
	我不知道这个大家理解吗？就是不是所有的问题用贪心算法都能得到最好的答案的？因为有的时候我选了起始的第二家位置和结束的最佳位置做匹配，或者说我用起始的最佳位置和结束的第二好的位置做匹配，其实有可能更好，就总体来说可能更好，那么简单来说就做这么一个处理，我们在这儿做了一个简单的，就是你你不是有这个384个做候选吗？我把这个384个里面取了20个，这边也做了这个结束的也取了20个。然后去做排列组合，做这个两层的一个循环，然后算出最佳score，相当于我把两个logic做了各种排列组合，但是不是384个都允许，那样就是384乘384了，也有一定的压力对吧？那做一个20乘20的top 20乘20的这这个还是可以的，有些太差的就没必要再去做排列组合了。然后把这个排列组合算出一个新的score，这个score才是我们最重要取得这个分数，就这么个逻辑阶段。然后取出来之后，当然可以按照这个方式去组合出一段真正的文本了。
	所以这段方式跟我们一开始的预处理的数据方法肯定不一样，所以我们又把这部分内容做成了一个新的函数，叫做validation的处理的方法，跟我们前面那个训练的那个prepare方法不一样我相信大家这个逻辑也很简单，然后捋完之后把它作用于我们validation的这个data sets。大家如果有注意的话，我们前面的那个处理方法是有一个叫做prepare train features。这个prepare train features它作用的是我们的train data sets，然后我们现在作用的是这个validation的这个data，是两部分。弄完之后相当于我们就能够把这个模型输出的结果和我们预测的这个结果去做一个比较了，然后这个比较经过最终的比较，我这儿我们就跳过一些部分，这个是他输出的一个结果。
	我们新输出的这个score，就是我们刚刚说的，把两个logit经过排列组合得到了一个score，这个score对应的文本是长这样的那这个就相当于以前是两个logic，不好排序。你把两个logic通过排列组合做成了一个score，那针对这一个score你是能进行排序的那最前面的score是16分，这个是我们模型输出的结果，标准答案刚好也是16分，然后我们拿到了跟标准答案一样的结果，这个算是一个好消息，说明这个方法是有效的，通过排列组合得到score这个方法是有效的。然后下面我们有针对这个metrics的计算，最终构造了两个因为我看时间关系是十点半了，我就不赘述太多的细节了，但这个代码写的挺清楚的。然后其实我们最终去算的时候，有两个指标，一个就是我们上面format的叫做exact match，一个叫做FE score，分别用来做这个计算，然后最终得到了这两个还不错的指标值。这个FE83还不错了，这个值已经算挺高的了，大家回头可以再试一试，针对我们这份数据，这个数据是公开的数据，这个模型也是公开的模型，看能不能获取到这个或能够训练出更高的F1 score。
	好，其实就是我们QA这种任务的phone，其实大概就这个流程。其实从代码量上大家也能看得到，更多的是在前后的这个数据处理，是比较大的这个内容。真正的train这部分的代码其实就是设置超参数，然后用这个trainer来train一下就完了。但前后很考验这个基本功，看大家有什么问题。
	Homework怎么提交？好问题，我觉得有两种方式。一种方式是咱们训练出来的模型，直接提交到这个hugin face上，那挺好的。第二个就是说咱们训练出来的这个结果，这个notebook，我们回头去建一个homework的目录，然后让大家可以提交这个homework这样也是一种方式，但主要是因为模型本身不太好验证，不太能让你提交到这个github上面，太大了。这也是为什么hugin face会出现的原因。对主机。
	上面。
	有多卡，训练的时候应该配置什么参数？一个就是我们刚刚看到的这个地方，有一个TGPU number。这个地方，这个同学问多卡这个NGPU这个地方可以调，这个地方。然后还是建议去读一下这个training arguments，有很多的参数，然后读这个github上面的这个定义是最清楚的，这是最清楚的。然后我们也会不断的通过课程，其实这个课程后面更多的就是大家越来越清楚这里面的不同的这些玩意儿都怎么用的。然后哪些是实用的，或者说你会接触的到的。比如说像今天讲的learning rate和这个wit decay，都是adam这个优化器会用到的两个套餐。
	保存状态和保存模型。保存模型就是真正的持久化了，你会看见有这个持久化的文件生成的保存状态。如果你没有把模型保存下来，它可能就缺少那个模型文件状态。这个其实是个好问题，刚刚没有给大家深度去讲，这是。我们看一个保存的这个状态的文件就能看得到了。
	这是保存的这个状态。你可以认为保存状态是一些超参数，而是一些原数据。就这个同学问training state是一些原数据，它能方便你把这些东西搂回来，但是他没有把那个模型文件真正存下来。为什么没有词向量的转化？Word to rect? 这同学得回看一下上节课的内容了，took nice这个方法就已经完成了这个embedding了。回去回看一下上节课的内容。
	多机多卡不太能用这个了，这个同学问的挺好，未来我们应该会讲的，但是也不太好演示。Deep speed会基于这个trainer类去做一些扩展，能实现分布式，但因为这个超纲了，超过今天的内容了，我们暂时先回答今天的问题，看今天大家还有什么问题。我的建议是这两个notebook大家一定要自己亲自跑一跑，找找感觉。然后我们后面才会才有机会逐渐的给大家讲其他的training。Arguments的这个价值怎么用？就是你总得自己做几道菜，你才知道里面的一些深浅。我们再在最后三个问题比较晚了，看大家还有什么问题。
	选择哪个token ized是可以从hugin face的模型上说明页面上看到的吗？不是。如果你不知道选哪个，你就用默认的。然后fast token anozer也挺好的，但它不一定支持所有的model，是这个意思。
	样本超长分割后，变成两个样本来训练吗？跟跟任务有关系跟任务有关系。然后在我们这个在我们这个就是在我们现在这个QA的例子里，不是。
	它会索引回到原来的那个ID去，但它确实会变成两条example。
	呃。
	Bert训练和GPT训练有什么区别？也要这样处理吗？肯定的。同学你要让模型输入的就是这个token vector，都要处理跟任务有关的模型，当然模型也有关系对。
	还有同学问为什么这个ChatGPT也叫fine tone？这个讲过了很多回了，fine tone是什么意思？Find time是微调的意思，微调是什么意思？就是不去大改原来的模型参数的权重，在开源直播就讲过了，怎么会来问这个问题？
	数据集的格式和模型之间是不是有配对关系？这个格式是指什么？数据集的格式，其实模型不关心数据集格式，模型只关心最后这个数据经过to consider处理之后的那个token vector满不满足模型要求，环境是推荐走哪个云环境需要扩大的是谷歌的collab吗？不是，我们上节课就讲了，谷歌的collab b只能当测试环境。它当然我说的测试环境是指你如果未来要做生产要去真正用的话，因为它第一需要科学上网，对吧？你生产环境科学上网有限制。第二collab它其实免费的使用时长是有限的。
	当然collab也是能够连接谷歌云的，就是连接GCP的。如果你在GCP买了服务器，挂载到collab也行，或者说你在其他的云服务买了这个服务器，也能用q collab去登录。但我觉得没必要，因为collab只是说早期你还没有搞定资源的情况下，然后你又想跑这个代码做的一个可以测试的环境。那如果你要训练一个后面的模型，可能训练一天，那不一定稳定对。还有什么问题吗？看大家。
	我们10点40结束，还有一分钟，看大家还有什么问题。大家如果现在想不出来，可以跑跑代码，到时候在群里去提一提。对，这位同学是这样的，big size设多少通常取决于你有多少资源，对，你的资源够你越大越好。然后ebook设置多少通常取决于loss的这个设置，就是e pop我们通常会设置的比较长。然后这个模型训练的宗旨的策略是一个多个条件构成的，有可能是loss多长多。比如说这个loss在连续3到10个模型都有关系，跟数据都有关系。比如说在连续几个epoch之间，然后它的loss都没有在降低，甚至还在增长，那可能你就该停止训练了也有可能过拟合了，或者说你的它没有降低，它也没有减少太多，它就停止不动了。那可能连续多少个一pok之后，他也就得停止训练了，因为再训练也训练不了什么了，是这个意思。
	老师对苦大的成员你了解吗？不知道了解多少算了解。对，但我现在不会去花太多精力去了解新的古塔了，那个酷大的一些新版本了。对，可能在四五年前还会去看，包括这个cool lus QDN的一些进展。但现在他都太底层了，对于我们的要做的这个事情没有太多决定性的影响。
	行，那我们要不今天就先到这儿。我看大家其实还没跑，实际去跑一跑吧，跑完之后会有不一样的上手的问题，到时候我们可以再交流。我们今天就先到这儿，已经快10点11点了。好，感谢大家。然后我们周日就来看看这个更大的模型怎么玩，逐步给大家加码，让大家从这个番茄炒蛋逐步能够做烧菜炖菜是吧？好。