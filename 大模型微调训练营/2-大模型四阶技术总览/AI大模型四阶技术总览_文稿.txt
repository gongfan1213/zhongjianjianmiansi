	考虑到各种各样的背景，就是咱们的同学。所以我想用一节课的预热片让大家了解AI大模型的发展和它的来龙去脉。我们怎么是一步一步从AI这个词刚刚被提出来，然后走到今天我们一起在学习大学模型，并且不仅是应用大语言模型，不仅是使用提示工程，我们也能够使用大语言模型把它作为一个基础来开发AI智能体。
	比如说各种各样的agents，以及我们整个训练营的重点，大模型微调，为什么需要大模型微调？大模型微调里面又有什么样的一些种类？做一个像是预热序幕一样的一个篇章。今天我们这两个小老师的时间主要就是跟大家分享这些内容。
	好，可能上半部分会相对来说轻松一点，大家会像听故事一样的，增加大家的兴趣，让大家了解AI发展有四轮的浪潮。然后这四轮的浪潮我做了两个维度的拆解。一个叫做技术的浪潮，我相信很多同学都已经听过了。第二个是叫做应用的浪潮，让大家去，尤其是像我最早了解到这个AI硅谷，是浪潮之巅这本书，当时看的是非常的兴奋。然后去到斯坦福大学去访问，然后去硅谷的计算机历史博物馆，看到了很多老的机器。然后历史上面的一些软件硬件的发展也是非常有感触。今天也是借这个机会跟大家讲一讲，其实AI发展过程当中，不只是一步就扩展到了深度学习和大模型。
	整个这几十年，有很多的高校，硅谷的一些企业都在做创新。包括最近这十多年，中美之间的一些博弈，最后就是落到个体上，就我们个人要怎么样把握最新这一轮的浪潮，让大模型帮助我们成为一个超级个体。或者如果我们要创业，或者我们在公司里面有一个小的团队，怎么样去把握这个机会，下半部分是偏技术的这个预览篇，更多的是讲提示工程智能体，大模型微调和预训练技术。因为我们整个课程的重点在微调和预训练，所以也是借这个机会让大家初步的去讲一讲提示工程和智能体。因为后面可能我们就不太会讲太多的这方面的内容了，那我们就正式开始了。
	首先我们讲一讲AI发展的这四轮浪潮。这四轮浪潮里面其实我们昨天有这幅图也看过，从1950年代到现在，这四轮浪潮有四个比较显著的标签，我们可以把它当做1950年代开始的这种弱人工智能，最早期的一些人工智能的实验，到1980年代开始出现的机器学习，以及基于统计及学习相关的一些算法。到2010年代开始，我们我们看到有杰夫定和吴恩达，包括李飞飞老师，他们在数据、在模型、在算法框架层面上提出了大量深度学习的一些基础性的建设。一直到现在我们有人脸识别，也有各种各样的识别系统，可以帮助我们解决很多生产和生活当中的问题。
	最后我们来到了2020年代，也就是GPT3发布的这个时代。我们看到大语言模型成功的掀起了一轮新的浪潮。而这四轮的技术浪潮的发展，其实是有很多的背后的故事，比如说我们看到这幅图，这幅图其实你就会发现这幅图首先它会分成上下两个部分，下面这一部分是一个跟论文相关的一个引用量，就是什么样的论文被引用的多。然后有两种颜色，一种颜色是连接主义，我们橙色，一种是蓝色，是我们的符号主义。这两个主义也像是两个山头一样，现在是整个AI的数或者说学术界最大的两个学派。
	这两个学派里面，我们看到连接主义其实是在第一波之前，就已经有一些引用和相关的一些研究发生了。也就是我们在1956年的这个达特茅斯会议之前，就已经有这样的一些研究了，这个研究其实主要是在神经学科相关的一些研究，包括生物学，就我们所有人都听过的这个神经元，或者说感知机。在最早期的一些研究里面就会发现人的这个大脑是怎么运作的呢？是不同的神经元之间通过神经突触去释放信号，然后把我们的不同的神经元之间的信号就传递起来了。当然我看到最近应该是这周还是上周，后半周的一篇论文有讲到。其实现在神经元之间除了通过突触的连接，也有无线信号的一个连接，就像wifi一样，可以从有线变成无线。
	但这个研究的最新进展还在这个过程当中，但无论如何，我们看得到，其实人工智能跟脑科学和生物学之间的联系，其实一直都是非常紧密的。只不过在1956年的时候，达特茅斯的这个会议或者叫下级研讨组，这是当时的这个会议的一个名称。有几个非常厉害的人，我们会在待会儿的这个高效共识里面去讲。他们首次提出了正式提出了人工智能这个概念。而这个概念就开始变成了全球不管是创业者还是学术界都非常关心的一个热点，也是我们这里看到的第一个小山峰。
	从1957年到1962年，这一波的研究其实是啊非常火热的。因为那会儿以图灵，包括香农明斯基为首的一大批CMUMIT和普林斯顿的一些研究学者，都在发表一些跟神经网络相关的论文。只不过那会儿神经网络不像我们现在学的这么深，它是一个比较浅层的神经网络，就像我们下面看到的这个感知机一样的。
	第二波浪潮的启动，其实就跟这个蓝色的向下走的这条线是有关系的。这里我们有一个很显著的词叫做专家系统。并且有一个很有名的企业IBM成功的在这个专家系统符号主义这一步，拿到了很多的收获，不管是在商业上的还是在学术界上面的那最后，我们看到符号主义经过了包括list日本当时有很多的第五代计算机的研发，这个迭代过程当中，我们看到慢慢它又变成了不算是主流的研究方向了。
	从第三波的开启，一九九几年那会儿，其实卷积神经网络就已经出现了。如果大家有过一些计算机和神经网络的背景，就知道我们的图灵奖三巨头，深度学习图灵奖三巨头，乐坤那会儿在1989年就已经在发布卷积神经网络。以至于后面我们会在所有学习深度学习的时候，第一个hello world的这个神经网络就是手写体数字的识别。M list也是在那个时期就已经做出来了。所以大家每天会看到这个停车场里面有识别车牌号，这些技术其实在三十多年前就已经有了。只是说它的这个算力设备和各方面的工业化部署的成本没有降下来，所以到二零一几年的时候，才正式推广到了全世界的停车场。
	到第三波的时候，其实我们会发现，连接主义又起来了。我们的深度学习写了就所有的这个深度学习神经网络这一套，我们都统一把它可以归纳到连接主义，那在连接主义里面自然就会有一些很重要的人物。好，大家还记得这个颜色，这个橙色是我们的这个连接主义的大佬们，左上角有写，右下角是我们的这个符号主义。那么左下角的两位很厉害的图灵奖的获得者乐坤，刚刚我们有提到包括hinton和他的这个学生，像alex他们都是深度学习的奠基者那这里我们再提两位很有意思的学者，一位叫做half field。他其实是我们认为现代的神经网络的一个很重要的提出人。他提出来的这个hot film的network其实是现代神经网络的一个基础。并且在1980年代的时候，他通过一些硬件设备实现了这个神经网络的一些推理。还有一个很厉害的人物就是马文明斯基，他其实是在达特茅斯会议上一个非常重要的角色，也组织了这次会议，他也有很多很厉害的学生，现在依然活跃在AI的前线。
	所以我们从这个视角来看，第一波、第二波、第三波也是有一个此起彼伏的过程。人工智能也不是说从一个石头缝里蹦出来的。从最开始的生物学脑科学的研究，到我们提出了人工智能这个概念，然后大家发现脑科学的一些经验可以直接借鉴过来。做感知机，做完感知机之后遇到了一些瓶颈，让瓶颈期又走另一条路，走符号主义专家系统，那会儿我们计算机本身也有一些发展了，专家系统走到一个瓶颈之后，我们发现互联网起来了。互联网起来之后就有很多的数据，这个我们会待会儿慢慢的给大家做一个展开，所以在这儿我们可以做一个短期的总结，我们看到这四轮技术里面，我们已经讲到了前三轮，从最早期的弱人工智能，我们可以一直推广到1950年。
	到1980年前后，都是以人工设计的规则系统为主。而这一类人工智能其实很弱，现在我们几乎都不把它叫做人工智能。有些高校甚至就直接把它叫做自动化，或者说一些SDK一些库就把它整个给包含下来了，没有那么复杂。而那会儿其实也不是一个数据驱动的智能，它都是由人工设计的一些规。规则集规模大概就在数百或者千这个级别。更多的是把人的知识，就把人的大脑里面的一些经验，一些规则能够通过计算机，通过软件沉淀下来。所以在那个阶段大家会发现，日本的包括像早稻田大学非常喜欢做这种拟人的机器人。因为那会儿大家走到了一个不算正确的道路上，认为人工智能应该像人一样有一个人的形态，拟人的机器人，然后这个拟人的机器人像人一样去思考。
	但后来我们发现不一定要这样，智能到底是怎么样产生的？现在脑科学也没有一个结论，所以我们会看到后面统计机器学习起来这个过程当中，开始初步的去使用这个数据了，要用数据做标注。然后这个标注数据的本质其实是想要去学习一个数据分布，也是昨天我们开营就讲过的。其实核心是有一块数据，我们通过统计机器学习或者通过深度学习，是为了学习这一块数据的分布。而这个数据的分布我们其实你可以简单理解，人其实也是在这样学习的。我们把这个数据分布它的表征学会了，就像我们学会了一个技能，这个技能你很难形式化的把它表达出来，但它落到一个具体的场景和任务里面。我们学会了这个技能之后，我就知道什么样的输入会对应什么样的输出。
	而从这个统计器学习到深度学习这个阶段，相信有过AI经验的同学应该都接触过这些名词。比如说因为net resident net were to vt，attention transformer，尤其是这个image net，由李飞飞老师启动的一个项目。这项目包含了千万级的数据，到最后他已经逐步的扩展，包括像现在不仅是有图像数据，还有视频数据。然后同时期其实NLP这个领域，我们刚刚提到的image net t是计算机视觉这个领域。而LP这个领域其实像google，它发布了word to c这样的一个工具，是使得我们可以把这些自然语言文本的知识变成一个高维的向量，然后把所有人类学过的这些书本上的知识也好，互联网上的这些文本也好，用一个统一表达的方式到一个高维的向量空间，那这样大家的知识就能够统一表达了。
	相当于我们统一了方言，开始说普通话。而这个普通话是我们的计算机，我们的深度学习网络能够识别的普通话。但我们所有人都知道，假设我们没有今天没有大模型，回到深度学习那个时代，给你这么多的知识，你也要学会怎么把这个知识喂进去，让它能够吸收下来。所以这就是我们的attention transformer能够带来的价值。Attention网络和transformer我们会放在后面给大家简单的提一提。
	大家简单理解一下，就是说通过这个attention和transformer的结构，我们让计算机能够吸收和消化这么多的数据，让他能够抓住重点，并且在深度学习这一轮技术浪潮当中，其实也爆发了非常多的成果，除了我们刚刚提到的这些学术性的深度神经网络以外，积累了大量的标注数据，以image net为主。同时期我们的深度神经网络结构，比如说reason net，包括像这个检测网络的一些迭代优势，包括它的开发框架tensor flow hydration也都沉淀下来，逐步的变成了我们第四轮大语言模型能够用到的一些基础。就像我们今天看到了这个开源社区蓬勃发展，pack gain face上面有数万的大模型。他们其实都是通过PYTAR或者TS or flow这样的深度神经网络所编写出来的大模型的网络。然后再通过开放的数据集进行训练，得到的不同的开源大模型。也正是因为有前期的一轮、二轮、三轮的积累，我们才能够拿到这么多的数据。
	包括全网万亿的数据，也是现在GPT4上线以来一直拿到的这些用户反馈的数据。我们知道像GPT4，包括像湾区的一些初创公司，athletic pic他们都有很多的用户。而这些用户提供的数据是以前互联网上沉淀的数据以外的一部分额外的数据，并且它是针对性的跟我的大模型交互得来的数据。那这些数据就会成为更加有价值，变成下一轮，我们不知道它是一个PT5还是一个AI的第五轮的一个发展模式。是啊，但至少这些数据产生了新的价值，而这些新的价值也会不断的让人工智能越来越聪明先进。
	在这个时期，我们的更重要的技术发展其实就体现在了预训练技术。我们的大语言模型千亿级别的模型相比于signet这样千万级规模的模型，其实是3到4个数量级的提升。那怎么样把这些数据喂进去，这个是这一轮我们第四轮大语言模型最厉害的一个发展方向。然后花了大量的成本，比如说几百万美金或者上千万美金训练出来的一个大模型上面如何去做微调，去适应我们具体的商业化的场景，或者一些私有化的一些任务场景，那就是要通过微调这样的一些技术手段来实现。同时我们知道开源社区是一个非常重要的推动技术的发展模式。在这一轮我们看到了像hugging face这样的一些新的平台，来推动全世界的研究人员和工程师，能够使用一些开源版本的大模型和数据去推动大语言模型技术的发展。整个第四轮的发展其实就是在数据，我们看到互联网的这个数据的积累和算力，比如说TPU，GPU这样的一些大型的分布式系统上面的积累，我们能够开始去做大规模的训练了。
	而有一个很很重要的一个理论，这个也是骨骼大脑的jeff定在十年前左右的时候，发布的一个演说里面的一个论文。这个论文其实这个报告其实很重要的一个点就是到今天也还适用的叫这个scale floor。就是我们都知道从一二轮的基于人的经验，人的设计，到基于数据，我们开始去学习数据。但是学数据就像人的大脑一样。为什么有的人说你很聪明，你不聪明？是因为他吸收了更多的数据，这个是吸收而不是看到。这个吸收就是把这个数据学到了这个模型里面。
	如果数据越多模型不变，其实你是装不下的。但模型可以增长。因为我们的算力在增长，我们的GPU在变多，我们的硬盘也在变多，我们的网络也在变快，模型在增长，数据也在增长。当我们会发现通过越来越多的数据和模型的增长，神经网络开始超过前两轮的统计。
	机器学习的这个方法的时候，其实是深度学习发展的一个底层的一个逻辑和原因。就是因为基于数据驱动的这种方式，推动了新的AI的研究方向。这也是深度学习，包括今天的大语言模型能够持续繁荣的一个很重要的一个底层逻辑，通过2010年的杰夫定的这篇报告，其实我们会发现整个2010年到2020年的AI的发展都是以数据驱动为主。就是我们怎么样能够在合理的成本的情况下，给你足够多的算力。这也是为什么今天说搞大模型需要很多钱，因为你要足够多的算力才能达到那个阈值。好，现在有了足够多的算力，然后也有很多公开的数据了，我们要比拼的其实就是训练的技术本身。我们能够看得到从1950年到2022年，整个我们的视觉部分，就是我们左边看到的这个。
	首先这一个点是我们的模型，这些模型的规模在逐渐的变大，包括像google的第一代的大语言模型，他现在又come to第一代的单元模型pom其实已经达到了5400亿的一个参数规模。这个5400亿相对于reconnect就是一个2000倍的一个参数规模了。但是，通过这个模型的增长，大元模型的规模增长之后，它的能力也有了一个非常显著的增加。它不这也是很多人说它是大力出奇迹，以力破巧的一个原因。
	因为它的模型参数的规模增长，它训练的数据变多，并且它不只是跑一下这个数据而已，而是真的把这个数据的分布学进去了。他的这个高维的模型里面有各种各样的参数。这些参数把特定的数据分布学进去之后，当我们把它运用到特定的任务上，不管是语音，还是我们的语言，还是我们的视觉，包括纹身图都达到了很好的效果。右边这幅图其实就显得更为关键，也是这一轮大家讲AGI的一个很重要的一个原因。
	所谓的通用人工智能。大家看到右边这幅图，其实是从将近2000年开始，到最近30年的一个研究。而这30年的一个研究，其中我们重点把人工智能分成两种能力。一种能力我们可以认为像人的眼睛一样，它有视觉的能力。我能看懂看懂这幅图，看懂我目前摄像头里面的有有哪些信息，几个人能不能帮我抓罪犯，能不能帮我去做这个监控或者说做人流的分析。另一个能力就是我的这个语言的能力，自然语言的能力，我能不能去读懂你给我说的话，我能不能看懂不同的语言，比如说我能精通十门语言，比如说英语、法语。中文等等。这两种能力也是人工智能在2010到2020深度学习阶段经常会被大家提到的两个词，就是CV和NLP。
	而中间这条加黑的这个线呢就是我们的human performance，就是人类的平均水平。关于这幅图，其实大家能看到在六个基准测试集上面，AI都已经超过了人类的平均水平。当然这个基准测试机还在不断的迭代，所以通过大元模型它本身的一个技术发展，现在我们能看到在一些早期的基准测试上，AI已经超过了人。并且目前我们看到CATGPT在很多的场景上都已经超过普通的或者说平均的人类水平了，只不过他也还有很多的路要去走。还没有那么厉害。
	但是做一个简单的助手，我们在这个大模型上面，在巨人的肩膀上面去做一些应用，显然是没有问题的，也是我们这个训练营要去学习的核心。好，这个其实就是势能发展的过程当中，它的一个发展脉络。包括底层逻辑，用大模型更强的大脑去学习更多的数据。当然它需要算力和我们的这个互联网数据的一个支撑。在这个过程当中，技术发展了。从1950年代到现在到今天，我们的各种各样的应用场景，包括商业化的场景和学术界的一些场景，是不是也是一蹴而就的呢？这个中间有没有一些过程化的研究呢？我们来看一看这个过程当中，高校发挥了一个怎样的作用。
	其实在1956年之前，1950年的时候，这个很重要的人。因为现在我们知道计算机领域最重要的或者说含金量最高的这个奖就叫图灵奖。而1950年的时候，就是在我们人工智能这个词被正式在学术圈提出来之前。其实1950年的时候，这个图灵alan图灵他在发表了一篇应该是划时代的论文。这么讲这个没有任何问题，叫做计算机与智能。它其实在这篇论文当中做了一个预言，就是说人类终究有一天能够创造出一个具有真正智能的机器，这个可能性是很大的。但是这个真正的智能怎么样去定义，我们如果不去量化它，这个词就没有意义了。那么他就提出了一个很有名的测试，叫做图灵测试。
	今天大家应该或多或少都听过这么一个图灵测试这个词了。图灵测试的核心其实简单来说就是，不管你是通过各种各样的媒介，当时我当时的人类更多的是通过电传设备。当今的人类因为有了互联网，有了通信技术的发展，其实我们的这个对话方式已经越来越多样了。我们可以打电话，可以用微信语音，可以用skype去打全球电话等等。这些不同的对话方式核心都是为了测试当一个人跟另一个机器，或者说跟你的对方在交流过程当中，你能不能够辨别出对方是人还是机器，这个其实是图灵测试的一个核心。
	显然大家想象一下，如果我们把这个CATGPT跟你作为这个微信在聊天的话，其实现在已经并且我们做好它的这个prom的一些设计，其很多场景下你是不太能分辨出它到底是一个人还是机器了。这个是我相信大家如果深度去使用过的话是会有体会的。尤其是如果你把这个大语言模型再经过你自己的一些，比如说你的电子邮件，你自己的这个微信聊天记录，再去做一遍这个反应透，那他的回复方式就更像是你自己了。这也是我觉得长期来看，可能5到10年之后，人跟人之间的直接交流会越来越少。更多的会变成每个人拥有一堆的AI agents，去面向不同的场景。比如说有的AI agents是去帮你刷这个，对，就最常见的场景就拼多多需要各种点点点，对吧？
	然后帮你去刷这个抖音过滤广告，去获取到你真实想要的信息。或者去帮你刷一些这个电商平台，去找一些你想要的内容，或者是去帮你回复这个电子邮件。这些都是非常常见的场景。而这些场景它之所以能够成立，其实就是图灵测试通过了。你的agents在回复别人的时候，别人不一定知道这是你了。并且你还有足够的控制力去让他按照你的思维逻辑和想法去做回复。这个其实在1950年代的时候，图灵做了这样的一个设想。
	接着我们会来看一看1956年的时候，这个已经是六十多年前了。六十多年前的时候，其实有一个个达特茅斯的一个人工智能下级研讨会。这个研讨会其实非常厉害，里面出现了很多的大佬，其中有不少是图灵奖的获得者，也有信息论的提出者香农。包括我们看到坐在中间的这一位，我们刚刚看到他是符号主义的一个很重要的一个核心人物，也是65年的图灵奖获得者马文明斯基。然后在左边还有模式识别的奠基人塞弗里奇和罗切斯特，当时是IBM701的总设计师。
	整个达特茅斯的这个会议，其实除了这七位以外，还有很多的人参加，包括刚刚我们提到的图灵在早期也有参与过这个会议的一些设想。因为他是55年提出来要开这个会，五六年的夏天大家去这里开会。所以其实整个人工智能的发展，大家回到60多年前，已经是在如火如荼的展开了。并不是像很多媒体会或者其他人炒作的，好像这个东西突然热了，大家就来追这个热点。其实很早以前就有一批抛头颅洒热血的科学家们在研究人工智能，只不过任何的技术发展，它都会有一个快速，就跟gartner技术曲线一样，有一个快速发展期。然后有吹泡泡的时期，然后有大家挤泡沫的时期，然后有真实的做这个贡献，做这个建设的人，逐步的去发展它的一个时期。
	当然1956年之后，人工智能迎来了它的第一轮的浪潮。我们刚刚也看过那幅图了，它有一个上升的这么一个趋势，但是没有那么快。刚刚我们提到的马文明斯基，其实他在很有名的一个电影，叫2001太空漫游。我相信很多科幻迷应该都看过。在2001太空漫游这个发布会的时候，他当时就就1968年的时候，他当时就预言30年内AI就会超感人，赶超人类。
	并且这幅图里面还有一个美国的经济学家，也是图灵奖的获得者herbert Simon，他跟艾伦on newer其实是长期的合作者，也共同获得了75年的图灵奖，他其实在更早期的时候，在应该是63年左右的时候，还预言说这个人工智能已经可以在十年内，在国际象棋这个事情上面超过人类了。但是我们都知道，其实一九七几年的时候，AI没有在国际象棋上打败人类，是由IBM的深蓝，最后在2000年之前超过了人类。所以那会儿其实大家是非常乐观的，那个状态跟今天我们对大模型走向通用人工智能的状态是非常像的。因为人类第一次发现计算机出现了，计算机的这个算力在当时的人类看起来也是一个快速的增长，跟我们用计算机，用这个笔和纸来计算是完全天壤之别的一个计算量。当时的人很乐观，现在的我们也很乐观。有很多人预言十年内通用人工智能就会产生了，但其实还有很多的路要走。
	我们通过读历史看60年前的这帮很厉害的图灵奖们在一起，最强的大佬们在一起讨论他们的预言，其实会发现也有点过于乐观了，甚至他们有的预言到今天也还没有实现，比如说明斯基68年的这个预言，还没有完全赶超人类。所以到我记得好像是前几年达特茅斯会议65周年还是60周年的时候，明基还被这个人记者现场提问，说你当时说的赶超人类为什么还没有赶超？这个也是一个段子。
	我们刚刚有提到，其实整个人工智能的发展，它一步一步的基石其实是非常坚固的。然后在第一波的浪潮快进走到终局的时候，我们看到专家系统出现了。然后专家系统里面IBM是一个山头。
	日本的这个研究学者也是一个山头。因为那会儿的日本经济达到了一个空前绝后的战后繁荣阶段，所以有很多的钱和资源搞研究。早稻田大学是当中非常厉害的一个研究单位，他们在1970年的时候发布了世界上首个拟人的机器人，代号叫做WA bot one。就是我们看看到的左边这个长得比较丑，但是他能够拟人，他能够去动。然后在1980年的时候，沼泽田田大学继续了做了这个研究，做了一个能够弹钢琴的技巧。那你给大家看一下，这是的优势，它都事实相明显。
	很有意思，做了一个长得像人的机器人，并且它很多细节大家可以看一下，还做了这个脚的机器，然后还像人一样去弹钢琴。
	这个在1980年的时候，其实已经算是非常先进了。对他还把机器人像人一样的去读这个乐，上面装了一个摄像头。好，那我们就听到这儿，大家有兴趣可以拿到材料之后自己听完。这个是珍贵的研究历史材料，找到田田大学非常好玩。他们对这个拟人机器人，包括到今天为止，大家都知道日本对于这个拟人机器人，包括这个恐怖谷效应，对于这个机器人的发展，他们是非常有兴趣的，并且一直在持续的研究，这个是最早的一些机器人的一些相关研究，其实大家数一数时间，也是53年前的一些研究进展了。
	斯坦福大学其实为什么被称为人工智能和美全美最好的计算机的学院，大学其实是有很多的原因的。其中最重要的一个原因就是，他们在整个这五六十年来，对于人工智能的推动有非常多的作用。第一个就是我们看到刚刚日本的早稻田大学在70年代发布了一个拟人的机器人，然后在1973年的时候，其实stanford就已经研制出了首台人工智能的一个移动机器人。而且我们这里看到的还是黑白的照片，他的这个工业设计明显就要好看很多。然后这个移动的机器人能完成一些基础的助理性的工作。大家其实看到像现在我们什么扫地机器人等等这样的一些底盘，其实1973年的时候就已经在积累很多的研究了。
	甚至在1960年开始，其实stanford就启动了一个叫做其实是自动驾驶出行的一个项目，叫做stanford cart，非常厉害。1960年大家想象一下1960年中国在干什么，对吧？在1960年的时候，stanford其实就已经开始研究自动驾驶了，并且这个研究项目一直持续了四十多年，然后1960年的研究一直到1979年，19年之后，他们做出了这个stanford cut的这个原型，也就是右边这个圆形。当时这个车是能够自动行驶的，只不过速度不是特别快。一直到最后大家看到机器学习课里面这个android g也就是吴文达机器学习课。当时用强化学习来做自动驾驶。其实那会儿也是在stanford去授课。
	自动驾驶其实在在加州的这个硅谷，在stanford这边是有非常深厚的一个积累的。包括像现在google下面的这个自动驾驶公司，vivo，它的CU也是在stanford的机械工程毕业的。所以整个自动驾驶的研究进展，其实是从六十多年前就已经有一些研究学者在积累了。
	这个是非常深厚的一个积累，就像这个机器人学，波士顿动力也是几十年的一个研究，这个项目其实一直到今天为止，最近我们看到在07 2005年的时候，dpa就是美国的最有名的科研赞助商，打卡，赞助了非常多的项目。包括互联网的诞生，在05年的时候他还举办了一个穿越沙漠的内华达沙漠的一个比赛。然后这个课题组就是stamp这个自动驾驶的课题组，在05年的时候还拿到了这个挑战赛的第二名，当时他们用了一个更新版本的，不是这个版本的一个小车了。
	然后我们看到为什么大家对于AI总是像冰与火之歌不同的认知，有的人觉得他非常厉害，有的人觉得他一文不值。其实这些事情在历史上也都发生过，一九七几年的时候，当时darpa最大的赞助商觉得这些高校美国高校里面的AI研究好像实用价值不大，离他们想要的那种一步登天的效果很遥远。但是另一波人其实又发又通过他们的哲学性的一些思考，也得到了一些不一样的你可以说是担忧也好，对未来的一些想象也好，也是包括像今天ella musk也深深地受到了这样的一个假想或者猜想的影响。
	就是在1981年的时候，包括刚刚参加这个达特茅斯会议的一些大佬，也都跟很有名的美国的哲学家，也是数学家和计算机科学家叫普特南，希拉里普特南一起讨论。然后这个普特南写了一本书叫做理性真理与历史，发表了一个很有名的假想，叫做缸中之脑，或者叫缸中大脑。左边这幅图其实是黑客帝国里面的一个电影截图。其实他整个假想就是在想说，如果像图灵想象的，我们的智能真的能够被创造出来，那么人这个物体它的智能是由谁来创造的那我们是不是就像elon mask经常讲的，整个人类、整个地球、整个宇宙就是一个更高级别生物的一个电脑游戏，大家都只是NPC而已。这个缸中之脑的这个假想，其实在1981年起初的时候是非常有影响力的。并且到今天为止有很多的学者在做这个方面的一些研究，然后对整个AI的发展，包括AI的伦理学的发展，也就起到了一些深远的影响。
	我们总结一下，就是美国高校，我们没有细数到今天为止我们就看到刚刚的这个时间线，到整个美国高校，其实在人工智能的发展当中是具有非常大的推动作用的。我们看到这里只是列举了部分的学校，MIT，stanford CMU和UCB，也被称为CS的最厉害的44所学校，在美国他们其实有很多的代表人物，而这些代表人物对于AI的这几年的发展是起着毋庸置疑的关键性的作用。包括我们刚刚提到的这个马文明斯基，他这个约翰麦肯锡这个newer Simon，包括bengel，Michael Jordan这个UCB的这两位，其实都是在整个AI的发展过程当中提出了很多关键性的理论。我们具体就不再展开了。大家如果有兴趣可以通过这一页或者前面几页的这些信息，自己去进一步的检索去了解。硅谷这样一个创新地，包括像大模型，现在也是硅谷作为最主要的创新地，在这个过程当中又起到了什么样的一些价值呢？其实经过前面的积累，我们看到刚从大脑也提出来了，计算机的各种各样的设想，然后我们的AI的发展也都进入了一个相对平缓的时期。
	大家还记得1991年的时候，是专家系统破产的时候，也是日本第五代计算机计划遇到一个瓶颈期的时候，更是我们的这个深度神经网络开始萌芽的时候。因为那一会儿提出了卷积神经网络，然后我们的反向传播的技术也已经提出来了。更重要的事情是互联网发生了。而互联网的发生，其中有一个很重要的历史事件，就是team burns lee发明的这个万维网上线了。1991年的时候，而很多人其实不一定整的明白这个万维网和互联网的关系，而互联网又又是我们整个数据驱动最重要的一个基础设施。所以我们单独有一页来跟大家扫个盲。如果大家不了了解的话，其实万维网和我们今天聊的这个internet，包括互联网是两个概念，它有包含关系，有重叠关系，有overlap。
	外围网其实大家都知道叫3w worldwide web，它的核心词其实是web，它是一特点，它是一种技术，它的这个技术的特点是基于当时是基于HTTPHTML提供各种各样的外部服务。就万维网其实核心是外部服务，提供各种各样的外服务。而类似其他的，web或者说其他的在因特网上面的服务，还有很多。比如说这个电子邮件的一些营销服务，大家经常会收到各种各样的垃圾邮件，FTP，文件传输协议，telnet的这个网络协议，这些其实都是架设在因特网上面的服务，包括大家后面知道了这个web，web一出现了，然后马云创建了中国黄页，l musk卖的第一家公司，是把纪实信息和黄页结合在一起卖到的一家公司。以及以以至于到3W的泡沫，中国的这个门户网站，三大门户网站web 21旦出现，到后面有的人在炒作这个web三等等。
	其实核心都在讲这个web，web是他服务的这些媒体内容，而internet是连接大家的整体的网络，大家可以这么理解，1991年数据有了，然后97年的时候，硅谷这个IBM的深蓝计算机，也击败了这个国际象棋的世界冠军，也是我们的这个卡斯巴罗夫。当时其实也不是一次就成功的，右边是这个深蓝计算机的一个基础，大家如果了解的话，其实他是1996年的时候，先去跟卡斯巴罗夫打过一次。二月份的时候2比4落败了。97年的时候，其实那会儿已经不叫深蓝了，他有一个非官方的一个昵称叫做更难，叫deeper blue。其实真正打败我们的卡斯巴罗夫的是这个deeper blue，然后这个改良版本的deeper blue打败了这个卡斯巴罗夫，当时也是一个很重要的里程碑事件了。Ok 97年发生了这样的一个事情，98年有一个更重要的事情发生了。
	并且其实在96年的时候，stanford的大家也提到stanford的两位博士，Larry page和share gambling in，他们是google的两个联合创始人。他们在学校的时候就开始研究一个搜索的研究项目，这项目就是后面鼎鼎大名的这个page rank。然后这个page rank其实在当年看起来，大家要了解在96年的时候，其实互联网也才刚刚架设起来，很多的编程语言都还没有出现。但是互联网上已经有很多的信息了。但大家要搜索这些信息的时候是没有什么办法的。就像大家现在要去访问暗网一样，你都找不到门路，对吧？域名也很少，那你要怎么样去搜索信息呢？那会的搜索引擎也没有什么好的搜索引擎。
	这两位谷歌的联合创始人在学校的时候就开始研究dota这个page rank。然后这个page rank反向链接的技术，成功的使得他们的这个搜索引擎当时的基本的一些搜索技术的准确度要高得多，就是总能找到我想要的。并且在96年的时候，其实他们在学校里面还没有单独去购买申请这个域名的时候，就在用google到stanford到EDU这个域名在提供服务了。在校园内有点像大家看过的这个社交网络，当时有一个电影讲facebook的起家，类似的在高校里面就支持这样的一些事情，然后在98年，他们正式成立了google这家公司。
	然后一直到最近他们25周年有很多的成长，包括google这家公司，后来为AI的发展也是做出了非常大的贡献。这是1998年的时候硅谷发生的一些事情。然后在我们快速过道到2007年，当然中间还有很多的风云变幻，最重要的就是3W的泡沫破灭，导致资源又是走了又回来，有一个过程的酝酿。
	但是我们看到，07年的时候，一家非常厉害的公司开始浮出水面，进入舞台的中央，那么是谁呢？就是今天我们所有人，包括咱们训练营的同学都得去打交道的一家公司叫做invidia invidia。其实这家公司，它的这15年来的一个发展，真的可以算是一个火箭般，像是有上帝视角的一个发展路程，他几乎踩中了这15年来所有的热点，最开始我们看到这个CPU是我们的计算处理器的核心，所有的算力都是CPU。然后英特尔跟MD这两家公司斗得死去活来，都想把自己的这个CPU做的非常好啊，一直到英特尔垄断相对垄断之后开始挤牙膏，大家那会儿0几年的时候，应该最有名的广告就是这个奔腾系列的广告等等等等，对吧？然后卖他的CPU，因为vidia那会儿其实不算是一个巨头。那会儿他自己在推出古大之前，其实他的古大的前身叫做GP。GPU就是通用处理的这个图形处理器。GPU就是这个图形处理单元，前面再加了一个GP就是general的这个意思，就更通用的这个图形处理单元。
	一直到07年的时候，他发布了这个酷达1.0。当然这幅图不是07年的图，是最近几年的图了。07年的时候他正式发布了酷达1.0，并且把这个代号沿用至今。
	而酷达是一个n vidia这家公司现在我认为最重要的一个软资产。因为扩大它的统一计算架构，到今天为止，上面有各种各样的生态建设，是没有任何一家公司可以撼动的。就像这幅图里看到的一样，他对接了各种各样的深度学习框架，这个channel MX net paddle，这都不算开源设计用的最多的，像pitou's跟tensor flow，包括SK那儿，这是它用的用户最大的几个群体。然后它的云服务厂商对接的也非常强，包括它的这个服这个深度学习的部署，onex是开源社区主导的一个部署方案，tensor floor serving工业级的部署方案。AWS上面的这个CG maker，也是非常重要的海外的一种部署深度学习平台的方案，然后它对接的底层的这个GPU硬件库也是非常强大的，所以invidia在07年的时候推出扩大到后面不管是游戏还是深度学习的发展，推出了这个V100系列，以及后面的A100各种迭代，其实是占据了一个非常重要的主导地位。并且到今天为止，他可以算是这个行业的绝对龙头。
	那刚刚讲的是07年的事儿，又过了两年，李菲菲老师还没有去这个stamp之前，其实那会儿他在普林斯顿大学，可能很多人不知道李飞飞老师其实在普林斯顿大学呆过。并且整个image net的一个项目，其实是他在普林斯顿大学的时候就开始去主导立项的一个项目。并且当时也是通过众包的方式，让很多的全球的人，众包的人帮他去做这个数据标注。一直到后面2012年开始办比赛，页面今天的比赛，整个1000万张的图片，几万个label标签，大家可以想象这就是一个当年就是10年代到20年代深度学习起来的时候，很多人讲的一个段子叫人工智能。人工越多智能越多，这是一个段子。但它其实也确实是这么回事儿，因为你的这个人工标注越多，使得有价值的数据越多，这个是深度学习跟大语言模型很重要的一个区别。
	学过这个应用开发同学应该学应该知道了这个有标注的这种训练模式，有监督的训练方法。它就是需要人工来参与标注，包括像CATGPT后期使用的这个ILHF，就基于人类反馈的强化学习，它也需要标注。所以你就是需要更多的人来标注高质量的数据，它才能产生更多好的智能。这个智能意思就是那个好的模型，因为它的数据好了，它的数据分布就好啊。你的数据处理过程越好啊，模型就越好是这么一个逻辑。
	整个image net项目其实是非常重要的一个深度学习的基石，催生了整个深度学习的模型网络的一个发展。也没有这些数据，大家都没有数据可以训练，这个是非常头疼的。而大语言模型又有所不同，它能够使用互联网上未标注的数据去进行预训练。我们待会儿在今天的最后一部分给大家带到一点这方面的知识，这里就先跳过。然后siri其实非常早在2010年的时候，F就在他的IOS里面加了这个siri的功能，其实是非常早的一个人工智能的助手了。只不过大家都知道，以siri开启的这一轮人工智能语音助手没有达到一个很好的结局，包括像微软小冰，这个小度小爱同学现在都开始转型做大模型，这也是因为深度学习为主的这一类语言模型，它有它的瓶颈，跟这个大语言模型还是不太一样的，模型参数也是差了三个数量级。
	2011年IBM沃森可以算是专家系统的一个绝唱，在当时IBM内部，在这个危险边缘是一个综艺益智类的节目里面击败了人类，各种知识他都能打，知识图谱，知识库干到了极致。那现在我们会发现这个专家系统做的再强，你直接通过一个大语言模型，不需要那么多的人工设计，就能一次性的把人类的知识学进去了。他不需要那么多精巧的各种rule base的一些设计，这个其实是一个范式上面的一个碾压，就以前大量的沃森团队在干的这个知识库知识图谱的维护，通过单元模型的以力破巧transformer的学习能力就被瓦解掉了。这也是为什么我省这个团队后面没有再持续加大投入的一个很重要的原因了。
	紧接着2012年google开始出力了，jeff dean和文达，也就是NNG，当时在google brain第一次使用CPU，那会儿GPU不多，我印象当中当时他们在google brain的这个报告里面有提到用上万个CPU，CPU芯片。CPU tips, 实现了一个猫狗识别的网络，就是你给他这个千万级别的互联网的图片，它都能够识别出那是猫还是狗。当然不是这里的这幅图，我们表达的一个含义。
	然后16年的时候，google已经收购了deep mind。然后那会儿我正好在加州大学看到了这个新闻，也是非常兴奋，以强化学习为主的这一类网络，其实那会儿成为了整个主流，包括像最近OpenAI爆出来的这个q star，也是强化学习本身就是一个深度学习的一个补充，它有它独特的一些优势，也是我们认为AI能够自主学习的一个很重要的路径。在16年的时候，deep mind的阿尔法狗基败了当时的围棋世界冠军李世石，李世石也在19年的时候辞去了职业棋手的这个职业，后面就不再专心下围棋了因为确实围棋一直被认为是人类智慧的一个王冠，非常难。19乘19的棋盘上，它的解空间非常大。但是阿尔法狗通过他的算法打败了人类，并且后续又打败了柯洁。
	所以很多事情就会发现，人类的职业也好，人类的这个智慧也好，通过AI其实在一个一个的被干掉，那你说AI现在超过人类了吗？我们无法说他能够完全替代人类，因为现在的AI没有手，没有脚，没有机器人学的对接。但现在是最热的研究方向，也就是embodied的AI聚生智能。怎么样把机器人学和大元模型做结合。但是他在很多细分类，甚至在很多职业上，其实已经超过了绝大部分人，甚至是顶尖的人。这个就留给大家自己去评价了。
	当然16年的时候google还发布了TPU，15年的时候发布了TESTFLO。好，这边就不再赘述了。然后17年的时候，invidia非常厉害的发布了特斯拉的V100以及DGXAI的。
	很重要的一个你可以认为是专为人工智能设计的一套工作站DGX，并且还在迭代，invidia在AI领域到今天为止仍然是最重要的一个存在，就得益于它的扩大和GPU的不断迭代。并且不管是invidia还是google，甚至是其他的一些公司都开始研发专门面向人工智能的处理单元。也就是我们有的地方叫做NPU neural process unit，有的地方叫TPU tensor process the unit。其核心都是因为人工智能，尤其是以深度神经网络，包括大模型也是以深度神经网络为基础transformer。以深度神经网络为基础的这些AI都需要大量的矩阵运算。而大量的矩阵运算天然用tensor这样的一些硬件级的加速，显然是比软件级的家属要快的很多的。这也是为什么现在有这么多所谓的大模型公司都在干这个事儿。并且有的大模型公司一定是先从推理开始干，因为他会更加聚焦这部分他不需要去做别的一些浮点数，或者说整形的一些通用运算。
	到这儿为止，其实我们都会发现，好像是蓬勃发展的，很多的公司都在尽心尽力的为这个AI做贡献，到深度学习，一直到一家公司的横空出世，也就是OpenAI。OpenAI也不是一出生就含着金汤匙的。在sam奥特曼去之前，elon musk曾经也是OpenAI的联合创始人。但是艾伦曼公司实在是太多了，后面有段期间，他把赛罗奥特曼叫过去之后，他就没有在OpenAI上花太多时间。但赛罗奥特曼成功的挽救了OpenAI这家公司，用挽救这个词也不为过。早来了钱，找来了人，找来了新的发展思路。
	我们最后总结一下，看看硅谷的企业在人工智能发展当中，其实也做了非常多的贡献。Ib m就不用说，deeper blue，沃森，包括它的专家系统都是非常重要的。并且养活了非常多的AI的研究学者，这些研究学者也都持续的在这个行业里面做贡献。
	Google也是发发收购了这个deep mind，发布的这个阿尔法go以及后面的阿尔法zero，后面这个阿尔法zero也有它的一些开源版本，不过大家可能没有关注到，就像我们的GPT有OPT1样。然后除了收购的deep mind transformer，这个当下大模型最重要的基础网络结构，也是google的研究员和工程师发明出来的。但也是在前人的基础上，在这个本就又是他分区有的这个基础上，attention的基础上，做的这个martial attention的这个网络架构，然后tensor flow，TPU，包括他自己的大模型胖，这个是google在整个AI从第三波开始到第四波，都一直在持续做贡献的一个状态。
	Facebook这家做社交网络APP起家的公司，其实乐坤也是图灵奖的获得者，一直是在为没meta这家公司做非常多的AI方面的研究。所以这家公司其实除了做一个的P以外，也做了像pyt watch、OPT，就GPT的开源版本，以及lama这些非常著名的AI方面的一些研究。OpenAI是这一轮的明星，也是主角一个估值千亿美金左右的公司。虽然最近有很多的八卦和这个系列的新闻，但是不影响他在AI方面做出了非常多的贡献。最大的贡献就是他发布的GPT系列的语言模型，可以毫不夸张的说，正是因为OpenAI让大家发现transformer这条路至少当下是可以走的。能走多远我们不说，但这条路是可以走的，因为当年的这个oppen air的最大对手google在18年的时候，这个bert我们知道这个bert是一个很有名的大元模型的一个基石，也是18年发布的，跟GPT1发布时间差不多晚了几个月。
	其实在开源社区领域，一直到GPT3.5，就是HATGPT出现的之前的都是大家的研究重点。那么GPT3.5，CATGPT出现3M奥特曼的这些产品化的巧思，怎么样能够去提升用户体验，包括CHAT最后去做人类价值观的对齐等等这些AI工程化这些tricks的叠加，使得我们重新把AI作为了目前这么多行业里面的一个研究重点，大家愿意投入资源，包括我们今天能够在这一起学学习和讨论AI，是功不可没的。当然苹果这家公司也有很多的贡献，他们尤其是在移动设备和语音识别上做了大量的一些叠加。他们拥有全球最多的手机的用户，自然有很多的数据积累。这家公司一直不喜欢凑热闹，他们的很多研究成果也通常是保密的，不太会发布到开源社区。
	Ok我们到这儿为止，我们其实可以发现一个特点，就是从第三轮开始，为什么我们开始讲高校，都只讲到第二轮？差不多第三轮开始，从jeff dean和android NG做这个猫狗识别到image net。其实我们会有一个很明显的感觉，就是现在搞AI真的是成本越来越高了。很多高校他是搞不起AI了，他没有足够的资源去拥有那么多的算力，他自然就搞不了AI大家还记得最开始我们讲的scale law，就是当你的数据越多，你的模型越大的时候，你的neural networks的这个准确率ACC是会超过其他方法的。那么你的算力和数据都需要资源投入。那么在高校里面，一个课题组是很难跟一个公司去做抗衡的。所以这也是为什么最近十多年大家会发现好像高校的成果越来越少。
	重要的研究成果都在这个企业，包括像微软，其实也做了很多的贡献。我这边没有列了，这边只是写了部分的这个企业。而且微软的总部也不在硅谷，在四家头。所以大家可以了解一下，这个是我们在这个人工智能发展当中一些很厉害的企业他们做的一些贡献。大家如果有兴趣去深入研究这个AI发展的历史，可以去看一看。
	在这个过程当中，中美又是如何博弈的呢？其实很有意思。首先中国确实起步比较晚。大家知道美国的这个互联网技术AI的技术发源地就在那儿。那中国其实大家想象一下，你生活当中第一次接触这个计算机是什么？我我印象当中应该是在这个网吧第一次接触计算机，打游戏，到了这个小学可以有这个微机课，但微机课教的是什么呢？教你怎么样使用office，对吧？其实起步是晚的。
	当然现在中国的小学生、中学生，他们接触计算机，接触互联网，接触AI已经跟美国差不多了。但是不得不说，改革开放刚开始，中国的这个经济还没有到达一个非常好的一个状态的时候。咱们的这些同学们，包括我这一代人可能接触计算机是比较晚的那对应的这些企业起步相对也要晚一点。所以大家会发现在互联网这一段时期，其实国内的公司，三大门户网站的起步。到我们的bat一直到移动互联网小米、tiktok、字节跳动，一直到深度学习这一轮的商汤AI4小龙，现在大模型公司的百花齐放，其实我们确实是起步晚。
	但是不得不说，其实中国的企业起步晚，但是中国的人是真牛逼。就是我们会看到刚刚的那些大模型，包括那些重要的论文里面，大家如果去读论文，大量的华人是这些论文和这些产品工程的一个作者之一，所以其实中国人一点都不笨，只不过中国的企业确实起步晚。所以中国的这些企业可能在人工智能的研究和应用上的创新，更多聚焦于一些应用上的创新。这是为什么我们说移动互联网，好像AI的这个事儿干的不多，都在倒腾数据，这些企业也有他们的一些代表作品。但这里值得一提的是，其实华为还是一直在做这个战略投入的，他们没有上市，所以他们有自主权。他们在这个芯片这一侧做了很多的深入的投入，这个也是我自己有亲身体会的。毕竟在在华为呆的那段期间，也能感受到到持续投入人种的决心。
	我们再回到大模型这件事情上来。其实现在整个中国，包括全世界的大模型研究，就是一个百花齐放的状态。这个是我在网上找到的一个整理的图，我们看左边是各种大厂研究的模型的一个望云的一个图，右边是很多小厂的一个或者说不是足够大的厂，研究的这些大模型的多非常多，现在应该比这个还要多了，有的统计是有两三百家大模型的公司。所以首先这个事儿，它不是一个大家不用担心它明天就会凉掉，它没有人关注了，整个大语言模型一定现在是处于一个非常早期的状态。我自己的一个切身感受，它就像是0708年iphone刚刚发布，然后android甚至都还没有正式的推出。然后我们正在研究移动互联网的应用是什么样，这就跟我们现在在看AI大模型要做出什么样的一个应用，是能够做成一个现象级的，做成一个千亿美金市值的一个公司的应用。是一个状态。
	所以现在去学，现在去拥抱这个大模型的技术是非常好的，也是非常有远见的。因为他现在这个技术本身足够稀缺，掌握的人必然就会有他的这个比较优势。那么从政府的角度，从这个全面对比的角度，其实中美两国在人工智能方面也会有很多的博弈我们能看到其实刚刚看完这些大家会发现人工智能的发源地和推动，确实是美国的高校和硅谷的一些企业在推动。
	但是现在，中国也在逐步的去跟上，就包括国内的这个质谱的大模型和华为的这个升腾的芯片，也都能够去逐步的去做一些取代。那从政府政策的角度都是支持的，从研究发展的角度，美国确实在理论研究和一些核心技术上，他们有一些独特的优势，但是在一些特定领域，确实中国也有一些突破，因为我们的数据足够多，美国的这个数据隐私保护和中国又国情又有不同，中国的很多企业它是能拥有很多，数据的。这个数据跟，其他的公司比起来是明显有优势的。然后在应用和服务上面，我们在模式创新、商业化、产品化上面有一些优势。然后在国际合作与竞争里面，确实我们现在还是一个追随的状态。
	大家也都知道现在最牛逼的奖图灵奖能成为院士。I triple e flow, II tripper e的这个fellow，然后我们的triple AI的fellow，最近刚刚评完这个会议的fellow。其实这都是一些美国主导的国际机构。但是像五季的标准，6G的标准以及一些其他领域的一些标准，我相信中国也会逐步改善，这个就跟80年代日本开始，像早稻田大学为首的，因为经济起来了，学术又投入了，他们也会逐步在国际舞台上拥有自己的一席之地，我相信中国也会像这样的一个发展模式，往这个方向去走。
	但额外提一句，就是道德与法规这一块，就是我们的整个AI的研究，其实现在都在对这个可解释性这一块是相对落后的。简单来说就是AI很强，但我不知道它为什么这么强我只知道scale slaw是生效的，然后我也知道AI在越来越厉害，在很多方面都超过人了，但是它为什么这么厉害？这个研究现在还相相对来说没有那么强。这一块会是整个中美，包括全世界都在逐步加强的一点，像这个相关的法律法规也都有出台，像国内有这个生成式人工智能的一个暂行办法，欧洲有GDPR，而美国也有对应的一些相关的文件。这个也是大家如果要去做应用的话，尤其是生成式人工智能需要去注意到的一些规范，需要去合法合规。
	那好，作为我们个体，我们每一个个人要怎么样去把握这个机会，我觉得这个是一个很有意思的话题，我们看一个十几秒的一个短片一个技术GIF。这个是一个应该今天整个中文互联网非常热的一个新闻，这是一家公司的产品截图。可以通过纹身视频来提高人生成视频的效率。这家公司其实是一个非常新的公司，刚刚成立六个月。然后这里引用了新资源的一个头图。
	刚刚成立六个月的一个公司，四个人的团队发布了一个产品。这个产品也就只研发了六个月，这个产品叫做皮卡1.0，这六个月的的时间，这个产品取得了非常长远的进步，至少目前放出来的这些demo的展示里面，皮卡已经开始能够通过文本来生成和编辑3D动画、动漫卡通和电影。就刚刚给大家播放的这些技术，包括什么elon mask的这个形象。然后怎么样去在人这个小的动物上面去替换局部的一些幕布，换个墨镜，然后换个衣服等等。这个四个人的团队的公司，六个月时间估值2亿美金。
	大家可以去看一下人类的这个创业史，其实很少的，我目前没有看到更快速的成长了。就这个更就在这样小的规模下面，这样短的时间里面达到这样的估值。然后他们有50万的注册用户了也非常夸张的。也是在大模型这个时代可以才能够实现的一种商业模式和创业方式。他们就是站在巨人的肩膀上，就是用了别人的大模型，但是我做了自己的创新，现在也是runway金兔最强的一个竞品。然后第二个公司也很有意思，在去年差不多这个时候是CHAGPT刚刚发布的时候，也就是明天CHAGPT，就去年的明天CHAGPT就应该是发布了。
	当时也有一家纹身图的公司很厉害，job的Jerry宣称就11个人的团队，并且11个人还有一些是兼职的，创造了1亿美金的收入。两三个月的时间，基于这个discard的这个平台去用纹身图收取订阅费用和额外的cost，创造了1亿美金的收入。然后我有查到他们几个月前，应该是在二三年的Q3，他们宣称现在应该是有40人左右的团队，2亿美金的年收入，没有融资，这个是非常夸张的。大家想象一下，全世界范围内这么高的人均产值，是闻所未闻的。但是这样的模式他成功了，并且我们相信这样的模式以后也会逐步推广开。就是因为大模型替代了绝大部分人的劳动，一个大的公司或者说需不需要一个这么大的公司运作去服务一些人和这个产品。那其实这个是一个大大的问号，有很多的劳动，就拿一个最简单的你生活当中的paperwork，需不需要那么多人天天写这么多paperwork，或者说搞这么多paperwork，是不是大模型就能够帮你去做这些日常处理工作，写写文档什么的。这些其实都是一个我们值得探讨，也是新的公司的一个组织形式这个是一个很很厉害的公司，mid journey. 
	当然不止这两家公司，我们看一下，不管是红杉这个很有名的一线投资机构，还是consumer这家机构总结出来的关于生成式人工智能的一些应用，其实已经非常多了。我相信国内也有，但我没有找到国内汇总的比较靠谱的一个汇总，当然如果同学里面有在做这个事儿的，也可以发出来，我们大家了解。在各种领域大家可以看到洪山这边统计的这个是V3版本，它还在迭代，在企业应用，然后在这个to c的消费者应用，包括一些专业的一个领域的应用，都有很多的创业公司在疯狂的呃突突破原来的一些巨头的封锁。因为我们都知道野蛮人，野蛮人到一个行业里面，他一定不是原来的对手。然后他要打败的也是原来的巨头看不见的一些小公司。包括像右边的这个统计的前50的生成式人工智能那些公司，他们都在快速的迭代。但是这些迭代说回头来都要筑起一个很很有意思的巨头。
	这个巨头可能是跟以往的巨头都不一样。因为他既做大模型，同时它还有GPTS，甚至GPT store这样的一些应用商店。它有可能会吞噬掉软件，吞噬掉中间价值，就是OpenAI这家公司。
	我们在def day上面看见sam奥特曼，也就是这个月刚刚发生的事情。两周前赛罗奥特曼告诉大家GPTS这个GPT builder可以非常方便的去构建APP。那是不是很多程序员也不需要了？就跟现在在中国有很多建筑设计师感觉到压力很大，我觉得有两个原因。我自己的一个体会，因为也做过这个建筑行业了，中国的建筑设计师最大的压力来源于，第一个是城市化进展到了一个相对平稳的阶段，不需要以这么快速的方式或以这么高频的方式，这么快的周期去修房子了第二个，就是说本身行业遇到了一些问题。既然这个供求关系需需求变低了，那供给方的价值就会被削弱，甚至供给方的数量会减少，因为不需要这很多供给，那么写代码也是这样的，大家想象一下以前一个大厂，几万人的大厂，甚至二三十万人的大厂，可能有一半都是程序员。
	那么这些程序员未来何去何从？尤其是那些CRUD的circle boy，或者是做前端的页面的一些调整页面布局的一些兄弟，他们怎么办？这些工作其实现在你说这个GPT做不出来吗？我觉得完全做得出来，只不过是现在的prompt技术，prompt engineering, 或者说基于GPT的产品还没做出来。当有一天产品经理可以直接通过一个基于GPT或者其他单元模型的产品去生成他要的软件的时候。我相信应该有很多junior的工程师会感受到非常大的压力，这个也是我们看得到OpenAI未来会去做的一个动作，或者说他的合作伙伴会在他的基础上去做的一步很重要的工作。好，我们的故事就讲到这里，大家可以缓一下，我再换一件外套，有点冷。然后我们一分钟后讲世界技术。
	回来了，我们故事听得很快乐，接着我们来一点技术的东西，让大家找找状态。但我看了一下时间，估计可能今天讲不完四阶了。我们可以在周日的时候把今天如果讲不完的部分给讲完好。
	那么四阶技术、大模型都有哪些技术？我们特指大模型，也就是我们所谓的AI的四波浪潮里面的第四波浪潮，基于大模型的AI的这些技术有哪些，这个是我自己的一个划分我相信每个人都有不同的分类方法。那么这个划分我的把它的从门槛、人群、技术的积累、应用场景，包括它的这个特征做了一个分类。
	首先我觉得咱们不管是要不要去做大模型微调，或者说做这个预训练，对于这个技术的框架性、结构性的认知很重要。我们其实自己也做了这个时间两个训练一样。咱们的那个应用开发的训练，其实重点就是在讲前面两个技术阶段。然后咱们这个训练营其实重要在讲第三个这个阶段。而第四个这个阶段预训练技术，坦白来讲普通人其实就玩不了，这个我们也讲了，高校的课题组都玩不了，因为他需要的资源太多了，那我们来细看一下，首先那个提示工程，prot engineering，我认为这个技术是不管咱们什么样的角色一定要去学的。这个玩意儿就跟你在小学的时候要学英语一样。我们之前看到五六年前有很多创业项目是做什么呢？
	做少儿编程的教小朋友学pythons，现在我觉得这帮教小朋友学pythons的同学，或者说这些企业和工作这些公司都会有一个很灵魂的拷问。就是小朋友需要学pythons？就是不是小朋友把prompt学好了，他就能用大模型来写pythons了。当时他其实自己不需要把pythons的语法花那么多的时间给搞明白，因为核心是学会编程语言的思维，就学习怎么样跟编译器和解释器沟通的这个思维，这个东西是最重要的，这个也是我们现在要站在大模型巨人的肩膀上去提升生产效率一个很重要的原因。
	提示工程是可以面向所有的人的。我刚刚提到了K12当中的小朋友，包括咱们如果是产品经理，或者说前后端的不同的研发工程师或测试工程师、运维工程师。我觉得你哪怕不想写代码，你也得把prompt给玩的非常溜，你就能够提升绝大部分的生产力了。
	坦白来说，50%以上的时间是能被省下来的。就你的工作当中，你想象一下，你作为一个程序员或者你其他岗位的人，你每天的交付物，你每天给公司交付的这些成果占了你多少的时间。其实我相信可能工作时间的一半差不多了，剩下一半是在跟人扯皮、聊天，要资源汇报，然后开会，做各种各样的所谓的paper work，或者说沟通的teamwork。这些工作占用了你很多时间，那这些时间能不能通过大模型，通过prompt去提效，我自己认为是可以的，我也会给大家举个例子，它的特征门槛低，易于上手，并且通过prompt你能做的场景挺多的，文本生成、摘要、机器翻译、debug很多场景都能通过prompt来。至于prom engineering那就是更多了，那么AI的智能体，AI智能体和prom engineering的区别在哪里呢？你可以理解成当下的基于大模型的APP。Agents是最热的，但他是不是未来的终局不知道。这就跟我们在微信还没出现的时候，我们也不知道小程序可能会是一个现在大家用的最多的APP。
	因为大家都不想装这个新的AP了，觉得好像很占资源。但小程序大家用起来又觉得没有负担，它是一个H5的应用，消耗资源又不多。那么agents显然它现在也不可能说它一定是终局，尤其是他自己还有一些限制。但在一些特定场景领域里面，agents还是有很多的价值的，尤其是以这个RAG为主的这一类，在这种客服助手、销售这些领域里面，它的交互性和用户体验相对来说还不错。
	但它可能就稍微需要有一点的技术积累，就不只是说你会打开ChatGPT，会跟他聊天就够了。可能你会稍微需要了解一点点这个大模型的一些基础原理和理论，不是需要你去推导公式。但是你要知道，这个大模型你至少能知道他有他的聊天是怎么来的。其实是需要有研发人员去维护这个聊天记录，这个memory，这个上下文你需要懂，它是需要去维护的。然后你不可能把所有的聊天记录都存下来，对吧？那你可能是选跟你的话题相关的聊天记录，这样你不会用太多的token突破他的上限。然后你还得要把它应用到你特定的领域里面，那你就要稍微了解一下业务逻辑和流程不是做着玩的，不是做一个demo，不是做一个大学生的作业。我认为这一类的人群我把它先称之为大模型的应用开发人员。
	我不确定现在有这样的阶梯或者岗位那么准确，但它就是基于大模型开发应用的这帮开发人员，可以是产品经理，也可以是研发。第三类我觉得它的积累技术积累要求会稍微更多一点，就是咱们的这个课程的面向的主要同学的这个背景了。然后我们也在开课之前留了一个月的时间，让大家去看我之前的一个视频课程，tensor or flow的这个视频课程。在那个课程里面教的神经网络和机器学习的概念就够了。就是我们在40年前，三四十年前，这些AI大佬们教大家的反向传播，我们的梯度下降神经网络到底是怎么训练的对吧？它的这个矩阵，权重的这个矩阵到底是怎么为数据更新的？你要有这个概念，你就基本上理论部分就过关一半了。
	同时我们会在大模型微调过程当中，处理很多的开源的数据集和开源的模型。我们会在这个过程当中教大家一些数据处理和模型训练的一些经验，然后这些经验就成为咱们微调很重要的经验了。因为我们都知道微调其实模型本身的代码不会怎么大改更多的是怎么把你的数据用的更好。简单来说就是这个出我们把它当做做饭的话，就是这个厨房它是不换的。然后我们要换的是什么呢？
	就是我们想要把这道菜口味调一调，或者说我们把它这个麻婆豆腐的做做一些调整，从这个经典的川味的麻婆豆腐改成什么现在像眉州东坡这个店里面有什么海鲜的、什么牛肉的、肥肠的，乱七八糟的，就做这样的一些事情。它的应用场景更多的是偏向于一些领域知识的学习，特点是什么呢？通用性比较强。如果你会大模型的微调，其实你换一个大模型你是可以微调的。你换一个网络其实也是可以微调的，然后它的性价比也比较高。因为大模型的微调我们可以分成几类微调。有的微调它只需要很少部分的硬件，就能去把这个千百亿甚至几十亿级别这个大模型给它撬动起来。
	预训练我认为是如果你要把这个技术画成一个金字塔的话，应该是塔尖的这部分人需要去掌握的。首先预训练他的这个资源要求太多了，只有塔尖的人有那么多资源，这个是一个客观原因。第二个就是说预训练它的周期很长，前期投入很大，如果你是自己家产殷实，对吧？你就想学习一下预训练技术，你愿意投很多钱，烧个几百万没事儿，那也可以。但如果你是只是想学习这个技术，那我们课程里面会用带量化的，就是这个q Laura带量化的预训练，让大家去掌握这个技术。然后这个技术其实它需要你熟悉一些深度学习的原理和网络架构，因为我们可能会带大家更细致的去了解这个transformer的架构，为什么长出了三棵树，有这个bert有T5有这个GPT，他们有的是重这个encoder，有的是重decoder，有的是兼修，那他们有什么不同？
	然后预训练本身它要处理的数据非常多，需要有大规模的数据处理和模型训练的经验，那它的应用场景就非常多了。这就是为什么我认为路漫漫其修远兮，就是呃现在的GPT4包括GPT4.5 assistant PI也还有很多的事情他没有做好。最典型的就是这个多模台，怎么样能够把多模台更进一步，是现在所有人都想要去解决的一个问题。然后运行链技术它的特点，我们刚刚提到了前期投入很大。但是如果你真的把这个技术掌握的很好，然后你的数据处理得很好啊，训练过程没有什么问题，它的效果是非常显著的。
	甚至能够支撑一家几百亿的公司所以我们再从两个视角，资源投入和预期效果的角度来看，我认为可以把这四个技术分成这样的一个增长曲线，对于我们个体的来说，你的资源投入当然前期是越少越好啊，滚雪球一样的，所以按照这个路径去学习没有问题。但如果你现在连prompt都还没有用过，那我觉得咱们应该把这个prompt先用起来。这个应该是复制的一个问题。
	好，那我们再看一下这个提示工程到底是怎么回事儿。这个是取自于GPT3这篇论文当中的一个对话，我们认为要理解提示工程prompt engineering，首先要理解提示词，就prompt。提示工程是在最近两三年出现的一个新的研究领域。那么在提示工程出现之前，其实我们都只知道提示这是什么，因为当年的GPT3是一个decoder only的general，就是通用的预训练的一个transformer。而这个decoder only的transformer，这个GT3它本身就是一个偏向于生成的一个大模型或者说一个模型。那这个模型就是你给一个上文，它会自动生成下文，这是由它的网络结构决定的。在这篇论文当中，其实当时提出了很重要的一个概念，就cher's source的这个概念。后期的所有的提示工程其实都在COT这篇论文上面做了一步的延展，也都引用了这篇论文。
	COT思维链的这个提示词，其实当时很有意思。他解决的问题是什么？就是大模型很强，预训练一个大模型的成本很高。这个就相当于你花了很多钱，终于把你的儿女们培养成了一个高材生。但是你现在不会跟他聊天，想让他帮忙，他就是不能帮到你。因为你不知道怎么跟他聊天，他也很痛苦，他不知道你到底要什么，你也很痛苦，你不知道怎么找他帮忙，对吧，那么这个就是COT我们的思维链，包括后期的提示工程想要解决的问题。
	在COT的论文里面举的这个例子也很有意思。就是如果我们不用思维链，不用帮大模型，去就不去跟你的这个高材生去提升你自己的沟通话术、沟通艺术。高材生他如果不变这个大模型不变不去做这个微调，你是没法拿到更好的结果的。所以你得想办法提升你跟你这个高材生的沟通水平。
	这里举的例子就是问了一个什么问题呢？其实前面第一轮对话问的是一个网球的问题，就是有几个网球，然后一个桶里有几个网球，然后还剩多少个网球，直接给了个答案11，这个其实是给到大模型去做参考的。然后第二个问题就问的是这个苹果的问题，但是这个就答错了，为什么答错呢？是因为其实大模型，尤其是GPT3的大模型，关于数学推理这一块是很差的，这个是本身能力上的一些缺陷。但是如果你给他解释了这个十一是怎么计算出来的那他是能学会的，这个就是一个参考示例，也是我们最早知道去让大模型理解一些相对复杂问题，需要把这个问题的解决思路呈现给他他就能照猫画虎，鹦鹉学蛇的来解答一些类似问题，一个很重要的研究成果。
	Prompt其实本质就是在干这个事儿，你想象一下有个几千万，甚至上亿美金训练出来的大模型摆在这儿，他一定很厉害的。尤其是这么多大模型选出来最前面的这个TIGT。那么你要怎么样提升你的沟通技巧，让他能够达到你要的效果，这个是一个很重要的研究课题，在GPT3的这个对比里面，我们也能看到，千亿级别的大模型使用了prom t之后，它的表现会更加的好啊。这个曲线应该已经很能说明问题了，就是有prompt和没有prompt区别很大，然后平均水平也是一样的。然后有few shot，就你给了一些参考示例，比起没有参考示例它的效果会更好。那么实操一点，我们这个课这个训练营不是主要教大家提示工程和agents，但是我们这个实操一下，让大家感受一下怎么回事儿。我觉得一个我自己的一个体会，最朴素的这个prom的技巧就是我们天然去雕饰一下，就没有那么多套路。
	你要怎么把大模型沟通好？假设你从来没用过，我觉得一个最简单的方式就是把它当成一个人。就是你把TGB当成一个人就好了。因为他已经做了大量的人类价值观对齐，做了IOHF，所以你就把当成一个人，当成你的工作伙伴。然后你想想你现在跟你的同事去交代一些工作，让他帮你干活，你会怎么干？对吧？其实这个过程能让你逐步理解大模型的一些运行逻辑，也能提升你自己的说话水平的。
	我们就看一个实际例子，假如说我想偷懒，我想让ChatGPT帮我写个日报。我们知道有些公司需要写日报或者周报的，或者有些场景里面需要写日报或者周报的。在GPT3.5上面，我印象当中，几个月前如果你让他帮你写个日报，他直接就张口就来就写了。那现在GP4还会要一些更多信息，这个就是我跟他的第一轮对话，我说帮我写一个日报，那么他的回复是说他需要更多的信息，一些细节来帮我写这些日报，就包括需要日期，我到底要写什么对吧？然后我有什么样的格式，有没有一些关注的领域，需要什么样的风格和语气。其实这些东西是我让他帮我干这个活儿本身就应该有的，但是比较随意。
	如果你有一个同事，这个同事是一个新同事，你想象一下为什么新同事需要老同事去带，对吧？就是这些背景信息他没有，那现在他其实就没有这个背景信息，因为我是新开了一个对话流，那么我给他说了什么呢？左上角我有圈出来，我给了他一些相对必要的信息，但不完整。我告诉他今天的时间，就11月29号，今天然后我说我是一个大模型的研发工程师，我的实际情况是我摸了一天的鱼，我希望他帮我写一个日报，签约GPT给出来了这个日报。但是大家都知道他前期要的信息是什么呢？他还希望有格式，还希望你告诉他这个是不是一个正式的日报，还是一个非正式的。但是你都没给他，就按照自己的理解先写一个。
	然后这个日报是轻松幽默的风格呈现的，所以你能看到有点调皮的这个内容一个11月29号一天日报摘要，早晨启动日常，然后上午探索新领域，午餐休息时间，下午灵感时刻，晚上总结与规划结束语。摸鱼也是一种艺术，今天我们的英雄完美的展示了这一点。有时候远离日常的忙碌，给自己一点空间就是最好的进步。显然他把这个场景理解成日记了，对吧？就是感觉像是写给自己的，还要给你鼓励一下，就是摸鱼也是好的。但如果这玩意儿你要交给领导，那不就完蛋了，对吧？所以给他一个补充，信息日报是写给领导的邮件，给我一点中国互联网的这种味道吧？
	融入一些中国互联网行业的特色，一来就是尊敬的领导，在这个晴朗的西班牙队，上午在研究行业趋势，探索和思考，分析中国互联网行业最新动态，尤其是人工智能和大数据领域的创新以及行业应用，中午在做团队交流和知识分享，下午在做策略规划和自我提升，尤其是晚上，还得有总结和未来规划，进行了今日工作总结，对明天的工作计划进行了初步规划，总而言之，今天成果满满。但是这个还是有点过于的震慑，就不太好能够汇报对吧？那么我们再给他一些更多的提示，告诉他其实日报不需要区分早中晚，但是主要的目的是要体现没有摸鱼，工作很饱和，不要安排太多任务给我，对吧？那这个也是很多人的实际诉求，我们如果把这个交给CHAGPT，他也理解了，那么他就要把这个日报的内容体现工作饱和，呈现我忙碌而充实的一天，那么他这边就会写更多的聚焦到主题上，项目审查和优化、技术研究与应用、团队协作知识分享，市场动态的策略调整等等。这个其实就是一个我们如果把太原模型当做人，其实你交代信息，如果一开始就交代清楚了，也没有这么多人的对话了，对吧？但是他比起你的队友，他最大的好处是他不会发火，对吧？
	你想象一下，你让你的队友，你让你的你作为mental，你让新来的员工帮你干个活儿，你第一遍不说清楚，第二遍再给一点信息，第三遍再给一点信息，挺恶心人的，对吧？但是像GPT能帮你干这个事儿，甚至是免费的。然后假设你是一个产品经理，他也能写出一个类似的，只不过内容变了，产品经理要做市场分析和用户调查，产品规划策略调整等等，用户体验优化。这个其实是prompt，还不能称之为prompt engineering。但prompt这个如果咱们从来没有用过同学，我有一个最直接的说法就是你把当成一个人，一个人需要什么样的信息，需要怎么样跟他沟通。如果你能理解到位，你自然就能拿到更多你想要的结果。不只是日报，包括各种各样的paper work。
	然后至于这个prompt的一些技巧，就是除了当事人以外还有什么技巧呢？我觉得其实挺多的，像我自己总结的一些，比如说也是很多后来open I官方文档也在提到，包括角色的设定。因为我们读过GPTAPI文档的同学就知道，他会能够支持你，给他不同的role，甚至不同的名字。同样的role还有不同的名字可以扮演多个人，这个也是一类agent，就包括stanford的这个人工智能小镇，其实都是基于这样的能力，角色的设定，指令的注入，这个是从最早GT3开始就有的问题的拆解，这也是来自于这个chair of thoughts。
	包括我们看到各种各样的prompt的一些技巧，都能够学会到的一种prompt的使用方法，包括一些分层设计。如果让他创作长篇内容，你去搭建一个树状结构，然后你让他创作，比如说你要让他创作20篇章，然后先创作哪几篇，再创作哪几篇等等，比如说小说生成，各种长文本生成都可以用这样的方式。然后你也可以把prot当做一个编程语言，这个就是南倩这个框架主要在干的事儿了。就是怎么样把prot编程语言，然后用prompt来编程，这个其实就是所有的基于能chin的这些应用都在干的一个事儿。然后few short就是有一些样例规范一些推理路径，就跟我们刚刚看到的这个网球和苹果的例子是一样的。
	就比如说我们可以让CHAGPT帮我们去构造标注数据，这里就是我们输入了一些这个这里设定了一个问一个具体的一个任务，这任务就是我会不断的输入一些正文的内容，就是右边我们看到的这个正文内容。让它形成一个满足特定的条件，比如说前面是prompt，后面是回复，然后来进行的这个构造的一个结果。然后它相当于就读了正文，把正文想一个方式来提问，提的问题的回复就是这个正文当中的一部分，然后有层次，那这个就用它来构造标注数据，那很方便，你用PI也能够实现。并且death day上面也讲到了，现在I的response的这个结构，还支持了这个Jason的结构。
	会更方便，然后也可以帮忙debug，很多程序员会遇到的问题，但是这个debug你直接甩给他他也很懵的，你可以稍微考虑一下from the对吧？当然这也不是最优解，你也可以根据自己情况去调整。比如说你将收到debug的问题。这个是system，这个road，如果用过TPT的API就都会知道这个system这个角色是一个常驻的指令，然后他给你的回复在assistant这个角色里面，你可以让他知道他永远要干的一个活儿。就是这个对话流里面是帮你解决这个debug差错的。然后这个格式也有一些要求，比如说报错日志更新的可能性推断解决方案，参考资料等等。这样你就可以通过这个对话流帮你解决很多的这个debug问题了。
	你再加一个前端，那不就变成了一个应用了吗？对吧？那这就是非常常见的一些prompt的设定。
	那么讲了prompt，什么是prompt engineering呢？其实很简单，就是把刚刚的手动变成自动，对吧？我们人跟动物最大的区别就是我们有造工具的能力，造轮子。那么刚刚都是手动去搞这个prompt，不管是在这个ChatGPT的网页页面上，还是在它的playground里面，去模拟GPTAPI的调用。不管怎么弄，它还是得你手动一个一个输入。那能不能去做出一个就像这个GPT4和大力three生成的这个图一样，找一些机器让它自动的持续的批量化的去去用呢？那么可以的，蓝倩是一条实现路径然后通过蓝倩和open AAI的这个APPI，我们可以去自动化的去构造很多的prompt。这里就一个典型的一个南迁的模块，model IO的模块。
	把我们的prompt通过prompt template管理起来，然后这个prompt里面什么需要去做调整。就比如说我们刚刚的这个例子，写日报的例子，我们其实是可以变更你的角色，变更你的日期，变更你今天是想摸鱼，还是今天是想做汇报，还是什么都可以。这些其实就是这个变量，就这里看到的X和Y，我们就把自然语言当成一个编程语言，这个花框起来的就是我们的变量，就编程语言里面的变量它是可以动态注入的，就跟我们刚刚看到的那些例子一样，通过prom template这个形式来组织。中间是我们的大语言模型，可以是GPT，也可以是别的单元模型。
	然后通过调用这个大语言模型给他print，然后我们最终拿到一些结果。这个结果我们还可以对它进行一些规范化的处理。这样就把原来手动去跟大云模型交互变成一个自动化的程序了。比如说通过这样的一个简单的代码，我们可以使用连线去调用我们的OpenAI的GP，这个GPT去给公司取名字。这里的产品就是我们的一个变量，那我们假设这个产品是性能卓越的GPU，那取十个名字，给出完整的公司名称，这就会有代码，很简单对吧？
	然后比如说我们要去做一个更复杂的调用，是多个大语言模型的调用的连接。这里我们举一个例子，就是两个大模型的应用，一个是生成内容。比如说它要生成的内容是根据一个题目，一个剧目的标题去给一个这个剧撰写一个简介。那这里我们看到它的输入有两个，一个是title，就这个剧目的标题，比如说三体人不是无法战胜的对吧？我是一。然后另一个是给他一个身份，就我们开始学到的prompt的技巧，只不过现在变成一个模板了，还是自动化。
	你是一位剧作家，你的任务是根据这个戏剧的标题写一个简介。标题是什么，这里冒号有个花括号title就是我这注入的。剧作家以下是对上述戏曲的简介，冒号这个是了解transformer的结构就知道这样的方式对于它生成下文更友好，他输出了什么呢？输出了这么一个简介，讲我这个剧里面讲了一个古老又充满悬念的故事，然后说了一大堆，当然GPT没有训练过三体这本书，所以他不知道三体其实是刘慈欣的三体，所以他就编了一个三体人，然后我们可以再做一个戏剧评论家的一个应用，那它支持的输入是什么呢？它的输入就是刚刚那个大模型生成的简介，他的工作是评论这个简介，为这个简介再写一个评论，那我们就把两个大模型串起来了。那这是不是就是一个简单的一个process engineering的一个操作？他甚至把大模型的输出序列做了一些简单的编程，就像我们写代码有面向过程的编程一样，刚刚这两个券就连在一起了，他就会去写这么样的一个结论。
	是一部引人入胜的戏剧，讲述了来自不同背景的人巴拉巴拉说了一大堆，最终的这个结构就通过一个年线内部的标准化的一个模块，叫做simple的sequences chain，就能够串联起来。而且面是一个它最简单的大模型的chal m chain，然后通过这个synthesis和这个review chain的连接，完成了这么一个戏剧评论，所以你看到整个代码其实就三行，第一行是当然前面有一些template，就是我们刚刚在图里面看到的那个template。那你可以调到导入这个simple sequential，然后把这个线串联起来，然后把它的verbs，就是它的debug的中间结构打开，然后去运行一下，其实只需要输入一个title，内部会去运行。第一段输出的是这个syn office，就是这个创作简介的这个大模型，他会生成一个简介。第二个是评论家，他会根据这个简介去生成一个评论。这个模式其实就能够其实完美的展现了一个from engineering，通过年轻人是怎么样去做的，并不复杂，代码量也不大，更多的是把你的from template完好。这也是为什么prompt engineer核心是prompt，你的temper要怎么样去写，你的variable要怎么样去设计，这个是核心，有一些推荐阅读可以大家去做扩展。
	就是我们的这个chair l sauce，就刚刚提到Jason we的这篇文章，也是华人。然后self consistency这个自洽性，也是三个臭皮匠第一个诸葛亮，我思维链可以有多条之后来投票，这个是它的核心思想，大家有兴趣可以去读一读，包括这个shelf thought，这个应该是普林斯顿大学和google一起deep mind的团队一起发布的一篇文章。用经典的数据结构里面的这个数的结构，把这个链条改成数，然后来做这个大模型的一些prompt的一些技巧。当然现在还有很多的先进的文章，但就这三篇文章大家都能发现，其实中国人在当中非常多，对吧？所以有兴趣的同学大家可以去读一读。然后这个就是probe的engineering，并不不复杂。如果学过欠的应该看的会非常熟悉。
	接着我们再来看一下什么是AI agents，也就是现在最火热的大模型APP是什么？我们知道刚刚的这个事例里面，我们搞了一个一个人创作这个戏剧简介，一个人去做简介的评论这么一个模式。它相对来说是一个比较死板的，或者我们叫hard code的一个方式。在就像我们写代码是hard code的，他的这个顺序是写死的这段代码他就只能干一个剧作的生成和评论，好像干不了别的事儿了，不够灵活。
	那么agents这个agent具体是什么意思？智能体到底是干嘛的？其实这里就要提到一个很有名的论文，然后也是它对应的一个范式，叫做react。跟前端的react不一样，有两个单词组成，一个叫reason、reasoning traces，就是推理，一个叫act，或者它对应的actions，就是它有一些操作，简单来说就是把开始的固定流程，固定流水线编程写好了，用prom的编程写好了。你要先干这个再干这个的流水线变成一个动态的流水线，这个动态的流水线就相当于你把大模型变成了这个厂房里面的车间主任，他能够根据你这个厂长的要求动态的去搭建流水线。然后这个大模型本身他就要根据你的每一个具体问题来想，我到底应该怎么样解决你的问题，举个简单的例子，就是我们都知道大模型是不能联网的。
	那么假设我们给了大模型联网的能力，那现在我去问他，今天就是2023年的11月29号，天气如何，特定的一个城市天气如何，大模型本身没有这个知识。他无法他无法得知这样的一个信息，那如果有一个厂长他知道他无法得知这样的一个信息，但它有额外的工具可以去使用，就比如说它有一个电话，它能连接互联网，它有搜索引擎，那这个时候他就自己能够去做推理。他知道这个厂长要的是天气信息，但他自己大模型本身不具备这个信息，就reasoning已经做到头了，他想破脑袋都想不出来这个问题的答案。但这个时刻他除了想问题的答案以外，他还能去想问题的解决方法。这个解决方法就是我周边的这些工具，我要怎么样去运用它。
	这个时候他会发现我可以去上网搜索因为有很多的大家都知道上网搜索就是连接一个AI。我调google的API，调百度的API都能够上网，查搜索引擎上面的信息，那我就去查一下，甚至有天气的API，我就去查这个API。他告诉我今天某个特定地点的天气信息市场他告诉我，我把这个信息拿到，我再告诉厂长不就完了吗？就告诉我们最终的这个终端用户就好了让他跟第三方AI跟其他工具交互的这个行为，就是这里的act action，它跟环境去交互，环境给他的信息就叫做这个observations，就是他得到的一个结果。
	那么它们组合起来就叫做react，reasoning加上action。当然我们能够想象查API是一种模式，那假设它能够调动机器人，吧？就有一个大模型，它是大脑，有一个机器人，就像我们看到斯坦福在一九七几年有移动机器人了。我们给这个移动机器人装上大模型的大脑，那他是不是就很厉害了？是不是就像这个终结者一样？1980年代，其实终结者是一个非常火热的讨论话题，因为那会儿大家觉得AI要突破了，现在也是一样。
	假设现在我们把聚生智能的这个场景，这个学术研究方向想到快速发展的话，那其实并不复杂。要做样这样的一个机器人。因为我们知道很多军方的机器人，单兵作战机器人，其实机器人学部分已经很强了，只是他的判断能力不强。那么AI agents的基础，这里只是开个玩笑，AI agents的基础更多的其实就是这么一个范式，让大模型有思考推断的能力。
	知道你的问题我有没有答案，我大模型有没有答案？如果我没有答案，我的身边可以调用的所有工具能不能形成解决这个答案的解决方案，如果可以的话，就去找环境，用操作，用工具拿结果，结果再给到我自己来判断这是一个完整结果还是一个过程结果。如果是过程结果，下一步我拿到这个过程结果能不能通过推理得到答案，或者说这个过程结果要去再调用一个API，拿到这个对应的结果。那这个就是react这个范式，那在南迁里面同样它有这个agent的模块，这个agent我们刚刚提到到了，他有最重要的一个是他有一个工具集，就是他能干的活，然后他自己要有一个执行器来执行刚刚说的react这个范式，基于这样的一个工具集加这个execute，它就能做出各种各样的agent了。那比如说我们要用刚刚说的这个PPT去对接一个google的搜索引擎，其实就这么几行代码就可以了。
	比如说我要问他这个2023年大运会的举办地在哪儿？我们都知道疫情原因，这个大运会举办地其实是在成都。但这个2023年的大运会其实应该在2021年举办，只不过因为疫情延了两年。这个问题其实对于大模型来说他是不知道的，尤其是我这边问的是这个GPT3的，GPT4的这个大模型，还不是dev day刚刚更新的那那会儿他是不知道这个疫情延误了哇哇哇一大堆的问题。他能通过谷歌的搜索引擎去搜搜完之后他自己要去判断。然后我们也能看到中间结构里面有写什么是2023年的大运会，是他自己的思考结果。
	因为他不知道2023年大运会是什么，就更不知道这个东西的举办地是什么概念，所以他问自己，就是他的reasoning的部分问自己，问了之后，那他去查了一下，2023年这个夏季的这个大学生运动会是什么什么什么意思。然后他又问，接着问大运会的举办地在哪里？这个就是我们刚刚看到react的这个模式。然后他又查出一个新闻，举办地是在成都的东安湖的体育中心，这里面有写各种各样的信息，那我们就不再展开了。
	通过这样的一个方式也能实现一个agents，就十几行的一个代码。然后包括我们经典的这个react范式，也是能够排列组合的。因为react的核心就是大模型做reasoning，然后外部有各种各样的took kids。
	这里我们就对接了一个数学工具，那就能够增加他的数学能力，然后他的整个南昌的这个agents部分的设计原理也很简单，其实就是我们刚刚看到的这个用户输入，然后这个上下文信息都作为整个模型的一个输入，然后输入是不变的。唯一的变化是说它不再像以前的我们看到的戏剧评论或者这个root chain，是用这个change来实现条件判断if else的一种方式。这两种方式都是一种面向过程的硬编码，它的流水线是固定的。
	在agents这种AI的设计模式里面，语言模型会被当做一个推理决策的引擎。他来决定什么时刻应该采取哪些操作，以及我这个目标被分解之后，现在的执行顺序是什么样的。整体来看，输入部分右边是它可用的工具集，中间是他自己实现的一些prom的一些策略，这个策略就是我们agents的关键了。
	那简单的一个agent execute的实现运行时有很多，比如说他自己年前自带了一个，我们有一些很经典的网上广为流传的像auto GPT，也是一种agent execute的运行时，包括baby AGI plan and excute agent，它的实现整个运行时的实现逻辑其实就是右边这个伪代码我们能看得到的，就是我们的整个react的核心，就是我每一步我都要决定下一步干什么。比如说下一步我不需要干了，我现在这一步的结果就已经完成目标了，那我就停下来，就是这里我们看到的，如果我的next agent等于了agent finish，就是我任务完成了，我的所有目标都达成了，我直接就return next action了，就我的任务完成了。但如果我现在任务还没有完成，我的目标还没达到，这个时候他就会去跑下一个操作，然后跑下一个操作过程当中会拿到一个结果。这个结果和下一个操作一起交给大模型去判断它的再下一个操作是什么。如果再下一个操作是他的agent finish这个停止符号，那么他就干完了。
	如果没有干完，那他可能就会有下一步的任务。比如说调一个API或者去做一个学计算等等。像年前目前支持的各种各样的tools已经很多了。这里我们看到搜索引擎，ban的搜索引擎，像我们的论文网站，我们的archive的这个API two，AWS的AManda API。然后google的query，就它的big query，它的这个搜索，还有这个golden query，然后我们看到这个graph QL等等，包括hugging face有一堆的tool。这些还在不断的增加，这个是现在我们能看到南茜这边逐步在积累他的这个tookey，那么在这个agents这一侧，其实整个智能代理它还会有一个简单的分类。
	在这个范式下面，这个范式的下为什么会有分类？取决于两个点。一个点是说我们看到prom的技巧很多，之前我们就看到像GPT4的API。它支持不同的角色，system assistant，user function call 4种。那么这四种不同的role你可以给他一些不同的名字。甚至比如说同样的assistant，就同样是一个gp 74的一I同样一个上下文，你可以给他的a assistance命名。比如说这个assistant叫top，那个assistance叫什么jean。这些不同的assistance它是有名字的，而这个大模型他会记住每一个特定名字的assistance说了什么话。
	这一类其实就像模拟代理的agents，就是simulation的agents。我们看到这个stanford的这个智能小镇，其实就很很明显是这种类型。还有一类就是把我们的大元模型当成一个解释器，编译器，包括像什么code的之类的function call这一类的，其实都是啊让大元模型帮你去做一些特定的工具调用，或者由他来动态决策现在该不该调用，既能够利用好大模型的聊天对话能力，又能够在聊天对话当中去调用一些特定的工具。
	还有一类是这个叫做寄予了人类的厚望，就是这个自主智能体，auto GPT、baby AGI, 都是这样的一个方向，它叫做自主智能体。简单来说就是他的任务就更复杂，你可以给他一个非常复杂的任务，然后他来把这个任务拆解掉，拆解掉之后再一步一步的去执行。这个是auto GPT和baby AGI这一类自主智能体要达到的一个终极目标。但是目前来看还有距离，因为我们的prom的策略很难写到让它能够拆解好。第二就是大元模型也没有那么强的能力，能够处理长期的以及长上下文的任务，当然它还会依赖整个南迁的这个工具站memory，包括我们刚刚提到的tour，这个我们就不再详细展开了，这里有它的长短期记忆，分别是存在内存里和对应的向量数据库里。
	然后我们再花一点时间讲一下这个RAG，就是很多人都关心的这个RAG。那么RAG其实是它的全称叫做检索增强的生成的这这个应用。检索就是从一个特定的目录里面去检索到travel。这里它从向量数据库，从知识库，从任何地方其实都能检索解锁增强生成这个a augmented这个增强是增强什么呢？其实就是用大语言模型，通过一些特定的prompt的设计，或者说特定的prom的模板，把你检索出来的结果整合，整合之后再给到用户，这个核心其实就叫RAG。
	这个RAG我们细看它分成两个阶段。第一个阶段是去构建你自己的知识库，这个知识库的来源可以是多种多样的。所以我们看到整个顺序里面这个document loading它的输入是非常多。比如说你可以从网上UL去从互联网上一个特定的资源里面去获取到一些你要的知识。或者说一些离线文档PDF或者是一些数据库，把他们统一构造成这个documents，这个是一个能嵌的抽象，能嵌的一个类。
	那这个documents因为它太大了，太大就导致一个什么问题呢？我们知道向量数据库存储的是向量存储的是embedding之后的结果。那么向量数据库里面存的这个向量，如果它本身太大，比如说你直接把一个十万字的小说变成了一个embedding的向量存进去，那它很难被检索好。因为这个10万字的小说的内容实在太丰富了，它的主题太多了。你要去检索它的时候，通常你是通过相关性或者一些其他的跟他可以发生运算的方式去检索出来的那如果一个十万字的一个小说变成一个向量存进去，首先我们不考虑工程上embedding好不好，存不存得进去，它的主题就是不明确的。
	做过信息检索，做过IR同学都知道，如果这个太这个块太大，你检索不到它，要么就是什么他他老是被造会，不管聊个什么事情都会被他被他覆盖到，你就会把它解锁出来。要么就是他平平无奇，然后权重都很均匀，怎么都检索不到他，所以要做切分，这个切分也是一个手艺活，切分的好不好？按固定长度，按什么比如按换行符，按什么特定的一些分割方法，分割好之后，通过embedding的这个模型变成一个的向量，像OpenAI的这个embedding，china GI，这个GIM团队就是质朴的这个mbele ding都有一些embedding的模型。
	那么embedding的模型要跟最终的单元模型去做配套，那么embedding变成了向量存到向量数据库里。然后当我们用户有问题的时候，因为RAG通常是一个对话式场景，有问题的时候，比如说我在问你的你是存了一堆的中国的小说，对吧？你问金庸写了哪些小说，然后他在vector store里面就会去检索出来金庸写了哪些小说。然后你问他这个杨过是在哪本小说里，这个郭靖出现在哪几本小说里，他可能就会根据这个vector store去查出来他们出现在哪些小说里面。然后把这些结果统一检索出来的结果给到这个大模型，大模型就会把这些结果根据你的prom去做一遍整理给到用户。
	在之前我们的应用开发的训练营里面，做过一个RA级的应用，并且是用gt 4来产生知识库里面的数据就是用GPT4来造数据。当时是造这个卖房子，比如说造了一堆卖房子的QA问答，然后存到了这个销量数据库里，chroma里面，face里面。存进去之后我们再用连线去调取一个GPT4，然后就可以构造出这样的一个聊天机器人的应用。通过一个radio的开源的SDK做他的GUI，可能也就四十行的代码就能做出一个RAG的应用，所以RAG并不复杂。
	好，那么今天可能我们就只能讲到agents的部分。然后大模型的微调和我们的预训练的这个技术中，我们可能要放到周日了，我们今天来重点回答一下大家的问题时间已经到了十点钟了，看大家有什么问题我们来提问。GPT现在国内可以付费了吗？GPT4的付费问题其实是可以付费的，只是要用海外的信用卡对。Auto GPT的二次开发与基于冷静开发有什么区别？基于auto GPT会不会更方便一点？
	这个同学问的问题挺好的，但可能还是看咱们的开发目的。因为首先能欠的那个auto GPT就是一个重新实现的order GPT。没有去做这个没有去调用auto GPT，所以我不知道这个完全取决于咱们的目标了。如果咱们现在工程里面已经引入了南茜，不想再引入一个alt GPT的工程，那可以直接用年前实现的auto GPT版本。但如果咱们的这个咱们的这个工程引用无所谓，你就想跟进最新的RTGPT，那也可以的，可以微调百川和千问吗？我印象当中好像这两个国内的大模型公司只开放了SFT，就是supervise的fine tuning的这个I你是没法下。我想想一下百川行是可以下的，它有开源的版本，千万我不确定。如果它有开源的模型，你就可以down下来，就可以微调，用的也都是hugging face的这些库。
	然后可以总结讲一讲agents和prompt engineer的区别吗？可以的。就是简单来讲，为什么先要讲prompt是什么，再讲prompt engineering是什么？可以这么理解，prompt是我们跟大模型沟通的一种方式，prompt engineering是把这个方式技巧化、套路化抽象出来了。而agents是基于prompt engineering去做的一种应用形态，基于prompt engineering还可以有别的应用形态。
	我不知道这样讲有没有说清楚现在大模型的应用是否不是很前沿了，有没有推荐的研究方向？这个同学我没有太理解你的问题，就是大模型的应用它也不是一个研究方向，大模型的应用是一个应用。你说的研究方向可以具体一点，就是你想问什么？量化和推理加速课程有涉及吗？有啊，我们一直在讲，我们会用量化的方式来做预训练和微调推理加速是deep speed的，这个框架会去讲的。
	Prom当中的system是什么？如何查看一个开源大模型的常驻指令？From当中的system是GPT提供的一种能力。你可以理解成GPT模型，尤其是GPT3.5的这个模型，CHAT接口的这个API，它是能让大语言模型理解它有不同的角色的。而system这个角色就是一个让他能够持续去输入的一个角色，留了一个这样的接口，然后在我们刚刚的事例里面，我可以再回到这个事例。
	比如说这里在刚刚的这个示例里面，如果我们调过GPT的API就知道，这个示例里面的这个system就是对应着GPT的PI里面的system role。然后这个role它的任务会一直告诉我们的GPT的。User和这个assistant是每一次的对话里面的持续迭代的内容。然后如果你用system就可以让他去固定干一些事情，然后开源大模型它不一定支持system role，你可以自己去读一下它的文档。有的开源大模型它只支持user和这个assistant，就像很多开源大模型也不支持function call一样。Function call跟system是同样级别的概念，就GPT支持4种不同的角色。
	然后所有问开源模型哪个效果最好的我都不回答。然后千问百川如果可以下载就可以微调。对，然后带MOE的模型微调有什么不同？微调不同，MOE是这个混合专家模型对吧？然后混合专家模型其实我们会在应该是在周日可能还不一定讲得到，可能下周三会讲到。
	对混合专家模型的核心，其实也是机器学习的时候就已经提出来的一种很很好的一种思维方法。包括像prompt里面的self consistency也是类似的逻辑。简单来说就是多个不同的专家模型，和机器学习里面的专家模型还不太一样。你可以理解为像GPT4用到的这个MOE，至少它披露出来的信息里面来看，会有多个大模型。每个大模型有自己擅长的能力，然后自己擅长的能力，如果我们在问问题的时候，他会去根据一些阈值去触发，他会把同样的问题问给不同的几个大模型，这些大模型都会给一个结果，这个结果我再去做一个处理。这个最后的处理是不是就像我们RAG1样，只不过它不是检索来的，而是大模型的结果产生的。
	然后我们再来看看，它的微调有什么不同？这个是根据你的任务驱动的，我们刚说完了专家模型，每一个不同的模型它有它的任务目标，最终要达到一个平衡。OpenAI的GPTS能带来什么？需要怎么用？GPTS如果你有访问权限就能够直接用，它能带来什么？
	这个太长远了，非技术问题，我们先优先回答一些技术问题。我想做一个基于行业知识库的这个东西，写的AGR应该是想说RAG是先学开发再学微调。然后不是我如果已经报了微调的课，可以先继续学。因为我们的微调课里面的实战会做RAG，就是比如说我们微调出来的一个模型，那最终得用，我们会做一个RAG把它用起来，所以没问题，可以继续学。
	对，一般的公司预训练任务多吗？主流就是微调。大家可以去数一数，现在中国的大模型公司有在搞预训练的吗？你们看你们仔细去研究你就知道了。
	现在还需要学习底层技术吗？线性代数之类的，你得知道线性代数里面就是这个同学问的线性代数要不要学习底层技术。首先线性代数和AI的底层技术关系不大。就是微调这个课我们刚刚有有提，需要了解什么？我再回到这一页，微调需要理解反向传播是怎么回事儿，只要你能理解这个反向传播是怎么回事，知道梯度下降能够更新我们的这个局，它能够通过这个loss更新这个矩阵，它参数是这么来的就可以了。我们也不需要你去从头写一个神经网络，所以线性代数你只需要知道什么是矩阵，矩阵相乘是怎么回事就可以了。
	有了OpenAI的assistant AI的话，南倩还有用吗？这个问题要去问OpenAI和南倩，我的观点是这两个不搭嘎。对，就是agents是实现prompt engineering的一种应用形态，南茜可以支持agents，蓝倩也可以支持其他的apt的应用形态。而这个OpenAI的assistant API只是基于GPT大模型做的一些应用，而能倩跟GPT不是绑定的关系，所以他们之间压根儿就不在一个平面上。所以这个问题其实没有什么有不有用的关系，因为他们不是IOS和安卓的关系，甚至就算是IOS和安卓一都共存了。
	然后是否可以用NECHAT结合agents形成业务人员完成业务流程。可以讲讲怎样实现这个不在咱们这个微调课的范畴内。有个同学问能不能讲讲stable diffusion模型的演进趋势，这个纹身图的模型也不在咱们的这个范围内。然后预习的TENER flow快速入门与实战课程没顾上看，周日之前要看多少，不会耽误进度。是这样的，就是学过应用开发的同学应该知道，其实我会在开头的一周多的时间跟大家普及一下这些理论的基础。但这些理论基础不会成为上手的一个绝对的阻碍。它更多的是能够让你在学完这个课程之后，或者在学完学课程的过程当中，能每次回看的时候有一些认知的理解。然后这个认知的理解会逐步提升你自己的一些天花板，让你了解到其实这些AI的技术发展他有一个演进的过程。
	然后这个演进的过程里面哪些技术点是重要的。然后这些技术点如果你反复看弄明白之后，你未来自己学习或者去学一些新的它的一些新的技术的时候，不会感觉到这么陌生，你会有这样的一个感受，但它不会成为你的阻碍，所以不用担心，老师可以分享一下如何构造agent的数据，使模型微调出agent的能力。现在我训练出来的模型总是想到答案，但是不知道最终结果。这个可能要结合具体场景来聊了。微调必须使用框架吗？像bert那一代固定几层不变，微调后几层的方法还会用吗？这个我们可以留到讲微调那节课的时候再给大家讲。
	课程结束后是否具备训练一个小模型的能力？课程过程中你应该就能够学会，并且具备微调一个小模型的能力。难过的时候是面试的时候，面试官一直在问全量预训练，全量预训练没有问题，就是你可以反你学完这个课你就能够访问面试官了。他是全量预训练的，一个多大规模的大模型？是使用全精度在训练，半精度在训练，还是量化后再训练？训练方式是什么？
	这些对GPT有很多敏感问题都会被屏蔽。这个被屏蔽我们在应用开发课里讲过，是因为OpenAI的CATGPT，它的ChatGPT这个应用程序跟直接调用GPTAPI不同，它会再加一个moderation的API，就是做合规的API。如果你直接使用GPT的API或者使用playground，你是能绕过这个moderation的。所以你都不需要微调，你就能突破，但是不建议突破。对，这个moderation是合规用的。要是咱们做了一个应用，说脏话或者说一些敏感话题也挺危险的。微调后的模型评估，老师能否可以在周日的课程里面扩展一波这个模型评估。我不知道这个同学是想扩展什么，但我们按照课程节奏来，应该周日还不太会讲到模型评估能欠加上RPA可以实现自动化测试和一些自动化的工作。
	是的，nura微调大模型自我认知影响了原有模型的文本总结能力解决方案老师会讲吗？这个我们会根据具体的数据来聊的。就是微调大模型相对来说还好一点，因为它不会全量的去动这个模型参数。但如果咱们用全量微调，就经常会遇到这个问题，这个问题就叫做灾难性遗忘，我们会涉及到这个的。看看大家还有什么问题吗？OpenAI类似的高可用部署架构能介绍一下吗？会讲transformer的内容吗？
	OpenAI类似的高可用部署架构。首先我也不知道OpenAI内部的高可用部署架构是怎么回事，应该是微软的edge团队提供的。然后我们这个课可能不一定会讲那么深，关于部署的，尤其是高可用的。
	然后有个同学问问，会讲transformer的内容？周日会讲会讲一些，但是不会讲那么深了。因为transformer的内容我们在应用开发课会讲，我会认为这个课的同学应该是懂一些这个深度学习网络的基础的。然后我们可以根据情况，在周末的课里面我们会去准备一些这个transformer的内容。但是不会像应用开发课那样，从注意力机制到transformer再到GPT1GPT31步一步讲。那么我们可能会讲一些核心点，就不会讲那么多，因为这个确实是大家关心的问题，但不会讲那么多会给大家涉及到一些对如何评价RAG的检索效果，除了人靠感觉评价，有极其客观的评估方法吗？
	做一个benchmark。对，就召回率这个是经典的信息检索的benchmark的方法，这个同学可以去稍微搜一搜，信息检索是怎么做召回的就可以了。微调后要确保模型的准确度和质疑度，以及其他地方指标。这次的课题主要关注的是哪些？我们可能会关注的是新增加的这些微调的数据有没有准确度达到他的这个要求。以及这个过程当中怎么样把微调的框架运用好，能够把微调这件事儿学会。
	我们最后再回答三个问题，已经10点16了，看大家还有什么问题。有个同学问RPA，RG, RPA是RPA也是一个这个叫什么？RPA也是一个专有名词。建议少一点基础内容，多写点技术知识和实战。这个基础内容可能每个人评价标准不一样我们还是沿着我自己的这个思路再给大家做这个课程的设计。大家如果有一些建议，也可以在后面的我们会有一个表单，应该是这周日会发出来，大家也可以在上面去多提一些建议。
	介绍一下如何使用AI agents来开发一个自动化平台的思路。这个自动化平台同学能介绍一下是做什么的吗？什么叫自动化平台呢？可以少点边缘代码逻辑。
	这个同学什么关于咱们要讲什么，然后课程内容的到时候都在问卷里面去多讲一讲。因为每个人关就微调是一个非常大的概念，每个人可能关心的点都不一样。我们只能尽可能选一些大家都关心的这个重叠的区域给大家讲，然后大家有什么问题倒是可以在群里多交流。那行，那我们今天的这个QA就到这里。最后提示一下，就是大家不用现在这么急就去开那个云端的g pu。因为我们可能应该是到第二周的时候，第二周周日或者第三周的周三才会开始正儿八经的去做微调。前面会有一些理论的部分和SDK的使用的一些介，包括一些代码的示例。真正用GPU可能是在那个时候，所以这十来天的时间大家可以省一下这个费用。好，我们今天就先到这里，感谢大家的这个时间，已经到10点半了，工作日我们周日见。然后大家有问题可以群里再沟通。