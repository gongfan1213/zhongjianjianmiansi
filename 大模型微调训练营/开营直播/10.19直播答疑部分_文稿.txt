	我来看看有没有什么观众讨论问题。
	这个课程要准备卡吗？这个课程是要准备卡的。建议如果你有这个消费级的卡，比如说4090或者4060之类的是可以用的。如果你没有的话，像这个云服务厂商其实是有很多的。
	这个其次是一个很老的卡了，应该是图灵架构的。三四年前应该就已经被广泛的使用了，这个卡现在应该是一个比较便宜的价格，然后也是可以大家来用的，如果大家去淘一淘的话，应该是我印象当中应该是几百块钱一个月，或者一千多一个月。但你不用包月，你可能就实际训练的时候去用。
	数学基础其实不会要求太深，我们刚刚有看到这幅图里面有讲，神经网络是什么，然后你理解什么是反向传播，这个其实是大语言模型最里面去做tuning的一个核心，因为tuning的核心是说大元模型是由一堆的神经网络的模型参数构成的那我们在tuning和training的是什么？就是在通过数据来调整这一个参数的权重，那这个过程其实叫聪明或者training，你理解了这个层面上的概念其实也就够了，你不需要自己去推一下这个劣势法则或者这个之类的，这个其实倒不需要。所以数学基础你有基础的这个钙就好。
	还有个同学问RAG和微调的优缺点，举个实际的例子说明效果区别。我先回答这个问题，首先要理解场景的区别，就是你到底要干什么事情。因为就算是find tuning，他也是基于一个特定任务来做的那比如说我们举个简单的例子，你要做的一个场景是做检索的。就是你你要做的这个事情就是公司的这个员工手册。你希望包括我们这个课程也有机器人，如果你要做的只是这个事情，那么RAG是一个相对来说比较低成本的方式，因为RAG不需要那么多的去跟大语言模型交互，你使用的大语言模型的频次低。如果你调的是API，那你消耗就少。如果你使用的是这个私有大学模型，那你部署的实力就少了，这个是成本端的一个考虑。
	第二个是说针对这种政策解读，或者说这种文档的一个解读检索类的这种事情，你用RAG的一个好处是说，你比较能够及时的去知道针对特定的query，你的库里面有没有，这个是可以通过we travel的这个结果去查询的。所以你可以有一个滚雪球的过程。你可以根据用户的常见问题。比如说当这个问题第二次被问出来，并且我都库里没有答案的时候，我可以人工的去补充知识库，你可以不断的去把你的知识库做丰富，然后你的这个库就变得很有价值，就你这个向量数据库里面的内容就变得很有价值。
	你还可以在这个过程当中不断的去把你的数据处理做的更优，就比如说你一开始做了分割，做了transform，做了数据的处理。然后用户也通过这个RAG拿到了答案，但他发现这个答案的片段有点冗余，或者说这个答案他有点欠缺，只回答了一半。那这些都可以在过程当中去做调整，这个是使用RAG的优势。
	但它使用RAG的劣势就是说假设你的这个规范解读，你的规范本身太差了，就是你的数据太少了。然后你的这个数据你又没有办法短期内解决这个问题，那你可能用这个反应冲顶是一种方案，但它不一定效果非常优。它可能这种场景里面就是比较像什么呢？比较像这个法律了。就是这个刑法很严肃，但是它的内容也许不多。那么你一定要让他记住，什么事情是不能干的那这个也许是可以的，用拌的方式。
	但简单来说就是如果只是做简单的这种问答，RAG是好用的，并且你是方面去调节知识库的。像刚刚如果你纯粹用一个反应处理，然后有些问题其实你是不知道大语言模型到底学没学会，或者他有没有把这个知识点真的记下来。或者说它的权重足够高，它不像这个向量数据库的检索结果这么明确，这个是finding的劣势，但它的优势是说你高度可控，你可以直接把你的数据硬塞进去。你只要不担心这个幻觉问题，你只要不把它变成一个非常通用的场景，只是一个特定场景，那反正中间是可以的对。
	然后还需要注意提到的一个重点就是说反应处理和rng不是一个排斥的一个关系，不是一个用了翻译聪明就不能用RNG的一个关系。这个是大家一定要搞清楚的。RNG有一个大语言模型帮你去做最终的这个润色。
	我们看到这幅图给大家回到这里，其实我们的实战也会有这一部分。大家看到这里有一个一坨大语言模型。这个小的云，像大脑一样的这个地方，我们可以使用一个没有经过繁触的大便模型，我们当然也可以使用一个凡触的大语言模型。大家想象一下，现在GPT它其实就是把我们这么多人提的问题先放到了向量数据库里。然后他再去清洗这个向量数据库，再把我们问的一些好的问题变成他的GPT的一个训练数据去做踝处。所以他的GPT会越来越聪明，就是因为他拿到了线上的数据，这个是一个良性的滚雪球的过程。
	就是为什么我说你的知识库后面就有价值了？因为这个知识库的量足够多了，它不会太少让你的防御中出现问题。当你的知识库结合的你的实际场景做的质量高的时候，把它内化成你大语语言模型的垂类能力。这个时候那你就不需要天天都去检索了。因为大宇的模型可以有举一反三，触类旁通的能力，这个是一个最佳实践的方案。
	我们再来看看，这个后面问了很多问题，我再看看大家的提问。一个一个来，老师垂直领域的训练会讲吗？其实垂类的这个类别取决于数据集，就取决于这个数据。我们会去选一些垂类的数据的来做这个的翻译处理微调可以提升垂直领域的翻译效果，垂直领域没有翻译的意思吧？就是他是想说一些专有名词吗？对，写了这个技术文档的翻译，有很多专业的词语和描述方式。
	微调可不可以提升垂直领域的翻译效果？这个应该是可以的。这个同学但是你要注意，它可能带来的代价是幻觉的产生和通用能力的一些下降。就看你的数据准备了。
	其实这个方案也不一定通过微调来做，就看你的这个专业领域的词汇有多少。因为我理解专业领域的词汇应该就是签这个级别。如果是签这个级别，可以有蛮多方式，也不一定只用微调来做。现在最通用的微调是使用deep speed的吗？不是这样讲，就deep speed的你可以理解成是用来加速的。然后刚刚我们看到的PEFT是就可以直接拿来做微调。这个同学我们看到这个技术栈，这里有一个PEFT，它里面的实现大量的像你提到的P20和lora，PFT这个库里都有可以直接拿来做微调，而deep speed的是可以拿来做加速的。比如说你有多张卡那PFT可能不管这事儿，它通过accelerator去对接deep speed就能做分布式的训练了。
	现在市面上的AIGC相关岗位对技术有什么要求，掌握哪一些大模型的知识，我理解可以把这个问题拆成两部分。一般AIGC的团队会分成2拨人，就跟我现在这幅图看到了两拨人一样。一波人是去搞模型的，一波人去搞应用开发的。如果你是想要去搞模型的话，那你就去搞模型。就右边这条线，如果你不想天天折腾数据，搞模型，其实绝大部分时间是在折腾数据，这个是大家要有一个认知的。你有百分之八九十的时间是在搞数据，这八九十的时间，你要把数据整明白，你才知道什么样的数据能训练出好的效果。如果你不是一个想搞数据的人，你就是觉得工程是美的，写代码要有结构，要确定性的结果，那你就去做应用开发。就是左边这一套，你要把能线的框架理解到位，它的基础模块有哪些，分别是什么样的作用，然后有哪些内置的一些好的工具能直接用，怎么样通过OpenAI的API去搭建一个大语言模型的应用，就左边这条线，这就大概就这两类岗位。
	这个同学又问了一个，我们先尽可能的多回答一些不同同学的问题。有同学问AI大模型的应用开发训练营适合小白吗？适合的这个有不少是什么学本来是一个前端开发，或者是一个java开发，或者是一个go的开发，还是拿到了咱们的很多的offer。本来我找班主任要了这个同学的，有很多同学是通过AI大模型应用开发训练已经拿到了offer，但我想了想还是没有贴出来大家可以私下找我们的班主任去看看，班主任应该也在朋友圈发过。然后学完这个能去求职哪个岗位？可以去，应该有几类公司，有几类岗位我觉得是可以的。比如说这个AI大模型的算法工程师，或者AI大模型的算法专家，这一类的岗位其实是啊目前还挺缺人的。因为就这幅图里面的东西，在全中国你说真的能能用起来，能能懂的其实非常少，我们再往前看看。
	还这个同学又在问这个问题，我的目的是替代设计研发的工作，工作内容包含大量的领域知识和复杂的科学计算。微调应该准备什么数据，怎么保证效果？这个一两句话说不清楚C他是A同学，你在两个月的时间好好学一学，然后我再看看问题，预训练和微调分别适用于哪些场景？有的同学在问，这个讲了很多了，就比如说你的预训练核心解决的是从0到1，大量未标注数据怎么用来训练的问题。微调是要处理和标注数据的，那如果你要让这个语言大元模型学会一门新的语言，那肯定用于训练，或者说你要让这个大语言模型学会一个新的特定领域，这个特定领域我指的不是比如说学会一本手册，而是说让他，但现在的基础模型基本很多大领域都已经覆盖了。但比如说一个特定的中医，这个中医到底应该用预训练，还是直接翻译成你好，其实是一个问号，那我的感觉得可能预训练说不定还好一点，因为他不需要掌握那么多外语，他可能更多的是要怎么掌握中国的一些传统哲学和相关的一些知识。
	预训练一定要从头开始，我只是想把一些行业知识灌进大模型，减少幻觉。可以把行业知识通过预训练灌进ChatGLM6B，首先预训练不一定从头开始，这个问题有点，这是一个这个叫什么呢？这是一个概念问题。我可以这么讲，就是预训练这个词，我们刚刚也提过，预训练也好，反应充电也好，它就是在调整模型的参数。
	然后预训练为什么叫预训练？通常是说我不是搞完预训练，我这事儿就干完了。它叫预叫pray，所以pray完了之后还有正经的工作要干。所以预训练通常是说我的冷启动阶段我有很多数据，那我把这个模型参数训练到一个差不多六七十分，我再用我在我的特定问题上给他干到八九十分，那你说这个算不算一定从头开始呢？这不好讲，这是个概念问题。然后你如果只是想把行业知识灌进大模型，你直接去搬通你是可以的，你就是不用纠结你现在正在做的这个操作是预训练还是反应处理，这个不重要，这个纯粹大家看一看，我刚刚为什么要专门把bert这个范式放进来，就是因为数据太多，我们想用起来，所以用预训练。
	因为预训练不用标注，具体问题我们又不可能让一个大学本科生把什么工作都做完了，那你就需要做two，他要去学习。微调课程和应用训练营的主要区别是什么？这个刚刚有讲过，我们通过技术站应该也能看出来，一个是工程应用开发，一个是算法模型微调。大模型能和实时视频了解、名流感知模型结合起来一起用吗？可以，这个是很热的研究方向。
	大家看这幅图，这个OpenAI anthropic包括国内的很多公司都在干然后还有同学说，记得老师讲过微调是在GT3的，明年年初就不能用了。想问微调这部分主要是针对哪些场景？这是一个上过我们课的，上过应用开发的课的同学。首先OpenAI的翻译处理，他是不把模型给你的，你是只能用OpenAI的fine in的这个模型ID，所以你拿不到这个模型。所以这门课我们不会讲怎么使用OpenAI来翻译。因为我相信大部分的同学的数据不一定方便出海，我们都会用私有化的可以部署的模型来做。然后确实明年年初GPT3的fine team就不能用了，翻译之后的模型也不能用了。但我记得几个月前GPT3.5支持fine了，所以这个同学如果是想要用GPT3.5的find two是可以用的。
	然后微调这部分主要是针对哪些场景，目前是相对开放的，我们也想广泛的收集大家的意见。因为翻译和应用开发不一样，翻译其实数据还是有一定相关性的。看看我们报名之后，大家我会去做一个表单，然后去收集意见，看大家都想做什么领域，什么类型的翻译中的数据，我们会去收集，然后平衡一下。综合来看。Macbook pro是不能跑微调的。这个同学然后高性能的英特尔CPU服务器，应该可以，但会比较慢，还是得用GPU比较快。大模型应用课和微调课都有了解。目前的话我建议你先学微调的课程。因为微调的课程现在是直播阶段，我们会有，我会更多的跟大家每周都有这个直播，然后会有每节课的答疑。
	老师你好，目前是名双非硕研二在读本硕，都是计算机专业。想通过系统性的学习大模型的课程，期待在明年找到相关实习，有可能实现吗？我觉得这个很有可能。首先这个同学你要理解，你是计算机专业的就已经很加分了。其次你如果真的把我们课程当中教的东西都学会对了，能用，你已经超过市面上绝大部分的所谓搞大模型的人了，这个我还是有谱的。
	GPU怎么解决？这个同学刚刚有提过，就是用消费级的卡或者去云服务器都可以。对，是的。我们这个课如果报名的话，之前我做的这个TensorFlow快速入门与实战的这个课，会给大家免费的去学习。里面会讲到反向传播神经网络相关的一些概念。
	4070可以吗？4070应该可以的。大家理解，其实我们GPU有两个关键指标，一个是算力，一个是显存。算力就是指它每秒钟可以执行的，比如说32位浮点数或者16位浮点数，或者高精度双精度浮点数，64位的这个计算次数。如果你的显存够了，但是你的算力不行，那它一定是能用的。只不过因为它算力不行，所以它会慢一点，但很多时候是显存不够。
	那显存不够，那它模型都加载不进来，那怎么办？那就加载不进来，对吧？那为什么会有q lora，会有lauda？那就是想了另一个办法，就是模型太大了，我就把这个模型本身变小一点，我不存这个完整的模型，我存的是有精度损失的。比如说我存了半精度的，16位浮点数的，甚至Q罗A，我存了int 4的，只有四个这个例子，那它就可以把模型变成原来的8分之1，那这个就能存进去了，这就是罗A的核心。
	看大家还有什么问题吗？除了讲适配华为的GPU，还会讲其他国产GPU的适配吗？这个我们暂时不会，因为华为的GPU是大家可以直接去访问到的。但是像海关很多其他的国产GPU，有的是还在研发状态，只有开发者版本，有的是相对来说通用性还没有这么强。
	老师咱们课程里面算法设计多吗？算法底子薄，能去面试大模型算法吗？这个问题第一课程里面我们第一周会有算法，然后在用的过程当中也会提，算法底子薄能不能去面试大模型算法？这个问题比较难回答，因为面试是一种技能，然后你的底子越厚，其实你就算没有这个面试的技能你也能过。但如果你的底子特别薄，你这个面试面基性特别强，那也是可以的。
	从这个大模型应用开发训练营的同学反馈来看，有的同学学完这个课程之后，他真的把那几个实战项目做完了。然后他去面试的时候，他是有主导权的。因为大部分面试官其实不懂大模型。我坦白来说，所以你至少把我们的课程当中的内容学完，你是可以在面试过程当中占据相对来说主导的地位。那你就可以去讲你懂的东西就会好一些。
	我是16GB的4080的显卡，系统是这个windows。然后会不会使用的时候有障碍？应该不会有障碍，但是确实会有一定的适配的工作。就比如说我们的这个我们可能会使用linux的server，linux的服务器加上英伟达的GPU，或者说华为的这个生成920的这个服务器，来做这个课程代码的展示和对应的代码那如果是一个windows的话，会有一些简单的适配工作，然后这个适配会给一些相关的指导。
	一个PDF文档如何转换成微调需要的数据集，这个问题问的不是很好啊。我坦白来说，第一就是你的微调核心不是数据集，是你要解决的问题，这个是我今天一直在讲的，没有数据集，只有一个面向特定任务的数据集。然后如果你解决的问题，想要问的问题是PDF文档怎么解析，那么我们的OpenAI translator就是训练那个业务开发训练营的课，有对应的实战，并且有实战一和实战2，分别做不同的工作，里面专门有讲怎么样解析PDF的文档。我们用了这个PDF lover这么一个库，然后它的效果还比较好啊，一个python库，有兴趣的话可以去看一看课程会有instruct tuning的实战吗？可以考虑去添加。这个同学看看咱们的instruct tuning具体想要问什么问题。可以在报名之后跟我们的斑斑或者跟咱们的这个平台的同学去做沟通，我们来了解。
	对于企业应用于客服系统的大模型，有没有必要去预训练基座大模型还是直接微调？我的建议是这样的，就是咱们四个阶段的技术最好的状态就是由易到难的去学和用。如果咱们的公司，我也很理解很多同学在公司里面，你说你只会用ChatGPT会被屌吗？就你的技术领导和这个项目负责人可能会说，这他妈谁都会用你，你去你没意思，你得去训练大模型，这也是我们做这个课的原因。
	但是我想要告诉大家的事情是说，第一，如果你的选择现在就是在微调和预训练之间，那一定是优先让大家去做微调的，因为预训练的成本太大了。你要学完我们这个课的第一周和第二周，你就能够告诉你的leader你要预训练。可以，你先给我几百万的GPU的卡，我要从0到1的去预训练，你有没有这个资源？没有这个资源我们就不能干这个事情。但你如果有这个资源，那你就好好学习学习，可以去做这个预训练，然后翻译to的好处其实还是核心一个逻辑，就是用小钱办大事儿。关键要办什么大事儿，得先想清楚，再来看看这个大事儿要怎么样去准备数据，然后在什么样的基座大模型上面去做踝处，然后用什么样的方式去翻车。
	后期的各种训练题会指导我们如何购买相关硬件吗？你是指实战的部分对吧？这个地方我们可以加上在几个预训练阶段，如果用云服务器的话，推荐使用什么样的云服务器配置，这个我们可以加到课程里面。
	Windows系统的话，安装一个linux系统不行吗？也可以，当然可以。更多的是NVIDIA的GPU库，大库库d nn这些库对于操作系统的依赖对。
	看大家还有什么问题吗？没什么问题，我就可以去吃晚饭了。
	实战的项目是在基础代码上迭代，还是我们从零开始写？这肯定是之前没有上过我课的同学，我的课程一直都是会有开源的代码库，然后你而且留下了这个可以做扩展的部分。所以咱们可以简单来说就是如果你是个小白，你可以一行代码都不用写，然后你拿着这个课这个代码就能跑。如果你是一个本身就有水平的选手，那你可以在这个课程的代码上面去做更多的事情，就像咱们的大模型应用开发训练营，有的同学就做的很好。他他在我们的实战课上做了很多的扩展延展，把留的接口都做得非常好啊。这些应该我们的斑斑，就是刚刚这个评论区的喵喵斑斑老师，都会有一些对应的blog和文档可以分享给大家的。
	然后还有个同学一直在刷屏问这个实时视频流点云流感知模型，这个我刚回答过了，我不知道这个同学是不是没听见，就是可以结合，关键是你这句话不知道问完是啥。什么叫这个能不能结合？那肯定能结合，关键是你结合拿来干嘛，对吧？比如说你其实说你要用大模型把这个视频流里面的内容去做翻译什么的，那这个能欠就已经有了，就能欠去对接youtube的字幕，对接哔哩哔哩的字幕，它的这个data connection模块都有。对，然后跟机器学习入门学习给点建议。大家都关注了斑斑特别好，关注一波。
	对，然后有个同学问机器学习入门，给点建议，我的建议是说还是那句话，就是现在这个时代不要去抠这个具体的知识点了。就是一个最简单的类比的例子，就是我们今天都知道学英语，背单词是一个很愚蠢的一个学习方法。大家知道背单词的时候，我们小时候像我其实是我觉得这个学习方法很蠢，他没有任何价值，然后它只会浪费时间。包括现在大家去看这个对教育的焦虑，芬兰这个国家很小众，然后这个国家的教育做的非常好，大家有兴趣可以自己去研究。
	有一些纪录片，有一些公开报道，最核心的问题就是我们学习到底在学什么。然后我们学完之后，我们要拿来这个知识用来干什么？这个是我们以终为始的一种思维方法。
	比如说我们要去学机器学习入门的时候，最开始像我也没有人教。然后我可能学的时候就开始抠一些很底层的概念，就跟学编程的时候，一来先学语法学什么是整形，什么是什么一样。但后来你会发现，机器学习这个东西，这个技术到底在解决什么问题？你把它把这个高度拎出来之后，你再去学就很简单了。就像在那个应用开发训练营里面给大家讲invading这个概念是什么的时候，就是一个从形而上的这个哲学角度，我跟大家落地的去讲，大家就很能理解这个概念。为什么要有invading？是因为知识的表达需要。
	那知识到底表达是谁表达出来的？你从哲学角度有波普尔的三个世界，你还会牵扯到两个很有名的哲学家，笛卡尔和康德。那为什么AI会最终一定会超越人类的知识边界，甚至在很多领域已经超越了？是因为第三个世界，人类的客观知识组成的世界，通过互联网的技术越来越多。而这个主观世界为什么大家觉得现在心灵空虚？因为主观世界越来越空虚，第三个世界越来越丰富。但第三个世界又充满了各种虚假的信息。那么AI在虚假的信息里面学出来的自然就会有偏见有歧义。
	为什么大家觉得大语言模型有歧义问题？偏见问题那会追根到底在数据出了问题。但是数据出了问题之后，我们要怎么解决，这个就是现在很热门的研究方向。大模型的benchmark和moderation等等等等。
	然后最后又落地到这个in bedding是一种表示学习的分支，深度学习也是一个表示学习的分支。他们都是为了解决从一个未标注的数据里面去学习一个概率分布模型，所以大元模型当然也是属于表示学习的分支。从这个视角，从知识体系的角度来学习，你就能够先知道就像我说的，他是个黑盒子，你先知道它是用来干嘛的，接着才会到数的层面。就看我们的这个理论基础一样。为什么是一个理论基础？在最下面再学工具。
	当我们有这个思维逻辑的时候，你把机器学习这个概念对等到AI2.0上面，那些特定的机器学习算法，比如说聚类算法、分类算法，又有很多种聚类和分类的算法就没有那么复杂了。就是看到本质，看到这个知识的结构的时候，再去了解具体的知识自然就不会那么的困难，这个是我给的学习建议。所以问这个一个未知的东西，一个新概念，先去了解它有什么价值，它能解决什么问题，再去看要不要学。然后学的过程是尽可能先往上去拔高度。然后再往下看的时候，你就知道，机器学习不过也只是一种称呼的方式，像一个集合一样。
	好，那么我们再看有什么问题。基于ChatGLM做完微调之后，反而回答不了基础问题，对，这就是翻译成没做好。对，没有通用的规避手段，同学没有一招鲜。这个完全是取决于你的数据和微调的方法，如何监控微调后的效果。这个很难监控微调后的效果，大家都只能通过benchmark来跑分。
	大家想象一下，刚才还有个同学问移动互联网和AI大模型，我觉得他们最相似的就是大模型。就跟当年小米刚刚成立的时候发布了小米手机。然后后来有了锤子手机，有了华为，有了中华酷联被干翻了。然后后来只剩下华为的这个状态，大家不知道哪这手机好，所以就跑分，对，硬件跑分现在其实是目前来看，坦白来说是这样的，如果你非要在一个特定问题上商业化的话，那就是你自己要做好这个特定领域上面的benchmark。就你的那个场景下的benchmark，你就能知道在你的那个场景下好不好。我们到十点钟结束，看看大家还有什么问题吗？
	没有问题了吗？
	课程用的是华为的920，不是的，课程用的是英伟达的GPU。然后华为的920是为了让大家能够去用国产化的硬件，因为刚好这个节点有禁售的这个条例，所以想让大家理解。其实除了英伟达的GPU，也有一些像这个升腾910之类的国产的硬件，也是能用来做微调和运行的，而不是说我们只用华为的910，这个是反过来的概念。微调的时候做公用数据和私有数据的配比。这个我没有太开始理解这个通用数据和私有数据的配比是指什么？
	华为最近对华禁售的消息有什么建议？大家让子弹飞一会儿。我今天在一些投资人和这个founder的群里也看到说4090的禁售有可能会打个问号。对最终4090是不是禁售打个问号，大家让子弹再飞一会儿。而且我开始也说过了，就是禁售。对，所有人都禁售的，所以他就不再是问题了。除非你要出海，那你要出海你就在海外注册一家公司好了。
	不要纠结这个问题，这个不可抗力35岁开发商应该会不会晚了？不会。我讲个笑话，就是最好的时候开发转AI是十年前，其次是现在，再问的话就是昨天。
	大家不要有年年焦虑，我觉得这个其实是挺不好的对AIGC的。
	时代就是很多。
	海外的程序员，我认识的很牛逼的程序员，人家都六七十岁了，仍然在积极的写代码。就是国内的这个他还是要有一个自己的核心技术。为什么国内35岁会被干掉？是因为一直在写CRUD的代码，自己没有技术上面的迭代。最好的方式就是学新的东西，学新的东西是有技术红利的。
	我开始举个例子，就是1617年的时候，像四小龙招的这个开发工程师都是大几十万的年薪，就是因为懂这个的少。那现在一样的，你说懂年前的，懂hugin face PFT deep speed，懂这个transformers微调过lama拆GM的有多少人吗？没有，然后就让他微调过，他微调的好吗？这个是有技术红利的。如果你早一点入局，你一定能够享受到红利，这个是一个很简单的逻辑对。
	想走C加加后端，首先我不是很推荐用传统开发这个词，这个针对性有点强。然后C加加后端也只是一个一种岗位，我理解。然后C加加的后端其实可以做很多领域的事情。所以当我们在聊这个卷和方向的时候，或者赛道的时候，其实我们核心先要忘掉技术。我们应该先去看你在聊的这些东西是怎么回事。这也是今天这个直播分享一开始给大家讲的是宏观的东西。
	我说一个最直白一点的，就是大家都看到了刚刚那么多大模型的公司融到钱了，他们开的offer会低吗？不会，所以如果能进到第一梯队里面去，那不就挺好的吗？那跟在一个所谓传统行业的技术公司里面，肯定不一样的。因为技术是服务于行业的，你的公司在什么行业？那个行业还有一个更大的增长吗？还是那个行业快不行了？如果那个行业快不行了，你哪怕卷到头，你不也还是不行里面的头。
	所以这个大逻辑，对，然后如果咱们现在是C加加的后端，然后想要做大模型，我觉得是蛮多机会的。因为我理解好的C加加后端逻辑能力各方面都挺强的，然后动手能力也挺强的。那么好好学一学，我觉得是蛮大机会。好，十点钟了，要不我们今天的直播就到这儿。然后大家有这个问题的话，可以再联系我们的班班。好像很多同学都关注了这个苗苗班班。
	然后对，有个同学说的很好，先跑起来，然后起飞。就像这个关键的竞速战一样，先把这个轮子转起来，我们叫飞轮也行，叫什么也行，先转起来，先用起来。哪怕你微调出来的效果变差了，但你走通这条路了，那你回过来再看哪儿差了。是数据没搞对，是参数没调对不对，还是什么？就是你一定要先把这个轮子走起来。
	在硅谷有一个很有名的说法，也是鼓励很多创业公司方，他们的说法就是60分，他不是说60分万岁，而是说60分比100分更重要。因为当你以60分为主的时候，你可以fast feel，你可以快速失败。当你是60分的时候，你先走起来了，你及格了，然后你可以去很多地方拿到反馈，这个反馈会让你进一步可以去做更实际的改进，而不是你想象中有一个100分。
	很多时候人是因为想象中有一个100分，我得做到想象中的90分，我才愿意交付或者跨出这一步。但就是因为这样的一种想法，你就慢下来了。其实你不够快，当你应对新事物的时候就是会很慢的那我其实一直认为60分是很重要的一种思维习惯。就先走起来，这样你不会被抛下。对，即使你可能一开始走的踉踉跄跄，但是你走起来了，你比那个呆在原地被甩下车的人，你已经走了很远了。好，我们今天就这样，感谢大家，回头有机会我们再分享。好像10月24号会有一个即刻时间的一个活动，我应该会去答疑，大家有问题我们可以再交流好。