	Hello, 大家可以看见吗？
	Water还没as . 
	well as well。
	声音正常，画面也正常，都没问题，对吧？
	好，那都没问题的话，我们就开始今天的分享。今天是一个更偏实战的，也是我们chat GM3这个大模型最后的一个微调的内容。接下来我们看看下这节课上完之后，chat GM3的微调我们就不会再去深讲了，更多的会转向deep speed的和华为的硬件，以及我们最后的lama。
	今天我们主要分成两个部分，一个是来讲一讲怎么样在私有的数据集上面去做微调。那它就会有前提，也就是怎么样去构造我们的私有的微调数据集。我相信对于绝大部分同学来说，可能想学微调，都是想在私有化的环境里面去部署一个chat GM3，并且这个模型还是在自己的私有数据上去部署的。我们今天就着重讲一讲关于数据这一部分。因为我相信有过做菜炒菜经历的人都知道，这个模型的微调我一直讲就是最后上灶头炒菜的过程。但前期去怎么样准备这个数据，应该是更花精力更花时间的。今天我们绝大部分的这个时间，都会放到怎么样去构造一个私有的微调数据集。大家如果有问题，也都可以及时的提出来，今天会更偏上手多一点。
	在讲这个私有数据集之前，我们都知道以前的数据我们都是来自于hugin face hub p上面，就从在公有的这个网络上面去拉拉取一个别人已经做好的数据集。如果我们想要用自己的私有数据，甚至这个私有数据我们都不想公开到hanging face hub上面，能不能做训练？这个数据要怎么样去生成，怎么样去构造，这个构造过程有没有可能自动化，有没有可能在构造的过程当中还能做数据增强，然后这个过程能不能自动化，这个其实是今天我们的前面这大部分时间要去讲的内容。后面我们会实际上手来操作一下，就怎么样去实战用私有数据来微调chat GM3好，那么先到第一部分，就怎么样去构造私有的微调数据集，一个典型的训练数据集的构造流程其实是三步走的。
	第一步来数据源，我们要找到一个合适的数据源。这个数据源你是拥有版权的，或者说至少你是可访问可触达，不会有大问题的那这些数据源里面的数据，其实都是一些非常原始的数据。简单来说就是他原来在它本身的这个平台格式上面是怎么样，你拿到的就是这样的一个成果。但这些成果，这些数据都无法直接拿来做训练。我们真正拿去做训练的其实都是一条一条的数据样例，一个一个的sample，或者说一个example。在我们的hugin face transformers的这个trainer概念里面是长这样的。
	比如说我们之前已经训练过的chat GM3或者说whisper，大概都可以抽象成一个我们中间数据样例这样的一个形式，就比如说chat GM3要进行微调，它可能有一个content上下文，我们之前用来训练的这个ADG，就广告生成的这个训练集，就长这样的，有一个前面的一个内容，后面有一个summary。那content可能是标，有可能是别的任何的东西，都有可能完全取决于我们去怎么用它了。Summary其实是我们希望模型生成的这个内容，有点类似于标准答案，但又不完全跟这个机器学习里面的大标签一样，因为它毕竟是一个自然语言的文本，它就算有一点内容的差异，最终生成的结果问题也不大。因为我比较的是这个summary。比如说我们在做训练的过程当中，模型其实一直在生成一些文本，他会跟我们训练经理的这个summary去做比对，然后去算这个loss。最终这一条一条的数据样例才构成了我们的数据集，就是第三部分。
	这个数据集肯定就是一个持久化的一个状态了，它可以是一个文件，也可以是N个文件。然后它也可以放在你的本地，当然也能放在hugin face上面。但是我们知道这个数据集的构造过程，它其实是非常痛苦的。这个痛苦就在于我不知道大家有没有自己去做过训练集，如果你但凡是做过的，你会发现这个过程它非常的无聊，很重复。就跟汪小姐被派到码头去卸货一样，他就是一个很恶心的按部就班的一个工作。
	你拿着原始数据，按照你要的这个格式去处理。比如说把原始数据改改，改成一个content summary这样的形式，要不断的去改，因为原始数据可能是非常复杂的。比如说我们要针对一篇文章来进行训练，这篇文章就得被我们不断的去切割。切割完之后再改成不同的格式，非常的重复，而且繁杂还容易出错。如果不出错，效率就会很低。这个是典型的一个传统的训练集的构造流程，但这种形态其实现在已经被渐渐的比重在下降，精品的数据集可能还需要咱们去做二次加工，真正的现在尤其是大模型出现之后，它需要的数据太多了，我们没法像以前一样手工的去做。会发现用GPT来合成数据，应该是一个现阶段在大模型训练里面非常好的一种构造数据集的方法，也算是一个新的趋势。就包括我们最近听到国内的一些大厂，在使用GPT来为自己的大模型生成训练数据。
	其实是一个逻辑，这个事儿也很好理解，就相当于你去饭店吃饭，你肯定是去这个至臻园吃饭，看至臻园的大厨做的菜是什么样的。然后你知道了原来这个菜可以这么做。你回去开你的夜东京的时候，你才知道这个菜应该怎么做对吧？你别一来就去了一个名不见经传的小店去学，那他造出来的数据也不好。所以既然要去学，要去生成数据，肯定用最好的模型来生成，是非常非常靠谱的一种做法。
	但是我们又都知道GT4很贵，所以在我们今天的这个分享里，包括我们的代码里用的都是GPT3.5。因为GPT4的价格是3.5的，我印象当中应该是十倍还是30倍的一个价格，它确实贵了很多。所以如果用GPT来做这个事儿，其实问题就简化了很多，我们也会带着大家一步一步，包括怎么样跟ChatGPT去沟通的，然后用什么样的prompt来构造数据样例，以至于后面我们要怎么样去做数据增强，其实也是跟他来沟通去做的那在这个过程当中就少不了要使用ChatGPT了，我们今天正式的这个，实战的部分，其实也是跟ChatGPT去沟通，然后选了一个，我主要是我们这个统计，各个行业的实战，但是也没有统计上来，没有一个绝大部分的比例。那我就选一些这个，既是现在chat GM36B可能不太擅长的领域，训练起来的这个效果也比较明显。同时也是大家都能接触到的数据，来做这么一个事例，也是所谓的中国哲学这个领域数据，然后也方便大家去做这个家庭作业，比如说我们现在用的这个原文是来自于周易。
	咱们这个家庭作业的同学可以去学学论语，学学大学中庸，看看能不能把文言文让我们的chat GM36P有更深入的一个理解。但是我们说回来怎么来做这个数据，我们现在有了数据源了，就源头想好了，有一堆原始数据，它都是公开可访问的一些史料历史资料。这些历史资料我们要交给下在GPT除了把原文切成几片片段之后，其实更重要的是怎么样去设计这个prompt，我们的提示词，怎么样把原文和提示词一起给到ChatGPT，让它生成很多不同的训练的数据样例。这个是目前我们需要解决的第一个问题，就是如果我们要实现合成数据的话，但是这个热血沸腾之前，我尤其跟很多的研发的同学都会讲，就是一定要先想一想这事儿它有价值做吗？他有必要性吗？就你别干了一圈之后发现这个事儿其实这个大模型它已经具备了，那就比较麻烦，相当于白做了，或者说它的带来的增值空间不大。那我们就来试一试看我们的chat GM36B在微调之前，它在该领域的这个知识，它是不是有提升空间，这里我就问了几个很常见的问题，就比如第一个问题，就是我们之前在上节课的时候，好像也部署过HIGM36B它的这个图形化的版本，今天我们就不去搞这个web UI了，我们着重聚焦在这个数据处理和训练上。我就问这个乾卦是什么？
	这个应该是非常常见的一个知识。哪怕不懂这个领域的知识的人，可能大概也知道一二。那显然chat GM36B能够胡诌的一些内容，比如说是第一卦八卦之一，然后由六个阳爻两个阴爻组成，成为这个基数排列。说了一大堆就明显感觉他是在他不是很懂，但他在各种臭知识然后来回答你的内容。
	但这个地方就显然他把很多概念搞错了。就比如说八卦和六爻，和8个瑶肯定是不一样的。哪怕他是简单的八卦，这个文这个不是咱们周文王这个电影里面演的那个复杂的六爻的八卦。它只有三爻的话，那也应该是像咱们这儿看到的，三个都是羊。如果是这个六十4卦的话，就应该六个都是一样。但怎么样它都不会变成八摇，就是有八个横线，更不会说有八个横线里面六个是阳，两个是阴。
	所以我们能通过，如果你自己懂，首先你要微调它。你自己得懂就相当于你在处理一个数据源，你在构造训练集的时候，如果你这个数据标注人员，你这个数据处理人员都不懂这个领域知识，那你肯定是没法处理的。你都无法鉴别GPT合成的数据是不是有问题，那从这儿来看，显然在就从乾卦的这一个问题来看，GIGM36B在这个领域的知识它是有一定的缺失的。所以我们认为至少在今天做的这个示例这个数据集上，它是有一些概念混淆和知识缺失的那也就有我们可以去做进一步微调的空间。
	类似的我们问一个更难一点的问题，这个好像也是在上节课问过的，这个就是六十四卦了，就不是八卦了，不是所谓的伏羲的这个传说中的八卦了，是六十四卦了。那这个地水师卦，其实是六十四卦里面的，但是显然他就搞错了。比如说他这个地水师卦，我这边有个截图，这个是一共有六爻，对吧？然后除了这个第二尧以外，其他五个都是音。但是你看它的这个描述，阴阴阳阴阳阴显然就不对，所以他的这个描述肯定是有错误的那这种更偏向于这种小众一点的知识，因为乾卦本身还是出现的频率太高了。在其他的一些文学作品，它的哪怕他不学这个训练集，我们今天用的这个训练集，学一些像我上次提到的清华的校训，里面也会用这个乾卦的这个卦象的一些解释。
	天行健君子以自强不息，所以他那个部分还能胡诌诌一些。但是你问到更深一点的这个领域的知识，显然就完全不知道怎么讲了。然后大家如果还有印象，刚刚写的乾卦经常与坤卦相对应，但是你看他这个写诗挂经常与坤卦相对应对，看着特别像。在这个部分有过拟合，或者说他不知道，所以他硬生成了一些内容。在这个领域里面，我们通过这两个小的测试就能发现，其实它是有很大的空间的。如果大家要去做一些其他领域，比如说医学的，或者说这个呃特定领域产品，包括像什么地理、天文学之类的，都都可以做一些你认为在那个领域里面的一个很常见的问题，或者再搭配一个更有深度的问题来问。那么你就会大概发现这个模型它的领域知识在这一块有没有混淆和缺失了。所以我们在这儿能做对吧？
	Before taking action, 现在我们发现有价值可做，那我们就开始实战怎么做？第一部分就是先要找一个数据源，数据源我待会儿我会随便你用google或者用其他搜索引擎去搜，都能搜到。因为这都是一些经典的书籍，并不是一个很私有的，就是你找不到的内容。但是有了数据源之后，这个数据源要怎么变成我们可以训练的数据样例，我们从这一趴开始讲，这里就开始涉及到了一个所谓的搬砖工的问题。
	就怎么样把原文当中的一部分的内容变成一个我们训练可以要的样式，这个是OpenAI的playground，这个是一个小工具，网页版的一个应用，是OpenAI。为了让大家能够去方便调用它的API，然后来做的一个小的页面，方便你去测试。在这个页面上比起ChatGPT有一个好处是说开放了system row这个角色，就系统这个级别的角色。而这个system raw里面的prompt，它的作用通常是用来描述任务的，就像我们最早在理论篇的时候就讲过OpenAI的GPT3文章里就提过这个所谓的meta learning的概念。然后meta learning的概念里面把prompt做了三段式的一个分类，非常早期的时候就有这个思想了。这个三段式的分类里面，第一段叫做task description，就是任务的描述。现在其实就对应着它更把这个概念抽象出来了。在训练集里他就做了抽象了，而不是让GPT3自己去悟，而是给他做了训练。
	现在就被抽象成system role，像chat GM3，他自己的这个多角色的训练也有做类似的这种训练集。当然这个system row里面描述任务，我们给他做了一个大概的描述，这里我们利用了GT4或者说GPT3.5本身有的一些关于这个领域的知识，所以他其实不只是把咱们这儿的内容给它放过来了，他也做了一些别的一些描述。如果你想要在system row这个级别上去多做一些事情的话。但如果你很不巧，你的数据连这个GPT4它都没有办法去访问，就是你太敏感了，都出不了这个私有的网络。还有一种办法，就是在软件工程里经常有一个词叫多，就自己的狗粮自己先吃是吧？然后你也没法去用这个领域知识了，那可能就只能帮你去做一个格式上的转换。那也行，那你就可以用一个chat GM36B用这个没有训练过的chat GM36B来做这个事儿，然后这个地方你就可以替换成一个chat GM36B或者26B都行。然后我用年欠的这个方式，也是为了让大家能替换不同的大模型来生成这个数据，就是你不用绑死在OpenAI上面，这是后面为什么不推荐open I的这个SDK的原因，我是希望这个步骤是足够灵活的，重点强调的就是这个system row。然后我们看到右边，其实就是我们经典的ChatGPT的对话的一个上下文的一个对话联络。User这个角色就是。
	我们人给到ChatGPT. 
	的这个内容。Assistant其实就相当于ChatGPT的回复。我们整个这一段的要求其实就是第一我们告诉了这个大模型，帮我们生成数据的大模型。通过这些prompt告诉他你现在的主要任务就是帮我去生成大模型的训练数据，并且格式上有一个期待的结果，比如说期待的结果是content。这个尸挂这个尸挂是从输入里面提取出来的，然后第二个，这个summary其实就是让他把这些内容变成一个相对来说不是这种文绉绉的，而是它有一定解读的这种说法。然后这里你的这个summary的内容其实也是来自于我跟ChatGPT的一轮对话，相当于这个system里面的这个summary，这个示例也就来自于ChatGPT4的一个翻译。
	那通过这样的一个模式，至少我们能造出一个样例了。我不知道大家get到这个点没有，就是现在这个红框里面的user来自于数据源里面的的某一个片段。然后通过这样的一个调用，我们可以把这一个片段变成一条可以训练的样例。就是我们经常在之前的这个课程里面讲过的训练的这一行数据。然后这一行有两列，一列是content，一列是这个summary。这个方式肯定是非常粗暴的，你还得复制粘贴对吧？所以我们肯定得写代码来完成playground的这个网页页面上的一些这些工作。这个页面只是为了让大家去调你的prompt，那怎么弄呢？
	我们之前上过一节南倩的快速入门的课，希望大家这个代码还能记得，不记得的话就去大概用一用，也不复杂。因为我们整个微调这门课就只需要能够用能欠去调一下大模型就好了。在这个页面这一页，我们其实就是把刚刚看到的playground的那个图形化界面，给它用代码做了一次实现。在南线里面为了去调用GPT3.5以后的模型，这种支持多个角色的模型，它的抽象叫做chat OpenAI，对话型的大模型OpenAI的那以前的老版本的很多OpenAI的模型后续也都会下线了，就可能大概率未来年轻人都支持下投PL老的像GPT3，就是达芬奇系列的那些模型都会慢慢下线。
	在这个事例里面，其实我们看到chat OpenAI它的初始化里面维护了一些状态。就像我们刚刚看到的那个页面的右边栏，有一些常见参数，包括temperature、max token、top之类的这些参数。然后那一段很长的系统级别的prompt被我缩略，就是收收起来了。在这个地方有一个system的一个content，然后这个role content其实就相当于用户的输入。那真正能欠去调用GPT3.5或者GPT4的时候，其实也是维护这样的一个message。这个message就跟我们看到的playground的这个一样，所以它其实也可以维护多段，就是多你把原来的第一个样例留在这儿，然后直接给他发第二个样例也行，不过就是有点花钱，没必要。
	因为我们的这个生成的示例，其实只要把system role给设计好，后面的每一次都替换这个user去洗数据就好了，所以我们其实实际要做的时候，只需要把这一轮我们要什么内容传给他，就是我们看到的human message传的是这一轮的一个role content，一个原始数据给到他，然后调用一下。调用就是通过这里的。GPT3.5这个能券关于GPT3.5的一个抽象叫做chat。Chat把message传进去，它就可以相当于获取到这个GPT3.5的回复了，放到了AM message里面。通过这样的方式，我们可以生成第一条训练数据的样例了。当然除了能欠OpenAI，自己的SDK也是可以用的。如果有的同学他你不是这个排行背景，你又不想去折腾南迁这么一大堆的事情，你就简单装一个OpenAI的python的包，那么这两行代码就能完成这个调用了。然后这里这个message可能就等于你手动的去维护这么一个数组，他们底层实现的这个原理是完全一样的，都是去发起这个HTP的请求。
	好，第二部分就是AM message就回来了，我们要怎么样去解析它，就像我们刚刚在在ChatGPT的回复里看到的，他回复了有一个content，有一个summary。但这个如果我们写代码来处理的话，你会发现它都在一个长的字符串里。那这个长的字符串我们还是需要去对它进行分割和处理的。尤其是如果你的这个应用场景里，不是这个content summary，那又怎么办？这部分代码，其实就是咱们今天看到的绝大部分数据处理代码，都是由ChatGPT生成的，不是我写的那我们只是把需求告诉他。
	像这部分代码也是一样，我们告诉ChatGPT现在我们要把这部分代码给它解析出来，把content放到了content的这个变量里，把summary放到这个summary的变量，就是两个字符串的变量，就是把一个字符串拆成两个。那拆完之后通过这样的一个简单的一个分隔符的定位，我们就能猜出来。猜出来之后这里就是content，这里就是summary，这就俩猜出来了，相当于把这一整段我们这看到的AM mesage content是回复的一整段，就给它摘出来了。如果咱们的示例里要换的列，要去换这个列的名称，你就去改对应的，改一改就好了，并不复杂。那解析之后，其实接着我去把我的猫关一下，稍等你。
	不好意思，太吵了。刚刚那一部分的流程，其实我们把以现在的GPT为中心的前半部分给做完了。我不知道大家看这个图有没有感觉，就是我们基于现在GPT去合成这个训练数据的话，第一部分是找到了一个数据源。数据源里面我们摘了一个片段，这个片段基于我们刚刚的system role和我们的这个user。其实这个from就是system里面的prompt，原文片段就直接给了这个user的prompt，就把这两个部分直接给到了一个GPT3.5 turbo 1106这个版本的模型。
	那给到ChatGPT之后，其实它生成了这里的一条数据样例，并且我们还做了一定的解析。下面其实是对应着咱们在代码里面的一些抽象，包括文件的抽象。只不过这个road data TXT我们还没去做，我们这个原文片段其实就从这里摘出来的。然后这个data simple就是我们的一条数据样例的这么一个抽象，整体的这个流程，其实下面的这些抽象跟代码是对应起来的。
	大家如果有一些对python不熟悉的可以看一看，那么这个流程至少一条样例跑通了，我们先不管怎么怎么自动化，一条样例跑通了。但这一条样例有一个巨大的bug，就是大家发现刚刚的这个content里面的内容过于简单了。我们我们这节课是假设大家已经会用q lora和PFT了，所以我们重点讲数据。如果这个都还不熟悉的，要回去看一看。
	现在这一条数据太简单了，就像我们去训练广告生成ADG这个数据集的时候，它就是一个井号，然后一个tag。井号一个tag这种模式，它的这个或者说这种模式太强了，它不像是真正一个跟人交流对话的chatbot的这种模式。所以我们需要做的事情是，第一就是我们知道summary可能不用怎么改了。因为我们现在也没太多的资源精力去润色这个summary，但我们可以优先让这个content变得更加的多样，让用户真正提问的时候能够一定程度上命中我们的content。这个描述，这个命中不是指刚好一模一样，而是指他的讲话的方式，提问的方式。
	那这里我们就要回到这个第二部分了，就是用ChatGPT来合成数据。第一步叫做自动化，自动把原始数据变成一个训练样例。第二步就是要做数据增强，就是怎么样去构造多样化的这个提问方式。这个我们一样可以借用ChatGPT的能力，就我们今天这个事例里面一部分是用的GPT的API来自动化的生成，还有一部分是通过ChatGPT，这个也是免费的。如果大家没有这个API的访问权限，你就麻烦一点，你就手动跟它多轮的去聊也行，或者你就用ChatGLM，或者用任何你能访问的大模型来来生成数据，那么这里我们就会给ChatGPT来提问了，就是左边这这个左上角我们有提到的，实际用户提问的时候不会直接说这个梦话，对吧？那么你要给出20种可能提问的方式，然后将这20种提问和原来的这个summary，有没有一个summary的变量，分别组成一共20条的记录，然后写到一个特定的文件里，最后我们换行，一个强制性的prompt，叫生成对应的python的代码。
	这个是我发现最近OKI把tools的功能增强之后，包括这个code interpreter，就代码解释器这个功能上线之后，它应该是训练集的这个比例发生了调整，在老一点的这个GPT3.5版本上，你如果去让他做一些像生成python之类的事情，它会很自然的直接把代码给你生成出来，就像我们右边看的这样。但是如果咱们是这个plus的用户，然后能用这些code interpreter之类的功能，这个地方大家需要可能会感受到它的变化。因为在code interpreter的训练方式里就会有大量的工具调用。
	就跟我们讲的AI agent一样，他会认为你是在让他做一个python解释器的行为。就相当于他是在运行你想要干的这些事情，然后直接给你一个最终结果，而不是给你生成代码。这是我们我自己能感知到OpenAI的训练集变化带来的一些from的响应的不同但这个扯远了，那么收回来。所以咱们在用的时候，一定要把这些，尤其是你给的prot prompt的末尾，一定要是比较强的要做的任务。
	所以这里能看到他给了一些描述，比如说这个代表什么？含义是什么？请解释一下是什么象征，深层含义是什么？有什么联系，讲述了什么？是怎样的一个卦象，怎样表达教育的概念、基本意义，然后代表了哪些方面，涉及哪些哲学思想。
	这种套路我觉得大家是可以值得去学习的，就是用GPT来帮我们去思考实际使用场景，尤其是如果你本身你的使用场景里面，你的数据你是有一些FAQ的。就像相当于客服或者这个售前售后的场景，销售的场景，都会有一些用户最关心的提问。你甚至就可以直接把这个作为few shot给到GT4。然后你说参考这些提问方式，然后来给我生成一些类似于模板的东西，这个模板就能被我们进一步拿去，给其他的数据样例做数据增强，这是一种比较常见的数据处理方法。
	我们看到右边就是TIGPT生成的代码了，他先给我们描述了提问的例子，右边生成了对应的代码，它的这个summary，因为他他得把这个代码运行起来，所以给了你这个示例。然后提问方式，然后新建一个文件，叫这个data set点CSV，然后写进去。并且因为他知道是中文，用了UTF8的编码，比较贴心，也写了这个标题。行，然后也给每个提问写到了数据。行，通过这个方式我们就能成功的运行了。这部分代码我也保留在了notebook里面，大家可以去玩一玩。
	好，那么有了这部分，其实你就会发现原来的一条样例就变成20条样例了。所以我们看到这个图比多了一个变化，数据样例从一个变成了多个。下面从content summary变成了一个content summary pairs，就变成了20对CS，这20对CS其实是这个20也都是可以改的。
	然后提问的方式模板我们甚至都可以去手调的。就像我说的，让他来让GPT4来帮你生成这个提问的模板。或者你借用之前公司FAQ，或者你的使用场景的FAQ，来做模板都是可以的。但无论如何，这就是一个数据增强的手段，非常常见。
	我们接着就要想问题了，这是原文的一个片段，然后变成了一个训练数据样例，让我们增强到了20个样例。那如果我们原文有20个片段，或者有100个片段、1000个片段怎么办？那我们我们这个时候刚刚的这一套操作，就需要再用一套代码把这条线能够循环起来，变成一个自动化的生产训练数据集流水线的一个代码了，这个逻辑也是很顺畅的那我们想象一下，现在假设这个row data TXT这个文件是现成的，就相当于数据源是现成的。已经有人帮你把数据从互联网或者从公司的某一个服务器上，考到了你的一个文件里了。我们从这一步开始，至于这个文件怎么来的，我们可以待会儿再去探讨。
	现在有一个row data TXT了，接着我们要开始把一个row data的TXT里面的所有的样例，从一个样例变成这个文本里的所有的样例，都按照刚刚的这个套路走一遍，自动化生成，我们看看怎么做。假设这个就是row data的这个TST文件，这里我是把这个做了一些截图，可能字有点小，大家在githa上面我都已经传上去了。大家可以看一看，这个其实就是从公开的互联网上复制粘贴的一些内容，包括原文这个相约，就是相传是孔子写的，给周易做的综述性的论文。大家如果有兴趣研究孔子跟老子的学说的话，就会发现他们也写了很多跟周易相关的文章，然后还有白话文的解释，包括湘瓷，还有一些后代的一些像北宋的邵雍，台湾的付老师，包括一些端一天机之类的一些描述。那这些描述其实你就可以直接复制粘贴下来，然后这些复制粘贴下来之后要怎么样去润色，变成一个summer，可以交给GPT3.5或者GPT4它来完成，甚至格式也是由它来完成。
	那么有了这个原文，下一步应该怎么做呢？我们继续让ChatGPT来写代码，就是我们告诉他有这样的一个row text row data的这样的一个text文件了。我们告诉他你要处理这个文件，对吧？你会观察一下每一个数据样例都有很多行的文本，因为我们在python里面，你去处理这些字符串的时候，换行符是一个重要的分隔服务。但是刚好我们的这个数据它又是多行的，它跨行了，那怎么办？
	一种比较常见的做法就是你自己在生成这个road data TXT的时候，最好有一个明确的分隔符。最不明确的就是我现在给的一个样例跟另一个样例之间隔了一个空行或者多个空行都有可能。样例内部不要出现空行，这个应该是人话应该能能描述的足够清楚了。那我们刚刚看到的所有的样单个样例内部不要有空白行，那么我们就告诉他样例间的分隔符是确定的一个空白行。那么现在需要让它生成代码，从这个TXT文件当中解析所有的数据样例，然后保存在一个叫做role content data的列表当中，然后给了一个原始数据。这些都是我们在理论课里学过的。然后大家如果学的好，其实这个prompt就是我们教的这种使用方式，对吧？
	下面就是给他的一些feel short了，然后我们能看到现在GPT很很好的生成了这样的一个代码，row content data是一个列表，原始是一个空的，它需要去打开这么一个row data text的这么一个文件，编码也是UTF8。然后打开之后，它在读的过程当中，使用连续的换换行符作为分隔符来分割文本。这个就是我刚刚提到的要求，有一个空白行。因为正常你换行下面是内容的话，不会出现两个换行符，所以通过这个就把每一段都摘出来了。摘出来之后，他还会去移除一些额外的空白字符，然后再移除之后，如果有一些非空的样例，那么也就能够被搞搞搞得年轻，就会被被删掉。
	这个是为了避免我们在造这个row data TXT的时候，如果你不小心多敲了几个空白行。比如说本来是只有一个空白行做分割，你敲了十个对吧？那按照这个代码，它就会把一些空白行当做一个data simple。但这个data simple是没有实质性内容的，所以通过这个strip方法就能把它的这个额外的没有意义的空白字符给移除掉，这是这一段代码考虑的比较周到，我自己写可能都不一定写下面这个处理逻辑。所以这个还是GPT igbt做这种胶水代码，数据处理代码是非常好用的。
	所以现在这种类型的代码我几乎都不太会自己写了也希望大家能用chat FT来生成代码，这样我们的代码质量平均质量都会提升。那我们实际运行一下，看他能不能用。左上角就是我们把那段代码给移过来了。移过来之后，下面有一个输出结果验证的部分，就我们把这段代码运行之后，打印一下样例，这个emerge是pya python里面的for循环，循环的时候我们去取取5，本来它生成的是五个，我这就打印了这个三个就好了。
	样例一，然后用这个短横线去做划分，我们看到样例一，然后右上角我不知道这看不看得清楚，右边这幅图的最上面有一个短横线，分割出了样例2。这个样例是我们打印输出的，在在他解析的内容里没有，是用来做分隔的。样例二样例2、样例3，这个应该算是做的非常好了，很到位了，可以用的。那么就我们目前的这个原始数据，用这样的方式至少能把原始我们要用的内容，就是我们开始给GPT4的user要传给GPT4的user里的内容就提出来了，提出来之后，我们实际情况有没有这么顺利？肯定没有，对吧？
	大家做过菜的就知道，一定没有那么顺利。买菜菜有可能是有烂叶子的对吧？洗菜的时候可能又洗出一些烂的，然后实际切菜的时候没切好，改刀还会造成一些废的废的一些菜或者肉，你就没法做了边角料，然后甚至还会切到手，是吧？有各种各样的问题。所以实际的数据处理一定会遇到问题，就比如说我们这儿会遇到各种各样的问题。我只是尽可能的在想模拟想象一些大家会遇到的问题，所以我训练了三个模型，也造了一些不同的数据，就是尽量把这个出错的多样性给大家枚举出来，就包括这个system的这个prompt，一开始我也没有专门去要求格式，果然就会出问题，怎么出问题呢？就是咱们刚刚看到它运行一个样例的时候很成功。然后这一个样例它也给我们造了20个模板，能做数据增强。
	数据增强的环节其实是不需要GPT4来参与了。因为模板给了之后，替换一下这个content的这个关键词就好了。但是我们会发现，让它去生成多个样例的时候，就开始出问题了。比如说这三个就是我摘出来的，摘出来第一个部分content蒙卦，summary蒙卦。然后下面就是出现了一个不该出现的内容，比如说叫做这个interpretations，就是GPT3.5，他自己又加了一段内容，这个内容是不该出现在我们的格式里的。
	如果我们不去做处理，就会出现一个什么事儿呢？就是content没有问题，还是这个content，它的模板20倍的这个数据增强也都还在这儿。但这个summary的内容就会变得比较诡异，那下面这个就更更奇怪了，我只截了一部分它这个content，然后里面还套了一层，这些其实你要去揣测的话，都应该是GPT为了增加，为了实现这个code interpreter和这个function call带来的一些问题。因为它就得模拟，包括他去造这种结构化的内容和输出这就是大模型所谓玄学的部分了。你没有办法确定性的给到一个输出的结果，只能去调这个prompt。
	包括下面这儿，我们看到content，summary，又来一个summary，这summary出现两边，然后我们在前面几周的时候，其实原理的上原理上跟大家分析过，就出现这种情况。就是因为他最终的这个summary和这个content的这些内容都是一堆向量的运算的结果。然后我们也给他了一个max token，然后也给了一个额外的参数，有一个阈值。然后他在计算过程当中，这背后其实都是一堆logical。那堆logic被解码回来就变成我们人看得懂的内容了。
	然后如果我们给他的这些提示词，刚好触碰到了一些他训练集里面的关于这个结构返回，或者关于function call，关于tools相关的一些训练级的一些内容，它就会响应成这个很奇怪的现象。除非我们在我们给他的prom再强调，所以这个生成格式不稳定的问题，我相信大家去把这个量提升起来之后，或者说你去换了不同的数据集让它去合成，让他去增强之后，有可能也会遇到。但我们给出一个参考的解决方法，怎么做呢？其实跟应用开发课里讲的很多内容有关，就是这个prompt engineering或者说prompt template相关的一些做法是有关的。因为训练基地也在用prompt template，我们在在讲过这个chair forts，包括这个chair force的作者杰森卫，现在也在OpenAI，就是我们现在看到的很多南券的这些模板能够有用，能够被很好的执行。
	它就是一个像DNA双螺旋一样的一个状态。就是一开始的standard prompt GPT3出现的时候都不知道怎么样写这个prompt。然后我们会发现，GT3自己提出来了有standard prompt，然后后续发现了有chair sorts。然后也因为chaf sorts对于我们的这个GPT也好，对于其他的大模型也好，是有效的，能帮助它生成更多内容。所以这些好的提示提示工程，提示模板的这些用法，也都会进一步又回到大模型的训练集里去。所以我们现在去用一些你在人群里面觉得比较好用的提示词模板，用到跟GPT直接去沟通大概率也是有效的。
	比如说我们这里看到返回格式上的要求，我们让他明确这里写了content，挂名，这个其实就是一个典型的template的一个描述方式。我没有再去写期待，结果是有一个具体的名字就没有跟这个事例对起来。而是说我在最后加了一个返回格式的要求，相当于我们原来的这个system的这个提示词，就又增加了一部分的内容。而这一部分的内容，现在南茜是这么去设计的，assistance的API其实也是这样去设计的，相当于它的这个三段式变成了任务的描述，然后feel short或者one shot，最后是你的output的这个poser，或者说叫做response format。This open I assistant CPI的一个描述方法，在能源里面叫做output puzzle。
	就是我你要让我干什么，你给我打个样，然后你最后要求我给你的这个格式是什么样的。这样的一个三段式。通过这样的一个方式，其实亲测是有效的，我们把它改完这样的一个prompt之后，我们就会发现它的生成结果就基本稳定下来了，就不太会再出现刚刚说的这种情况它也是一个content能够提取成功summary，能够把它原来用户给的内容给总结好，然后不会再额外出现一些奇奇怪怪的内容，最后我们能够把它存下来，存到一个CSV文件里面，我们能看到这个CS文件里面是这个content。各种20个不同的模板。但实际去训练的时候，肯定不会说这个batch里全部都是一个挂，因为我们会打乱，会瞎否。然后右边是它本来的这个summary的一个结果。
	好，那到这儿其实数据的处理就我们就讲的差不多了，接着我们再看一下如果要去实际去做训练的时候，还会发现什么问题，以及你真正在做这个训练的时候，你有没有这个信心，或者你有没有细心去找出来它的格式问题。就它返回格式这个问题是怎么会被发现的，其实也是很有意思。如果你有经验，今天我是在在没有改这个格式之前先训练了一版。然后训练的时候发现这个loss值的变化有点异常，反过来一看，果然生成的训练数据是有问题的，这个我们待会儿可以再去细看一下。
	使用这个q ora来进行训练，训练的过程当中，因为我们可能会用不同的超参数，会把一些重要的超参数放到模型的目录名目录名称里面，也方便我们去查找，这也算是一种行业潜规则了。所以我们除了这个模型本身的名称以外，我们在后面加了两个，一个是这个a poc就是我们用了训练了几轮数据，第二个加了一个时间戳，因为有可能你的数据改了，然后你的这个a poc没有改。所以这个时间戳其实来自于训练集生成的这个时间戳，然后我们看到右边的这个loss变化其实是一个相对比较正常的一个loss变化值，就是从这个4.67最终一路下降，然后很多同学问什么时候算训练好了，我们看最后这个是step对吧？而不是我们看到最后的这十个stamp，其实几乎已经没有这个大的变化了，都在0.004左右，这个loss就算是差不多了，你再训练大概率也会过拟合了。然后这个训练的这个超参数里面，因为用的是T4的这个显卡，16GB的显存，所以base size可能最大也就是到8，如果再大可能就显存不够用了，然后我们可以再做一个简单的对比，就是前后的一个对比。右上角这个我写了一些细的参数，标题大家可以注意一下，在代码里也有。这个版本其实是手动造的一个数据集，还不是我们刚刚今天课程里讲的那一套自动化的。
	就相当于你手动把这个road data，就是我们一开始讲的很繁复，然后很效率低，还容易出错的做法给大家打了样，做了一个手工做的这个数据集。也传到了github，大家可以去看一下。我们对比的话，在微调前和这个微调后，这个是用了50个apple完全过拟合了，给大家看一下过拟合是一个什么样的状态。那过拟合之后，其实它的这个输出应该这个截图可能是有点问题的。他应该会完全复刻咱们的这个训练集里面的那个summary，这个是完全有可能的，待会我们可以实际跑一跑。对，然后这个就是跟这个训练集里几乎一样了。
	然后还有一个就是我们说的训练集这个有问题。因为我们的返回格式的问题，造成数据增强之后，我们的训练集可能也有问题。这个其实就对应着我们这里看到的三轮的训练迭代，然后是自动化生成的数据集。然后这部分在在这个输出结果上还看的不明显，我们换一个输出结果就会发现就很很有意思。就比如说讲道理，这个周易中的这个送卦是什么卦象，应该是咱们训练集里有的内容。我是试了一下，那么这里就出现了一些很奇怪的生成，什么时运解卦发了一大堆。
	这个就是你从训练完之后，你再来做测试的时候会发现的一些异常现象，跟它的loss值也不太匹配。就讲讲道理，如果loss值已经降到了0.00几之后，它应该是快能够去复刻你要说的内容了，尤其是你给的这个输入跟这个content几乎一致的情况下。但他没有，那就只能说明可能他当时的summary就出问题了，就是训练集里就出问题了。
	这个也是能比较明确的反映出训练集问题的一个特征，那么这个fix的就是指我们把返回格式这个问题处理好之后拿到的一个结果。然后这个结果几乎是跟我们想要的这个描述是很像的了。然后他说的也都是相对来说是正确的。那我们接着就来细看一看，看看怎么做的。
	一个一个来，我们把今天这个实战的内容，大家可以有问题也多提问。我先把最重要的这个部分讲完，然后我们再来针对性的提问。今天的代码已经提交到github了，所以大家如果还没有拉取代码的话，及时的去做一下代码主要是这里能看到更新时间，主要就是一个是生成数据的，一个是训练模型的。然后这里训练模型有两个，一个叫kora 7IGM3，这个是在我们的有问题有返回格式问题的数据集上训练。因为留下了这个输出的日志，落实变化的日志。稍等一下。
	网络没有问题，只是刷新了一下。
	这个QLA77M3没有加这个时间戳后缀的是用的返回格式有问题的数据。所以大家能在这里看到那个loss变化的一个情况，待会儿我们也会看到。那加了时间戳这个就是修正了返回格式之后的一个训练集，然后训练出来的一个结果。
	好，我们回到这里，这个就对应着它的代码。我们先看一下数据的生成，这部分怎么做的。这里我列了一下整个关于数据这个数据集的构造相关的一些主要步骤，然后这些主要步骤里面也有一些参考，这些参考是可以直接点开的，就比如说用GPT3.5去生成这个基础数据，这个playground其实这已经点开，不这个地方。还有就是用ChatGPT去生成代码之类的，这部分其实就在这儿也提前打开了，大家应该都可以直接访问。好，那我们还是回到这儿来然后用OpenAI的HDK来调用ChatGPT a来调用GPT的API也留了一部分的代码，然后大家如果有兴趣可以试一试，然后这种代码要怎么来实现在代码的生成都不复杂了。在这个playground的界面里面，大家可以看到这个view code，就可以直接生成OpenAI的SDK的代码。然后如果你是一个node JS的同学，你更喜欢用node JS，也可以在这儿去做的一个版本的代码。但这个不是我们最推荐的使用它的方式好，现在我们先看一下就是怎么样去构造这个训练集。我们回到刚刚讲的这个过程里，第一步其实就是要去构造一条数据，这一条数据我现在重新启动一下。
	关掉，重启一下。
	好，运行起来了。这个警告大家可以先忽略一下。然后这三个参数其实他现在没有用了，但这个难劝的这部分代码无伤大雅，因为这几个参数也不是最重要的，那么我们看到这个用能欠去调用GPT3.5 turbo 1106，其实跟这部分是对应起来的，只是大家用了不同的的实现方法，我们把它先收起来。然后这个system content其实就是我们开始讲的第一版，怎么样有这样的一个描述，甚至示例的这个输入其实才是role content。大家如果有印象的话，就这个部分其实才是我们从原始数据里捞出来的，就是我们看到的这个里面。
	这个其实是我们原始数据，但这个原始数据可能跟我们想要润色的这个效果还有差距，所以我们才会有一个期待的结果。然后这个期待的结果其实是来自于我们的ChatGPT。
	我看一下有没有，那可能那个页面那一个对话是在另一个对话流里。其实就是这一部分的翻译是由ChatGPT来生成的。这个大家可以去试一试，就你直接把这部分的前面的这个命令交给ChatGPT，然后把你的role content也交给他他会有一个翻译一样的这种说法。然后这个翻译的说法，现在就变成了我接下来要去调API的一个one shot，就是一个参考示例。然后我们可以来实际运行一下，就有这么一个system的一个role了。然后这个是原始数据，就是我要去让他帮我洗，然后去生成的一个数据，这俩是不一样的，这个比较明显，content能看得出来，两个不同的描述卦象。我们生成了这个message，然后这个message再通过check方法去调用我们的GPT3.5。
	调用之后，生成了一个结果。这是它生成的结果。就我们刚刚看到的这个结果里面，它确实把这个返回结构也做成了这样，就我们期待的这样的一个结果，有content，有summary，中间有一个换行这个结果其实我们还得再对它进行处理。就是这里讲的你把这个一长字符串切成两个字符串，所以我们使用了咱们这个ChatGPT给的代码，这些代码包括它的prompt其实都流到了这个示例里，我们让他这个是开始有一个报错，让他找其实是因为换行的引号的问题这个就是我们开始让它生成第一段代码了，大家可以看到这部分，就跟我们刚刚拿到的结果一样，这份代码我们让它生成一个python的代码，实现将这个里面的字符串从这个content summary作为关键词解析出来，然后使用对应的变量名来存储，这是它生成的这段代码。这段代码其实就是我们刚刚考过去的代码，就是我们这里能看到的代码。
	这个模式是大家回头可以去在自己的数据集上，按照这个流程去复刻的。就你自己是什么样的一个原始数据，你需要让GPT帮你变成一个什么样的数据。样例的格式是，然后这个格式从AM message content里面拿出来，要怎么样去做分割。你也可以告诉他你的关键词也好，你的分割符也好，是什么样的，让他来帮你去做这个分割。那我们再执行一下。看一下text . 
	AI message . 
	content，sorry. The mary draft. 在周易中summary男士summary。这是一个什么样的bug？为什么会出现这个玩意儿？3、mary猛瓜content。Air message content start find content, just a length content. 
	我看下。是有点脏了，这个比较神奇，猛化找到了这里，然后分割符找到了换行。我有。
	一些。
	小的bug发现很神奇。可能是这个分隔符它有问题了。因为他这儿把这一部分的这一部分也拎出来，当成了一个需要单独处理的文档。然后这里刚好又没有这个多余的引号，然后又解决了这个问题，这个是比较扯的一个小bug。
	这个就是我们在数据处理的时候会遇到的各种各样的很恶心的问题。不过好处是说，第一就是刚好就遇到了，相当于什么意思呢？就是我们在这个事例里面因为返回结构没有做的特别好，它就是会存在。有的时候是刚好这个分隔符达到我们想要的这个发挥结构，不会有一些多余的引号之类的，然后就不会出现这个分割出现问题。但是就相当于你的第一次运气特别好的话，就会发现不了这个分割的，这个分割的时候就会暴露不了你的这个返回格式的问题。但刚好我们这个运行的刚刚演示的时候，运行的那个返回结构就出现了一些问题。所以刚好在这儿解析的时候，就会暴露这个问题，这算是比较幸运的，就暴露这个问题反而是比较幸运的。
	因为暴露这个问题你就会发现这个地方的返回格式跟你预期的结果有一些变化了。那你可能就会在这个早期阶段就要去调整这个system的这个prompt。那么我们先跳过这一趴，就假设我们可能运气比较差，然后它生成的结构也是比较稳定的。我们先往后走，先把单个样例给捋明白，那么生成的这个结果我们从content和summary里面找到了。
	找到之后我们开始有题需要去把这个数据写到一个可以用来做训练的文件里。因为最后真正chat m3去用q lora来做训练的时候，也是加载文件来进行训练的。那我们同样的可以让ChatGPT帮我们去生成这个写入文件的代码，像我们这里提到的，生成这个python的代码，实现的这个功能就是第一新建一个文件，第二就是将前文分割出来的每一段按顺序写入这个文件里。所以这里ChatGPT实现了对应的代码导入python的这个CSV的模块，然后使用这个CSV的writer来写这些对象，其中就包括这个标题行和数据行，然后这样的方式其实就能往咱们的这个这里咱们的这个可以运行一下。
	我这里应该已经专门分割出来了，这个文件我没有上传。因为这个是让大家来做这个试验的这部分代码，下面有完整的代码，这个我先删掉，这下午生成的这个。或者我们取一个简单一点的名字，叫做test的这个dataset。这个是我们刚刚生成的test dataset。
	有个同学问是不是必须是content of summary？不是，这也是我们刚刚拿到的一个结果。就是从这个流程我们再再跟大家讲一遍，有可能有的同学不一定全程在在听着，或者后半段后半程进来的。这是我们通过跟GPT3.5调用之后，然后又解析之后拿到的结果。然后再把解析的结果给他写到了一个CSV的文件。后面我们训练q ora也是用CSV的文件写进来了。但这只有一条样例对，甚至这一条样例它还没有做数据增强。
	我们接着再看做数据增强的部分，数据增强要生成不同的提问方式，同样的我们基于这个ChatGPT的沟通来生成对应的代码，一步一步的这两边其实是一步一步在这个工作，那个notebook就是这么生成的，然后这个notebook里面的一些核心代码也都是GPT写的。就像我们这接着在问了，他已经生成了。但是我们就问他实际用户提问的时候，要给更多的这个提问方式。然后我们看到他描述了20个模板例子，然后也给了对应的代码。但是比较调这个是经常让在GPT生成代码的时候会出现的一些情况。就是有两种场景大家需要注意。第一个让ChatGPT生成代码的时候，如果他前面描述过这些模板，他有可能在后面的代码正文里是没有的，这个是需要咱们去注意的。第二个就是说如果你让它生成一些复杂代码，或者说代码量比较大的时候，他自己的你可以理解成他用了类似于我们前面讲的nation memory的功能。
	因为他自己的token上限有限，所以他通过其他18个问题这样的一个描述，在它的这个大模型内部的上下文里，相当于就映射了这一堆token，它就不用那么多token的拿去计算了。如果我们要生成复杂代码，比如你让PT写了十个函数了，然后你说现在这十个函数要某个函数要怎么样去做调整？它也经常会出现这种缩写，就是直接一个注释写原来的那个函数，然后下面一个注释写跟之前保持一样变化的只有这一部分，就跟我们用gate的这个diff一样，它只会把变化的部分拎出来。所以在这儿我们一开始直接call过去的时候就会出现问题。如果不细看的话，这个模板就会有问题。所以我们当然得告诉他第一这个模板里面的这个question，我们要给它改成这个蒙卦是可替换的，不是一个写死的，变成一个模板。所以我们告诉他这个question列表当中的这个蒙卦是一个可替换的变量，不是硬编码的字符串，这样才能扩展我们的数据样例做增强。所以这地方这样的prompt是比较好给ChatGPT去做代码生成的。
	就是你明确告诉他，就像你让他做出文本处理一样，你告诉他你需要定义一个函数，函数的入参是什么，返回结果是什么这里我们就写到了入参是content和我们从刚刚的这个一段样例生成解析出来的这个阶段拿到的两个结果。一个是content，一个是你mary。返回是20对待写入CSV文件的数据，然后我们让ChatGPT来生成对应的patent代码，生成了一个函数的入参，content summary，给了这个注释内容内容的总结，返回的是20对提问和总结的列表。这个地方他同样做了省略，即使他省略的这个数量不一样了。
	15个模板，然后这个模板巴拉巴拉代表什么，其实就把我们刚刚的content蒙卦的这两个词给替换掉了这有一个示例使用，它会保证他给你的代码你是能跑得起来的，所以它通常会给示例使用。然后这我们就会发现有省有缺省，所以我们需要强调在pyper代码当中给出完整的模板，这里就会给出完整的模板，这部分代码是我们可以再去做调整的。刚刚也提过，并且也不一定是20种，完全取决于咱们自己的一个情况。然后把它拎出来之后，这里就有一个完整的python代码了。这部分的python代码其实就是我们下面看到的这部分的python代码，生成20对提问和总结的配对，那我们来执行一下。咨询一下，然后这是他给的一个示例文化。
	然后我这边也有给一个注释，如果咱们的同学没有办法用GPT的API，那么首先你可以用ChatGPT。如果你非用ChatGPT，那你能去造这些数据的无非就是手动跟自动的区别。然后如果你这个年轻人GPT都没有，那至少这有一些事例的这个字符串content和这个summary，那我们就用我们解析的，就不用他实例的了。然后这个pair其实就是把这个content和summary传到我们刚刚用ChatGPT生成的这个函数里，generate question summary pairs, 返回的是20对question summary pairs，最后我们把这二十对写到了这个CSV文件里。执行一下，这儿名字没改，还是给它改成test，不跟里面重复了。它会刷新这个我们就删掉了，这个跟里面的正式的训练集名字一样。我们看下这个。
	没刷新，刚刚应该是就pat lab的一个缓存问题这是我们生成的20个模板，大家能看到成功的替换了里面的content，然后summary是不变的。这个按照我们刚刚的逻辑，它生成了20个不同的提问方法，做到了数据增强的效果。好，我们接着看啊，这个流程是一条数据样例。然后我们刚刚有提到，我们希望能够完成整个原始数据文件里面的这个样例，全部都按这个流程来做。那怎么办呢？这个原始数据来源，这里有做一个补充。就有的同学如果想要去做更多的事例，在我现在这个数据集上做更多的事例，我现在只取了很少的一部分，但你如果有这个方面的爱好，随便找一找，这只是我上网随便搜的，也都是公开可查的一些文件。然后我们的训练的原始数据，就来自于这样的一个部分，他的这个编号也很好做。如果有这个爬虫能力的同学，就会发现这个UIL是很好处理的。如果你非要去做这个自动化原始数据的生成，41034104。
	他不让我们这么改，不是吧？试试。我印象中它是可以，提前有打开，观察一下它的UI，410341054111，它不会是这个基数？1009，这不都有吗？神奇，但这个UIL这个规律应该是可找的，有可能刚好4104没有，我们找个什么4107是肯定能跳出来的。
	这肯定可以，那刚好可能4104没有。也许是这个网站的运维人员对这个四有什么奇怪的见解。对，这个其实简单来说就是这个也是是想告诉大家，如果咱们要做爬虫，然后这个爬虫应该还是比较好做的。类似的一些网站应该也都能搞。或者你自己也有这个数据，都可以通过这样的方式来扩展你的原始数据。就是这个部分，这个是可以去做扩展的，甚至你可以把它关于每一爻的解释也都能拿得到，就看咱们自己的一个实际最终的应用了。
	通过这个方式我们有了row data text t，然后有了row data text t之后，我们也让ChatGPT来对原始数据进行处理。我们开始课件里有写到的要处理这个原始数据。然后这个原始数据我们之前只处理了单条，这第一条样例是我们刚刚的整个流程里面的这个数据样例，现在有很多，其实是八个八个数据样例。这个八个数据案例要从TXT文件当中解析，然后并且获取SSH断了重连一下，要从这个地方获取，所以我们告诉他这些prompt还是大家可以去看一看的，挺挺有意思的，如果能能值得借鉴，可以去看一看。然后这个地方，我们让它生成python的代码，继续生成python代码来处理原始的这个数据的文件。然后把这些数据从原始的这个数据文件里面加载到python的字符串的列表当中。这就是我们的real content data生成了这样的一份代码，这个代码可以用来进行这个数据的一个处理。好，我们可以回到这个部分执行一下，很快运行完了，可以看到它的样例提取做的很成功一共应该是生成了811共应该是有八个样品。我看它打印出来12345678，就这八个样例，就是我们从row data text里面提取出来的，每一条都应该去走一遍我们刚刚说的这个流程，就是怎么样去做这个样例的提取。
	好。接着我们就开始考虑了，就是这个循环自动化的这个流程要怎么样去做。这里我们把之前上面的这些模块，我们整合了一下。第一个就是要去整合这个调用GPT3.5的这个部分，做了一个生成数据的金data这么一个函数。就把刚刚的这部分调查的逻辑放到了一个函数里，这样方便我们在主函整个循环的主函数里面去去调用它。然后这个roll content之前我们是手动复制了一段，现在就是对应着我们这里提取的每一个样例了。Row content data里面的每一个样例，我们都需要被传到这个金data里面，然后来进行润色生成，那我们进行执行一下。当然这个进data大家可以想得到，肯定也是ChatGPT生成的代码。
	好，然后我们来做一个示例的调用，其实也没必要，我们可以直接来调用了。对，这个其实就是拿我们的第一条来做调用，这个肯定能用的。接着我们讲，就是要把这个返回结果从这个AM message里面提出来，做了一个提结果。好的，我们也把它放到一个函数里，data set part里面，放到一个函数里来执行一下定义。好啊，这也有示例调用，我们就不示例了，来直接跑一下这个代码。
	然后我们接着让这个ChatGPT再生成一个主函数的代码。这个主函数的代码顾名思义就是要完成整个循环。就现在我们是八个样例，那可能就会循环八次。如果你有1000个，那你就循环1000次。如果有1000个人，然后你都需要用GPT的API的话，那就更需要在早期的时候用小的样本数量去试一试。第一个是试一试你的prompt稳不稳定，会不会生成一些没法用的数据。第二个就是在这个过程当中，你也可以看一看这个GPT它的这个返回结构，或者一些其他的诡异的问题有没有出现，确保你的prom是相对稳定可用的，那么这里我们就让在GPT继续帮我们生成一个主函数，这个也都在这里的分享的ChatGPT的对话里有啊。就比如说我们刚刚说的gin data的函数，让它去定义了一个函数返回结果是什么，入参是什么，他就生成了这样的一个函数，进data的函数，然后包括让它定义一个data set poser的函数，它也有生成这样的一个函数，然后最后我们告诉他需要定义一个主函数。就跟我们课件里讲的，这个自动化的批量的流程，就是把每一个样例按这个循环来走一遍。
	其中就有提到，第一步是解析原始数据，这个只需要做一次，然后循环遍历从原始数据里面得到的每一条样例，就逐个使用row count的这个data的样例去调用这个金data的方法得到了一个什么，然后又解析这个得到了什么，在调用这个方法，得到了二十多组pair，然后把pair写入CSV文件，就跟我们去写代码一样。这个方式其实就很像，如果你写南茜的temp写的多了，或者你用ChatGPT的prompt用的多了，应该是能很顺畅的写出这样的prompt，你要跟他做好沟通，你定义好你们的对话流里面有哪些变量，这个变量是干嘛的，有哪些函数的方法，最好是它生成的。但是是你是描述这个函数的输入参有什么主要的逻辑，是干什么功能的那它就会帮你生成好这个主函数，并且帮你做了这个分级。
	第一步是解析row data，text文件得到这么一个row content data。第二部分是循环，在这个循环里面，我们再看到它去把这个一步一步去写，调什么，然后解析，然后再调这个，然后再写进去。但是我当时就犯了一个小错误，浪费了一些钱，就是咱们这个流程里没有打印content和summary。如果我要是在这儿打印的话，应该在第一次执行面的时候就会发现content和summary有问题。就像我刚刚手动运气比较这个运气比较好啊，就第一次执行就遇到了问题。但这个昨天的是昨天的时候没有，所以就不知道这个system的prompt有问题。
	好，那么运行起来之后，还有两个小问题，就是这个content summary它是表头，它不需要每次都写一遍，所以他要移除这个循环体。第二他是以为我要把它变成一个点P该文件，所以他给了一个这样的实例，这个也是我们的一个homework，就是把我们的整个生成数据集，就gin dataset的这个jupiter lab这个文件，大家自己把它改造成一个均data set点POI文件。这样就方便你去用python在后台执行，去批量的生成数据了。这个也是可以作为大家的一个homework去提交，那回头我们也会在平台上把这个homework加上。
	好，那我们回到这个部分，就看到它的一个改进，就是把这个content summary标题列移出来了，循环里面没有这部分的内容，那我们可以实际来执行一下。我看在在这儿，然后我手动加了这个print content和这个summary，这是开始执行的一个结果。对，这个是开始执行的一个结果，我们在这个直播之前再执行一下，这个3.5还是用得起的，关于这个钱的部分，我这也有一个链接。
	大家如果比较敏感的话，就是调这个GPT的价格。我们看到我们现在调的这个示例里面调的这个模型是GPT3.5 turbo 1106。它的价格是input是每1000个token 0.001美金，然后这个字是不是有点小，放大一点。然后它的output的部分是是这个input的两倍，0.002美金每1000个token，我们的这个生成差不多应该一条样例，就是差不多将近1000个token，输入加输出的话差不多。然后GPT4大家可以看到这个价格对比，还是很夸张的，应该是30倍，我没记错。对，可以看到GPT4的标准版本不是长上下文版本。Input是0.03，这个是0.001，30倍。没错，output也是一样，0.06等于0.002，所以这个30倍的价差我还是用GPT3.5给大家做的演示。
	如果有的这个同学他不差钱，那用GPT4可能会更好。但是GPT4建议用在不仅是帮你改格式和整合这个段落，而是还能利用GPT4来生成一些他知道的领域。指使你这儿没有的，就像字节跳动干的一样，他们就是拿GP4来照他们自己大模型的这个训练数据，而且是大批量的，据说是调用了几百万还是上千万的投资费用，然后我们在这执行，他这个本来就要花点时间，这个是正在执行，我们看到懵挂，这个执行完了猛挂还出现了问题。
	第一个就出现了问题，对吧？Comment非常全面的解读，reference，还有这个什么，这个就更离谱了，content summary什么云上于天，君子以饮食宴乐，对吧？这肯定就出bug了。这个就是我们刚刚遇到的那个bug，就是它的这个summary这个部分应该是出现了一个不必要的标点符号，导致把这个summary和summary分成了两个。
	然后这下面也是出现了各种奇奇怪怪的现象，包括这里content，interpretation，image等等等等，这些都是一些因为我们的system prompt做的不够健壮，不够鲁棒造成的一些问题，包括这个到这儿为止，其实是站在这个回看的视角看的，就在之前我的训练集里，我其实是没有打印的，大家还记得吗？就我们在这个构造它的时候是没有输出的。所以我下午训练的时候是直接就没管，就把这个有问题的数据集拿去训练了。也就是对应着应该是最早的这个版本，大家可以荡下来搂一眼。应该在这儿一栏你能看得出来。
	在这儿就能看出来了，大家发现这个content就开始出问题了。因为生成起来的有问题，就生成出来的这个解析就有问题。本来这个还挺好的，对吧？从第二个开始就出毛病了，什么重要，不要为表象所惑，巴拉巴拉的一堆问题。下午还比较幸运，可能下午的GPT3.5我运气比较好。撞到的是一个问题不大的。我们再来看刚刚生成的这个应该就问题更大了，几乎全是问题，它的这个生成内容。
	这里就image笔，也不是它的content，是指出了一个问题，就summary出现了很多奇奇怪怪的问题。对，就这儿image包括它的还是荡下来比较好看一点，我们把这两个档下来放到本地看看。
	一个是下午三点的，我们使用上麦打卡，这个是CSV文件表头content summary，对吧？可以搂一眼。这个CSV文件这么打开，大家就理解这个是猛刮，代表什么？是content，这个是它的这个输出，就是是它的这个输出。然后我们能看到里面有一些这种奇奇怪怪的东西，都是它的本来不应该出现的内容，这种奇怪的结构，这样看就比较明显，会有很多问题。然后包括刚刚晚上生成的这个版本。
	我们也能看到会出现像这种东西，并且因为是summary出的问题，summary在数据增强的时候会直接复制，对这个问题就会只要他的summary有问题，这样这一条样例基本就挂了。那怎么样去解决这个问题呢？第一就是真正在做数据增强的时候，可能你的summary也是可以去再做调整的，就相当于不仅对你的这个content做调整，summary也可以去做调整，取决于你的这个应用场景。如果你的应用场景是提问的方式比较简单，但是用户对他回复的这个方式要求比较高，就是得变着方而来说。那这个时候可能你要做的增强部分反而是在summary这一侧。
	然后刚刚还有同学在问content summary是不是定死的？也不是，就取决于你的这个，还取决于你最终要怎么用。像我这个场景，我最终可能是用作就是你聊天，就是问你。所以真正要把这个用起来，肯定会再加一些这个road data然后来用。包括但这个好像是这个比较偏偏这个灰色的也比较灰色，就是不太愿意在显学场景上去讲的一种使用场景。它拔高之后，我相信大部分人能用，并且它的这个概念足够的小众。然后这个小众的概念他去训练领域知识，是更能体现出你的这个训练到底有没有掌握学会的。所以举了这么一个场景。好，我们回过头来看啊，就是这个是数据，我们真正要用的应该是下午某一个时间点，我去你的一个版本，这个版本我生成了一个版本，应该是在四点，我们看一下。
	应该是这一个文件，这个好像是正常的，就调过之后的对，先锁定一下。
	云的恩泽好像也有点小问题，他说这35分钟。
	我这个是大家用合成数据的时候需要去处理的一个必要的流程。它已经相对咱们去去搞这个手动来来生成这么多数据要快很多了。但是他也不可能，这个是有问题的那可能现在下午最好的版本是这一条。4点36的这个版本就是我传到get up的这个版本，但肯定还可以再优化在这里。
	4点36的这个版本，是的，应该就是这个文件，但这个文件显然在在这一条上面是可以再优化的。什么臀挂这个玩意儿。好像说了一些什么这个没必要的。Anyway就是这对这个格式上已经非常的稳定了，没有出现奇奇怪怪的这些reference什么的。然后对get up的这个预览做的挺好的。这个是我下午看过，没有什么大的问题。这个是能支持咱们去跑的，去跑这个QOA微调的。
	好，那我们说回来，就怎么发现这个问题的？就我们没有print，我怎么发现这个问题的？这也是为什么会传两个kora的notebook的原因。
	这里有一个没有带时间戳的就开始讲。我们上面这些代码之前都讲过了，这些大家应该都已经学会了，我就不再赘述了。我们重点看它的这个train过程当中的一个下降，这个大家也都可以做实验。
	大家看这个loss的变化，其实很有意思，正常的loss不会跳的这么离谱，尤其是我用了这个warm up racial之后，大家去看这个loss的变化，从3.59、4.04、3.09、3.38、3.54、2.612.65、3.16。如果我们把可视化出来，它是这样的，前期是非常夸张的，这个就不是一个好的loss，好的loss应该是据此很小，然后呈现一个下降的状态，就像我们看到的用四点钟的那个数据训练出来的一样。我们可以对比一下，这个是没有加那个的，就这俩loss对比起来应该是很明显的，再把它放大一点，大家可以应该能看到，当然了你自己把代码拉下来也能看到，就是3.59、4.04、3.09、3.38、3.54、2.61又到3.16，一直到一以下，就loss值小于一之后才逐步的去收敛。但它的它的波动率是有点过高了。好一点的话大家能看到像这个4.67、4.7、4.27、4.44、3.9、3.69，基本就很快就开始回到一个比较正常的状态了，这都是训练了三个epoch。但是这个loss，左边这个loss就是我发现不太对劲之后，还没有第一时间去看数据，但感觉数据可能出问题了。那么实际看就是出问题了，就是我们对。就是我们开始看到的这个很奇怪的这个版本，我传上去了，看一下，四点钟的三点钟的，应该就是这个版本content。
	对，你看这个content都被拉到这儿来了，这个就是没有带time step的这个版本，大家会发现这个里面的数据比较奇怪，就是可以用来复现咱们的这个loss变化的。这就是没有去调整system的prompt，所以它合成的数据会有一些问题。然后这个问题当中的奇异值，就是大家发现为什么突然有一个step一下子就起来了，大概率就是遇到他了。因为刚好我们的best sign是8，是很有概率遇到一些这样的异常的一些值的，包括这个后面的这个结果，其实它它的输入跟输出绝大部分是重复的，因为它的这个本身合成数据的问题，所以这些都是在就是我说这个训练模型。
	像炒菜一样，只有你炒了100次青椒肉丝之后，你或者十次，十次青椒肉丝后你才知道今天这个青椒肯定有问题，或者今天这个肉丝不新鲜。然后你也才能在学的这个鱼香肉丝的时候，知道肉丝那部分要怎么处理。只是鱼香味你得勤学，就是学这个大模型微调也好，做其他的模型训练也好，就是得多上手去玩。这也是今天这节课准备了大量的，大家可以回头去可玩性比较多的内容。你可以用这些prompt去调整那些代码生成的胶水代码，也可以去调整这个prompt去生成更多的训练数据，还可以选其他的领域，但是用这个套路去生成那个领域的数据。但无论如何，大家一定得去多训练，多实操，才能找到这个问题所在。当然我们实际的反映出来的这个结果，在在loss上能体现出来，在我们的这个influence上也能体现出来。
	就我刚才讲到的我们的微调前后的对比里，这个代码里我们看这个怎么加载QLA微调之后的chat GML6B之前也讲过，这我们就不再赘述了，就是加载一个原始的G136B，因为它不会动原来的模型。再去加载一个q ora的adapter的数据，这个都会保存下来的，我们这个model我们又传上来了，就这里比如说我们的这个a pox 3，这里会有它的60个steps的一个check point和它的adapter的这个权重，包括这个后面版本的。好的，这个带了时间戳版本的，还有一个是我手动训练的。对，就手动训练的。我再提一句，这个手动训练的是过拟合的。然后这个过拟合的这个玩意儿，是对应的这份数据，我看一下应该也传上来了。Handmade这个应该也传上来了，这个hand made我确认一下有没有传上来。
	对还用github的这个预览好一点，这个就是纯手动。就想象一下刀耕火种时期，你可能就这么去处理数据的这就我们直接复制的这个原文，大家还有印象吗？就是row data，然后row data，这个是我还做了一些替换，把换行符换成了这个，这就是纯粹的手动做数据集的效率，非常的原始，然后也没有变化，然后它的content也很粗糙，对吧？很少会这么问，所以我们才需要今天讲的那部分。
	但是基于他训练的模型，也做了一份我自己做了一份试验，在我本地要训练50个ap OK在八个样例上，很快的大家应该十分钟就能差不多就能训训出来这个模型，那我们可以看一眼这个对比，首先这个过拟合的这个版本对比。在这个对从这儿开始微调前后的这个效果对比，当然用这个PFT加载对应的，第一个就是这个handmade hand made，是epoch 50里面的，你自己得去完你才能对比。我们的代码库里可没有模型，你得走完我们今天的流程去数据。所以你只需要把代码pull下来之后，在我传的数据上面你去做训练，就能够有模型了，有了模型之后就能够去跑这个influence的代码了。我们首先看这个过拟合的手动数据里，我们能看到，我们跑一下。
	看一下我的GPU还有剩余吗？
	不是这台服务器，是这台服务器。OK现在是有GPU的显存可用的。来，我们来跑一个。
	好，我们加载一下，这个是加载原始的模型，只不过这个模型是量化过的，而不是用的全精度的。这些都在transformers的量化课就开始讲过了，一点一点的去讲这个技术栈的。所以大家但凡这里哪个部分不熟的，需要去补对应的这个内容加载这个token either加载之后，这个是微调前的，我们就不看了，我们直接看对比的。你加载这个过拟合的，然后定义了一个对比输出的这么一个函数。执行一下。好。
	看大家有什么问题都可以先提一提，这个跑完我们应该就讲完了，对。有点慢，这个是chat GM，这个确实在提示上还是这个是上面是原始输出，微调前的，这个是微调后的，然后象征着这个什么元亨力争，但这个就是过拟合了。因为我们在训练集里只有乾卦，没有解释一下乾卦是什么，所以他就比较尴尬我们可以试一下用这个训练集里的原来的这个content去对比一下，就能看到它的不同。这个说起来。
	像这个就是典型的之前的历史输出，因为我们在训练集里面，他没有对content本身去做数据增强。所以在这个里在解释一下乾卦是什么。这个事例就是为了给大家说明，当你的数据增强没做的时候，即使你过拟合了，你输出的内容也没有那么爽啊。就是他他也会比较奇怪的，但是当你刚好这个content就是滴水石挂，对吧？这个滴水湿挂就是我的训练基地过拟合的content，那他一定就把原文直接给你打出来了，一点变化没有。就这个师卦原文说了一大堆，这个就等价于我们的训练集里的内容，就是这里的内容它直接就输出出来了，因为它纯粹的过拟合了，所以数据集小的时候，样例少的时候，第一必须得去做增强，不然很容易出现过拟合。第二，你的a pox不能拿很大，就是不能因为咱们一开始用的hanging face上面数据集量很大，然后你训练了这个三个ipos可能就要几个小时，现在少了之后你就使劲训练肯定不行的。你的loss已经有十个step都没怎么变化的时候，你还在努力的去训练，它就只能over fit了，尤其是这个content又这么短。然后我们可以再看一个刚刚说的，在有问题的去解析的训练集上训练的一个模型，就是我们的ap OX3没有加时间戳的这个版本。
	这个问题跟刚刚一样，解释一下乾卦是什么。
	稍微有一点点慢。对。这个就很明显了，大家可以看一下这个回头我把这里也加上，加上这个玩意儿对比比较明显。下面的格式是长这样，ebook 3。好，我把这里加上，叫做130。加到这个地方来，下一次执行应该就有了。同样的我们在有问题的这个数据集上面，然后我们做了数据增强。
	解释一下乾卦是什么，他的这个内容这都要好得多，这个代表什么？天完了说一大堆，虽然有一些重复，但是比过拟合的这个版本显然要好得多，大家可以看一下这个版本要好得多。什么also means the heaven is a symbol of the universe，six lines of in and one nine of Young, 就是乱七八糟的对吧？显然就是过拟合了，就是带来的两个问题，一个是原来的这个知识没了，因为你参数调的太多了，对吧？第二个就是他这个幻觉，然后我们再看一下修正过的这个版本，就是数据修正过的这个版本，这个tim step，4点45这个版本。
	这个版本就是在我们发现有问题之后去调整了gin data里面，就是我们刚刚看到了异常分析，training loss变化很奇怪，然后我们把这个system的prompt加了这个内容，加了这个内容，生成的数据我们也实际跑一下给大家。就用了这个新的加了这一部分，就这一点内容调整之后，生成的这个结果就会好很多，大家可以搂一眼。他会把八个样例都去掉一次，我们可以先看这个结果，结果上来说的话，这里有个fixed，就是修正了数据集的输出之后，它的这个是我们继续说实际运行一下，至少不会说外语了，对吧？那至少相对来说像个正常的回复了，不会冒出一些奇奇怪怪的英语，在正常的这个数据集上。稍等一下，在执行中。
	这里就能看到这个是bix之后的，解释一下解释一下，周一中六十四卦之首，说了一大堆，就相对来说正常很多了。这个其实就是在数据处理方面，大家需要注意很多的细节。比如我在讲整个微调的核心就是第一，你对数据处理的经验在不断积累。所以你知道在训练过程当中的一些特征现象，有可能是数据带来的问题。第二个就是这些超参数的调整，但我觉得在在调超参数之前，第一一定是把数据的这个基本功得做好。就跟你做菜先从把菜切好，当小工，当打下手先做好。对，那么要打好下手。今天这个事例就是值得大家去去深入研究的。这里好像还是出现了一个小小的在，这应该是一个调用上的bug，他直接丢了这个summary，可能是一个难劝的调用的时候丢掉了这一次请求，其他的请求格式上都没有出现任何问题。
	那么对，这个就是我们咱们今天要讲的用怎么样用总结一下怎么样用这个GPT ChatGPT和GPT的API来帮我们自动化批量的去构造私有化的数据集。然后为什么要用棉签来调用这个大模型？就是为了考虑到有的同学可能不一定能把自己的私有数据交给GPT3.5。如果你实在不能交给3.5，我们前面也教了怎么样用南茜来调这个ChatGPT ChatGLM two。大家如果忘了的话，可以看看这个notebook，用南茜来调用私有化的ChatGLM的模型，或者你调用国内的你合规这个场景可用的模型都可以在南线都能调。所以你只需要去去替换这个背后的模型就好了。这套合成数据的方法还是可用的。同时我们也讲了怎么样用ChatGPT来帮助咱们写很多的这些数据处理的代码，这个是很实用的功能。
	最后我们也实际生成了很多数据，包括做了数据增强。然后使用我们的chat GM36B来完成了对应私有数据的q ora。还在过程当中发现了system process的一些问题造成的格式问题，然后也调整了。调整之后我们在不同的质量高的数据和质量低的数据，包括没有做数据增强的数据，三种不同的数据集上去做了对比，发现了训练的效果确实差异性很大，这也更进一步提醒我们要重视训练数据的质量。
	好，这个就是我们今天分享的内容，包括实战的代码，大家一定要多跑代码，多去试。我们接下来QA看有什么问题。如何解决大模型的幻觉？这个问题不好回答。对，这个问题相当于说食神的周星驰在最后做佛跳墙的时候，就是如何做好一碗佛跳墙。这个问题没有一句话的答案。对，这个问题就是你得要去跟少林寺学完很多的功夫之后，才能回答这个问题。它不是一个电脑或者电灯开关的按钮这么一个玩意儿，对它是你的这个综合技能。然后如果你非要回复一个套话的话，那就是把你的数据质量做高。然后在训练过程当中，不要一次训练太长的时间，而是先用相对较少的样本去观察loss的变化，然后不断调整你的超参数。
	我需要的是有很多Jason参数的输出，同时输入也是超过4K以上的。这个同学你可以具体描述一下吗？就你只你描述这个维度不是你的最终要解决的问题，或者说不是你最终要用的场景。就是什么叫很多Jason参数的输出输入是超过4K这个是什么概念？对使用OpenAI或者其他模型生成数据集，那训练微调的新模型就不会比OpenAI好。是否理解？正确理解非常不正确。同学我说的比较严肃，就是很不正确。
	对，为什么呢？第一这个数据它是一盘菜，他跟这个厨师的水平是两回事儿。我一直用做饭来打比方，什么意思呢？你去至瑧园吃了一盘干炒牛河，你回家自己烧了一份干炒牛河，你能说你比至臻园的大厨牛逼吗？对吧？
	你想这个逻辑对，就是你去吃了很多好吃的，你甚至把那个好吃的端回去给他做了各种研究，不代表你就一定比炒这个的东西牛逼，对吧？因为有可能他用了两成功力来回答你这个问题，因为他的数据集有关，他训练的权重有关，对吧？所以这个是不能划等号的对，我们只能说就我刚刚举的例子，你去一个小店和去至瑧园点的甘草牛河，那肯定甘草牛河要去至瑧园吃，他炒的好。就是你那些在数据处理过程当中费的心血就可以少费一点了。因为它能帮你搞定格式问题。我举个最简单的例子，就是你把这个金data这个示例，你从GPT3.5换到GPT4，它可能生成的这个质量就更高了。但你把它换成一个，我们不说哪个换成一个几十亿的模型，你可以去再感受一下。
	老师，你说申请云服务器的优惠的事情咋样了？不好意思，这个问题确实我也一直在跟进，这周都还在问，是因为刚好跨年了，所以整个华为云的商务政策正在制定24年的版本，然后最近是初步有一些落实了，我会尽可能的在，反正年后肯定能搞定，就是年后肯定能搞定。对，但年前不确定，因为整个大公司年前都在做各种各样的reload，然后政策的调整等等。
	私有的语音数据集有什么想法？你这个想法是什么意思？对训练大模型调用agent的数据要怎么构造呢？调用agent的数据是指什么？Function call吗？就是你说的调用agent的数据，这个同学能展开讲一下吗？这种微调的数据量建议多少以上？
	如果是我们现在这个课里面做的这个示例，如果我正经要去做成一个产品，因为我们毕竟这个时间有限，也要方便所有同学都能用。不可能直接给你一批数据传到github上面也很难。但我不排除我可能会在一季度的时候去做一个数据集发布到hugging face上，这样大家就能训练更大规模的了。
	我觉得如果要做，比如说我们就做这个所谓的给大家答疑解惑的中国古典哲学大师，然后回答这个周易相关的问题，浅浅的回答不能多轮对话。然后我们不涉及什么算命这种不让讲的东西。我觉得可能至少得准备样例，就是没有增强的样例就得准备小几千条。所以我说刚才有讲到要爬虫去获取这个数据，但咱们国家现在特别敏感，爬虫也是一个不能公开讲的东西，所以我们不能在课程里去讲这个。对，但是这个技术大家都都知道的对，甚至爬虫的代码ChatGPT也能写。对，所以几千条是要的。
	会遇到一定时间调用API次数过多，产生PY文件中断。这个是指调OpenAI的API吗？这个很有可能，因为OpenAI的API它如果你是没有付费过的用户，他有明确的每分钟三次的限制。然后如果你是已经付费了的用户，也会偶尔遇到服务不稳定的情况。你看我们刚刚直播演示就遇到了，就是掉了八次，他有一次生成结果就出问题了，就没给我就是这个虚挂，其实这个summary他没没返回给我。肯定是南线底层调VAI的API的时候等待时间过长，time out了，然后就没了。戴帽子之后就直接他就掉下一个了。
	这个是open I的服务，服务没办法，那只能你在调用这一端去多做一些工作了。其实也不多，就try catch一下。你发现这次调用失败了，就重调一下。
	很长的context加入输入很长的任务描述会造成乱输出。这个同学说的是对的，就是你可以这个也很好理解。因为大部分的训练集它就是很短的content，这个数就是你的训练集预训练的这个数据集它就是短的，所以你梳短的跟他的训练集是更匹配的。
	我们通过过拟合展示这个content也说明了，但如果你要给一堆很长的就很烦，就像人也是这样的，你的领导和同事给你说一个事儿，说了2个小时了都还没说到点子上，你都不知道他要干嘛，你就晕了。他提取不出你的主题。对，这个是是是没办法的一个情况。你要么就是针对性的去做一些长文本，这个长文本是在你的应用场景里，比如说我还没有特别想到什么长文本，可能做摘要总结。有可能。但摘要总结这个对，摘要总结这个事儿，其实也不需要把整本书总结出来，就这个看看咱们自己的了，在这个场景可以再深度去讨论。
	对，增加summary的方法已经有一些summary了，怎么让GPT帮忙生成类似但不相同的summary呢？这个就取决于你这summary，就是你这个生成要怎么用了。就是我刚刚提到的，就比如说你是给领导汇报的，我说个最简单的例子，这个就是你现在要做一个chat GM的6B是用来写日报、写周报、写月报、写OKR的那你这个就好搞了，对吧？你说你就告诉GPT，而且我觉得这个应该是能告诉GPT的那你给一些参考示例，然后你就说你现在场景是同样的，领导的OKR或者领导的要求给我写出十种不一样描述的OKR，这不就增强了summary吗？
	如果大家都不知道怎么增强，一定是你自己还没遇到问题。当你遇到问题的时候，全是这问题怎么解决，而不是说我靠有哪些问题我需要去解决。然后一定是这样的KOA吗？不是。可以的。
	这个同学这个同学问音频数据集可以润色，咱们不要把音频当成洪水猛兽。音频就是文字，对吧？音频是一个没有被语音识别的文字。那我们课程里面用过whisper，你是不是可以直接用whisper把语音变成文字？好，然后文字你现在要把这个文字去做增强、做扩充，做各种事情，它还是文字。
	但是文字也是可以变成音频的，有各种语音包，甚至OpenAI自己也出了一个对称的模型叫TTS，就是把一个文字给它配音说出来那他不就又变回音频了吗？那你不就把音频数据寄给做出来了。所以音频跟文字是最最直接的，他俩就是一回事激活。对，只有说图像跟视频确实比较麻烦一点。
	做微调的商业价值主要是来自于私有数据集。因为小店有自贞元没有的特殊食材，我觉得也不是。你说夜东京的食材是特殊的吗？也不是，关键是在于你找到了用户需求，就是我一直用做饭这个来处理，就是开至臻园和开业东京就是咱们的商业问题。而至于怎么样能把它开下去，做的菜能不能符合你的商业场景的需求，这个是微调。
	好了，那现在为什么我要说要去至瑧园学这个555百块钱的套餐，对吧？他是在学有哪些菜？就相当于我们现在在对比你的这个商业场景里面，你就把这个商业场景你觉得是能有这个市场的，然后你把他现在的这些问题交给GPT4。
	就是我们开始第一件事情就是在课件里写的，专门有一页大字写的，叫做before taking action confirm the value。就是你要去做这个商业决策，然后你要去做他的技术方案了，你要先去考虑这个商业决策有没有价值。只不过国内有国内的场景，所以我们用ChatGLM来做对比的。
	如果你是要出海的话，那你就先要去跟GPT4来做对比，对吧？GPT4它在这个场景上做的好不好，就相当于为什么夜东京他要的是小而精，而不是大而全。他为什么做的是本帮菜的怀石料理，他没有去做仙鹤神针，没有去做这个港式粤式大餐，他就是找到了一个差异化的场景。并且这个场景里面整个93年的上海就没人卖这些菜。那他就有场景食材都是淘淘的食材，对吧？但是就像我们的原始数据都是这些东西，但是加工的水平不一样，就是你微调的水平不一样。然后你而且你找的场景很好，你就是指定了这么做这一份菜就是放这么多材料，然后他是定时还是它是这个婚宴的这种大作，是这个逻辑。我不知道有没有表达清楚。
	如果不做ChatGPT生成的20个不同问法，只导入一个问法是不是也可行？这同学是不是刚上线？这个就是我讲的over fit，过拟合的数据集也有，然后生成的结果也有。对，然后是不是也可行？就不建议这么做对，因为这么做就是就把路走窄了，就用一个网抖音的直播的说法，你就把路走窄了。你怎么知道你的训练集就做的这么好，刚好符合你的真实use case里面的这些query呢？对吧？
	除了GPU内存需要多大合适？建议是最好跟你的不低于你的显存。就比如说我们现在是T4的16GB最好你的内存也是16GB以上。因为q ora本身它是有这个offload的技术的，它是可以把这个不用的一些offload到内存里的原始数据至少需要多少？这个回答过了。然后GPT3.5是不是需要新开通，是否付费？
	你三个问题都跟ChatGPT问一下，这都是对可以直接搜出来的问题，然后和我回答过的问题，我不回答我先看一个没回答过的问题，后面会讲到RLHF吗？RLHF的微调数据应该是不是也可以使用LLM清洗，不可以。就是RLHF的数据核心是人类反馈，所以一定是人来做的。如果要用大模型来清洗这个路线，我们其实第一节课包括开营就讲过叫RLAIF，就是基于AI反馈的强化学习。但是这条路不是那么好走，他现在受限于那个AI，就是给他提反馈的那个AI因为如果给他提反馈的AI的反馈不好，那就有可能让你的模型越训练越差，就相当于他本来应该选出一个更符合人的答案，然后再去训练那个策略网络。但是因为你是让AI来弄的那AI可能打出来的就啼笑皆非了。所以ILHF我们不一定会实操，但我们会把原理和这个技术战讲明白，因为他需要准备的数据就不太好弄了。
	就现在整个所有的像anthropic OpenAI，包括google这个进展不会一下拉满。不像这个搞软件，对1000个人就能上了。就是因为ILHF它比较费时费力费人，他不是一个100个人就是100倍效率的事情。
	把某个系统的代码去微调，回答系统相关的问题。你的这个系统可以具体举个例子，不就是这个同学问做这种微调的数据，就你的这个系统具体是什么？是circle吗？还是什么？
	无监督学习的微调用来干什么呢？有个同学问对什么叫无监督学习的微调呢？就自然语言里面，我能想到无监督学习的微调是一种说的神经错乱的状态，对吧？就是因为它是画，这个是自然语言，它不是打标签做分类，它不是咱们经常见到的那些聚类的场景。对。
	它不是数值逻辑那么强的对，即使把temperate设置成0，返回的结果也没法保持稳定，不太可能。这个同学你能复现一下吗？你复现一下，提个一休，理论上只要GPT把temperature就设置为零，然后你的prompt不变，包括你的history不变，它生成的结果应该是稳定的，它不太可能不稳定。你咱们能能复刻一下的话，我我我也很感兴趣。如果真有这个问题，我们可以一起提给这个OpenAI微调之后，泛化能力还会保留吗？
	数据大部分内容比较重复，会不会过拟合？第一就是过拟合，就是有两种情况会供拟合，大部分情况是你的数据不够，就是我举的那个极端例子只有八条样例，然后一定会过拟合。还训练了50个air pox，这就是把两个缺点都给它凑齐了。样例又不够，又训练太多，大部分时候是样例不够，数据不够。
	然后数据不够，不管是做计算机视觉还是做自然语言处理，数据增强都是标准操作。对，像计算机视觉里面怎么做数据增强，就是同样一幅图给它增加噪音，增加一些背景噪音，然后增加到这个图上当中的不同的位置，这都算是数据增强。然后旋转一下，对称一下等等。其实这大部分就是这个逻辑，所以数据增强是一定得做的，只要你做模型的训练，几乎都得逃不掉的一个步骤。这也是我把它加到咱们今天这节课的这个流程当中，它是一个几乎是必备操作。
	所以大家不要再去想不做数据增强行不行，就他他是一定得去做数据增强的。对他不去做数据增强就不太正常。就是你你怎么就觉得你的数据造的这么好呢？对吧？
	然后第二就是说如果做完数据增强还是不够，那这个你就训练就太考训练水平了。简单来说就是相当于相当于你这个不太好找一个类似的炒菜的例子了。对，就是你你相当于你闻着味儿你就知道他怎么做的菜了，这个有点难度对。然后微调之后反而没有之前的效果好是有可能的。如果你是指你现在在比如说在这个领域的知识上去做了训练，然后你又去问他，原来他这个能回答的问题现在答不上了，这个是有可能的。
	而且我觉得这个事儿也挺好理解的，就是这个模型容量有限，尤其是几十亿的。本来几十亿的模型就是盯着特定领域去做微调的。它不是几千亿的模型，哪怕GPT4，它下面也是八个模型，16个模型去做这个混合专家模型。每个模型都有自己擅长的。就像你公司招100个人，不可能招100个1样的人，它都是各有能力的，这个偏长的那你不要企图一个几十亿的模型能干所有大模型的事儿，你做完微调就是在培养他那个方向的能力。说一个职场人都理解的逻辑，就是你到35岁了，你到底要走专家路线岗，做垂直的这个路线，还是你要做管理岗去发展纵向去横向发展。这个就是两种能力，它是不可兼得的，因为你就这么多时间和精力，这个模型也是一样的。
	多去试一试。很多同学都在问有没有可能比之前差怎么样都去试，就是多去试。学会炒菜最好的方式就是去炒菜，而不是去想。对，为什么把这些no talk留在这儿，就是方便大家能够去改去试对，这是最直接的，就是模型训练这个事儿想是想不出来的对，只有你自己去试。然后对于RAG来说，不是的，这就是RAG跟微调的区别了。
	有同学说RAG这个事儿，对，就是你要知道RAG如果你有一堆相似的FAQ是个灾难，为什么？第一它会掩盖一些多样性，就比如说这个数据增强理论上是为了让我们的大模型在对类似主题的时候响应的足够好。但是如果你是RAG的话，你相当于往向量数据库里塞了一堆类似的答案。然后这一堆类似的答案其实是挺占容量的，举个简单例子，就是哪怕我今天数据增强了1000倍，我模型的参数体量没变，还是67个亿还没变。但你的RAG你给他搞了1000万条数据到下量数据库里，你的检索效率会巨慢无比。就RAG的这个场景里面，向量数据库里放的一定是模型不具备的知识，没有训练进去的。然后一些常见问答FAQ、FAQ，FAQ的逻辑绝对不是说我类似的问题我全写过去，就是大家把rng当FAQ是最好理解的。就是在这个查检索检索效率这个逻辑上，就是如果你IG的向量数据库里塞了一堆类似的问题是没有意义的，甚至会造成性能和效率的双向下降对。
	会介绍多模态模型吗？暂时没有这个计划，实在讲不过来了。对，但是我们有可能会在后面加餐来讲，但至少在原计划的八周的微调课里面应该不会。而且多模态的训练现在还早得很，就是他很不成熟。然后他需要的资源也特别多，包括算力的资源和数据的资源。但是做这种理论技术的介绍，我们后面是有可能加餐的，然后这个也是接下来2425年的重要的一个发展方向。
	对你像这个google的gym，就是重点在做这个方向。文本你可以直接增加噪音吗？你问了一个特别好的问题，这个问题我还不知道怎么做。然后我估计应该有的一些论文在研究这个方向了，就是怎么样去做自然语言的增强。但是自然语言跟图像最大的差异就是图像的总体体量是可控的。就像你不管给这个图上面增加多少个噪点，分辨率没有变，所以这张图的容量是没变的。但是在这个自然语言处理transformer的架构里，token已经如此珍贵了，你还要往里加垃圾，这个是比较难搞的。在当前的这个状态下。
	这个同学提到微软的这个肥兔的模型，是的，微软的最近迭代的这个系列的模型是挺有意思的。我们现在因为还在做这个课程，还没来得及去深入研究，但是会去看的对，看完之后如果他真的不错，我们后面加餐有机会跟平台讨论看怎么。简单来说，大家不用担心有些新的技术会错过，因为现在大模型太热了，一定会有天天都有新东西出来的。然后我是做这个帮大家筛一遍，这个相对来说从个人视角来去伪，也不叫去伪存真，优中选优，或者说从我的视角来选一些还不错的技术，在后续也会给微调课不断做刷新。就像我们年后的应用课也会去做一遍刷新，会去把年前的零点、1.0，甚至有可能0.2它出了。我们也会讲assistant API会刷新。微调也是类似的，有新的东西出来我们也会刷新对。
	看，还有什么我没回答的问题吗？我搂一眼。看大家还有什么我没回答的，大家可以如果微调的数据只有一列叫content，里面放的是各种表的数据结构，没有数据增强。我没懂这个同学为什么这么纠结，无监督微调，就是这个概念是我没见过的对，然后你只放一列是什么意义呢？你别纠结到无监督微调这种概念上来，我们这个课已经前面理论课的时候可是好好讲过的，就是核心你要理解训练的逻辑是什么，对吧？
	就是我们为什么可以训练这个，你回头再好好看一看。对，就是用梯度下降来训练的前提是要有目标函数和损失函数，对吧？这个是在第二节课讲，第二节课讲语言模型发展的时候就已经讲过了。我们是怎么从统计频率到这个神经网络的语言模型就bengel的，一直到我们的大语言模型的，它怎么来的？就你说的那个场景我都不知道怎么训练。
	对，就是他他咋训练的？对他怎么去算的？他没法训练。这个兄弟就是你你懂我意思就是你做事情要有目的，对吧？就像你你看书也是为了学习，但如果说你看书只是为了看书，我就脑子里面一直在看书，那你得到什么训练的呢？他他不能称之为训练了，对。
	然后所谓的机器学习的无监督，那个也不叫无监。那个其实也是造出来的词。他也是为了跟这个super west去做一个分类，就是别停留在这个词上面，要挖他的内涵。然后为什么会存在无监督？是因为在那个年代有一类问题，然后这类问题被大家想了一些方法，这些方法最后因为需要分类才定了一个名字叫无监督。
	那是什么问题呢？就是有太多的数据了，然后这些数据需要被我们分类或者聚类，对吧？然后聚类的时候就是我不知道他有些什么样的名字。分类的好处是说它已经有label了，这个是猫，那个是狗。那现在我要聚类，它没有名字的，只有一堆数据。数据有很多的特征，很多维度的特征。
	就像我们说举个最简例子，什么叫老龄化？什么叫青年人？什么叫中年人？这就是一个典型的无监督的聚类场景。所谓的老年人多少岁算老年人？随着老龄化变得比较那啥之后，这个老年人的这个时间卡那个range也在调。
	什么叫高血压对吧？在医学里面这个标准血压是多少，也是因为人类的正态总体有一个分布。这个分布大家发现如果我们按照原来的标准，那90%人都高血压了，那不是所有的人都精神焦虑了。那不行，就把高血压的标准调高一点。大家一大部分人都没有得高血压，大家心态就好了。这个是无监督的逻辑。
	对，就不要落到那个词的这个表面上，得抓他解决什么问题。就所有的技术是解决问题的那这个问题它的内涵是什么？为什么需要这个技术？这个技术特点是什么？这样去理解，对。
	可以将RAG向量数据库中的数据作为原始数据喂给模型微调训练吗？肯定可以，但是不是你的这个描述方式，我稍微调整一下你的描述方式。这个在应用课的时候其实做过相关的一些拓展，但是没有去实操。因为大家学的技术门类不一样，就是RAG这个场景最好的一个点，包括你看像现在的这个ChatGPT，他也会去收集用户反馈。就是你可以理解成绝大部分这种模型或者大模型的应用上线之后，他是非常希望用户给他反馈的，然后用户的反馈，如果用户的反馈好大概率这是一个好的样本，可以拿去进一步做训练。然后这些好的样本第一时间可以先甩到向量数据库里，然后再由人去筛选，或者由AI来筛选。筛完之后我们把它作为进一步迭代的数据。你看OpenAI的GPT一直是在干这么干的。从22年的11月底上线到现在，每个季度有一个稳定版的模型，每两周有一个相对开发测试版的模型，一直在迭代，他就是这么在用数据的对，只是说他不一定强调rng而是强调用户反馈。
	什么叫直接翻译过来？这个同学问的这个数据库如何准备这个？
	怎么没太看懂这个同学问的wasp的问题，要不你在群里再详细描述一下。我看已经星期四的十点过了，那我们今天就先到这儿。其实这半个小时的QA很有意思，大家很多技术问题和这个场景的问题就是得这么聊。他也不尖锐，也没有任何对人的角度，就是咱们抛开很多问题的本质去想这个事儿到底咋回事，然后多动动手，多上手去用用，就很快能get到那些技术特点了。
	因为像这个算法和模型训练这些技术，他你说他代码量大吗？大家想象一下，我们这几周没有特别多的代码量，但是一点一点的在讲这些API是怎么用的。然后从一个一开始让跑跑样例，好像知道是这么个流程了。然后到用了这个q ora然后调了几个模型，然后调了不同的数据。它其实变量大的维度就是模型数据，然后微调的方法。但是这里面又充满了细节，然后这些细节只有你不断的上手去玩儿，你才能整明白。对好，我们今天就先到这儿，然后感谢大家，我们周日开始讲这个跟这个怎么样去做，就从这个千亿的大模型怎么样去做指令微调，和RHF这相关的一些东西我们就先到这儿，谢谢大家。