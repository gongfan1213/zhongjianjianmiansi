	Hello, 大家能看到吗？我的这个。PT播放了吗？
	咱们在的人只有三位，我看到只有三个写了一，咱们现在在线上的同学发个一。
	应该是刚刚没看到。
	好，将近十个人，那个同学没有加入，我在群里再说一声，然后就开始。好，班主任说了，那我就那我们就开始。今天最后一节课，好，大家好。
	今天我们来讲ChatGPT的智能配图与容器化发布，也是ChatGPT这个agent最后的两个版本。那么从目录来看，其实是内容很清晰的两个不同的功能模块。第一个就是chat PPT的0.6版本。我们在整个chat PPT的read me一开始就定义好了这个agent有哪些功能。大家可以去read me再看一看除了之前开发的0.1到0.5的所有的功能以外，其实我们还有一块是一直没有填补上的一个版图，就是我们的生成的powerpoint。希望能有一些智能的配图，它能够一键去把我们的PPT里面的纯文本变成了一个图文并茂的内容。
	要配图其实有很多种不同的方案，主要的两种方案。一种就是生成图，通过stable diffusion，middle journey等等这样的纹身图的模型来生成图像。第二种是检索，我们基于一个特定的关键词去搜索引擎上面找一些图来进行配图。通常来说人在写PPT的时候也更倾向于第二种。但随着这一两年的这个纹身图的模型的成熟，比第一种现在也越来越多了。只不过它可能面向的领域有一些不同。
	那为了去实现智能配图的功能，我们的0.6版本做了哪些工作？我们待会儿会逐步的去展开。并且为了让大家了解这个流程，我又写了一个jupiter的notebook，方便大家去交互式的去测试。因为这里涉及到了一些你要通过python去访问搜索引擎，然后去获取一些或者说去检索一些图像，这个过程当中图像本身大家如果用过这个爬虫或者写过一些爬虫的脚本就会发现，当你去访问浏览器的时候，并不是每一个UIL都是可用的。这里还会有很多实操上面的一些东西，我们会在过程当中给大家讲。0.7版本其实是面向生产，我们去做一些必要的工作。在github的city now 0.7版本我们也做了类似的事情，今天我们再来回顾一下，有一个好的开头，一个好的结尾。
	对于ChatGPT这样面向企业办公提效的一个多模态的agent，它要怎么样去做单元测试？它涉及到这么多种不同的文件类型和内部的数据结构，自定义的数据结构。同时这样的一个APP我们都知道，如果要面向生产的话，最好还是以docker镜像dock er容器的方式去进行部署。那怎么样去部署？如果有这个跳着看的同学没有去看这个get up signer，今天我们会讲的再细点，包括用docker去部署这个chat PPT的服务，然后跟我们前面讲的，怎么样去做engines，怎么样去做反向代理，那就能够连接起来。那你就只需要在你的这个部署服务器上面去启动一个doctor镜像links，也可以去反向代理，这个就会很方便了。最后我们再花一些时间去讲一讲这个节课的作业，以及之前的一些课程回顾。
	好，这是今天的主要内容。首先我们来看一看chat PPTV0.6的智能配图要怎么样去做设计和研发，为什么要去做智能配图？一个很直观的感受。我们在chat PPT的0.5版本里面，其实已经做了这个布局，雷out，模板方面的优化了。它生成的内容也很好，并且大家能看到会有一些像这个加粗的字体，其实一些我们对于文本内容的一些，你可以认为是布局方面的一些优化，包括这个模板也越来越让人看着比较清爽。但是会有一个很大的观感上的差异，就是始终如果你想要做一个好的汇报，或者你想要做一个好的PPT的材料。没图是差点意思，就是没有图像，没有图片来嵌入到你的power point里面，其实是没啥感觉的，跟看word差不多。
	那怎么样去做这个智能配图？我们就通过这个对比的方式，其他的可能还有很多其他的方案，但是我们主要就讲这两个，也是比较主流可能会考虑到的方案。一种叫纹身图，就是用文本去生成图像，另一种叫检索图。然后他们两个随着我们这一节课的这个内容的展开，你会发现他们的前置步骤是可以share，是可以共用的。他们的后面的步骤就这个图到底怎么来的，其实是有这个分叉，那么纹身图我们会统一用蓝色的这个smart art，然后检索图的这个方案，对比等等，我们会用这个绿色的，所以大家可以关注这个颜色的设计这也是想给大家留一些启发。但这个时间点我们先不讲这部分，到作业的时候再讲。
	Stable diffusion其实应该很很有名，最近也出了三点几的版本了。Stable diffusion本质上它是一个diffusion的算法。从降噪去噪的这个过程当中诞生出来的一种图像生成的新的模型，或者说新的方法。它本质上也是一个深度神经网络，它的最大的好处就是stable division是可以不断的去迭代这个模型的。
	相信大家如果去看过SD这个mid journey runway，他们的纹身图模型的迭代的话，两三年的时间质量已经非常高了。不管是细节分辨率还是一些之前没有做好的人物的四肢、手部，各种各样的这些东西都已经非常好了。所以它是一个上限不断提高的一个思路或者说技术路线。然后它还能生成一些比如说你在图像库或者搜索引擎找不到的一些内容。
	还有一种情况就是他可能会比如说就以这个例子为例，梦幻森林这个梦幻森林可能我们用搜索引擎也能找到一些相关的图像。但这完全取决于这个搜索引擎有没有把这个梦幻森林这个文本和一些高度相关的图像之间的标签打好啊。因为你在搜索引擎里面去找的时候，其实找的是这个文本上面绑定的这些图。但是SD只要你版本不断迭代，你给它一个特定的prompt，一个text，它其实生成的理论上是高度相关的。所以相关性方面肯定SD会做的更好。但是还有一些特定的类型，就比如说你要查一个上证指数过去十年或者五年的一个增长这种charts，那搜索引擎显然又会比SD好啊。这个是我们highlight从比较直观的视角去看，他们其实是有不同的擅长的类型的，就是这个图像上传的类型。这是一个宏观或者说highlight的一个理解。
	我们如果要落地的去看这个事儿，怎么样去一步一步的把这个事情给做出来，把这个功能给研发出来。那我们就得在干活之前先去了解这两种方案各有什么样的技术特点。SD首先我们知道它未来的高质量创意类的图，艺术类的图，并且可以生成搜索库或者说图像库里本身没有的图，这是它的优点或者说特点。然后在这个过程当中，你还可以基于你比如说你生成了一版这个内容，然后你发现有一些不满意，你可以去调节你的这个提示词里的部分的内容，然后去获取一些新的生成的图像。这个是SD的特点，高度的定制化，可以生成没有的原来没有这些图像。而搜索引擎的好处是快，就是它只需要去就跟爬虫的这个逻辑是一样的，它只需要去基于关键词去找一找，我们的这个特定的搜索引擎提供的这个关键词有没有一些好的结果。通常来说就是一个秒级的一个过程。
	但用过SD的就会知道，它虽然生成能力很强，可以生成一些从来没有的图，但它会比较慢，而且它对于算力的要求还很高。而搜索引擎就是只要你的库里面有高清的图，甚至你可以加这个参数，你就是获取一些2K甚至4K的这种高清的图。那他也很快，他只是把这个文件当下来。并且这个过程当中，如果你用的是第三方的这个搜索引擎的API，你还可以去做这个用户习惯的一些学习。
	但SD通常来说它是一个无状态的，你给什么样的提示词，然后你如果种子就是这个set，这个种子不变的话，它生成的东西是一样的。那这个是两个最大的不同。总结来说就是纹身图能力强，能够在一些特定领域生成一些非常高质量，甚至库里没有的图。但是算力开销大，时间可能会比较慢，这个搜索引擎就是快，几秒就能生成。但是有可能有时候在一些特定领域，特定的关键词，怎么都找不到你要的结果。而且它还有一个弊端，我们回头去在细节里面再去看。
	所以总结一下就是成本来说，一个是计算资源需求非常高，并且如果你想要深入去迭代的话，你还得自己去训练这个lora的SD或者像flux这样的一些征图的模型。它对于你本身的这个初期投入是很高的。而搜索引擎它通常来说是在这件事情上的成本会低很多，但是他会有这个版权的问题。但版权现在在国内可能不是一个特别大的问题，在海外是一个蛮严重的问题。但海外的SD其实也有一些目前还不太明朗的未来的copyright版权的问题。
	然后这个是从成本的角度我们有所了解了。从耗时的角度，我们再直观看一下SD如果要生成多张图，因为我们是为整个PPT去配图，其实是。如果你的算力是有限的话，那它的时间其实会非常长的。因为它一张图一张图的生成，可能最终会需要几分钟的时间才能给你生成几张图片。然后这几张图片如果用户不满意，还得改成这个改提示时再去生成。这个过程其实是非常影响用户体验的。但如果你的你愿意投入更多的算力资源，那你说你就分开并行的去生成，那那也可以，只不过可能你的前面的那个成本就会更高。
	而这个搜索引擎相对来说要简单很多，你可以一次性去并发的发起多个请求。这个在我们前面讲landgraf的时候大家应该也看过了。用这个tabling或者用serve API都可以，然后就是一个秒级的检索。
	但额外提提一嘴，就是大家如果去在脑子里想象这个过程，其实会有一个问题，就是搜索引擎就是要给个关键词。通常有时候它也没有返回一个高度相关的图像给你，它也不是网页。这个时候如果是人很方便，一眼就能看到满满一屏幕的候选的这个图，你一眼就能锁定哪个可能是你想要的。但是如果我们是让这个ChatGPT来做这件事情，其实它会获取到一堆的图。同样是以屏幕的图，但是他没有能力，他不像人脑一样可以去判断哪个图是我要的，哪个图是高度相关的。这儿就是未来的一个潜在的可能比较大的坑，也是我们的整个结课作业里面的这个homework one要去让大家解决的，这两者其实是需要结合的，各有自己的特点和优劣。
	所以在应用场景方面要怎么结合，我自己给的一个思路，这里大家可以去看一看，对于这个SD来说，其实有一些广告类的，就比如说你要发这个小某书，你要发这个朋友圈、发ins、发twitter，你想要有一张配图。然后这个时候你用SD这类的纹身图是可以的。因为它不追求一种细节上面的或深挖细节，就比如说你要一个一束花的插图，或者一个动漫人物之类的这一类其实是用纹身图出来的，这个质感非常高，我相信大家如果用过的话应该非常能理解。像左边这个配的图，你用SD去生成就非常好啊。你去搞一段提示词，像prom hero类似的这样的网站有很多，我们在前面应该也介绍过那种情况。
	比如说你要发一些相对严肃，或者说这个话题深度要更深一些的内容的时候，比如说你要去研究什么量子力学，就像我们前面讲的量子力学与相对论，你要去讲什么是纳斯达克，什么叫美股。这个时候你让纹身图的模型去给你生成一张配图是很难的。但这一类属于公众媒体或者大众媒体，已经有大量的配图了。不管是新闻配图，别人发的博客等等。这个时候搜索引擎其实是非常方便的，如果我们去理性的去考虑这个问题的话，如果我们的ChatGPT未来要面向的这个使用场景同时包含了这两种。那么大家未来可以考虑的就是在不同的场景里面用不同的方案来解决这个问题，就陪读的问题。
	图像质量我们前面其实提过了，stable diffusion其实它的质量只要你的这个参数设置正确，然后你给一定的算力，其实它生成的质量是非常高的，而且质感非常的优秀。但是检索就质量参差不齐了，有高分辨率的，有低分辨率的。就是你打开一个搜索引擎的时候，那个搜索引擎给你的图搜结果是感觉好像图都长得差不多。但你去细看这分辨率肯定不一样。我们如果用搜索引擎的这套解决方案，下来的这些图我们应该怎么样去进行处理，这个我们留在待会儿实现的时候再跟大家讲。
	合起来我们要把这两个方案进行一个结合，应该是未来的发展方向。不管是ChatGPT还是类似的一些提供内容的工具和产品，都需要去做这样的一个整合。就是把HD和搜索引擎去进行互补。在我们的这个场景里，但更多的其实是生成和检索的结合。REG是这样的，不过它在文本层面，但在图像，包括未来的视频、虚拟人生、配音各种各样的这个场景里面，我觉得可能都是这样的一个结合。检索是人类已有的数据积累，生成是通过数据积累训练出来的一个生成模型。然后生成模型再基于你的新需求去make一个新的物料，这两者的结合应该是一种未来的发展趋势了。
	但是这个不是我们0.6要去做到的一个内容，而是咱们的结课作业之一，我们后面会讲还有哪两个。如果大家在这个过程当中发现，首先大部分我相信大部分的同学或多或少都接触过SD了。所以而且我们的课其实也不是做纹身图的，所以我们就没有把这块内容作为重点去展开。因为要讲的话这个详略得当很难控制。但是这个how mark一是一个可选作业，因为我们最终的这个作业是三选一的。大家如果有熟悉SD的那这个就会对你非常友好。另外两个也有一些鲜艳，如果你熟悉一些东西，你可以选适合你的这个结合作业。好，这个是homer关，我们大概有一个说明。
	然后到这儿为止，其实我们知道要去做配图，无非就是找到图源，然后这个图源尽可能跟我们要配的这个内容是足够的匹配的那怎么样去评价这个匹配，这其实就是我们接下来要讲的那个维度的事情了，现在假设我们已经把图搞定了，我们知道去哪儿找图了，不管是生成的还是检索的。但我要去生成需要一个prompt，我要去检索需要一个关键词，那谁来提供呢？这就是我们接下来要讲的用大模型来做这件事情，我们发现其实在这个配图的过程当中，最关键的是你配的这个图和我现在的这个文本的部分是高度相关的，哪怕你没有一些实际性的相关性。因为有些内容它也没有一些好的图去配，但是你能提供一些视觉上的辅助，那也是非常好的。所以这里有一个核心，就是要用大模型来理解这个主题，然后再去找图源来给它进行匹配，所以目标是基于主题的内容来进行配图。
	举一个简单的例子，我们看啊这个左边是我们ChatGPT已有的功能，就是基于一个跟他聊天，基于一个输入，我们把它变成一个给大模型的需求。大模型再生成一个powerpoint slide content，就是它的我们所谓的这个PPT的每一页的内容，并且是一个markdown的格式。我们希望这些内容不是干巴巴的文字，而是图文并茂的一个slides。所以其实我们需要有一些pictures for slides，对吧？就是各种各样的图跟它是相关的，而且我们特指的不是上个版本的这个word two car points，而是就是从0到1的。通过我们跟他的沟通，从0到1的生成内容，而不是去把历史的老素材去做powerpoint的生成，那这个时候核心就变成了我们想要有好的图，并且去配到特定的里面。
	左边这个是咱们的data structure定义的这个格式，二级的这个标题就作为了每一页的内容的分割。所以我们在这儿看得到这里有四这个四页，第一页是古巴学家的介绍，后面有3页是正文的内容，古巴学家的历史背景、制作过程。种类。
	显然假设我们有右边这样的一幅图，它更多的是去跟种类里面的品牌也可以去做一个比较好的主题内容的匹配，但这个事情具体要怎么做，如果没有大模型之前，其实相对来说还是比较难做的。大家可以去想一想，但是如果有了大模型，我们可以傻瓜化的去处理这件事儿，我们直接告诉大家实现的这个技术路线，可以分成四个步骤，这四个步骤其实这四个步骤其实是跟我们前面做的，所有基于大模型的这个agent都是类似的思路。因为已经到最后一节课了，我希望大家能够做了。我们在PPT里其实做了大量的check port，有的是直接跟用户对话的，有的是在后台去运行的那有了这么多的chatbot，相信大家包括我们在language mental，相信大家能够逐步体会到要做一个agent的一些核心要素，就是那三要素。然后那三要素里面的prompt的最重要。在一个多模态的agent chat PPT里，除了这个prompt本身以外，要对业务去进行高度的理解，才能知道要有多少个不同的prompt驱动的agent来干活。
	这儿我们再单独拎出来一个agent，它的作用就是帮我们基于powerpoint slide contents去找一些关键词。当然如果我们要去支持这个SD纹身图的话，那他可能就是去找一些或者说去生成一些给SD的prompt。然后这个proms再去用SD的模型去生成图。所以我们现在回到这个检索配图的这个技术实现路线的话，这四个步骤我们可以看到。
	首先在前面的版本里，我们已经可以用这个ChatGPT生成至少十页的纯文本内容。这十页的内容我们其实并不需要每一页都去配图，这个大家应该能理解的就是不需要那么多图。那么需要几张图，其实也可以在大模型的prom里面去做设计。那么我们假设三张假设就是三张图，这三张图到底给哪些页面去配图，其实是需要去思考和决策的。但是我们又要知道，像PPT面对的使用场景其实是高度自由的。我们不知道用户会拿它生成什么内容。这个时候最简单的冷启动的方式就是告诉大模型，让大模型理解和分析他自己生成的这些文本内容，然后再来决策哪些页面需要去配图。
	当然这里的两个它其实是不同的模型，他们的这个prompt是不一样的。所以第一步让模型基于powers points的contents来决策哪三个页面需要配图，那决策了我知道了有这三个页面之后，接下来为了检索，我需要去构造一个搜索的关键词。然后用这个关键词再去访问搜索引擎，得到内容相关的图像的121，这个可能跟人直接去访问搜索引擎的不一样，你可以去想象一下，其实最后只要写过爬虫的就知道，我有关键词，我访问搜索引擎，搜索引擎给了我一个list。这个list其实是image OL的list。然后这个image OIL的list，在搜索引擎那直接就给你渲染出来了。
	在你爬虫这儿，你还需要一个一个的再去尝试来去访问这个UIL到底能不能得到这些正确的图像的集合。比如说给了你十个候选的UIL，这十个你都去这个request访问，然后访问到之后再去看看这些图有没有可能，比如说分辨率太低了，或者分辨率太大，或者说这个图其实是破损的，这个是有可能的。在搜索引擎里面，它的UIL可能都是加了快照，cash等等，所以它它能够看到并不代表你最终还能获取到这个图，有可能图源本身它的服务器把它下载就是给关掉了或者移除了等等。所以这四个步骤其实是非常直观并且一气呵成的。
	大家可以想一想，大模型决定哪些页面需要配图，大模型生成搜索的关键词。然后后面两个步骤是跟技术路线有关了。我去获取从搜索特定的搜索引擎的去获取了一个图像的集合，它是候选的图像的集合。在这一堆候选的图像集合里，再基于我们咱们这个产品的设计者预设的一些条件去筛选出最终得到一张，也可以是多张，取决于我们配图的策略。那现在我们在做MVP的版本，就是一张，那么就会有三个页面得到三张各自的配图，那么就完成了用大模型来基于主题内容的一个检索配图的实现方法。这是一个技术路线。
	那怎么样再去落地呢？第一步就是要让大模型来决定哪些页面需要配图。那他的这个决策最终这个决策怎么样去体现，其实是他生成了一个搜索关键词，那我们要怎么样去写这个prompt，我们可以看一下，这是它的就咱们的刚刚说的这个大模型，它的agent驱动的过程当中的prompt。
	同样的我们再次深化这个RTF的这个prom framework，row task format，然后重点把这个标红的是这个RTF里面的关键内容，road的这个描述。通常来说helpful assistant肯定是没有问题的。然后specialized的让他知道的领域，这个具体的一个身份就是提供一些相关的图像，就是在presentation里面去提供一些相关的图像，让这个presentations的表达更好。
	其实我们开始前面中文说的这个意思，它的具体任务再展开来讲，就是会给他一个powerpoint的text content，就是给他前面我们看到的纯文本的powerpoint的内容，each slide is separated by仅仅这两个井号，然后选出三个slide。Identify three slides when inserting images would make the presentation more vivid and specific。更加的生动和特别，有特色。For each selected slide, 红色的provide a best keyword that can be used for google search to find。找到的这三个决策出来的要配图的三个slide，提供每个slide提供一个最佳的搜索的关键词，给到谷歌的搜索引擎去找到合适的图片，然后并且指明这个slide是哪个slide。那要指明它，那就用slide title来指明它。就像我们这一页的slide title就叫from design那format就显示了，最终返回的是三个sly title 1，slight title two, slight title three, 后面都是它对应的best cure。
	其实并不复杂，但是大家如果不习惯写英文的这个prompt，还是得多花一些精力把这个技能提升。要让写一个prompt就像你喝杯咖啡一样简单，事实上也是如此。有了这样的一个prompt，我们看看它的实际的效果会怎么样。首先我们看到这是在这个左边，就是有一个实测的一个搜索关键词生成的效果。我们提了一个问题，我印象当中好像是问他什么是这个纳斯达克，他给了一些描述，包括纳斯达克的概述、市场结构，指数交易机制等等。然后我们又把左边的这个全文，这个powerpoint的全部内容丢给了刚刚的这个prompt驱动的agent，我们就叫它image adviser，就是图像的这个建议或者顾问。那么image advisor就返回了右边的这三组keywords pair，是这个格式。大家应该刚刚看过chrome的时候会有印象了。
	左边的这个括号里框的是slide的title，纳斯达克的概述，然后冒号后面是搜索的关键词，股票市场的电子交易，纳斯达克的市场结构，收的是高科技公司，然后纳斯达克的未来展望，搜索的关键词是科技创新与投资机会。当然你可以想象得到这个关键词是由大模型生成的，什么页面需要去配图，也是由大模型决策的。当你去再点击一次的时候，它其实要配的图，要查的关键词肯定也会不一样。这个也是他能够去多样性为不同的用户提供不同结果的一个好处。我们解锁一下这个股票市场的电子交易，出来了一个什么图呢？长这样，有一个像是这个应该叫什么证券公司或者这个证券市场上面的这个大屏幕的截图，经常这个电视剧电影里面会有OK。
	有了这样的一个流程之后，我相信大家有一个初步的感觉了。是还是用大模型来决策，大模型来生成关键词，然后去访问搜索引擎获取到图像。但是这个搜索引擎到底怎么选？这个其实是另一个问题，也涉及到了我们一个最关键的模块，就是搜索引擎到底怎么选，以及所谓的这个成本的模型。因为最终我希望大家能把这个光线商用，他如果能够商用或者真正能够用起来，也不一定商业化，至少变成一个产品能帮助你的这个工作。那他就需要反复的用搜索引擎去配图。
	在前面的一些学习的这个章节里面，其实我们已经接触了很多去访问搜索引擎的方法了。然后他们的成本也各不相同。最有名的搜索引擎其实就是google，可能并相对来说是在google之后的，但他们的市场份额差了得有几十倍。然后除了这个搜索引擎本身的选择上面，其实不同的这个搜索引擎，它的成本结构也是完全不一样的。Google相对来说是最贵的，因为它的你可以就你可以列成它的检索结果，质量要比其他的要又多又好啊。所以这个是比较直观的一个考量。就不同的搜索引擎的成本，单次计费或者说这个检索包。我们有哪些可以去访问搜索引擎的选择，就是搜索引擎其实就没太多可选，但是我们去访问搜索引擎的方法还有得选，它的成本也不一样。
	我们先说这个土豪有钱的这个方法，就是我们之前也讲过的完全合规的方法，用第三方的API平台。比如说在讲n graph的时候，我们引入了tavy，这也是nine graph，南茜社区的agent tool，也不叫官方支持，叫最佳实现。你去给大家推荐过的一个第三方的搜索的引擎的API，然后它也有它的这个资费，大家也可以去看一看，在前面讲的grab的时候已经介绍过，也是实际用过了。还有一个就是更早一代的前辈，google search API，又叫serve API，从最早只支持google到后面其他的搜索引擎也都支持了。在我们的应用开发实战营也讲过怎么用这个surp API，那他也是能欠的，最佳实践里去链接的这个API，这两个大家可以再回忆想想，其实是非常简单，直接可以去调用搜索引擎的。
	但是我们都知道，尤其是很多同学在开发方面是没有什么预算，预算比较紧张的。我不想花钱，我现在还在开发状态，我调调个几次这个API，可能我的免费额度就用完了，那怎么办呢？还能不能继续呢？大家如果了解的话就知道肯定会给大家想办法，对吧？不想花钱也可以，但是不想花钱谷歌我是没有试成功的。如果有同学有很强的爬虫的本领，可以充分的骗过谷歌的服务器，那可以分享一下方法。
	我们是以并这个搜索引擎作为一个示例，其实逻辑上来说，就是跟爬虫一样的思路。你通过python的requests库去访问这个并搜索引擎，去向他发起请求，并且把你自己模拟成一个用户。所以你能在hider里面看到各种各样的这各种各样的haters，各种各样的user agent的描述。其实他就想模拟啊不要让这个病感受到你是在在爬虫爬取他的这个数据库，这个是比较常见的方法，而且大家如果去试的话会发现是work。那么通过request去模拟访问这个搜索引擎具体怎么做，提供了一个可以交互式的no talk。待会我们也会带大家来实操感受一下这个notebook在jupiter下面，像现在PPT的jupiter下面，跟之前的PPTX quick到是在同一个目录。下面是它的这个UIL，大家可以去访问一下。
	那么接下来我们就来实际操作一下，怎么样用这个inner notebook来带大家去学习。把刚刚的四个步骤，12344个步骤我们。看一下。我们如何把这四个步骤，通过这个notebook一次性的完成，然后逐步的去学习和理解。好，我们现在就打开这个。
	我看看。
	基本落户。好。好，我们在这里。我们在这个chat PPT的githa项目上面可以看到，现在已经有0.6和0.7的分支，然后我们去到就拍ter。的页面就adviser。然后0.6版本其实就已经提供了这样的一个交互式学习的demo，0.7并没有做任何的改动，在0.6版本就提供了这样的一个文件。我在右边我们来实际看一看怎么样去实现它。大家记得要去装一个to拍lab，这个怎么装应该非常简单和明确了，这个我们就不再展开讲了。然后我们的lab也加到了requirements里面，所以有的同学如果你的康大也没有装to the lab，你甚至就是用的type的这个虚拟环境的管理的话，那至少你去更新一下，去install requirements，你也有就是lab了。
	好，那我们来实际看一看这里要怎么去执行。同样的我们还是先重启一下这个channel。对，这里还要再提一下，我们前面也教过，现在的这个chat PPT的调用就变得比较复杂了，会有很多次的调用了。所以我们再次在在咱们的这个ChatGPT里去引入了s miss smith的这个关键的环境变量。其实就这两个，那还有一个它的APIT，这个是建议大家配在自己的环境变量，或者说你的比如说你是ZSH就配在你的ZSHRC，你是其他的shell就配在你的这个RC里面，你是windows也可以去配这个环境变量。
	在这个jupiter里面，我们的projects是用chat PPT，就piter来进行命名的。在这然后我们在这个radio，在这个正式启动的环境里面，是命名了ChatGPT。那么现在我们可以点一下这个下PPT的主拍摄，然后就对应着我们这里的结果，会在左边的next miss里面去进行这个chess。
	这有一个比较重要的点，就是我们的jupiter目录和源代码目录不一样。因为之前我们在应该是在在这个set的时候也做了一些拍摄的demo。但是是放在source的目录下面的，并且它不涉及到很多的文件读写，也无所谓。但现在我们为了让大家get到这一个tricks，一个小的技巧，我把它单独放到了这个跟source同级的目录。
	大家可以看到有jupiter有source source code。但是这就会带来一个问题，就我们会在这里去实践各种各样的PUC的测试。可以这么理解。但是我们这些代码希望实践完了之后，能够直接一次性的生成一个source下面的这个模块代码。那这里的一些包的导入路径可能就需要跟source里面是一样的。
	那怎么做到这一点呢？其实就是我们这儿看到的，它的一个去拍照环境的设置。简单来说就是我们把这个主拍摄目前它的直接的执行路径，其实是在jupiter的他所在的这个目录下。比如说我们在这可以执行一下，看看当前的工作环境，工作目录环境在修改之前，大家可以看到这个要打印。
	打印当前的工作目录，它是在jupiter下面。但是我们为了让它跟sauce一样，我们所有的启动都是在跟目录下去启动的项目的根目录下去启动的。我们就把这个目录提到他的上一级，也就是chat PPT这一期。这个区别大家应该能看出来，这个是一个python的语法堂，一个小的语法。那有了这样的一个切换之后，其实我们就拍ter现在的当下的目录就变成了这个项目的根目录了。
	然后为了让我们打包的时候，比如说我们在源代码里导入的包，都是config架构的，直接去导入的那现在肯定不行。如果我们没有做这一步的话，那么就得写成这样的形式，对吧？应该很好理解。好，那么我们把SaaS目录加到python的这个路径里面加到这个python的路径里面。这样大家能看出来，这样其实我们的这些包的导入就不只会去我们的，比如说mini contra的虚拟环境，或者说它的这个系统，就python这个系统的库里面去找。同时我们当前的这个CPP的项目里面的源代码目录，也会成为它的一个找包的一个路径。这个时候，我们就能直接from，这应该很好理解。
	好，那这样导入之后，我们去把chatbot的prompt打开看一眼，check for the prompt就是对应着rather。我这儿打开了。0.6。
	Chat what source? 我们的chat part其实就是最终应该叫开始为咱们的用户提供每一版power point的content，就是我们的这个check port。而他的这个prompt其实其实就对应着。
	这个。
	chat board点。TXT这个是我们在上一版也迭代了让它的slight title这里显示的更更多样化一些。并且我们希望他response in chinese，用中文反馈。这些是他的prompt，我们可以在这验证一下是不是成功的导入了咱们south目录下面这些内容执行一下，你可以看到这是最新的chatbot的prompt，尤其是我自己写的，所以很有印象。这个迭代过程当中，response in chinese应该是最后一次加的这里这些描述，额外的这个描述也是后面新加的。所以从这里的打印我们能看出来，他其实成功的把这个check out config都加载进来。
	那接下来我们要做的事情是，既然chatbot加载进来了，那我们就能够基于一个idea变成一个powerpoint的这个内容。那我们就问这样的一个问题，input test等于像没有做过投资的小白介绍一下纳斯达克，这里我们去模拟一下在radio server里面的行为，我们在radio里面其实是有加一个这样的前缀的，叫需求如下。不知道大家有没有在源代码里去好好观察这个，因为我们会有很多轮的对话。所以如果你不加这种prefix，可能多了他都不知道哪些是它生成的，哪些是用户的需求。我们可以看到这个generate contents里面，我们通过一个初始化一个text的列表来维护不同的多模态的来源的内容，要怎么样去处做处理。但最终这个user requirements会加一个这样的前缀叫需求如下。然后把各种模态的需求放到这个列表里，然后join起来。所以如果你寄给了寄输了文字，我们前面的版本还介绍了OpenAI的waster又传了一个音频，你甚至还给了一个我们的图像，那这些其实都可以再进一步去做扩展，把这个给到我们的chatbot，然后chatbot再生成了一个结果，就对应着我们这儿的一个实际情况。
	好，我们让它去生成一个特定的powerful points的内容，这是我们的第一步，先把内容生成出来，还原0.5版本的一个结果。向没有做过投资的小白介绍纳斯达克，然后这个是chatbot的输出，check box的输出，我们可以看一下。
	这在我们的chat . 
	with history之后，最后会有一个debug级别的日志，去展示前报的输出了什么。就对应的这里，然后纳斯达克简介，概述主要特点，交易机制优势风险，如何投资投资策略了解市场动态，未来趋势总结。这些就是我们目前0.5能够得到的一个效果，然后我们看一看怎么样去给它嵌入图像。这儿我们其实是需要用一个大模型加载一个我们新设计的prompt，然后再来选择或者说决策哪些页面要配图，然后生成对应的关键词。我们按照之前已经非常熟练的方法来做这件事情，从文件里面导入对应的这个需要的包，然后prompt image added，就是我们在课件里刚刚看到的新的prompt。长这样you . 
	are . 
	helpful。然后permit长这样，那我们来咨询一下，拍的就是是你是这执行过了吗？这个执行过了。好，然后这儿我们会略微有一点差异，就是给大家看的这个细节。我们看到这个提示词最终是怎么组装的，system的这个prompt就是这里我们刚写的这个prompt。但我们希望它能够把最终要的特定的页面和关键词都很稳定的找出来。实际大家如果去去感受过的话，其实你就会发现在这儿用一个content来作为描述会效果更好。举个简单的例子，让大家能直接的感受这个过程。
	在。
	在去实现这个prompt好不好用的过程当中，我们看到是用的GPT s omni，然后temperature mex token都是试出来的那怎么试出来的呢？其实是在这里。
	我们可以看到。
	这个是一个。
	ChatGPT的playground。在这里我们给了这还是保存的不是最新的版本，对吧？这个最新的版本不是我的。
	之前我还测试了一个sly title给多个search k warm。然后我们看到在这儿其实最关键的是这个部分，就我们在这段内容里其实聊了，刚才课前也讲了，但是我们学过这个应用开发的，包括你自己去阅读了一下这个OPI的chat的这个API到底怎么回事的话。你就会发现其实最终这个GPT能够拿到的这个结果是相当于把它们拼起来拼起来的那拼起来的话，这一段的格式其实相对来说统一，但是内容是非常多样化的。
	而我们在这个简写的第一版的system instruction里面，其实写的是比较简单的。我们只写了giving a powerpoint text content，但是我们没有写明白哪些是powerpoint的text content。所以用一个跟roll task format类似的形式的一个关键词来做说明。这个会让结果更加的稳定，那为了达成这样的一个效果，连线的基础知识，这个属于我们其实是要做一个user的这个prom tempt。然后因为我们在这个过程当中基本已经锁定了这个形式了，所以就直接把这儿展现出来了，就是长这样一个content，然后先有一个换行符就到这儿了，再有一个换行符就到这儿了，就从这儿开始的这样的一个形式。那我们能看到这是我们构造出来的image adviser的整体的。然后我们再去实例化一个check model，用的是4O的这个omino，然后构造一个image adviser，这是年前的基础知识，有一个排管道，那我们去看一看它的结果。这儿我们把slice content给传进去，只有一个input variable，就slight content，就是我们这儿看到的这一堆内容，我们来执行一下。
	他获取到了一个结果叫纳斯达克概述。它的搜索关键词是like electronic trading market，然后technology companies，artificial intelligence and blockchain not after的未来趋势。这个就达成了我们前两个步骤了，就是找到了三个slide，以及这三个slide各自的关键词都有了。接着就是我们要去做这个检索了，去做搜索引擎的检索了。
	这要怎么做呢？其实有一个直观的需要解决的问题就是大模型输出的这个结果，假设它足够稳定，那我们其实要从这个结果里去取这个slight title和这个p ver。对的，这里我们希望把slide title和key y word取出来，为我们所用，后面还得再用他们保存图这个图像文件等等都还要用到他们，不要把它提取出来。
	为什么以这样的形式来写，而没有写成一个节省或者XML？就是考虑到大家可能会咸，这个OpenAI太贵或者用不了OpenAI。你在实际用的时候，也许你会替换成一个开源的模型。那就算是一个开源的模型，它也能返回这样的一种format。但是开源的模型不一定能返回稳定的节省结构。所以如果你锁定你确定你最终的结果，你在实际使用的时候可以用OKI，那你甚至可以在这儿就把它做成一个节省，那就更稳定了。因为偶尔还是会出现一两次这个东西不好用，没法用，没有生成合适的关键词。那你就如果你用的是开源模型，你就再让这个模型生成一次就好了，也能解决跟下面的搜索引擎第一张图没找到，再retry一次，再retry一次还不行就放弃它，去找第二个要一样的逻辑。
	好，那么接下来我们再看看这个搜索引擎怎么用。所以我们先把这个提取出来，用正则表达式，这个就不说了，这应该大家都都明白。就算不懂把这个玩意儿或者把这个玩意儿，不管你是把提示值给他，还是把生成的真实结构给他，就给到现在GPT，让他生成这段代码，它应该都能做好，那我们这就直接执行了，提取出来。
	我们提取出来的是一个字典。这个字典我们把这个纳斯达克概述，这就有小细节了，大家去看我的选中的这个操作，其实这个trading market后面还有空格，这里还有空格，这儿这没空格，那前面也有一个，前面这个空格是正常的这是我们by deline。而真正懂搜索引擎的同学就知道这个门道很深。如果你有空格和没空格，对于搜索引擎来说是两的关键词。所以我们在这儿有一些小细节，把key和这个value的前后空格都去给它去掉移除掉了。最终提取出来的是这样的三组slight title，keywords 3组。
	然后提取出来之后，接着我们就要去访问这个搜索引擎了，对搜索引擎的这个header，但一看就知道这个代码其实也是GPT生成的。怎么生成的我就不展开讲了。这应该大家都在整个这门课里学到了太多。我们快速看一下这个代码的逻辑，构造一个header，发送一个请求response request，然后检查条形码，如果是200就可以，没有的话就没找到图。然后杰西这个是经典的python爬虫的库，beautiful so去解析，然后选择器去查找提取图像的链接怎么就突然到提取图像链接呢？
	又回到这儿来构造了URL，这URL怎么构造的呢？这就是并搜索引擎的图搜的URL，它前缀是长这样的，就是bean image search。然后这个问号，这就是我们的pass parameter。在UIL里面的这个parameter，我们找这个query，就是我们要的关键词，然后找几张图，在这儿有一个默认值是找五张，什么时候用到了number image呢？就在这里，大家能看到在这里。首先我们如果直接调这个，或者说直接去请求这个121，他反馈给你的肯定不止五张。然后我们只是说在这做了一个判断，我们只取五个就够了，大于五个的时候就break了。
	知道下面来了，获取图像的这个分辨率并存储为字典。这里为什么要用图像的分辨率呢？其实尤为的重要。就我们要想象一下，最终我们是要把找一个，比如说我们其实要去新建的，找一个有图的。
	我们要去新建的时候，这个图其实是第一，它是有分辨率的要求的。太小太大的可能都不行，太大的可能你还得把它缩小，太小的你强行给它放大，也许会很活泼。然后长宽比也是需要去做处理的，因为你有picture的这个place folder，这些问题其实都是要考虑的。那么我们就需要把它的分辨率给记录下来，宽度、高度resolution，包括我们的sly title和query都记下来。这样的每一张图都有一个字典去既有它本身，又有它的原数据。然后我们最终就得到了一个图像的列表，就相当于从就像我们这儿看到的，从这个。需要配图搜索关键词图像的集合了。
	最后我们其实是在做条件的筛选，得到一张主题内容的配图，怎么塞呢？拍个脑袋可以先想在我们不知道怎么塞的时候，图越高清越好，对吧？越高清越质量高的图越好好，那这个时候我们就能看到按分辨率的大小从大到小来排序，reverse就是从大到小来排，然后返回了一个sorted images，这样的一个函数，就是我们的get bean image。
	定一下这个函数，然后接着我们来获取第一个键值对，我们的这个key words，获取他的第一个建制队。这也能看出来，他跟我上一次执行的就不一样，因为你生成的powers points的结果不一样，然后这个就相当于chatbot生成的结果不一样。Image adviser给出的这个sly title和keyword pair肯定也不一样。第一个键值是纳斯达克概述，对应的值是electronic trading market。然后接着我们再来去做检索，这应该是啊这里应该是不需要的。Images这个images就是最终按分辨率从大到小排序的一个images。
	接着我们要做的事情是检查这些的第三步，从图像集合到最后只要一张，这一张要怎么再去取？我们可以看一看。首先得先把这些图保存下来，因为它现在其实是在内存里面是一个这样的结构，一个二进制流的一个结构，里面9款披露去加载的，那么我们要把它保存下来，并且进行一些处理。我们先去查看一下它的原数据，这个是比较重要的，其中的分辨率比较关键。就比如说electronic trading market，找到了前五张图，它的分辨率倒序来排的话，显然这个分辨率就特别大。4500乘3000，这个放在我们的PPT，它的好处是很高清，然后坏处就是会让你的PPT变得非常大。这个文件，这个分辨率还不错，这些是额外的，然后我们是按分辨率而不是长宽的一个特定比例来的。
	好，有了这样的一个概念之后，我们把这些图存下来看一看找怎么样。然后唇save image，这里就有一些小细节了。第一个点就是大家要对图像文件格式有一些基本的概念。什么是PNG，什么是JPG，什么是JPEG，它们有什么区别？其中一个比较重要的就是大家如果要无脑去记这个东西的话，去了解这个东西的话，就是PNG它几乎是无损的压缩，然后它也支持透明度这样的一个选项，也就是所谓的A通道。大家知道有这个RGB3种不同的三颜色去构成一个图像。
	那还有一种叫RGBA的格式，就是有透明度的，只要用过photoshop或者类似的一些图像编辑软件就都了解了。然后像JPG和JPEG它是有损压缩，但它带来的好处就是如果你没有把这个图放的特别大，肉眼是看不出来的。然后它的图可以它的这个图像文件可以变得非常小，然后我们的save image里面首先默认是支持在使用JPEG来进行渐进式的加载，或者说渐进式的压缩的那当有这个RPGA的时候，RRGBA的时候，我们会选择用PNG来进行保存，这个是这个image要注意的一些小细节。然后在这儿，我们这个quality的参数，maxus的参数，包括scaling factor这些大家就自己再去研究了，都是一些比较基础的东西了。然后我们把这个函数定义好，save image定义好，然后我们把这个存下来，存在哪儿呢？存在一个本地目录test里面test。
	在这里test目录，这个是两天前的，不是现在的。那么test目录。执行一下，我们把这个图像存下来了，大家可以看到名字叫做test目录下面的纳斯达克概述1点JPEG。然后就纳斯达克概述就是我们的name，也就是我们纳斯达克概述这一页。对，就这一页这一页我们给他配了这个图，找了五张图。这五张图分别以这个slight title加上这个ID的方式去做了生成。也就对应着这里我们看到的这五张图。
	7秒钟之前的。
	这个就是纳斯达克概述一找到的图，我们可以再看一下。2。他应该表达送给你了。还有关键词匹配到electronic training，下面有market。这里。
	这一张可能有点大，也没有，只是服务器的一好，这是我们从bing上面刚刚找到的五张图。然后其实熟悉我们的II python或者其实就patter的这个同学应该也都见过。我们用过多次查看图像的方法，其实就长这样，用这个方式也可以在就派的内部去查看录像，然后尤其是你的服务器有时候比较慢的时候，也提供了一个选择。
	好，接着我们要做的事情是这是图是图文是文，还没有把它嵌入回去，对吧？就我们要把这个一张一张的图再嵌入回去，那怎么做呢？其实生成一个image pair，其实就是一个slide image的置顶。前面我们有一个字典是通过正则表达式来的，不知道大家记不记得在正则表达式里面，我们生成了一个slide和keywords的字典。现在我们要生成一个slide image的字典，然后把它嵌入回去，这个过程我们可以看到比较简单，这个参数是可以选的，就是我们去搜索引擎到底要几张，再选成三张，然后前面的keywords我们是直接取了第一组。但实际情况我们要把每一组或者说每一页的这个标题和keyword都进行这个过程，所以外层有一个for loop，然后里面会针对每一页的多张图像，这里是三张来进行判断，然后检查输出图像的数据。然后这里我们只去处理分辨率最高的图，我们只把分辨率最高的图存下来，给到这个原文里面嵌入回去，这个是我们的一个主要流程。那这儿我们就看一看具体怎么做的，这儿先把image pair给造出来，先有一个控制点，然后不露出。
	我们可以看一看。
	Type object image has no attribute, open time of I have no other. 这个应该是在调用我们的。
	就是打印了，这是去获取了，然后没有获取到，我们看一下。对，拿到了。Save image. 他们也没去object。
	Image data image objects然后。这儿报错了，没有拿到。A. 
	奇怪。只有一面简单。See you option solution. Option resolution. 
	Image open. 孕妇没有拿到这个图。data. 
	有可能是被bing搜索引擎给ban，这个是之前我复现过一次。这里就是穷人开发要注意的一个问题。就是咱们的并搜索引擎它也是没有，它也是有一定的所谓的防爬机制的。
	然后如果你针对这个词老在获取，有可能就会出现这个问题。但我们简单简简单绕过去一下这个问题，其实换一组关键词应该可以试一试，我们来重新获取一个在。这里。换一组关键词应该能绕过去。这个问题从他没生成正确中文的。啊哈。
	然后这个是新的一组keywords，然后我们针对这个keywords再来试一下。先让他变成孔子的。
	这是一个。
	看一眼我们的。images. 没货渠道。
	这不应该。
	我们。
	打印一下。
	然后。
	我们再来执行一下image link，获取到了三个。然后data也获取到了。三个。这一次就可以了，很神奇。大家如果去细看一下这个日志，这次他就成功获取到了。我自己试下来，这个实际情况应该是搜索引擎在在办这个请求，因为这个IP是固定的，然后他多次的在用这一套user agent去访问它。这个有搞过爬成功同学应该都有经验，但这个也不能讲怎么规避，简单来说就是你你得想办法让自己隐藏的更像一个真实用户，有各种手段，但这次他就成功获取到，我们可以看到image pair这个它就成功生成了。
	前面没有加这一段日志输出，所以不知道内部发生了什么。大概率是我预期如果他仍然报错的话，应该是image links是有的，但是可能去去实际请求的时候就发生了问题。我们看这个是原本的这个日志输出，我们看到有纳斯达克概述找到了三张，因为我们这次是要访问三张，分辨率分别是长这样的，然后最后image received存了这一张，因为我们只存这一张，仅处理分辨率最高的这个图像只存这一张，然后最后存了三张，那这个image pair，就是存的这三张，分别是纳斯达克概述意义，对纳斯达克的主要特点一和投资纳斯达克的优势一。我们可以看一眼，在test目录下就对应着一分钟的这三个一，一和这个一。
	然后我们需要再把这个因为GUIL给插入回去，就是image pair里面的这个玩意儿插入到这个slide里面。这个怎么做其实就好解决了，就是markdown content，就是原文。Image pair是这个字典，然后我们就只要去在这个image pair里面针对它的key去找到那两个这个我们叫井号，就是这里，然后再插回去就好了。我们实际操作一下，看一下这个过程就好理解了。执行一下insert页面，打印一下。大家可以看到这个纳斯达克概述就插入了一个图，主要特点插入了一个图，下面是投资纳斯达克的优势插入了一个图。这个new content其实就是一个满足咱们ChatGPT的图文并茂的markdown的这个格式了。然后这个格式经过我们的input power就变成了powerpoint slide content。
	然后再经过PPT generator，就能生成这个PPT的文件了，这样的一个流程刚刚这个其实还正好想演示这个可能出现的情况，还真就遇到了。我他大概可能是因为今这两天我的这台电脑IP服务器访问太多了，它的频率还变高了，平时我可能会多试几次才会出现这个情况。所以这里也是大家到时候如果遇到了这个情况，也不用紧张，也不是代码出了问题。就是bing的搜索引擎对你这个埃批在做一些防护。那这个流程下来，其实我们应该理解了，到这一步为止，最终的这一步为止，其实就已经完成了这个智能的配图了。只是我们没有去执行最后那两步骤。
	好，这儿是我们给大家提供了一个主拍，大家可以去做这个测试。我们接下来会再讲一下怎么样去把它集成到我们的ChatGPT里，就是怎么样去集成。这我们可以快速看一看，我们在刚刚的这个jupiter里面看到了这样的一个输出。这个输出大家如果还有印象叫做keywords，是一个字典，前面是select title后面是keyword。在这个image provider里面有一个日志叫做advise的建议配图，这样的一个字典。
	检索的关键字，我们通过正则提取出来的这个，这个是keywords里面去打印的，下面是我们去搜索的结果，这个也跟刚刚看到的一样，有sly title作为name，然后这个query就是它的关键词分辨率，然后分别把这些又保存下来了。保存下来之后，其实在chat PP的界面里面就长这样了，我们在去拍摄里面看的一样。为了让大家直观的去把这个流程给感受一下，我做了一个录屏，是下载GPT0.6的一个video demo，有视频demo大家可以看一眼，它包含了从0到1的生成一个PPT，一键的配图，以及从word到PPT的生成。
	不对，这个是未剪辑版本，这个有点慢。我给大家看剪过的这个剪过的版本其实是在ChatGPT的REDM里就有。
	在我们的read me里面，read me这个也新更新的日志，然后0.7会讲后面这部分，我们可以看到这个产品演示，30秒而已。稍等，我把它放大。
	哎。
	这还居然有网络问题，先等它缓冲一下。我这儿给大家解释一下。首先我们看到他问了咱们在用其他笔记，应该已经很熟练了。问了一个问题，就是讲讲什么是量子力学。这儿其实是我们一直以来的功能，有AI一键生成PPT。它生成的内容。
	然后我们刚点了一下一键生成报point，这个是很快的，是毫秒级的，生成了一个量子的一些概述，也就是0.5版本的功能。我们把它放下来看了一眼量子力学的基本的一些内容。然后我们这儿再让他把内容深化一下，就深入讲一讲量子力学和相对论什么关系。这是它重新生成的内容，量子力学与相对论的关系等等等等。接着就是我们image advise的功能，就一键配图加内容优化。还真卡了。
	稍等一下，其他的服务器。我靠。
	然后点了这个一键为power point配图。点完之后，大家如果去细看这个有量子力学与相对论的冲突，量子引力的研究，这都生成了新的图片。然后的规则是在images的temps目录下面生成了咱们的slide title，然后下划线一这样的一种格式。这里有两个在上面还生成了一张图，然后我们再点了一下一键生成powerpoint，它生成了。然后我们再看到从浏览器这儿下载了这个最新配了图的内容。这是配的三张。
	然后后面演示的其实就是我们上个版本实现的内容，就从word到我们的这个PPT钉钉。这是一个word文档老素材，然后这个太太卡了，大家可以在ad查看到这个video，然后课件的这个我回头替换一下，然后这个image advise具体代码是怎么实现的呢？肯定会比jupiter要稍微丰富一点，我们来看看改变是什么，把这个拖过来了。在0.6的分支里面我们看到source。然后有一个。
	gradual . 
	server，那这儿我们新引入了image advise，我们新定义的这个class，这个image adviser用在哪儿呢？在这里。呃。我看一下。
	在这里，我们新增加了一个按钮，大家看刚刚的这个图的话。
	我看一下有没有窗口保留了。在这里新增加了一个按钮，叫一键为powerpoint配图。这个新增加的按钮，我们就可以首先来到radio的代码模块，这是chatbot。这chatbot这是新的按钮，叫image generate button，这是一个radio button，一键为powerpoint配图。然后这个button有自己的clink，然后function是handle image generate，inputs和outputs都是chatbot，所以关键就是这个handle image generate。A handle image generate这里面我们就能看到，它首先获取到了输入，就是它第一版生成的这个输入chatbot生成的这个获取方法跟我们的一键生成powerpoint是一样的。就他上一次的结果，然后去image advise去生成了image，返回了两个，一个叫content with image，图文并茂的内容，一个就是刚刚我们在这里知道的image pair，这个image pair理论上我有尝试过，把我们叫多模态的chatbot。这个radio组件最好能够在这儿不只是去展示一个这样的页面，GOL, 还能把图也在这儿给它附上。
	但实际来看，radio的这个多多模态的chatbot的前端组件还是有一些局限的。就是他如果把图放在这儿，会搞得特别复杂。因为它整体的是一个check out，由chat和u message和history构成了一个你可以认为是一个列表或者一个聊天记录的序列。然后如果你有把图放进去，会让它的数据结构变得非常的恶心。但这个我们最后也留了一个homework，就是非常擅长前端的同学可以用streaming或者其他的一些前端框架。把我们现在PPT里已经提供的各种能力，用一个新的前端去把它开放出来，让更多的用户能够充分的去使用它的能力。最后我们的这个带有图文并茂并茂的这个内容就变成一个new message，扩展到了history里面。它在radio的chatbot里面就会变成最后一条记录。那这个generate image，包括image advise具体怎么定义呢？我们可以看一下。
	应该能跳转在右边。跳过来了，这是image advise，首先我们看上面的代码会感觉跟其他的short是一样的。这儿我们有一个profile，load create advisor，这些都是一样的。但这个generate image会比其他的只是去调一次大模型要复杂很多，因为这儿我们是提供了不不通过第三方的搜索引擎的API来访问的方法，所以它就是会有被骗的风险，但它确实是免费的。如果你想要说你不差钱，然后你愿意去付那个API调用的费用，那你其实就把前面我们的这个南倩里面的那个代码，很简单的就是把这个部分给它做成一个with two。如果大家还有印象有一个LLM with two，而不是chat OKI，然后再去给他接一个table，那他就能够在这个部分的这个过程当中，把get bean image换成了直接通过tabi去搜图，再去处理就简单多了，然后generate image。
	然后这里我们看到达到了这儿建议配图，拿到了一个建议的配图。所谓的建议的配图就是我们看到的这个结果。这个结果，slight title keyword。然后在这儿针对每一个图再去做处理，处理这个分辨率最高的核心的流程。在这个里面我们的bean这个bean的image获取他的这个方法做了一些增强。比起旧patter里面做了单个UIL的三次重试，包括如果有一个图你请求一直没有结果，也有一个time out，这是相比于我们的拍ter多的两个参数。因为你要想象一下，你自己有这方面的实操的经验，你就会知道要做这些事情了。举个简单的例子，就比如说我们开始在去拍的里面遇到了一个很尴尬的事情，就是他给了这个UIL，但你去请求的时候就是请求不了，那你可以选择重试三次，这一般可以说是一种业界行业的规范，然后重试三次都不行就放弃他。
	那还有一种情况就是他不会告诉你没法访问，他一直拖着你把那台服务器一直你在请求拿数据，但是这个链接他就拿不到结果。那他可能就会变成一个request默认的time out，也许是60秒，那这个你是等不起的对用户非常不友好。所以好的请求一般就一秒之内应该能拿到这个图了，拿不到就算了。
	然后这个算了是指这一次算了，但你还有三次机会通过这个方式来做处理。所以这个是一个额外的新增，包括把所有的print都改为了咱们的log，save image这有一个迭代，就是我们可以看到做了一个max size 1080的设计，我们认为在咱们的PPT里不用特别高的分辨率，1080够了。如果特别大的图缩小，把这个图往小了说，如果图不够大就放大，最大的那张分辨率的图都不够大，那就只能把它放大。但如果最大分辨率的你最大分辨率的那个图分辨率特别高，你把它缩小一点，缩小之后再来存，那么你的PPT文件你就不会放很多大的图像文件去占用你的这个资源这就是我刚才提到的RGBA。如果是RGBA我们就存成PNG默认的还是纯结派比较省空间插入图像，通过这个我们就完成了智能的配图，我们可以实际体验一下在这里。重新启动一下，给大家看一下它的效果。
	下载好了。
	比如说我们就。
	问这个。
	就派他的问题，去哪儿了？这里。
	介绍一下纳斯达克。
	日志给大家打开这儿，需求如下，介绍一下纳斯达克。
	我们看到这个是他给的一个结果，一键为他配图。这里是一些bug，还没有生成这个框框。对，没有get到这儿，可以优化正则表达式或者去优化format。这比较简洁的处理方式就是retract。
	We do the. Video的这个retry比较暴力，直接把两个都发起了。稍等一下，我们再点配图。这次OK它生成了右边，大家能看到右边生成了这个建议配图这三种，然后获取了对应的图，然后在左边就看到了，他这个就偶尔会铉会渲染成这样的形式，偶尔也不会，这个is radio前端的能力上线了，那我们能看到这样的标题，它它的这个我们叫message的对话框，把它渲染成了一个图。但这个图它展示不了，它的对话框不支持，但这个图其实是存在的，这个图就在它的还原在这儿，直接点开VS code，这就有一次从事失败的日志，大家能看到attempt，然后我们看看它最终使用的这些图，就比如说纳斯达克的未来展望，这张图点开，这就是这张图。然后历史这样的概述，这样的我们让它一键生成。
	已经生成好了，点下载。网还挺快，今天。他在下面这个屏幕。好的。这是它刚刚生成的这个power point。
	这样的一个样式可以继续让它配图。
	这样继续让他配图。它这一次就是历史主要指数影响力跟刚刚的那个是不太一样的，我们可以点生成。
	这个是新生成的。
	这个退出了。
	这个一是新生成的，他找到的图是一样的，可能是。我看一看新生成的右边，我们能看到有影响力，主要指数历史，确实历史这张图跟它是重复的，用的关键词是。在你插入千家主要。
	指数。
	影响力，未来展望。
	这儿纳斯达克成立的背景历史图片，这个是他的检索出来了这样的一个图。但是大家会发现，其实之前有的这个配图它都会存在了。这个主要是给大家看一下它的这个整体的逻辑，然后他一次生成三张，或者说他一次给三个配图，这个完全也都是我们可以去控制的。在咱们的proms里面就再提一嘴。这我们看到prompts里面明确写了三个slides，那这个三个slide也可以做成一个input variable，让我们在实际用的时候去用户去决定，那么就可以在radio里面有一个组件去选，要给几张配图，甚至你也可以在前端做成要给哪几个配图，这个都是去可以操作的。这就是新生成的几个图。好，这个就是我们0.6的这个就是我们0.6的主要的一个功能。然后接下来一个小节，我们再来讲讲0.7的这个主要的功能，就是单元测试和容器化发布好。好，我们先看一下大家有没有什么问题，正好我也去接一杯水。
	大家有什么问题吗？就是关于0.6的这个智能配图。
	每个版本的requirements应该如何更新？你用对应版本的分支就用对应版本的requirements，对，跟着分支走的。
	就是每个版本分支的代码和它的requirement肯定是不一样的。对。
	看大家还有什么问题吗？自己通过命令可以更新。我没有太听懂。这个同学你这个是什么概念？你要更新什么？是我没有理解到位吗？你要更新的是啥？
	当然你也可以生成图表，对，只不过图表你需要数据，就看你的数据怎么弄。对，后期还有什么优化？这个你可以待会儿等一等我们的结课作业，那个是咱们要结课必须要做的事情。而且理论上这个不是产品，这个是咱们的一个课程的实战。然后这个实战如果你每一节课都认真跟下来，你应该会有很多的感悟的。甚至也有一些同学再跟我联系想要做商业化，我也有有可能会去做商业化。对，好，大家没有什么别的问题，我们就来讲讲0.7，然后后面我们再来提问。
	好，接下来我们来讲现在PPT的0.7单元测试与容器化发布。其实我们在get up city，get up的这个city now里面也跟大家讲过。但这里我们在一个好的开头，一个好的结尾。我认为TIPPT和这个get up central都是不管对于个人还是对于用户来说有非常大的使用场景的。
	然后我们来看看怎么样把它变成一个容器，做成一个稳定的线上服务。首先单元测试，单元测试的代码怎么来呢？那我把这个服务关掉。我们回到代码这来看一看，在0.7版本里面，我们的text目录新增加了一些核心模块的单元测试的代码。而这些代码怎么生成的，其实蛮关键。大家看这个test下面的这些文件，其实之前在第一个A检测项目里面认真学习过的，应该知道怎么样去进行处理。然后我们接着来看看这个是怎么生成的，就怎么样去做一个咱们的单元测试的开发。
	回到TIPPT，我们有一个TIGPT的这个对话给大家再次做一个分享。就怎么样你写完代码，其实理论上在真实的生产里面更推荐是先定义功能，然后去设计测试样例，然后再去开发真正的功能代码。这里我们课程的设计就不这样干了，反正关键是把这个方法论教给大家，就是怎么样让AI，让大模型帮你去完成单元测试，尤其是最近我印象中google的一个agent还把circuit的一个人没有发现的bug给修复了。你可以想象未来测试有很多功能，确实或者说测试人员的很多工作，确实有可能大模型会做非常多的替代。
	那我们接下来看看怎么做。首先我给这个GTCO的一个输入是这个word文件，这个word文件就是我们项目里面的这个示例的一个输入。就这么的marti model LLM overview，然后同时给了他input puzzle的源代码。然后这里也很关键了，生成单元测试代码并添加中文注释上传的是测试文件，正确的输出格式和内容如下，这就正确的。
	这怎么来的呢？其实我们在讲这个dox power的时候也提过，可以给大家再回忆一下在我们的。在我们的这个dog part，这是可以直接执行的，然后生成了输出了这样的一个内容，并且生成了一个marty model，Martin model LLMOBU这样的一个内容。在我们的。
	源代码。然后dogs. 
	趴在。
	这里，本来我们的generate markdown from dogs，最后会输出这样的一个日志，然后同时我们直接去执行这个文件的话，它也会生成一个结果，就输入是给到TIGPT的这个word文档，输出是它转换之后的markdown的文档，那个markdown的文档我们在本地拿到了，然后把它也给到这里来。当然实际真正大家去干这个事情的时候，应该是你先设计了一个word文档，又设计了一个markdown的文档，然后再研发研发让这个研发的输出跟你的那个markdown的实力输出是一样的。那这儿我们就已经验证过了这个dogs的这个power的功能是正常的。那么就把这个当成标准的人工造的输出给到他，相当于他就拿到了标准输入、标准输出源代码实现。然后他的要做的事情是这一段话，生成单元测试代码并添加中文注释当然它生成了这样的一个代码，我这一行是有错误的，明眼人一看就知道了，因为我没有告诉他我们的这个文件叫什么，没有告诉他。如果你在这儿最前面加一个这个，比如说我们在这儿最前面加一个这样的描述符，加一个这样的描述符，大家应该能看到，这是比较标准的做法，那么他这儿应该就会正确了，他缺少信息，所以这里也不怪他，不怪CDPT。然后生成了一个结果，set up去读了这个文件，因为他自己的code interpreter就上传到它的一个临时存储的位置。
	然后test，就是这个是期望的结果，就我们传给他的就比较就比较就是加载了一个word文件，然后生成了一个结果，再去比较跟预期的这个结果，然后最终get到这些单元测试的代码，我就不展开讲了。如果对这些单元测试的代码不熟，可以去看get。好，然后接着我们想了一下，说在这个位置我们去执行了一下，第一版执行了一下，执行了一下之后，测试失败的原因是什么呢？是生成的markdown的内容和它的内容有一些微小的差异。其实我也不想看到底哪儿不对，他其实帮我迅速的看了一下，就是有一些多的空行，什么概念呢？就这多了一个这多了一个。两个空行多了两个空行，这两个空行怎么来的呢？它其实有分析，就是我们的这个。直接给大家看数据，应该简单一点。我们的现在。
	定义。
	的数据结构里面，一个井号是powerpoint的主标题，两个井号是每一页的标题。但我们其实没有定义三个井号，所以这个三个井号是未定义的。这个未定义的它就不属于任何一类，在我们的dot partner里面有实现的，有hedging，它是指这个标题有bullet point，有纯文本。当然图像它会单独保存成图像，但无论如何没有定义这个三个井号的，所以它会默认的就不换行，继续贴在这儿，这个是本质问题，这个问题因为我们本身by deland就没去解决，那么在这件事情上我们正确的处理就是你可以看到在这儿其实是ChatGPT多做了一件事儿。我们其实给他的这个markdown的内容里面，这也是没换行的，它自动帮我们换行，它的自作主张，我们可以看到我们一开始传给他的第一个请求里，这是没办法的，然后这也是没换好的。所以最简洁的方式就是他提到的也是他提到的这个他没有提到。是我是我想到的对，就是把咱们的这个恢复一下，我们就用这个格式没有换行，然后这个也没有什么大的问题，因为最终我们在ChatGPT里还有一个模块叫content for matter，他会去处理这些事情的，那么我们就按照正确的这个输出来作为标准答案，我们看到这里，我们就不应该这样来处理，就不去硬编码。我们给他一个标准的输出的markdown也就是我们现在右边这个马知道，我们告诉他。
	这个就是我们的。喂。我没有在跟他对话，这一轮的内容我直接应该是自己改了一下，我确认一下，是的，我应该是自己直接就改了一下把大家可以看到test的代码，因为有时候确实是这个问题，如果很简单的话没有必要跟他深究。我们看到在这里面我们的set没有变化，当然这个你也需要自己去适配，因为它给你的代码是在MAT的data下面，我看到他给的代码在在这儿，因为他不知道你本地的路径inputs改到这儿来。然后expected的这个markdown，我们就改成正确的样式，就是改成这个样式就可以了，那这样就我们来实际执行一下。Test . 
	test. 
	通过这有一个直接的run one test，0.357秒，这个就测试通过了，它的转换是完全OK的。我不知道刚刚这个描述大家有没有get到这个点，本来这里就应该长这样，但是TGBT它自己以为这个地方的格式是应该换行的，所以它生成的这版代码就运行不了。然后我把它拷到右边的VS code之后，只改了这个输入的路径之后，没有成功运行。那没有成功运行就是因为他自作主张的这个换行没有通过。然后我们把他的加的这两个换行空行给处理掉之后，当然是正常的一个结果。
	那类似的其他的核心模块就是下面的部分了。就这里我们能看到这个是应该是input power，然后这个是data structure，然后slight builder。Layout manager。同样的，生成以上文件的单元测试代码，上传的文件为示例输入，就是我又上传了一个咱们的test input，这个示例输入把这个传给他。Input puzzle正确执行后，生成的结果如下，就是我们如果输入是一个markdown，那么它就会直接用input part去尝试解析。Dogs才会有那个puzzle在formatter在这个assistant的这个流程大家还记得的话，然后我们看到执行的结果是长这样的，our point presentation，然后这是标准的一个powerful point的一个输出结果。
	好，那我们就告诉他正确执行后的结果是这样，相当于又告诉了他输入是什么，输出的这个内部的数据结构是长什么样子的。理论上他拿到了我们的data structure的代码。它的这一段输出其实就是来源于这个来源于这个。所以他是知道powerpoint的结构，输出应该是长什么样的那我们再看他会怎么做。它生成了input puzzle的测试代码，比如说这里test input power，然后模拟一个lk mapping，然后实例的输入，然后输出，这个是输出结果，是一个our point的一个数据结构。好检查每一项是否匹配。因为前面我们相当于word转markdown，我们有单元测试能够匹配到了。现在是markdown转成我们自定义的powerful point的这一系列的数据结构，2 point slide slight content要去检查，这里我们就发现有一个细节，就是首先set up去读我们的test up test的文件才对，而不是直接硬编码我们就让他直接去读，这儿要改，不用直接定义input text。
	第二个就是其他的几个模块，他忘了生成单元测试代码，这儿我们看到GT4O其实已经有点到上限了。第一他是去读的文件，inputs mark down。这个我告诉了他文件路径的，告诉了他文件路径就不用我手动改了。他的test部分其实就做的太简单了。他只去检查了slide title，而没有去检查别的内容。因为你看它的前一个生成是检查了layout ID lame，然后bullet points等等。所以这儿其实就需要我们手动的再去做一次结合，具体来看就是我们看一下。
	哎呀。
	The test. 这个是input power。对，我们继续有一个模拟的布局映射。然后这儿它上面这部分C它改对了，我们就用它改对的这一版。但下面的这个比对，我们其实还是需要一个完整的powerpoint的数据结构，而不是像他这样只去比标题和主标题。其实我们沿用他给的第一版的这个样式这个结果来做比对，然后我们再来执行这个测试。
	一样的，OK说明测试OK然后其他的几个模块他也给了出来，像test slide builder，然后layout manager，data structure等等。然后这还有一个小的优化，就是我们看到这个test slide builder. 
	里面。
	要给大家提一个细节，是之前UT没有的。在test slide builder里面我们看到他set up，然后去实例化了一个layout manager，然后layout manager会给下面去用，去set的时候去使用。实际情况就是如果我们直接用它的代码，会发现它会输出四次。
	Out manager的初始化主要原因其实很简单，就是set up的方法其实是在每一次我们去执行test的时候，都会去执行到我们的slight builder。这里。你可以看到这个set up其实每一次去执行这个test的时候，它都会执行一遍。那相当于按照它的代码，我们每一次执行的时候都要实例化一个layout manager。但其实不应该，因为the out manager应该是初始化执行之后，就不会再有新的the manager，然后你哪怕是加载新的模板，也可以在这个manager下面去做扩展。所以要引入一个新的方法，叫做set up class，set up的类方法。也就是我们这儿看到的，理论上我们只需要一次that manager的初始化就好了，那么就把它放到set of class方法里面。
	然后我们的每一个test还是需要实例化slight builder的。因为sly builder你是往里去加一个新的slide，那个是需要清空的，所以这个是一个小的细节。把这个改好之后，其实理论上我们的几个核心模块就都有了对应你的测试代码。当然包括这个PPT generator，也可以让他去做对应的这个测试，然后后面甚至包括这个测试的这个文档的更新，也是跟他去做的沟通，有了这些之后，我们熟悉的同学就知道，为了让容器的构建能够自动化的去测试这个搜索起来，我们肯定还需要有一个脚本，叫做valley test，这个是我们的，跟这个get up set其实是一模一样的。因为所有的单车都可以用这个脚本可以来执行一下。一共13个测试，0.5秒all test pass。
	那有了这样的一个脚本之后，其实我们的自动化的持续集成就好做了。我们就可以在build image里面去build页面，就是用来给docker镜像做构建的。那么在构建这个docre镜像之前，我们可以去检查一下这个是不是测试通过，是这样的一个流程。好，那对应的这些代码就包括单元测试的这个容器构建的，在我们0.7，包括面分支是一样的，它就对应着0.7都已经更新了更详细的文档，比如说单元测试这个游戏要调整多了，单元测试验证脚本使用docker构建与验证，然后这个build image点SH，然后构建的过程，这个是它的doctor file。我们看到这个地方有啊dog file，然后dog file里面会去赋予这个validate test，如果validate test没有去执行通过的话，这个的话是构建不了的。在这儿构建过程中运行单元测试，然后这个就是用这个doctor来构建了，我们也可以实际执行一下这个dock er的构建，可以直接用这个脚本。
	大家可以看到前面全部都用了缓存，但这个run a validate test它其实还是会再执行一遍的，执行一遍之后就有了chat PPT0.7这个标签，这个tape。如果你想要在自己发布到你的私有的doctor仓库的时候，更多的一个常见的做法就是在这个部分，你可以去docker build杠T然后image tag，这个image tag是怎么来的呢？就是取得branch name是这样的，有的地方还会去同时构建一个，就把你最后构建的这个东西当做。对，这个是。Latest image. 
	这个就取决于不同的公司，有的时候我们还会可以这样去做，就是我不仅构建了当前这个分支，而且我认为我当前这个分支就是最新的分支。我还同时可以打一个latest的标签，这个时候我们就能看到。再输出一个。
	它会继续缓存。它其实同时就打上了这两个标签，我们可以通过docker image。大家可以看到chat PPT有V0.7也有latest，但是他们的image ID是一样的，因为它直接可以复用这个缓存，然后这个医美GID也是用来检验的咱们。
	当前的。
	这个多块镜像到底是不是这个0.7版本的一个标志。好，这我们就先退回了。好，然后有了这个镜像之后，接着怎么运行呢？在github city now里面我们没有去加这部分的文档，待会我们就一次加上，就使用docker来部署服务，在这个部分使用docker来部署服务网，这里重点讲几个参数，就我们doctor around，杠IT是指交互式的杠P，就是端口映射。
	我们知道最终使用的是radio，在dock file里面我们有写启动的是radio，那这个radio是要启动在7860的容器内的端口的，那么我们容器外也要用7860来做映射。这样的话就最终对于我们的NGX来说的话，就是本机的7860这个端口其实是跑着radio的，然后从容器内映射出来的，同时还有一个杠一的参数是环境变量，因为我们整个这个ChatGPT其实有两个重要的环境变量是一直被设置了。但是如果你在在做多ker的时候，你没有处理好，他就跑不起来。因为他缺这个东西，那就是我们的能能欠的API key，这个是能smith要用的。一个是这个OpenAI的APIK，是我们的OpenAI，GPT是omen要用的。然后同时还有一个杠V，杠V就是硬盘的挂载，它的第一个参数同样是本地的这个路径，然后这个是容器内的路径。因为我们的the file里面把工作目录设置成了APP，那么APP下面的outputs就是我们的PPT生成的路径。最后跑起来跑一个特定的版本的话，就是为0.7，那我们可以来执行一下这个。
	为了区分我们现在其实是在项目目录下面，我们可以退到上一层目录，就是我的project目录，然后我们在这儿建一个outputs的目录。这个其实就是跟我们的ChatGPT已经完全不同的目录。那我们在这儿去启动容器。大家可以看到run IT杠P7860-1，执行一下。
	这里有一个小细节，大家可以看到它在这儿是在加载OpenAI的vest模型，然后为什么会这样呢？是因为我们的。Radio server里面会去加载OpenAI的这个whisper ASR，然后当他去加载的时候。
	这儿这是一个having . 
	face transformers的这个performance的小的细节，我们看到在。在SR里面会去加，应该是在。看一下。在这个位置，对，在pipeline这里它会去加载模型，然后模型是ONI的waster。
	在我们本地的服务器为什么不会下载？是因为hugin face它默认有一个自己的，你可以认为它是缓存目录，它只要它下载过一次，它就会把这个模型放在那儿。但是在容器里面，其实它每一次运行都是新下载的，除非我们也把那个模型拷到这个镜像里面去。但没有必要，就是正常一个docker启动之后，它就会持续运行了。你没有必要把这个docker镜像变得特别大，然后这个是一个同样的我们的mini CPM也有类似的问题，就是我们的在这儿这个mini CPM也需要去加载一个模型，为了不让这个镜像搞得特别大，所以而且我们的前端其实现在没有同时支持这么多功能，让他们串联起来。所以在0.7的这个版本里面，也就是我们打的这个镜像里面，我默认是把这个注释掉了，就我们没有去开这个图像识别的这个功能，然后他也就不会去同时在docker around的时候去加载master和这个mini CPM。
	就有的同学他本机或者说他用的是mac的这个统一内存，或者是用的小一点显存的服务器。那这个时候你要同时加载，也许你的GPU的这个显存就不够了。所以我把相对消耗多一点的这个就给关掉了。然后我们也可以看到在本机。
	在本机上面现在还没有真正的去加载这个whisper，因为我们要去上传一个音频文件的时候，它才会实际去跑。这个大家如果忘掉的话，可以复习一下那节课，就是vesper的这个显存占用的，但mini CPM就会直接去加载，所以就会让你如果没有这个大的显存，可能就会比较麻烦一点。好，那我们把这个关掉。
	我们回到docker，这个是在docker内部运行了。大家可以看到这上面加载了一堆。然后我们docker其实本质上是为了方便大家去做服务的管理治理而做的一个引入。
	在这儿我们看到，其实这个域名同样被成功的解析了。就是因为刚刚我们有一个很重要的参数，这个7860的这个端口映射这个透传。我们如果用多ker来启动，其实理论上我们不加这个杠IT它就会更稳定，也会不像就不像之前我们有一次因为网络环境的问题，跟这台服务器的连接断掉了。那么这个部位就断掉了，那你也可以用nop来启动。Help, 它不会有docker的有restart等等这些policy，那我们就可以问一问，介绍一下这个长城学家。右边我们看到杠IT这个参数，让这个docker能够实时的把它的日志给打印出来。
	这个是它的内容，我们可以配图。
	第一次不要了。
	第二次不用了。
	好，那我们下载下来。在这儿。
	这个是他配的三个图。这些都没有上升去的。制作工艺。
	文化。
	意义，这个就是我们用docker来运行的一个模式。然后理论上如果咱们想要在就像我们在讲github set的时候在后台运行的话，那么我们把杠IT参数去掉就好了。有的同学可能不是很熟悉这个，如果没有加这个启动起来之后，等半天也没看见它正在加载，正在下载这个模型，就会感觉很困惑。所以我们默认给你加了NIT的参数，但如果要用服务的方式，用这个dim service的方式去执行杠D就好了，就杠D杠D们就可以了。
	好，这个是我们0.7版本的容器化的发布和运行的一个整个从测试到我们的构建镜像，到docker的运行部署的一个全部流程。好，希望大家能把反向代理域名docker都连在一起。其实你就已经拥有一个非常稳定的生产服务了。
	好，接下来我们讲一讲结课作业，应该是在这个屏幕。我们的结课作业会是一个三选一的。但如果你能力很强，你也可以都做，但是至少是有一个要做一个。这个三选一的结课作业是对应着我们的不同你自己的不同能力属性来做的。
	第一个就是你可以去集成一个图像生成的模型。就像我们这个0.6版本的研发过程当中讲到的，纹身图检索图本身就是去给PPT配图的两套技术路线。并不是所有的内容都适合用检索，有一些内容用生成方式更好。所以在搜索引擎的检索质量不高的时候，可以去使用SD或者其他的纹身图的模型为powerpoint来智能配图。
	这是第一个可选的homework。这里其实聪明一点的同学就会想到，那怎么去判断检索质量不高呢？我们有mini CPM，你可以把这个mini CPM用起来，把搜索引擎的图丢给他，再把他那一一页那个sly sly的那一页的内容丢给他，然后你让他去判断这个图和这个东西相关吗？可以让他打个分，比如说这个打分就成为你去判断它的质量的一个标准，你可以设置这个阈值。
	第二个可选作业就是我们在这个课程的中间部分给大家讲讲过这个nine graph，其中最有意思的market agent应该是大家都印象深刻的反思机制，一个writer一个teacher。Writer是在写文章，teacher给反馈和建设性的意见，通过多轮的对话让writer生成的质量变高。那么我们的check point其实也是一样的。大家可以想象这个ChatGPT，当它用到不同的领域的时候，首先我们现在生成的这个深度，就比如说我们看到的这个长城雪茄我们现在生成的这个深度好像内容很少。这是因为我们的模板就设计成了不同层次，它的字号也会缩小等等。但理论上大家如果去看过那种演示文，演示的这个slide deck，其实它每一页的内容不会特别多的，它就是相对比较少，只是排版上要再做一些处理。我们因为课程的原因，我们没有去做那么多不同的slide master，那么多的模板来做介绍。但理论上现在这一版的chatbot生成的内容是合适的，就不需要那么多的文字。
	但是考虑到我们有不同的场景，我们可以在这个作业二里面给这个建设PPT增加一些radio的按钮。比如说你是要内容丰富的，还是内容简明扼要的，然后当你去选了内容丰富的时候，或者简明扼要或者其他一些可以想象到的维度，然后把这个选项做成一个marty agent来支撑的一个形式。比如说你要内容深度很多的那这个时候你可以有一个teacher，然后原来的chatbot还是这个chat，你让这个teacher就是接到了要内容深度或者说内容多，那么他就去不断的给这个采购的一些意见。就像我们在已有的chat PPT里面，我们可以去让他比如说我们现在有一个内容，我们让他这个内容可以在详实一些，每一页。都展开讲讲，但这么说肯定没有我们的反思机制来的简单直接，所以我们可以这是一个场景，也是可以去做扩展的，这是我们的第二个可选的homework，我们等他把这个内容扩展。
	右边是它的这个日志。这个是他补充了一些内容，我看到确实多了一些。你光看这个对话框的宽度就能看得出来，变得更多了一些。这个是通过反思机制去针对一些特定的场景和内容的分布情况可以去做。然后同时还要注意一个点，就是提醒大家的我们的chat history，就是我们的gradual的chatbot有一个history。它不需要去保留在这个反思机制中间过程当中的生成内容。理论上它只需要保留最终的这个生成版本，就你满意的这个版本，那这个也是一个可以选择。
	Homer第三个其实就是这个前端，就是我们经过了这0.1到0.7的七个版本，相信大家看到了77IBPT这个多模态的agent集成了很多模型的能力，很多agent。现在的这个gradual框架，它虽然支持多模态的chatbot。你要硬说它能满足我们的功能性上的要求，但是它的U这个交互上面，它的这个展现方式上面，其实还有很多可以优化的点。如果本身你是一个已经用过stream net，或者你是一个前端的研发，你有这方面的经验，甚至你把它集成到小程序APP里都可以。就是你可以去更换一个前端。然后更换一个前端不是目的，是为了去把这些像whisper像mini CPM这些东西能够把他的能力释放出来，然后更好的给这个用户提供串联的交互的体验。包括我们的智能配图，也能把配出来的图也在前端展现出来。
	所以最后的这个泡沫其实是一个三选一的，只要你完成了任意一个就达到了这个要求。但是如果你能都去尝试去做，甚至你自己想了一些方向那更好。这个是关于我们这个节课的作业，最后我们关于这个课程我们再来简单回顾一下，一起带大家。这个课程其实我们有三个agent作为主线，然后这些agent都通过了agent hub这个项目给串联了起来。大家应该还记得这个项目吗？在agent hub里面我们描述了这三个agent的使命，可以分别再去回看一下。
	首先我们看一下最后的ChatGPT。第三个在chat PPT里面我们明确的讲了它是一个。是一个多模态的智能助手，主要就是去提升企业办公自动化的效率。生成powerpoint，然后支持多种模态的输入，自动生成PPT，然后支持语音识别。Whisper支持图像处理与嵌入。我们图像处理支持用mini CPM来理解图像，也支持用刚刚我们这节课教的智能的配图，多语言的支持其实是在这个大模型这一侧，就原生支持的中英文我们都可以去生成，包括其他的语言语种你也可以去试一下，GPT s omi都是支持的。通过radio我们实现了一个简洁易用的GOI，它能够完成我们功能性上面的要求。
	然后这个版本的历史，其实一共有七个版本，从0.1一直到最后的这个0.7，大家在学习的过程当中是建议按照这个一个版本来啊不要一来就跳到0.7。你会有一种抓不住重点或者不知道怎么开始的这样的一些困惑。从最开始我们0.1版本实现了从markdown到一个PPT的一个流程，到0.2开始有引入布局的管理。0.3我们用这个encoding，用你内容的权重去实现了一个布局的编码，然后并且完成了动态的布局的一个设置，有layout group了。到0.4我们开始集成了语音识别的模型，whisper large v3，然后去完成了ASR。并且在0.4这个版本还引入了极简风格的幻灯片模板，一直沿用至今。
	0.5我们集成了多模态的模型，mini CPMV2.6，然后在我们的最低的GPU的资源条件下，我们可以跑起来V2.6的in 4量化版本。同时在0.5还支持了面向这些word文档，这些老的历史素材，一键把word变成我们的PPT的一个type。而且这个pipeline里我们不仅做到了DODOCX或者说word文档的解析。我们还引入了两个agent，content for matter和content assistant。Assistant来完成这个内容的进一步的适配，格式转换和优化，包括图像的自适应。然后在今天我们又讲了0.6版本，用image adviser去实现了自动配图，并且提供了一个i notebook，让大家去交互式的去了解，怎么样去把这个智能配图的四个阶段一步一步给做好。之后，在0.7我们为了让大家能够把新的PPT引入到生产环境，去做了核心模块的单元测试覆盖以及docker的集成。也是在0.7我们补全了它的read mi文档，就是大家可以看到的read me的这个文档。
	然后再我们看看第二个，这个language mental，这个是相对时间比较短。这个language mental我们只有四个版本的实现，我们在这个agency项目里面是一个承上启下的，因为它作为第二个agent，在第一个agent里面我们没有讲年前第二个agent里面，我们其实借助这个过程让大家去学习了南茜的这个LCELN graph，mart agent等等。同时language mental这个agent更多的是要让大家去了解，怎么样把一个非常好的有商业需求的一个场景，用最简单的方式，就是我们各种各样的prompt的设计。然后把radio能够引入进来做对话，包括多tape的设计，快速的去实现一个比如说hi echo是100分，那我们能实现一个60分、70分的一个版本。用可能一周的时间就能够达到这样的一个效果。
	当然你要再把这个70分做到90分，可能里面还会有很多的细节，一个最大的一个需要去做的点就是数据的积累。I echo比起language mental，它最大的优势就是它有雅思的数据，有网易有道的这么多年的积累的数据。但这些数据也不是无处可寻的，只要大家花心思，其实网上像雅思的这些数据包都有啊。只是说你要考虑到这个合规各方面的问题，你还要再做一些简单的处理。或者你不用雅思，用别的一些公开的英语的数据集也是OK的。
	然后最终我们其实实现了不同场景的多轮的模拟对话，还可以进行评价，也可以进行背单词闯关等等。第一个这个get up set al的这个agent，其实是讲的最细的，而且我们是面向零基础的。就是你可能连用开发实战营都没有上过，但是没有关系，could have city al agent。其实是希望让大家能够即使是一个小白，也能够通过他啊不要有太多的学习的障碍。或者你觉得有太多的学习的困难，也能够去快速的把AI agent的这些技术红利能抓住的一个第一个入门的agent。所以我们能看到它的迭代版本非常的细，而且支持多种不同的启动方式。
	在过程当中我们还穿插的介绍了很多的偏实战的一些经验和tricks，包括就patter的使用。然后我们看到的日志系统多种模式的运行，然后模型从开源换到本地化的这个欧拉玛，然后用单元测试的介入，然后新增不同的信息渠道，就不只是github热门的rapper，hike news上面的热门话题。以至于任何其实你想要了解到的信息源，都能够用这样的方式去做横向的扩展。然后再给你发送邮件，那你就可以非常好的去提升你获取有价值信息的效率。
	这个是给到agent想要解决的一个实际的问题，这个就是我们整个我们看到agent half项目的话，我们整个企业级agents课程的一个入门项目，入口项目。这个项目我回头应该也还会在不断的迭代，如果有一些新的想法，可能也会在里面去做增加。希望大家能通过这个课程，这三个agent以及在这个课程当中穿插的agent开发的核心技术的一些知识点和要领，把握住AI agents的技术红利和机会。好，谢谢大家。我们的企业级agency的课程就正式的完结了。好，看看大家还有没有什么问题。我们关于这节课和整个这门课。
	大家有什么问题吗？
	后续学期有更新课程的话，本期也会相应看到吗？是的，按以下方法更新。按以下方法更新。
	freeze . 
	in store。我没太听懂你这是在干什么。这个同学。我没有太看懂你的这个pap是在干什么。对，就你自己的环境你prays了，然后你又去把它更新到特定的对，我实在没看懂你你到底想干嘛。对，然后多智能体我也不确定你说的多智能体是一个特定的框架还是什么。如果你或者说我换一种问法，就是你觉得language mental和ChatGPT是不是。
	多智能体的项目呢？
	如果你问出了哪个项目最适合引入多智能体，我就会以为你认为chat PPT和language mental不是多智能体的项目。所以我就疑惑，什么叫多智能体的项目？是像这个反思机制一样，一定要两个agent之间互相在一个workflow里调用，或者在一个框架里调用，或者说nang graph和chap t的本身的这个组织的代码有什么本质的不同吗？其实没有，对吧？
	然后这个反思机制是用在哪儿呢？是用在内容的迭代上。我也讲到了现在PPT可以用反思机制来做内容的迭代，这个是可以引入的，但它的代价就是过程当中会需要等一等。然后你需要设计好场景，就是需要内容做深化，还是要做不同语言的，就同时生成中文、英文的或者巴拉巴拉，这个其实是需要场景化去设计，做设计的对。是不是只有后两个项目可以基于这个基础继续产品化？我不懂，就是我不希望同学问我产品化的问题，因为这个太虚了，这个问题太泛了，没法回答。什么叫产品化？你可以先定义一下这个，我们再来探讨。
	看大家有没有什么想要去深入探讨的问题，咱们现在还有人在线上吗？在线上的打个一。
	Agent的课程有QA直播吗？我们一期没有QA直播。对，后面的近期他们会有2周一次的QA直播。
	这个同学你关于这快门这个问题我实在不太能理解。对，就这么说，就是这个requirements正常来说一个正常的逻辑它是怎么来的？首先你是一个干净的环境，然后它什么都没有。你用康达去创建了一个虚拟环境，它是干净的，它只有python的标准库。然后你再开发一个项目，这个项目需要引入一些非标准库的。这个python你就引入，引入之后你就记录它是什么版本，就这么简单。然后我实现了一个python文件去帮你自动的记录，就是这个merge reliance。对，然后我在get还是我忘了是在get up now里面，好像是在get里面引入的对，这个文件你可以再去看一看，如果你本地的环境的包跟我有冲突，那么你就直接去执行一下这个文件，你就知道冲突是什么了。
	它会帮你自动匹配，就是你的requirements和你的环境里的包版本对不上，他会告诉你，我记得在是在给他city里面引入的，然后会去讲，我看一看是不是。
	对，然后你就可以去看了。
	看大家还有什么别的问题吗？
	我印象中是在。
	那反正就是language mental。
	就是解决这个包的问题，应该是之前讲过的。
	对，在language mental里面当时就引入过。对，好像也是有个同学问这个包的问题。这俩文件是完全一样的。对它实现的功能就是你有一个requirements，你又有一个环境你去执行它它就会告诉你requirements里面的哪些包跟你就是你的环境里的包跟requirements里的包是有冲突的。然后这个展现形式跟git的这个冲突形式是一样的。
	大家还有什么问题吗？没问题的话，我们就到这里了。有个同学问agent的工作流串联特征体现在哪里？这个我没有太懂，这个agent工作流的串联特征是啥概念？如果你问的是这个n graf的话，那确实没有用，因为我们是想把它留成一个作业的形式来做的，这是我们的作业2，我想了想这个代码单独讲一节课意思也不大。就是理论上把那部分的代码引入进来，再跟radio去做一个集成，其实是一个蛮好的homework。然后agent的工作流程，其实你问这个问题挺让人伤心的，就是感觉应该是没有好好去听这个课程。你再回想一下我们的word到PPT这里面是不是有一个很重要的agent的串联，包括外部的tool function，dogs puzzle到两个agent的串联，content for matter和我们的content assessment，到最后再反馈到前端类似的其他也有一些agent的工作流。但我不知道为什么会有这个疑问。对，看大家还有什么别的问题吗？
	好，要是大家没什么别的问题，我们就到这里，大家可以在群里再积极的交流。好，今天就到这里，我就吃饭去了。