### 第5章 ChatGPT中的提示工程
大语言模型（LLM）的基础知识以及提示工程（prompt engineering）的一些应用和技巧在前面章节已经做了讲解。

作为引爆这一波大语言模型技术和应用浪潮的关键角色，ChatGPT是最受关注的一款产品，首先是其背后的一系列GPT模型的能力，其次是基于模型构建出来的支持流畅对话问答的交互体验，都令人印象深刻。基于ChatGPT，可以进行对话、问答，也可以做更高级的任务，如文本概括、数学推理、代码生成等。近期OpenAI基于ChatGPT推出更多衍生能力，包括函数调用、插件等，这些极大地扩展了模型的能力，也建构起围绕ChatGPT的生态系统。 

本章着重讲述ChatGPT的能力，以及基于ChatGPT的提示工程和相关应用场景，包括文本分析、内容生成、编程等应用，也会对函数调用、插件（plugin）等做相应介绍。

### 5.1 ChatGPT的基本模型设置
通过提示词使用ChatGPT的时候，一般有两种方式，一种是通过ChatGPT UI直接进行交互，一种是通过程序调用ChatGPT的API与模型进行交互。通过API调用模型的时候，ChatGPT提供了一些不同的模型参数，通过这些模型参数的设置，可以获得不同的提示结果。两个最基本的参数如下。
- （1）temperature：简单来说，temperature的参数值越小，模型会返回越确定的一个结果。如果调高该参数值，大语言模型可能会返回更随机的结果，也就是说这可能会带来更多样化或更具创造性的产出。在实际应用方面，对于质量保障等任务，可以设置更低的temperature值，以促使模型基于事实返回更真实和简洁的结果。对于诗歌生成或其他创造性任务，可以适当调高temperature参数值。 
- （2）top_p：同样，使用top_p（与temperature一起称为核采样的技术），可以用来控制模型返回结果的真实性。如果需要准确和真实的答案，就把参数值调低。如果想要更多样化的答案，就把参数值调高一些。

一般建议是改变其中一个参数就行，不用两个都调整。除以上两个参数外，ChatGPT还有其他不少参数也可以设置，例如以下两个重要参数。 
- （1）presence_penalty：介于-2.0和2.0之间的数字。正值越大，表示已经出现过的字符再次出现的概率会降低。 
- （2）frequency_penalty：介于-2.0和2.0之间的数字。正值越大，表示出现过的频率比较高的字符再次出现的概率会降低。 

在某些任务中通过合理设置以上模型参数，可以起到更好的效果。

### 5.2 提示词的基础知识回顾
本节对提示词的基础知识做一个简单回顾，ChatGPT一般可以通过简单的提示词获得大量结果，但结果的质量与提供的信息数量和完善度有关。一个提示词可以包含传递到模型的指令或问题等信息，也可以包含其他详细信息，如上下文、输入或示例等。可以通过这些元素来更好地指导模型，并因此获得更好的结果。这也是本书围绕提示工程所探讨的重点，如何设计出最佳提示词，用于指导语言模型帮助用户高效完成某项任务。

#### 5.2.1 提示词格式
标准提示词应该遵循以下格式：

<问题>或者<指令>


这种可以被格式化为标准的问答格式，如：

Q：中国的首都是哪里？

A：北京


以上的提示方式，也称为零样本提示，即用户不提供任务结果相关的示范，直接提示语言模型给出任务相关的回答。对于一些简单的任务，通过这种方式，ChatGPT直接能返回不错的结果。

相应的还有少样本提示范式，即用户提供少量的提示范例，如任务说明等。少样本提示一般遵循以下格式：

<问题><答案>

……

<问题><答案>

<问题>?

可以根据任务需求调整提示范式，例如可以按以下示例执行一个简单的分类任务，并对任务做简单说明。

- 提示词：

  - 这个真不错！ //褒义

  - 这个很坏！ //贬义

  - 这部电影真精彩！ //褒义

  - 这场演出真差！ //
-
- 输出结果：贬义

语言模型可以基于一些说明来了解和学习某些任务，而少样本提示正好可以赋能其上下文学习的能力。

#### 5.2.2 提示词要素
前面章节已经讲过不少提示工程相关的技巧，这里简单总结一下基本要素，包括以下几种。
- （1）指令：想要模型执行的特定任务或指令。 
- （2）上下文：包含外部信息或额外的上下文信息，引导语言模型更好地响应。 
- （3）输入数据：用户输入的内容或问题。 
- （4）输出指示：指定输出的类型或格式。 

提示词所需的格式取决于需要完成的任务类型，并非所有以上要素都是必需的，在后面的具体示例中会讲到。

#### 5.2.3 设计提示的通用技巧

1. **从简单开始**

提示的设计通常是一个迭代的过程，需要大量的实验来获得最佳结果。ChatGPT这样的UI平台提供了一个很好的实验起点。


可以从简单的提示开始，不断添加更多的元素和上下文，来优化得到更好的结果。在此过程中，需要对提示进行版本控制。一般来说有几点需要注意，包括具体性、简洁性和简明性等。

对于涉及许多不同子任务的大任务，可以尝试将任务分解为更简单的子任务，避免在提示设计过程中一开始就添加复杂的内容。

2. **指令**


通常可以使用命令来指示模型执行各种简单任务，例如“写人”“分类”“总结”“翻译”“排序”等，从而为各种简单任务设计有效的提示。

在实验过程中，可以尝试使用不同的关键字、上下文和数据，尝试不同的指令，以适合特定用例和任务。通常情况下，上下文与要执行的任务越具体和相关，效果越好。

很多文献和实验指出，指令放在提示的开头或者最后会比较有效。建议使用一些清晰的分隔符，如“###”，来分隔指令和上下文。

3. **具体性**


对希望模型执行的指令和任务要非常具体。提示越具体和详细，结果就越好。在提示中使用示例会非常有效，可以以特定格式获得所需的输出。

例如，从一段文本中提取特定信息的简单提示。
- 提示词：提取以下文本中的机构名。
- 所需格式：机构：<逗号分隔的机构名称列表>
- 输人：虽然这些发展对研究人员来说是令人鼓舞的，但仍有许多谜团。里斯本未知的香帕利莫德中心的神经免疫学家Henrique Veiga-Fernandes说：“我们经常在大脑和我们在周围看到的效果之间有一个黑匣子。”“如果我们想在治疗背景下使用它，我们实际上需要了解机制。”
- 输出结果：机构：里斯本未知的香帕利莫德中心

4. **精确性**


提示通常要具体和直接，例如，想了解提示工程的概念，可以这样写：解释提示工程的概念，保持解释简短，只有几句话，不要过于描述。

上面的提示中不清楚要使用多少句话和什么样的风格。虽然可以通过上面的提示获得良好的响应，但更好的提示是非常具体、简洁和直接的。例如：使用2～3句话向高中学生解释提示工程的概念。

5. **做还是不做？**

设计提示时的另一个常见技巧是避免说不要做什么，而是说要做什么。这鼓励更具体化，并关注导致模型产生良好响应的细节。

以下是一个电影推荐聊天机器人的示例。
- 提示词：以下是向客户推荐电影的代理程序。不要询问兴趣。不要询问个人信息。
  - 客户：请根据我的兴趣推荐电影。
  - 代理：
  - 输出结果：当然，我可以根据您的兴趣推荐电影。您想看什么类型的电影？您喜欢动作片、喜剧片、爱情片还是其他类型的电影？

以下是更好的提示。
- 提示词：以下是向客户推荐电影的代理程序。代理负责从全球热门电影中推荐电影。它应该避免询问用户的偏好并避免询问个人信息。如果代理没有电影推荐，它应该回答“抱歉，今天找不到电影推荐。”。
  - 客户：请根据我的兴趣推荐一部电影。
  - 代理：
  - 输出结果：抱歉，我没有关于您兴趣的任何信息。不过，这是目前全球热门的电影列表：[电影列表]。希望您能找到喜欢的电影！

### 5.3 文本任务
#### 5.3.1 文本概括
自然语言生成的标准任务之一是文本概括。文本概括可能涉及不同的风格和领域。事实上，语言模型最有前景的应用场景之一就是能够快速概括出易于理解的文章大意和相关概念。下面使用提示词尝试一个简单的概括任务。

假设想了解抗生素的相关信息，首先可以给出这样的提示：
- 解释抗生素
- A:
- 输出结果为：抗生素是一类能够抑制或杀灭细菌的药物，通常用于治疗或预防细菌感染的疾病。抗生素可以由生物（如细菌、真菌或放线菌）产生，也可以人工合成或改造。

抗生素的作用机制不尽相同，但大致可以分为以下几类。
- 抑制细胞壁合成：例如青霉素、头孢菌素、万古霉素等，能够干扰细胞壁的重要组成部分肽聚糖的形成，导致细胞壁薄弱、易破裂或透水。
- 抑制蛋白质合成：例如四环素、氨基糖苷类、大环内酯类等，能够干扰细菌的核糖体功能，从而阻止蛋白质的转录或翻译。
- 抑制核酸合成：例如喹诺酮类、甲硝唑等，能够干扰细菌的DNA复制、修复或转录，从而影响基因表达和遗传稳定性。 
- 抑制代谢途径：例如磺胺类、甲氧苄啶等，能够干扰细菌的叶酸合成或利用，从而影响核酸和氨基酸的合成。

抗生素的使用需要根据感染的类型、部位、程度和耐药性来选择和剂量。

在问答形式中，“A：”是一种明确的提示格式。

因为模型返回的信息比较多，如果想要进一步提炼它，可以通过提示词去指导模型用一句话总结相关内容。
- 提示词：用一句话解释上面的信息。
- 输出结果：抗生素是一类能够杀或控制细菌的药物，它们通过破坏细菌的细胞壁、蛋白质、核酸或代谢来发挥作用，但要根据具体情况合理使用。

本示例是模型在没有过多关注上文输出内容准确性的情况下，尝试用一个句子来总结段落内容。

#### 5.3.2 信息提取
ChatGPT不仅可以用于执行文本总结这样的自然语言生成任务，还可以用于执行信息提取、文本分类等其他自然语言处理（NLP）任务。

以下例子使用示例提示词从指定段落中提取信息。
- 提示词：在研究论文中，作者贡献声明和致谢部分应该清楚明确地说明作者在撰写手稿和分析时是否以及在多大程度上使用了AI技术，例如ChatGPT，并指出使用了哪些大语言模型。这样可以提醒编辑和审稿人更仔细地检查手稿是否存在潜在的偏见、不准确或不恰当的引用。同样，科学期刊也应该在选择提交的论文时公开他们使用大语言模型的情况。

指出上文中提到的AI技术。
- 输出结果：根据题目的要求，上文中提到的AI技术是：
  - 使用ChatGPT来撰写手稿和分析的方法；
  - 使用大语言模型来选择提交的论文的做法。

我们也可以通过许多方式改进以上结果，在此基础上进一步利用这种能力来构建更强大的产品和体验。

#### 5.3.3 文本分类
对于文本分类任务，除了指令，还需要思考如何在提示词中包含相关语境和其他要素，如输入数据和示例。
- 提示词：将文本按中立、负面或正面进行情感倾向分类。
  - 文本：我们这次玩得还行，吃得还可以。
  - 情感倾向：
  - 输出结果：中立

本例给出了对文本进行分类的指令，模型做出了正确响应，判断文本类型为“中立”。如果有一些文本分类任务的分类目标要特殊一些，除了规范输出内容的范围，用户可以考虑采用前文提到的少样本提示（Few-shot Prompting）方法。

#### 5.3.4 问答
问答是ChatGPT特别常见的使用场景，有些问题可以直接通过模型回答，有些需要给出上下文或相应的提示词才能得到答案。如前所述，提示词可以通过指令、上下文、输入和输出指示以改进响应结果。虽然这些要素不是必需的，但如果指示越明确，响应的结果就会越好。以下问答示例可以说明结构化提示词的重要性。
- 提示词：基于以下语境回答问题。如果不知道答案的话，请回答“不确定答案”。
  - 语境：Teplizumab的起源可以追溯到新泽西州的一家名为Ortho Pharmaceutical的药企。在那里，科学家制造了这种抗体的早期版本，称为OKT3。该分子最初来自老鼠，能够与T细胞表面结合，抑制它们的杀伤能力。1986年，它被批准用于帮助预防肾脏移植后的器官排斥，成为第一个被允许用于人类的治疗性抗体。
  - 问题：OKT3最早起源于哪里？
  - 答案：OKT3最早起源于老鼠。

#### 5.3.5 对话
ChatGPT已经支持了基本的对话能力，通过提示工程可以进行更有趣的工作，例如，指导模型和系统该如何表现，指定它的行为意图和身份。在构建客服聊天机器人之类的对话系统时，这项功能尤其有用。

例如，可以通过以下示例创建一个对话系统，该系统能够基于问题给出技术性和科学的回答。这种应用场景有时也称为角色提示（Role Prompting）。
- 提示词：以下是与人工智能助理的对话，语气应该专业、技术性强。
  - 人：你好，你是谁？
  - AI：我是一个人工智能助理，你可以叫我AI。我可以帮你完成一些任务，你想让我做什么？
  - 人：你能告诉我黑洞是怎么形成的吗？
  - AI：
  - 输出结果：当然可以。黑洞是一种天体，它的质量非常大，以至于它的引力超过了光速，所以光也无法从中逃脱。黑洞通常是由恒星坍缩或合并产生的，比如在恒星耗尽了核燃料后爆发成为超新星，或者两个中子星或黑洞相撞。黑洞的边界叫做视界面，它是一个没有返回的点。黑洞的内部结构仍然是一个未解之谜。

下面，我们让它给出更易于理解的答案。
- 提示词：以下是与人工智能助理的对话。请给出易于理解的答案，最好是小学生都能看懂的那种。
  - 人：你好，你是谁？
  - AI：我是一个人工智能助理，你可以叫我AI。我可以帮你完成一些任务，你想让我做什么？
  - 人：你能告诉我黑洞是怎么形成的吗？
  - AI：
  - 输出结果：你问的问题很有趣。黑洞是一种特殊的天体，它的引力非常非常大，它可以吸住任何东西，包括光线。黑洞是怎么形成的呢？有时候，星星会变得很老很大，它们会爆炸成为超新星。超新星会把一部分物质向外扔掉，剩下的物质则会坍缩到一个很小很小的点上，这个点就是黑洞。黑洞因为太小太密集了，所以引力就变得特别强。你能想象吗？

### 5.4 编程
得益于大语言模型在训练数据中的代码数据，以及模型自己的自然理解和生成能力，大语言模型在代码生成、调试、优化、注释等方面表现出很大的潜力，例如GitHub Copilot就是一个很好的产 
