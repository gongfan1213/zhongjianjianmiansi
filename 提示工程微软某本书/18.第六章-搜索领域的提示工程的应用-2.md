
2）“创造”（creative）模式，该模式旨在给出丰富多彩、具有个性化描述的答案，适合喜欢探索和交流的用户。 

3）“平衡”（balanced）模式，该模式综合了前两种模式的优点，给出长度适中、既包含搜索结果又有一定描述性的答案，适合不太在意具体聊天风格的用户。 

表6 - 2展示了不同用户查询问题在不同聊天风格下BingChat生成的回复示例。

表6-2 三种不同聊天风格下的例子

![image](https://github.com/user-attachments/assets/8400fc98-19ed-4178-8b0d-b330659d2ac5)

![image](https://github.com/user-attachments/assets/23484af3-8c3e-440d-960b-1b51b6764bee)


|聊天风格|用户查询问题|
| ---- | ---- |
|精确模式|（展示了关于“The Mini Cheetah”相关问题的回复界面，包括搜索提示和回答内容，如“What is the Mini Cheetah?”“What makes the Mini Cheetah unique?”“How is the Mini Cheetah designed?”等问题及对应的回答，还给出了一些相关问题提示如“What are some other features of the Mini Cheetah?”等）|
|创造模式|（展示了以唐纳德·特朗普的口吻为萨蒂亚·纳德拉生成的一些可能的面试问题，如“Satya, you're the CEO of Microsoft. a very big company, very successful. How do you feel about AI?”等一系列问题 ）|
|平衡模式|（展示了关于拜登总统相关新闻文章的搜索界面，如“Trump or DeSantis? Democrats aren't sure who they'd rather see Biden face in 2024”等新闻标题，并询问用户想了解更多关于哪条新闻 ）|

### 3. 必应图片创造器

新必应的聊天模式中集成了的多模态的功能——必应图片创造器（image creator），如图6 - 4所示。必应图片创造器基于OpenAI的视觉 - 语言预训练模型DALL·E，通过解析用户输入的文字提示（text prompt），来生成逼真的人工智能图像。文字提示中可以包含对目标图像的各种属性和条件的描述，如类型、风格、颜色、位置和动作等，常见的提示格式如表6 - 3所示，用户也可以在多轮对话中不断添加或修改提示来微调生成的图像。必应图片创造器使得用户仅凭文字就能创作出精美且个性化的图片，有效地解决了用户通过搜索引擎查找图片时可能遇到的以下痛点：

- 网络上不存在符合用户需求的图片；

- 网络上存在的图片受版权保护而无法随意使用；

- 网络上找到的图片质量低劣，分辨率不够清晰；

- 用户缺乏时间和技能利用现有图片制作出自己想要的图片。

必应图片创造器赋予了新必应一种多模态交互的能力，让用户可以通过提示来挖掘自己的想象力，创建有趣、富有创意和个性化的图像内容。


图6-4 必应图片创造器功能
（展示了必应图片创造器生成“a logo for a pet hospital”相关logo的界面，有四个不同的logo示例 ）

表6-3 常用的图片创造器提示模板

|提示词描述|形容词|名词|动词|风格|
| ---- | ---- | ---- | ---- | ---- |
|生成一张图片：戴着墨镜的毛茸茸的生物，数码艺术|毛茸茸的|生物|戴着眼镜|数码艺术|

## 6.1.3 必应普罗米修斯模型

新必应聊天体验背后的技术支撑，是必应团队称为普罗米修斯（Prometheus）的模型，它能够将必应搜索的实时排序结果与OpenAI最新的GPT - 4模型进行有效的结合。如图6 - 5所示，普罗米修斯模型的核心在于利用必应协调器（Bing Orchestrator）来协同搜索和大语言模型两个组件，从而生成满足用户需求的聊天回复，进一步提高用户的搜索体验。

具体来说，当一个用户查询发送到BingChat时，必应协调器作为中心节点依次执行以下流程。

1）用户查询的近似最近邻检索（ANN retrieval）：若存在与当前查询完全一致或相似度超过一定阈值的历史查询，则直接返回对应的回复，不再进行后续步骤。

![image](https://github.com/user-attachments/assets/0ff7651d-8cd2-4917-9c7d-892fd92fa37b)


图6-5 必应普罗米修斯模型

（展示了普罗米修斯模型的工作流程，包括User query & Conversation context输入，经过Bing Orchestrator协调，与Bing Index, Ranking & Answers和Next Generation GPT交互，最终输出Chat answer ）

2）冒犯性查询检测（offensive query detection）：对查询进行语义分析，判断用户输入是否包含不礼貌或不恰当的内容，如果存在冒犯性内容，则拒绝提供回复。 

3）提示GPT - 4模型来判断当前查询是否需要利用搜索结果的信息来生成回复：

- 如果需要，则继续提示GPT - 4模型给出合适的搜索查询并调用必应API获取实时的排序结果；

- 如果不需要，则直接进行下一步。 

4）提示GPT - 4结合外部的知识源（如果有搜索结果）或者仅根据自身内部知识库来生成回复。 

5）对模型生成的回复进行冒犯性以及提示泄漏（prompt leakage）检测。 

6）提示GPT - 4模型来给出下一轮相关或引导性的问题。 

7）返回回复或者结束聊天。

对于以上步骤，首先可以看到查询接地是其中重要部分之一。查询接地后，以必应搜索结果作为重要的外部知识来提供相关性强且时效性好的额外信息，使得GPT - 4模型能够回答最近的问题并提高答案的可信度和准确度。这部分内容将在第6.2节再做详细的介绍和分析。其次，另一个重要部分是必应协调器在各个步骤中使用的提示链（prompt chain）。例如，在步骤3）中需要设计提示以利用GPT - 4判断是否有足够的信息完成一次回复，以及设计提示生成发送给必应搜索后端的二次查询；在步骤4）中设计提示以结合实时的搜索结果来给出回复等。

必应普罗米修斯模型通过精心设计的提示链，将大语言模型的回复锚定在传统的搜索结果上，用户不需要再自行筛选和浏览多条搜索结果，提升了搜索体验，让搜索变得更具交互性和趣味性。


# 6.2 检索增强的大语言模型

大语言模型利用大规模文本数据进行预训练，可以在很多自然语言处理任务中取得优异的性能。但大语言模型也存在一些不足之处，尤其是在生成文本时容易出现幻觉现象，即生成的内容与事实不符或不合逻辑。

为了缓解这一问题，一种可行的方法是将搜索与大语言模型结合起来，利用检索到的相关文本来指导或约束大语言模型的生成过程，从而提高生成质量和可靠性。如6.1节在新必应聊天体验中利用了查询接地的技术来辅助大语言模型进行回复。这种方法称为检索增强的大语言模型（retrieval - augmented LLM）。

本节首先对大语言模型的幻觉问题进行举例说明和分析，其次概述检索增强的大语言模型的基本思想和框架，接着介绍两个近期公开的检索增强型大语言模型的具体实现和效果，以供读者深入了解。


# 6.2.1 大语言模型的幻觉问题
幻觉问题导致大语言模型生成与事实不符或者毫无根据的内容。这些幻觉信息往往具有一定的逻辑连贯性和表面合理性，但实际上没有依据现实世界中的证据或者推理过程，甚至可能违背常识或者道德标准。

硅谷一家对话人工智能初创公司（Got It AI）的首席执行官彼得·瑞兰曾披露，ChatGPT系统在与用户交流时有15% - 20%的概率会产生幻觉信息，即在胡编乱造而不是基于事实回答问题。

幻觉问题一定程度限制了大语言模型在专业领域（如医学、法律、金融和军事等）的应用价值和安全性，因为这些领域对信息的准确性和可靠性有着非常高的要求。因此，如何消除或者减少大语言模型中的幻觉问题，提高其在各种场景下的有效性和可控性，是当前学术界和工业界共同关注和努力探索的方向。

表6-4 ChatGPT的幻觉问题示例

|提示词|ChatGPT|
| ---- | ---- |
|杜甫的静夜思|《静夜思》是唐代诗人杜甫的代表作之一。以下是《静夜思》的原文：床前明月光，疑是地上霜。举头望明月，低头思故乡。《静夜思》是杜甫创作的一首五言绝句，采用了平淡自然的语言，却能够通过几个简单的意象，表达出深沉的情感。这首诗被广泛传诵，成为杜甫最具代表性的作品之一，也是中国古代诗歌中的经典之作。（实际《静夜思》作者是李白 ）|
|西班牙男篮拿过奥运冠军吗|是的，西班牙男篮曾经获得过奥运冠军。在2008年北京奥运会上，西班牙男篮战胜了美国男篮，赢得了金牌。这是西班牙男篮历史上第一次获得奥运冠军。此外，他们在2012年伦敦奥运会上获得了银牌，在2016年里约热内卢奥运会上再次获得了银牌。西班牙男篮一直以来都是国际篮球比赛中的强队，并在多个国际赛事中表现出色。（实际西班牙男篮未在奥运会战胜美国男篮夺冠 ）|
|福建舰|福建舰是中国人民解放军海军的一艘航空母舰。它是中国第一艘国产的航空母舰，以福建省命名，代号为001A型。福建舰的正式名称是中国海军辽宁舰。辽宁舰最初是苏联在20世纪80年代建造的库兹涅佐夫号航空母舰，后来在中国进行了改装和现代化升级。福建舰于2012年9月25日正式加入中国人民解放军海军，并在同年进行了命名和下水仪式。它具备一定的航空母舰作战能力，可以搭载战斗机、直升机和无人机，并用于海上作战、空中支援和训练等任务。（存在信息错误 ）|

目前认为大语言模型出现幻觉问题的可能原因有以下几点。
- 模型在训练过程中吸收了一些错误或者不准确的知识，这些知识被编码在模型权重中，并在预测阶段被激活。 
- 模型当前所拥有的知识并不完整或者全面，导致它在处理一些特定领域或者场景的问题时缺乏足够的背景信息和理解推断能力。 
- 模型当前所拥有的知识已经过时或者落后于最新的发展和变化，使得它在回答一些涉及时效性或者更新频率高的问题时出现错误。

针对大型语言模型存在的幻觉问题，目前一些可能的解决方法有：
- 检索增强的生成（retrieval - augmented generation）：这种技术可以从外部知识库中检索与问题相关的信息，并将该信息作为大语言模型的输入。通过在预测时提供与知识库相关联的数据（附加到问题提示中），可以将纯粹的生成问题转化为基于已有数据进行简化搜索或摘要的问题，从而减少幻觉信息的产生。 
- 自我评估（self - evaluation）：有研究发现，如果要求模型不仅生成答案，而且还给出答案正确的概率，那么这些概率在大多数情况下是良好校准的。也就是说，模型大多数情况下知道自己对某个问题的把握程度和不确定性。可以在生成回答时同时获取模型对答案是否正确的概率评估，并在后处理时使用它们（如丢弃可能错误或者低置信度的回答）。 
- 思维链提示（chain - of - thought prompt）：也有研究表明，在给定一个需要多步推断或者复杂逻辑推断的任务时，如果能够提供一些将任务分解为步骤（即思维链）的示例，并将各个步骤的结果聚合起来，那么模型能够在很少的示例下显著提高性能。 
- 人类反馈的强化学习（reinforcement learning from human feedback）：人类评估者来审查模型的回答，并选择最适合用户提示的回答，然后利用这个反馈来调整模型的行为。

# 6.2.2 检索增强的大语言模型框架

检索增强的大语言模型是一类在生成过程中动态地利用外部知识源的大语言模型。外部知识源可以包括各种结构化或非结构化的数据，如知识库、文档集合和网页列表结果等。

检索增强的大语言模型通常由两个核心组件构成：检索组件和生成组件。检索组件负责根据输入的查询（如一个问题或一个上下文）从外部知识源中检索出与之相关的证据（如实体、关系、文档片段和网页等），并将其作为输入的一部分传递给生成组件；生成组件则负责根据输入的查询和检索到的证据综合地生成输出（如一个回答或一个对话）。图6 - 6展示了检索增强的大语言模型的基本框架。

![image](https://github.com/user-attachments/assets/9839a49d-98df-4783-b487-814e8fd265ee)


图6-6 检索增强的大语言模型基本框架

（展示了外部知识源（Knowledge Store）经过Index处理，进入检索与生成模块（包含Retriever和LLM ），最终输出结果 ）

接下来的小节将介绍近期学术界提出并已经开源的两个具有代表性的检索增强型大语言模型。

## 6.2.3 开源实例
### 1. 开放域问答中通过检索增强大语言模型
开放域问答（open - domain question answering）是指在没有限定特定领域或知识源的情况下，根据用户提出的自然语言问题，从海量的文本数据中检索或生成正确、完整的答案。本小节介绍的第一个开源实例，是来自于谷歌DeepMind的一项工作——在开放域问答任务中利用互联网检索来增强大语言模型。谷歌研究员Angeliki Lazaridou等人提出使用少样本提示（few - shot prompting）的方法，让大语言模型可以从检索到的相关文档中抽取或生成符合查询问题要求（如事实性、实时性和多样性）和上下文逻辑的回答。

少样本提示方法的整体流程主要包括3个步骤：①给定一个查询问题，使用谷歌搜索引擎从互联网上检索出一组与问题相关性较高的文档，同时将检索到的文档切分为可能包含答案的事实段落（evidence paragraph）；②构造查询问题的少样本提示，引导大语言模型为每个事实段落生成一个候选回答（answer candidate）；③使用同一个大语言模型对所有生成的候选回答进行打分和排序，并选择最有可能正确的答案。下面对各个步骤做详细介绍。

（1）检索 使用谷歌进行文档检索。

给定一个问题q，将q作为查询内容向谷歌搜索发送请求，获得前20个URL并解析HTML内容以提取出包含的文本内容。这样就得到了每个问题q对应的一组文档D。文档D的内容可能包含了一些大语言模型没有存储过的知识（如最新的消息），这些知识可以作为模型回答问题时的事实依据。D中的文档长度可能超过了大语言模型能够处理的最大输入序列长度。因此谷歌研究员将每篇文档切分成由6个句子组成的事实段落，并对问题q以及切分后的所有事实段落进行TF - IDF向量化，最后根据余弦相似度得分选择前50个事实段落作为事实段落集P。

谷歌研究员发现，相比于仅仅使用维基百科这种经过人工筛选和编辑的静态知识源来进行问答任务，利用谷歌搜索可以让大语言模型获取更多样且不断更新的网络文本，在一定程度上提高了检索效果和覆盖面。

（2）提示 利用少样本提示对事实段落条件化。

在获取了与问题q相关的事实段落集合P之后，谷歌研究员采用了少样本提示来引导大语言模型根据P中的事实段落生成候选回答。少样本提示是指通过人工构造少量示例来提示大语言模型如何解决特定任务的技术。这里使用了k - shot提示（k - shot prompt），即在提示中先展示k个事实段落、问题和答案的三元组示例，然后再给出目标问题q。表6 - 5展示了谷歌研究员提出的一个k - shot提示的模板。

表6-5 事实段落条件化所用的k-shot提示模板

![image](https://github.com/user-attachments/assets/9a86fbad-093d-4ae8-a1df-c202946be5e1)


|k - shot提示|内容|
| ---- | ---- |
| |事实段落$p_{a1}$: <内容>…<br>问题$q_{a1}$: <内容>…<br>答案$a_{a1}$: <内容>…<br>…<br>事实段落$p_{a15}$: <内容>…<br>问题$q_{a15}$: <内容>…<br>答案$a_{a15}$: <内容>…<br>事实段落$p_1$: <内容>…<br>问题$q_1$: <内容>…<br>答案$a_1$: |

在所有的实验中，谷歌研究员将k统一设置为15。并且根据不同的数据集，从相应的训练集或开发集中随机抽取k个三元组来构造小样本提示。

（3）排序 采样多个候选答案并用大语言模型计算概率。

通常来说，增加模型的参数量、扩大训练数据的规模量，以及加大训练时长可以提高模型在各种少样本任务中的性能。谷歌研究员认为加大大语言模型推断计算的时长也可以获得相似甚至更好的效果。例如，可以采样出多个候选答案，然后利用大语言模型计算概率来对候选答案进行重新排序和选择。

具体来说，P包含了所有按照与问题q的TF - IDF相似度排序得到的事实段落，对于每个事实段落$p_i$，将其与问题q一起拼接到少样本提示后面，利用大语言模型产生多个候选答案$a_{i,j}$（每个事实段落生成4个候选答案）。这一步目的是增加候选答案空间的覆盖面，一定程度上可以提高生成过程中可能存在的错误或偏差。然后使用大语言模型作为概率打分模型，并考虑以下3种概率打分方式。

- 直接推断，选择能够使$P(a|q)=\sum_{j = 1}^{n}P_{tfidf}(p_{i}|q)\cdot P(a_{i}|q,p_{i})$值最大的候选答案。 

- 噪声信道推断，选择使$P(a_{i},q|p_{i})=\frac{P(q|a_{i},p_{i})\cdot P(a_{i}|p_{i})}{P(q|p_{i})}$值最


![image](https://github.com/user-attachments/assets/102561ff-eb08-49c4-91f7-3879fb7f0c41)
