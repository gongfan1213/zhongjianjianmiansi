### 提示工程：方法、技巧与行业应用
当答案空间是无限、连续的时候，也就是当人们试图在大量的、无结构的数据中搜索答案时，就需要用到更先进的自然语言处理技术和算法了。这些技术包括非结构化数据查询、模糊匹配或语义匹配、排序机制（返回的答案可能需要根据相关性、可信度或其他标准进行排序）、上下文相关搜索（搜索的答案取决于上下文，例如，同一个问题在不同的文档或时间点可能有不同的答案），以及动态搜索（随着数据的变化实时更新或调整答案）等。

此外，还可以通过模式匹配、语言模型、机器学习等技术手段，运用关键词、语境等信息来缩小寻找答案的范围，并评估答案的可靠性，从而挑选出最佳答案。这种方法通常应用于问答系统、语音识别系统等领域，以便更精确地回答问题。

#### 2.2.3 蓬勃发展的提示工程
1. **提示工程的应用**
   
虽然提示学习的应用领域很多，在现阶段，可用性和易用性最强的是提示工程，尤其是手动模板工程。

在很多情况下，应用提示工程都不需要显性地先生成模板再带入内容，而是直接手工构建完整的提示内容，直接输入给大语言模型，以获得期望的结果。在这样语境下的提示工程是一种通过设计恰当的输入提示来引导大语言模型生成期望输出的方法。简单来说，就是如何向模型提问，以便获得最佳答案。

它的核心思想是：设计一种有效的输入提示（prompt），以引导大语言模型生成我们期望的输出。

这些提示可以是问题、陈述或其他形式的文本，其目的是激发模型的知识和推理能力，从而得到满足特定需求的答案或建议。通过精心设计的提示，人们可以将模型的潜在能力发挥到极致，实现各种复杂任务的自动化处理。

在实际应用中，提示工程需要考虑多种因素，如模型的预训练知识、任务的难度和领域特性等。为了获得高质量的提示，研究人员通常需要进行多轮的实验和优化，以找到最佳的提示策略。

在这里需要先搞清几个概念：少样本（few - shot）、单样（one - shot）和零样本（zero - shot）。

这三个词后面还可以再接不同的词，可以接学习（learning），也可以接提示（prompting），如图2 - 9所示。它们接不同的词的时候，表达的含义是很不一样的。

![image](https://github.com/user-attachments/assets/f5bf9820-b19e-4c1b-83c6-12a72b8cbe44)


有些人可能会混淆这些概念。他们在说少样本或零样本时并不说明到底是学习还是提示，把这两个概念混在了一起，导致误解。读者在阅读相关文献时需要注意这一点。少样本/单样本/零样本学习和少样本/单样本/零样本提示是两件不同的事情。

2. **少样本/单样本/零样本学习**

首先介绍 * - shot learning。这几个学习最主要指的是利用模型完成分类任务的一些方法。

零样本学习（zero - shot learning）是指从未在训练数据中看到过的类别上进行学习的机器学习任务。这意味着模型需要能够在没有任何关于新类别的先验知识的情况下进行分类。在零样本学习中，模型的目标是学习一个从输入空间到语义空间的映射，这个映射将输入映射到一个已知的语义空间，然后再使用这个语义空间对新类别进行分类。这通常需要使用属性、语义嵌入或其他辅助信息来帮助模型进行泛化。

例如，我们训练了一个图片分类模型来识别动物，包括狗、猫、老虎、大象等几个类别。现在我们想要在测试集中识别河马，但我们的模型从未在训练数据中看到过河马这个类别。在这种情况下，我们可以通过描述河马的一些属性（例如，河马有四条腿、属于哺乳动物等）来生成一个河马的语义嵌入向量。然后再将这个向量映射到狗、猫、老虎、大象等类别的语义空间中。最后，我们可以使用距离度量或分类器来将河马分类到与其语义空间中距离最近的类别，如大象类别。

单样本学习（one - shot learning）是指分类模型从仅存一个的样本中学习一个新的类别。一个经典的单样本学习的例子是人脸识别。

假设我们想要训练一个模型来识别人脸，理论上每一个人都需要提供多张照片才能形成训练数据，但是某一个人（如Tom），我们只有他的一张照片用于训练。在这种情况下，我们可以使用卷积神经网络（CNN）来提取人脸图像中的特征，并将这些特征映射到一个低维空间，对应于不同的人脸类别。在训练阶段，我们将网络的输出与正确的人脸进行比较，以更新网络的权重。

在测试阶段，当我们输入一张照片后，模型首先从这个图像中提取特征，并将其映射到我们训练的人脸类别空间中。其次，模型在这个空间中寻找最近的样本，假设它离“Tom”的照片最近且这个距离低于阈值，就可以将输入的人脸图像分类为“Tom”。

少样本学习（few - shot learning）是一种介于单样本学习和传统的机器学习之间的学习任务。少样本学习尝试从非常少的训练样本中学习一个新的类别或任务。在少样本学习中，通常使用元学习的方法，如模型预训练、基于相似性的度量学习等。这些方法可以让模型在看到很少的样本时，快速地学习新的类别或任务。

当然，也可以通过数据增强把极少量样本生成更多样本。例如，在训练图片分类模型时，本来某一个类别只有5张图片作为训练数据，但是可以对这5张图片进行裁剪、翻转、变色、加滤镜等操作，生成更多的图片，用于训练。

3. **少样本/单样本/零样本提示**

在解释零样本提示（zero - shot prompting）之前要先解释一下提示（prompting）是什么意思。

前面介绍了提示学习的完整流程：要能够定制一个模板，还要能够把这个模板转成一个嵌入向量（embedding），然后把这个嵌入向量输入给语言模型，最后再得到这个语言模型直接的输出。也就是说，一定要能够直接去调用这个模型，才能够做提示学习。

但是如果人们无法直接访问模型本身，能够访问到的实际上是这个模型外面又封装了一层的服务（service），那可怎么办呢？最典型的比如ChatGPT，它实际上并不仅仅是一个模型，它实际上是一个在线服务。在这种情况下，人们可以输入给它一个自然语言的文本，但是这个自然语言的文本被转成了什么样的嵌入向量，人们看不见。模型直接输出又是一个怎么样的嵌入向量，人们还是看不见，它怎么再传回最终的输出的自然语言，人们仍然看不见。

在这种情况下，人们只能是去修饰输入给它的这些自然语言，然后指望通过对自然语言下的功夫，来得到一些结果。

零样本提示就是给语言模型一个指令，直接告诉语言模型要做什么。例如，用户把“白日依山尽，黄河入海流”这两句诗输入模型，让它翻译成英文，这就是零样本提示——直接发出指令，没有给例子。

单样本提示（one - shot Prompting）就是在零样本的基础上，又给出了一个例子，例如，用户先把另一首诗歌翻译成了英文，然后把那首诗及其翻译结果和“白日依山尽，黄河入海流”一起输入给语言模型，同时发出指令，要它翻译成英文。这样，在被告知“做什么”之后，语言模型就可以从这个例子中学习“怎么做”。

少样本提示（few - shot Prompting）延展了单样本提示，给语言模型不止一个例子，希望模型从这些提示中中学到更多的知识，然后帮助人们更好地完成任务。

图2 - 10展示了零样本/单样本/少样本提示的几个不同例子。

在图2 - 10的例子中，我们希望达到的效果是将中文的单词“烙饼”翻译为英文。

当使用零样本提示的时候，直接提出要求：“请将下列中文单词翻译为英文：烙饼 ->”——在这条提示中，只有指令和被要求翻译的词。当使用单样本提示的时候，除了零样本提示的内容，还在烙饼前面添加了一个中译英的例子：“苹果 -> apple”。而进行少样本提示时，中译英的例子则变成了3个（也可以是2个、4个或者更多个）。

### 图2 - 10 * - shot提示例子
- **零样本**：在提示中仅给出问题或者指令的自然语言描述。
  - 请将下列中文单词翻译为英文： -> 任务描述
  - 烙饼 -> 提示
- **单样本**：除了给出问题或指令，还要在提示中给出一个具体的例子。
  - 请将下列中文单词翻译为英文： -> 任务描述
  - 苹果 -> apple -> 例子
  - 烙饼 -> 提示
- **少样本**：除了给出问题或指令，还要在提示中给出多个例子。
  - 请将下列中文单词翻译为英文： -> 任务描述
  - 苹果 -> apple -> 例子
  - 蛋糕 -> cake -> 例子
  - 鸡蛋 -> egg -> 例子
  - 烙饼 -> 提示

![image](https://github.com/user-attachments/assets/dd4577ac-1808-45a5-8ad6-ada65a7e746e)

#### 2.2.4 提示工程的特点与优势

1. **提示工程的特点**

提示工程具有领域依赖性、灵活、可迭代等特点。

大型语言模型是具备非常丰富，甚至可以说是庞杂的知识储备的。当人们需要它去完成某一个特定领域的任务时，就需要设计包含领域知识的有效提示。这就要求提示的设计者对任务领域具有一定的了解。这意味着提示工程不仅需要计算机科学家的技术支持，还需要各领域专家的参与，以确保模型能够准确理解和处理专业领域的问题。

此外，提示工程允许人们通过调整输入提示来适应不同的任务和场景。这使得大语言模型具有很高的灵活性，可以应对各种复杂的自然语言处理问题。

而且，提示工程是一个可迭代的过程，人们可以根据模型的输出反馈来不断优化提示，从而提高模型性能。这一过程可以借助于人工智能和人类的共同努力，实现模型与人类的协同创新。

2. **提示工程的优势**


提示工程的优势主要体现在以下几个方面。

首先，模型的训练通常需要大量的计算资源和时间。提示工程可以在一定程度上降低这些成本，因为它允许人们在大语言模型的基础上，通过调整输入提示来优化模型性能，而无须对模型本身进行昂贵的训练。

其次，通过设计合适的提示，不仅可以引导同一个模型完成不同领域的特定任务，还能提升在同一任务上的效能。这无疑有效提高了模型的性能。

再次，通过观察不同提示下模型的输出，人们可以更好地理解模型是如何处理输入信息、进行推理和生成答案的。也就是说，提示工程有助于揭示模型的内部工作原理，从而提高其可解释性。

最后，提示工程为研究人员提供了一个实验平台，可以通过尝试不同的提示来探索模型的潜力和局限。这有助于发现新的应用场景，推动模型的创新和改进。

#### 2.2.5 提示工程的局限、挑战及探索
1. **提示工程的局限与挑战**

提示工程在实践中还存在着许多局限性和挑战。

首先，设计有效的提示需要大量的经验和专业知识。为了获得满意的结果，提示工程师需要花费大量时间和精力来测试和优化提示。而且对提示工程师自身的素养要求颇高，这使得提示工程很难在短期之内普及。

其次，当使用复杂的提示时，难以确定模型为什么会生成特定的输出。这可能会导致用户对模型的信任度降低，从而影响其在实际应用中的采纳率。

还有，因为大语言模型通常是通过学习大量的文本数据来训练的，这些数据可能包含了人类作者的偏见和刻板印象。如果提示工程师在执行提示工程时没有考虑到这些问题，那么生成的文本可能会加剧这些偏见，从而导致不公平的结果。

当然问题还不止这些。不过，提示工程作为一个新兴领域，遇到问题和挑战都是非常正常的，这需要研究人员和提示工程师们共同努力，尽早发现和解决问题。

2. **提示工程的探索**

针对上述这些局限和挑战，研究人员正在探索多种方法来改进提示工程，具体包括以下几个方面。

1）开发自动化方法来生成和优化提示，例如，可以使用强化学习或遗传算法来搜索有效的提示等。这样可以减轻研究人员和开发人员的负担，提高提示效率。

2）开发新的可解释性技术，例如：通过分析模型的输入特征对输出的贡献，来了解哪些特征对模型的决策过程起到关键作用；将模型的内部表示和计算过程可视化，以便直观地观察模型如何处理和理解输入数据等。以此来提升用户对模型的信任度，以促进提示工程在实际工作中的应用。

3）在提示工程中引入公平性和无偏见的原则，例如，可以使用去偏见技术来消除提示中的刻板印象，或者在模型训练过程中引入公平性约束等，达到减轻模型生成的文本中偏见的目的。

4）开发适应性提示技术，根据任务的特点和用户的反馈动态地调整提示，从而提高模型的灵活性和实用性，使之更好地适应不同的任务和用户需求。

5）通过建立开放的、社区驱动的提示库，让众多提示工程师共享和学习彼此的经验。



提示工程作为一种与大语言模型配合使用的方法，为人工智能领域带来了新的研究方向和应用前景。通过不断地探索和实践，人们有望进一步提高大语言模型的性能，使其在各个领域发挥更大的价值。 







