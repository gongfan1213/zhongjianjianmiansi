# 4.3.6 其他进阶方法简介
## 1. 提示集成

提示集成（prompt ensembling）是指使用多个不同的提示来尝试回答同一个问题，目的是为了增强结果的可靠性。提示集成跟所有的集成方法一样，包括两个明确的过程，一是需要产生多个提示来解决问题，二是通过特定的策略将多个提示的答案结合起来确定最终结果。下面将分别针对这两个过程简要介绍一些当下流行的方法，供感兴趣的读者开阔思路。

首先，与前文自洽性在同一个提示的多条推理路径中采样不同，提示集成需要准备多个不同的提示输入。这么做是因为不同的提示可能包含不同方面的信息，具有不同的侧重点。每条提示不一定是完美的，也不一定是最适合当下问题的，但却可以互相查漏补缺。这可以避免用户面对任务时绞尽脑汁去构造和挑选最完美的那一个提示，从而大大节省在提示工程上耗费的时间。

现存非常多的方法来生成多个不同的提示。一般来说，最直接有效的就是对提示中的指令或问题进行多样化改写，生成多个新的提示。在如何构造提示问题上，Arora等人提出的AMA（ask me anything prompting）集成法中的一些思考非常具有借鉴意义。简单来说，用户在构造提示问题时一般有两个大方向，一种是构造开放式的问题，例如“今天中午吃什么？”“宇宙有多大？”；另一种是限制式问题，例如选择题“今天中午吃汉堡吗？回答是或者非”，问题的答案是限定的。Arora等人发现开放式提示的性能要优于限制式的提示。借鉴这一点，用户在构造提示时可以尝试将一个问题转换成不同的提问方式来强调不同方面的信息，并增加开放式提示的构造，增强推理的可靠性。

此外，如果提示带有样本示例，样本对推理路径的生成会有较大影响。对于一个特定的问题，为避免固定的样本局限住推理路径的生成，在单样本或者少样本提示中，可以通过替换不同样本示例来生成多个不同的提示。当然，除了这些人为构造不同提示的方法，还可以直接借助模型来改写原始提示。 

当生成多个提示后，用户接下来思考如何将多个提示的结果组合成最终结果。一个简单的策略是采用多数投票，即多个提示生成的结果中出现最多的就是最终结果。在前文提到的自洽性方法中，Wang等人就是采用了多数投票制。这个方法在很多任务上都有不错的成绩，但它也有局限。因为它给所有候选结果的权重都是一样的，但这并不完全符合实际。并且有时候占大多数的结果并不一定正确，有时真理掌握在少数人手中，所以简单的多数投票可能会失效。在Li等人提出的DiVeRSe（diverse verifier on reasoning steps）提示集成方法中，他们就使用了一个训练得到的验证投票器来评估输出的每条推理路径的正确性。正确性是一个概率，在集成中也用来表示该输出路径的权重，将指向相同答案的各条路径的概率相加，最终选择概率和最高的那个答案作为最终结果，以此来增强推理的可靠性。其他可借鉴的集成方式还包括Arora等人提出的AMA集成法，他们根据同一个问题下不同提示之间的相似度赋予这些输出不同的权重，如果一个问题有很多非常相近的提示和输出，那在集成的时候会降低相似提示的权重，来避免过于相似的提示占比过高导致最终结果偏移。另外，针对不同的提示的质量有时参差不齐的问题，Schick等人提出根据提示在训练集上的预估准确率给各提示分配权重来加大优质提示对结果的效用，类似的方法也出现在Jiang等人的实验中。这些例子都属于广义上的加权方法，一定程度上解决了多数投票的弊端，可以供人们参考。

总体来说，提示集成可以增强结果的可靠性，在处理复杂的提示任务上有超于寻常的表现。它可以将之前提到的所有提示构造方法和集成学习模型结合，在当下具有广泛的应用。
## 2. 提示调优
在GPT-3为代表的大语言模型出现之前，使用预训练语言模型的更广泛方式为微调（fine-tuning），即指面向下游具体任务时对预训练模型的参数进行再优化的过程。大量研究和实践表明，微调可以使模型对于特定的任务有更好的表现。然而，随着预训练语言模型参数量越来越大，调优的成本也越来越高。如果对每个不同的下游任务都进行微调，那么将非常耗时耗力。人工设计的提示虽然一般不需要再度训练模型的权重，但是模型的表现往往难以达到微调的效果。为解决这个问题，Lester等人在2021年提出了提示调优方法（prompt tuning）。图4-7展示了提示调优方法与一般模型微调的区别。主要的不同是该方法冻结整个预训练模型，而只允许每个下游任务在正式的输入文本之前添加k个可调节的词（token）。由于这些token实际是可训练的嵌入向量（embedding vector）因此它们组成的提示被称为“软提示”，以区别于按照自然语言中固有的词构成的提示。这个“软提示”中的权重用反向传播的方式训练而得。由于所有下游任务都复用同一个预训练模型，此方法相比微调能够在大幅减小任务参数的同时接近甚至达到后者的表现，且显著优于人工设计的提示。

模型微调

任务A数据→任务A模型

任务B数据→任务B模型

任务C数据→任务C模型

混合批

提示调优

任务A提示、任务C提示 任务C样本1

任务A提示 任务A样本1

任务B提示、任务B提示 任务B样本1

任务A提示 任务A样本2

任务C提示 任务C样本2

任务B提示 任务B样本2

→预训练模型


![image](https://github.com/user-attachments/assets/b88046e1-a1ad-40d8-9944-3a4daf181540)


图4-7 提示调优方法与一般模型微调的对比（虚线框的模块为参数需要训练的部分），模型微调需要对每个任务复制一份模型然后各自进行参数训练，而提示调优仅需要训练每个任务的提示
## 3. 主动提示

随着大语言模型的规模不断增大，人们越来越多地利用它来处理复杂的任务。如前所述，通过在提示中给出思维链推理的示例，可以显著提高模型在复杂推理任务上的性能。为构造合适的示例，一般需要人为选择一些特定的问题，然后给出标注（包括解决此问题的思维链和问题的最终答案）。而不同的推理任务在难度、范畴和涵盖领域等方面存在显著差异，刚开始构造示例的提示工程师通常并不事先知晓选取哪些问题来标注，即使可以根据主观猜测或经验构造了一些示例，往往也存在可以继续优化的空间。为了解决这个问题，Diao等人提出了“主动提示（active-prompt）”方法。该方法借鉴了主动学习的思想，通过衡量大语言模型在各问题上的不确定度，来合理地选择最有帮助和最具信息量的问题进行标注，以减少人工标注的工作量，最后将这些问题作为提示中的示例，以提高模型在推理任务中的表现。其总体思路如图4-8所示。

未标注的问题$q_1,q_2,...$

问题$q_1$：结果$a_{11},a_{12},\cdots a_{1k} \Rightarrow$不确定度$u_1$

问题$q_2$：结果$a_{21},a_{22},\cdots a_{2k} \Rightarrow$不确定度$u_2$

…

多次访问模型，根据模型的多次推理结果计算不确定度

选择不确定度最高的问题→人工标注→使用标注的问题给模型作示例进行推理

图4-8 主动提示的思路 



![image](https://github.com/user-attachments/assets/bc62bb18-37f1-43b0-bf58-4a75136d499b)
