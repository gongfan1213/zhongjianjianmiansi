通用的新闻写作、文本翻译、各种领域文本的基础处理。语音合成
技术能够替代基础的播音工作，随着该项技术的推广，人们在各大
视频平台接收到的最新发布的短视频、长视频等内容有一定比例已
经由语音合成技术自动合成，替代了人工播音。


更多的岗位则是被AIGC技术赋能，主要是那些重复性低、创
造性高、规则性弱、标准化程度低的工作岗位，如艺术家、教师、
医生、科学家、管理者等。这些岗位的部分或全部任务需要人类的
判断、决策、创新、沟通等高级认知能力和情感能力，难以被人工
智能完全替代，反而可以通过人工智能的辅助和协作，实现更高的
质量和价值。


例如，人工智能可以通过生成技术为艺术家提供新的灵感和素
材，更快地进行概念验证，而人类则在选定方案后进行艺术的实
现；可以为教师提供个性化和智能化的教学方案和评估方法；可以
为医生提供精准和快速的诊断和治疗建议。
还有一部分岗位是相对于人工智能暴露较少的工作，例如体力
劳动（工程建设、快递配送）、服务工作（护理、餐厅服务员），这
一类工作目前难以被人工智能替代，其劳动力价值目前没有受到影
响，甚至有所提升。


总的来看，人工智能技术的发展和推广将会改变就业结构和就
业方式，促进就业质量和工作效率的提升。同时它也会导致传统工
作岗位的转型，如教育、医疗、咨询等行业的工作。这些岗位的从
业者需要及时学习和应用最新的人工智能技术、适应其带来的变
化、挑战和机遇。
## 3.3.2 提示工程师的诞生
随着大语言模型、图像生成技术的突破，一种全新的工作领域
诞生了，那就是提示工程，随之带来了全新的工作岗位——提示工
程师（prompt engineer）。


提示工程师是一种重要的人工智能工程师，因为他们能够帮助
生成模型提高质量和效率，降低成本和风险，为用户提供更准确、
更相关、更有价值的内容服务。提示工程师也能够激发生成模型的
创造力和想象力，为内容创作提供新的可能性和灵感。
提示工程师不一定需要有计算机工程或资深编程的背景，但需
要具备以下几方面的技能。


（1）基本的编程技能和对生成模型的熟悉度 提示工程师需要
能够使用简单的代码或工具来调用和控制生成模型，以及理解生成
模型的原理和机制。


（2）优秀的自然语言处理和写作能力 提示工程师需要能够使
用自然语言编写清晰、准确、有效的文本提示，以及评估和分析生
成模型的输出。

（3）良好的沟通和协作能力 提示工程师需要能够与其他人工
智能工程师、内容创作者、用户等进行有效的交流和合作，快速地
学习、解读行业工作流程，能够将大模型通过提示工程迅速地应用
到行业里。
# 3.4 AIGC图像生成与提示工程
## 3.4.1 Stable Diffusion的提示工程
### 1. Stable Diffusion介绍
Stable Diffusion，一个在图像生成领域引起热烈讨论的模型，
首次亮相于2022年。作为当前图像生成领域最为流行的开源模型
之一，它凭借开源、可微调、轻量级和广泛适用于多种任务等优
势，在用户群体中建立了独特的地位。


Stable Diffusion是一款全开源的项目。这意味着它的源代码和
神经网络权重值都是对公众开放的，用户可以自由获取、使用和修
改。这为研究人员和开发者提供了一个实践和创新的平台，使他们
可以根据自身需求对其进行定制和优化。借助GitHub等开源平台，


Stable Diffusion的代码和模型可以轻松获取，并可以在个人计算机
上运行。


作为一款可微调的模型，Stable Diffusion允许用户根据自己的
需求和数据集中对模型进行进一步训练，以获得更适合特定任务和数
据的生成结果。例如，人们可以用自己拍摄的照片来训练模型，使
其生成出符合自己审美的图片。


在资源消耗和计算成本方面，Stable Diffusion的运行效率是
相当高的，适合在较低的计算资源上运行。多个厂商都对Stable
Diffusion进行了优化，例如，苹果公司推出的工具可以让Stable
Diffusion在M2芯片上单机运行。


然而，与任何工具一样，使用Stable Diffusion也需要注意一
些事项。由于它出身于科研领域，并非产品级别的模型，Stable
Diffusion并没有对生成结果的质量进行过多的限制，以及进行人类
道德标准的对齐。因此，用户在使用此模型时，需要进行大量的测
试和相关的优化，从而获得较好的生成效果。同时，用户还需遵守
相关法律法规和道德准则，避免滥用该模型造成不良影响或侵犯他
人权益。
## 2. Stable Diffusion生态
Stable Diffusion是当前图像生成领域发展最好、相关作品最多
的模型之一，其生态系统包括以下方面。


□官方产品：Stable Diffusion的官方产品包括DreamStudio等。
DreamStudio是一个全功能的图像生成工具，它提供了丰富
的功能和选项，帮助用户实现高质量的图像生成。


□开源工具和WebUI：除了官方产品，还有许多基于Stable
Diffusion的开源工具，其中最为出众的就是WebUI。



□基于Stable Diffusion改造的垂类模型：Stable Diffusion的生
态系统中涵盖了许多基于Stable Diffusion改造的垂直领域模
型，如Controlnet、Stable Diffusion Infinity等。这些模型在
Stable Diffusion的基础上进行了改进和扩展，以满足特定任
务或应用领域的需求。


□微调：针对Stable Diffusion，也有许多微调（fine-tune）的
方法和模型被提出，如LoRA、Hypernetwork、Dreambooth、
Embedding等。这些方法和模型可被用于对Stable Diffusion
进行进一步的训练和调优，使得生成效果更可控、更收敛。
下面分别介绍这几个层级的Stable Diffusion。


（1）官方产品 如图3-1所示，DreamStudio是Stable Diffusion
的官方产品之一。它提供了非常简单的用户交互和可配置的参数，
用户通过设定风格、撰写提示、配置基础的图像属性、选择模型，
即可快速地生成自己的AIGC作品。

![image](https://github.com/user-attachments/assets/46fb2241-e0dc-4cc4-90f2-baf581e95348)


图3-1 DreamStudio产品界面

□尺寸：决定生成图像的分辨率。

□Cfg Scale：控制生成图像与提示词的相关性。

□Steps：指定去噪（denosing）阶段的步骤数量。

□Sampler：确定从潜在空间中采样的策略。

□Model：选择使用的Stable Diffusion模型的版本。

□Image：选择输入的图片。

（2）开源工具和WebUI 除了官方产品，还有许多基于Stable
Diffusion的开源工具。其中一个比较强大而简单易用的工具是
WebUI，如图3-2所示，它支持多种任务，包括图像的Upscaling
（超分辨率增强）、Inpaint（修复图像缺失部分）和Instruct2Img
（根据指令生成图像）等。用户可以通过GitHub或其他平台下载
WebUI的代码，并在自己的计算机上运行。

![image](https://github.com/user-attachments/assets/df520b2f-93af-41d2-ad62-67a38bb25af3)

图3-2 Stable Diffusion的开源项目WebUI

WebUI还有强大的插件系统。用户只需选择需要的插件，在前
端界面填入按照约定规则开发的代码的GitHub地址，即可一键安
装。这种软件设计使得用户能够根据自己的需求灵活地扩展工具的
功能。插件系统给予了WebUI极强的可拓展性。


（3）基于Stable Diffusion改造的垂类模型 Stable Diffusion的生
态系统中涵盖了许多基于Stable Diffusion改造的垂直领域模型，如
Controlnet、Stable Diffusion Infinity等。例如，Controlnet是一种基
于条件生成的模型，它可以利用内置的OpenPose工具来提取人物的
姿态，并根据文本提示生成与姿态相一致的图像。除了姿态，还可
以引入深度图、语义分割图的信息，从不同角度控制Stable Diffusion
的图像生成。


（4）微调 如果我们希望模型的输出能够更加收敛，例如仅输
出某个特定的人物，或者仅输出某种风格（如中国风），那么就可以
使用微调方法，改善模型的生成效果。其中，一种非常有效的微调
方法就是LoRA。图3-3展示了基于国画数据训练后的LoRA生成
的图像。


![image](https://github.com/user-attachments/assets/fafa7474-d211-480f-a817-691609bb48d6)


图3-3 Stable Diffusion基于国画数据训练后的LoRA MoXin

LoRA方法通过在训练过程中引入目标形象、风格或主题的信
息，使得模型在生成过程中更加倾向于产生与目标相一致的图像。
通过微调，模型可以更好地收敛于用户所期望的形象、风格或主
题。从图3-3中可以看到，在国画数据上微调得到的LoRA MoXin，
其生成的图像具备国画风格，如线条、色彩和气韵等。

使用LoRA时，首先需要收集关于某一形象、风格或主题的少
量图片（约100张左右），作为训练数据。其次，可以使用这些数
据对模型进行训练，以使其更好地适应目标形象、风格或主题。最
后，在进行预测时，需要同时加载LoRA和Stable Diffusion两个模
型，这样就能够输出微调风格的图像。


LoRA的特点有以下几个方面。相比于一些需要大量训练数据
的方法，LoRA方法所需的训练数据量较小。几百上千张图片就能
够微调模型，相比于动辄数亿张训练数据的大模型而言是非常划算
的。LoRA方法引入的额外模型参数较小，通常在几十MB到几百
MB之间，不会过于增加模型的复杂度。此外，LoRA的训练过程
不会更新Stable Diffusion模型的参数，这样使得二者从结构上是可
分离的。


感兴趣的读者可以在Civitai网站下载开源的LoRA，配合原生
的Stable Diffusion，在WebUI中联合加载使用。

Embedding也是一种微调方法，称为文本反演，它可以在不
修改模型的情况下，为模型定义新的关键词，从而引入新的概念。

Embedding的原理是通过寻找最能代表新概念的文本向量，然后将
其作为模型的输入。这相当于在语言模型中找到一种描述新概念的
方式。

使用Embedding时，首先需要收集关于某一对象或风格的少量
图片（约20到50张），作为训练数据。其次，可以使用这些数据对
模型进行训练，以使其生成一个文本向量。最后，在进行预测时，
需要同时加载Embedding和Stable Diffusion两个模型，这样就能
够输出微调对象或风格的图像了。

Embedding的特点有以下几个方面。相比于一些需要修改模型
结构或参数的方法，Embedding方法不需要改变模型本身。这样使得
模型保持了原有的性能和稳定性。Embedding方法只需要训练一个文
本向量，而不是整个模型。这样使得训练过程更加快速和简单。
## 3.图像生成与提示词
提示工程的目的是让文字生成图像模型能够更好地理解和实现
用户真正要表达的意图。基于对文本生成图像大量的实践，可以总
结出撰写提示词生成图像的一些要点。
首先，需要对图像有一定的描述角度，例如：确定图像的类型，
如风景、人物、动物等；描述图像的主题，如具体的名词、形容词、
动词等；描述图像的场景，如背景、位置、角度、氛围等；指定图
像的风格，如卡通、写实、抽象等；包含光照和细节，如阴影、纹
理、色彩等；说明图像的构图，如对称、平衡、对比等；定义图像
的色彩方案，如暖色、冷色、单色等。
其次，避免过于复杂或模糊的描述，以免造成混淆或失真。
需要注意的是，由于文本生成图像模型的结构、版本不同，输
入的具体的关键词、语言和描述方式所产生的效果是存在区别的，
例如DALL·E 2，Midjourney和Stable Diffusion采用的具体的提
示词是不同的，但都可以以上的经验作为指导进行撰写。
## 4. Stable Diffusion中的提示词
在WebUI中，提示词可以使用一些特殊符号或标签来指定或
修改某些信息，从而影响图像生成的效果。这些符号或标签可以看
作一种运算符，可以对提示词中的词汇或短语进行加权、组合、排
除等操作。他们通过影响扩散模型的去噪（denosing）过程中加入
的词嵌入来控制图像生成的结果。

以下是Stable Diffusion中的提示词常用的符号或标签及其含义
和用法。

□#color=xxx：这个标签可以指定图像的整体颜色为xxx，例
如，#color=red表示图像为红色调。

□#style=xxx：这个标签可以指定图像的整体风格为xxx，例
如，#style=cartoon表示图像为卡通风格。


□( word)：这个符号可以增加word指代物的权重，让Stable
Diffusion更关注word指代物，例如，(猫)表示更想要生成
猫的图像。这个符号可以嵌套使用，例如，((猫))表示更加
强调猫。


□[word]：这个符号可以减少word指代物的权重，让Stable
Diffusion更忽略word指代物，例如，[狗]表示不想要生成
狗的图像。这个符号可以嵌套使用，例如，[[狗]]表示更加
排除狗。


□(word:x)：这个符号可以指定word指代物的权重为x，x是
一个大于0的数字，例如，(猫:2)表示猫的权重为2。这个
符号可以代替括号或方括号来精确控制权重。


□/：这个符号可以用来分隔不同的信息，让Stable Diffusion
同时考虑它们，例如，猫/狗表示既想要生成猫也想要生成
狗的图像。


□-：这个符号可以用来排除某些信息，让Stable Diffusion不
考虑它们，例如，猫 -黑色表示不想要生成黑色的猫的图
像。这个符号可以和括号或方括号结合使用，例如，(猫 -[黑
色])表示更关注非黑色的猫。

提示编辑（prompt editing）是一种高级用法，通过参数化的方
法，构建不同的提示词，能够在生成图像的过程动态插入不同提示
词的嵌入，实现更细粒度的控制。

提示编辑的基本语法是：[from:to:when]，其中from和to是任
意的文本，when是一个数字，表示在生成图像的哪个步骤进行切
换。切换的时间越晚，模型就越难把to文本代替from文本绘制出
来。如果when是一个0到1之间的数字，表示切换的步骤占总步
数的比例。如果when是一个大于0的整数，表示切换的具体步数。
提示编辑可以嵌套使用，也就是说可以在一个提示编辑中再使
用另一个提示编辑。


例如：a landscape painting of a garden painted by [Van Gogh:Picasso:0.5]

实际执行过程为：

在生成的1～50步时采用的提示词为：a landscape painting of
a garden painted by Van Gogh


在生成的51～100步时采用的提示词为：a landscape painting
of a garden painted by Picasso


交替词汇也是Stable diffusion WebUI提供的一种提示语法，用
于每隔一步就交换词汇。


输入提示词：A cute [cat|dog] in the yard in the cartoon style，图3-4
和图3-5展示了利用交替词汇的生成图像的中间过程：当输入A cute
[cat|dog] in the yard in the cartoon style，在生成的第1步时使用的提
示词是“A cute cat in the yard in the cartoon style”；第2步的提示词
是“A cute dog in the yard in the cartoon style”。第3步的提示词是“A
cute cat in the yard in the cartoon style”，以此类推。


![image](https://github.com/user-attachments/assets/44ecf98e-24f4-4cf1-bbd0-930f92b3716d)


图3-4 通过交替词汇生成图像：A cute [cat|dog] in the yard in the
cartoon style，30%：A cute dog in the yard in the cartoon style



![image](https://github.com/user-attachments/assets/9822ca35-9716-4866-8b6d-7ee2059b31a8)

图3-5 通过交替词汇生成图像：A cute [cat|dog] in the yard in the
cartoon style，73%：A cute cat in the yard in the cartoon style 
