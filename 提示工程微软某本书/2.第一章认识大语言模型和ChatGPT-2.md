![image](https://github.com/user-attachments/assets/e5beb649-fbc3-48da-82a9-f612194ac573)

![image](https://github.com/user-attachments/assets/a54e247c-759f-411c-bff4-535edcadadfe)

![image](https://github.com/user-attachments/assets/78c33fc4-62e5-4941-92c3-6c3c9dd39ed6)

![image](https://github.com/user-attachments/assets/c2f6a372-881d-4c8a-b065-6b2a7db9f470)

![image](https://github.com/user-attachments/assets/afc430e3-e4b6-491d-b6a3-6ecf41889832)

![image](https://github.com/user-attachments/assets/186454aa-d33f-4c74-b8d6-887259322933)

![image](https://github.com/user-attachments/assets/acb47579-6ff7-4928-a38a-e82cbd91ef65)

![image](https://github.com/user-attachments/assets/8f1a0539-50b7-46bc-abe7-0a4ec0acc1cc)

![image](https://github.com/user-attachments/assets/f1b4dbcb-ff82-4208-aa47-2940a107402d)


![image](https://github.com/user-attachments/assets/62f8029d-6c0f-4a1b-afbc-cae62a6b394f)


必要的处理，例如分词、去除停用词、标准化、添加特殊符号等，
使得训练数据符合语言模型的输入格式和要求。

2）参数初始化：参数初始化是指对语言模型的参数进行一些
随机或规则的赋值，为后续的参数更新提供一个初始状态。参数初
始化对于语言模型的收敛速度和最终效果有着重要的影响。

3）参数更新：参数更新是指根据训练数据中的词序列和语
言模型的输出，计算语言模型的损失函数（loss function），并根
据损失函数对语言模型的参数进行调整，使得损失函数达到最小
值。参数更新是语言模型训练中最核心和最复杂的部分，它涉及多
种算法和技术，例如反向传播（backpropagation）、随机梯度下降
（stochastic gradient descent）、动量法（momentum）、自适应学习率
（adaptive learning rate）等。

4）参数保存：参数保存是指在每个训练周期（epoch）或者每
个训练批次（batch）后，将当前的语言模型参数保存到一个文件或
者一个数据库中，以便后续的评估或使用。


语言模型的评估 语言模型的评估是指根据给定的测试数据，
测试语言模型的性能和效果。一般来说，语言模型的评估可以分为
以下几个步骤。


1）数据预处理：数据预处理是指对原始的测试数据进行一些
必要的处理，例如分词、去除停用词、标准化、添加特殊符号等，
使得测试数据符合语言模型的输入格式和要求。


2）模型加载：模型加载是指从一个文件或者一个数据库中读
取已经训练好的语言模型参数，并将其加载到内存或者显存中，以
便后续的计算或使用。


3）模型测试：模型测试是指根据测试数据中的词序列和语言
模型的输出，计算语言模型的评估指标（evaluation metric），并根
据评估指标对语言模型进行比较或排序。常用的评估指标有困惑度
（perplexity）、精确度（accuracy）、召回率（recall）、F1值（F1-score）等。


4）模型生成：模型生成是指根据给定的主题或上下文和语言
模型的输出，生成新的词序列，并用人工或自动化的方法对生成结
果进行评价或反馈。生成结果可以用来展示或验证语言模型的能力
和效果。


语言模型的训练和评估是相互影响和相互促进的过程，通过不
断地训练和评估，可以不断地改进和优化语言模型的性能和效果。
下面对具体的评估指标进行简要解释。


（1）困惑度 困惑度是一种衡量语言模型预测能力的评估指
标，它反映了语言模型测试数据中词序列的不确定性或复杂度。困
惑度越低，表示语言模型对测试数据中词序列的预测越准确，反之
则越不准确。困惑度perplexity可以用以下公式来计算：
\[
\begin{align*}
\text{perplexity}(M)&=M(s)^{-\frac{1}{n}}\\
&=\sqrt[n]{\prod_{k = 1}^{n}\frac{1}{M(w_{k}\mid w_{0}w_{1}\cdots w_{k - 1})}}
\end{align*}
\]

其中，$W = w_{1},w_{2},\cdots ,w_{n}$表示一个词序列，$M(w_{1},w_{2},\cdots ,w_{n})$表示语言模
型给出的词序列的概率，$n$表示词序列的长度。困惑度可以看作语
言模型给出的每个词的平均选择数，即语言模型在每个时间步需要


从多少个候选词中选择一个最有可能的词。

![image](https://github.com/user-attachments/assets/c9cec891-2ea8-4a92-9330-2c2535a169a6)


我们通过一个例子来更好地理解什么是困惑度。

假设有一个简单的语言模型，试图预测英文句子中下一个词的

概率。词汇表包含了以下词语：“I”，“love”，“cats”，“and”，“dogs”。

测试集包含一个句子“I love cats”，而模型预测每个词的概率


如下：

$M$(“I”) = 0.5

$M$(“love”| “I”) = 0.4

$M$(“cats”| “I”, “love”) = 0.7

在这个例子中，句子的概率是各个词概率的乘积：

$M(\text{sentence})=M$(“I”)×$M$(“love”| “I”)×

$M$(“cats”| “I”, “love”) = 0.5×0.4×0.7 = 0.14

现在，为了计算困惑度，我们需要对句子的概率取倒数，并将

结果的乘积开$n$次方（$n$为句子的词数）。在这个例子中，$n$等于3。

所以，困惑度

\[
\text{perplexity}=M(\text{sentence})^{-\frac{1}{n}} = 0.14^{-\frac{1}{3}}\approx1.93
\]


在这个特定的测试集和模型下，我们计算出的困惑度约为
2.63。这个数字表示的是模型在预测下一个词时的平均不确定性或
混淆程度。较低的困惑度表示模型对未来的预测更为准确。困惑度
是一种通用的评估指标，它可以用于任何类型的语言模型和任何类
型的任务。

（2）精确度 精确度是一种衡量语言模型预测正确性的评估
指标，它反映了语言模型给出的预测结果与真实结果之间的一致程
度。精确度越高，表示语言模型给出的预测结果越正确，反之则越
不正确。精确度ACC可以用以下公式来计算：

\[
\text{ACC}=\frac{\text{TP}+\text{TN}}{\text{TP}+\text{TN}+\text{FP}+\text{FN}}
\]

其中，TP表示真正例（true positive），即语言模型正确地预测了下
一个词；TN表示真负例（true negative），即语言模型正确地排除了
下一个词；FP表示假正例（false positive），即语言模型错误地预测
了下一个词；FN表示假负例（false negative），即语言模型错误地
排除了下一个词。精确度可以看作语言模型给出的所有预测结果中
正确结果的比例。精确度是一种简单直观的评估指标，它适用于二
分类或多分类任务，例如文本分类、情感分析等。


（3）召回率 召回率是一种衡量语言模型覆盖能力的评估指
标，它反映了语言模型能够正确地预测或生成多少真实结果。召
回率越高，表示语言模型能够覆盖更多的真实结果，反之则覆盖更
少。召回率REC可以用以下公式来计算：

\[
\text{REC}=\frac{\text{TP}}{\text{TP}+\text{FN}}
\]


其中，TP和FN的含义与精确度相同。召回率可以看作真实结果中被
语言模型正确地预测或生成的比例。召回率是一种重要的评估指标，
它适用于召回类任务，例如信息检索、问答系统、文本生成等。

（4）F1值 F1值是一种综合衡量语言模型性能的评估指标，
它反映了语言模型在预测正确性和覆盖能力之间的平衡程度。F1值
越高，表示语言模型在两方面都表现得越好，反之则表现得越差。


F1值可以用以下公式来计算：
\[
\text{F1}=\frac{2\times\text{PREC}\times\text{REC}}{\text{PREC}+\text{REC}}
\]

其中，PREC表示精确率（precision），即$\text{PREC}=\frac{\text{TP}}{\text{TP}+\text{FP}}$，REC表
示召回率，含义与上文相同。F1值可以看作精确度和召回率的调和
平均数，它能够兼顾语言模型的预测正确性和覆盖能力。F1值是
一种常用的评估指标，它适用于多种类型的任务，例如命名实体识
别、关系抽取、文本摘要等。
# 1.1.5 什么是大语言模型
大语言模型是一种基于大规模的数据和参数的神经网络语言模
型，它可以用来表示和生成自然语言的各种特征和任务。大语言模
型的基本思想是，使用一个统一的神经网络结构和一个统一的预训
练目标来学习自然语言的通用知识和能力，然后根据不同的下游任
务和数据，进行微调（fine-tuning）或生成（generation），以达到特
定的目的和效果。

大语言模型和基础语言模型的主要区别在于以下几个方面。


（1）数据规模 大语言模型使用的数据规模远远超过基础语言
模型，通常达到数十亿甚至数万亿个词。这些数据来自不同的领域
和来源，例如新闻、社交媒体、百科全书、文学作品等。这些数据
可以覆盖自然语言的各种类型和风格，从而使得大语言模型能够学
习到更丰富和更深层次的语言知识和能力。


（2）参数规模 大语言模型使用的参数规模也远远超过基础
语言模型，通常达到数十亿甚至数百亿个参数。这些参数可以使得
大语言模型具有更强大、更灵活的表达能力，从而能够捕捉到更复
杂、更细粒度的语言特征和任务。


（3）网络结构 大语言模型使用的网络结构通常是基于自注意
力（self-attention）机制的Transformer（变换器）网络，它由多个编
码器（encoder）层或解码器（decoder）层组成。Transformer网络
可以有效地处理长距离的依赖关系，同时具有高效并行化的优势。
Transformer网络也可以通过添加不同的组件或机制来增强其功能
和性能，例如跨注意力（cross-attention）机制、稀疏注意力（sparse
attention）机制、卷积神经网络（CNN）、循环神经网络（RNN）等。



（4）预训练目标 大语言模型使用的预训练目标通常是基于掩
码（masking）或因果（causal）的自回归（autoregressive）或自编码
（autoencoding）任务，它们可以使得大语言模型能够从无标注或少
标注的数据中学习到自然语言的内在规律和结构。预训练目标也可
以通过添加不同的约束或目标来增强其效果和泛化性，例如对比学
习（contrastive learning）、多任务学习（multi-task learning）、知识
蒸馏（knowledge distillation）等。


大语言模型在自然语言处理领域有着广泛而深远的影响，它可
以用来实现或改进各种类型和层次的自然语言任务，例如文本分类、
命名实体识别、关系抽取、文本摘要、机器翻译、问答系统、对话
系统、文本生成等。大语言模型也可以用来探索或解决一些前沿而
有挑战性的问题，例如常识推理（common sense reasoning）、知识表
示（knowledge representation）、语言理解（language understanding）、
语言生成（language generation）等。
# 1.2 大语言模型的类型
## 1.2.1 从左到右大语言模型
从左到右（Left-to-Right，LTR）大语言模型是一种用于学习
自然语言的统计模型，它根据给定的上下文，预测下一个将出现的
词。它的一般架构如图1-4所示。在从左到右大语言模型中，所有
后面神经元的输出，只和之前的相关信息有关。例如，给定一个句
子的前半部分，LTR语言模型可以估计后半部分的可能性，或者给
定一个词的前缀，LTR语言模型可以生成可能的后缀。LTR语言模
型通常使用神经网络或Transformer等深度学习技术来建立复杂的
语言表示。

LTR语言模型有很多应用，例如机器翻译、文本生成、文本摘
要、问答系统、拼写检查等。LTR语言模型可以作为特征提取器或
微调器，将预训练的语言表示应用到下游任务中。著名的LTR语言
模型包括OpenAI GPT、XLNet、GPT-2、GPT-3等。


LTR语言模型的优点是可以利用大量的无标注文本进行预训
练，从而捕捉语言的通用知识和规律。它也可以灵活地适应不同的
任务和领域，只需少量的任务特定数据和参数。此外，它可以生成
流畅和连贯的文本，因为它始终考虑了前面的内容。


LTR语言模型的缺点是不能同时考虑左右两边的上下文，因
此可能忽略了一些重要的信息。例如，在自然语言推理或问答任务
中，需要理解句子之间或问题和答案之间的关系，而单纯地从左到
右生成文本可能不足以捕捉这些关系。

![image](https://github.com/user-attachments/assets/a2adff4b-c00f-4705-abf9-948d2e5b4574)

图1-4 从左到右大语言模型架构
# 1.2.2 掩码语言模型


掩码语言模型（Mask Language Model，MLM）是一种用于学习
自然语言的统计模型，它通过在输入序列中随机掩盖一些词或符号，
然后根据剩余的上下文预测被掩盖的部分。它的网络架构如图1-5
所示，每一个神经元和其他的神经元间都可能存在联系。例如，给
定一个句子“我喜欢吃苹果”，MLM可以将“苹果”替换为一个特
殊的掩码符号，如“[MASK]”，然后根据“我喜欢吃[MASK]”这
个输入生成一个可能的输出，如“苹果”。MLM通常使用双向或
多向的神经网络或Transformer等深度学习技术来建立复杂的语言
表示。


MLM有很多应用，例如机器翻译、文本生成、文本摘要、问
答系统、自然语言推理等。MLM可以作为预训练模型，将双向
或多向的语言表示应用到下游任务中。著名的MLM包括BERT、
RoBERTa、ALBERT、DistilBERT等。
MLM的优点是可以充分利用输入序列中左右两边的上下文信
息，从而捕捉语言的深层含义和关系。它也可以利用大量的无标注
文本进行预训练，从而学习语言的通用知识和规律。此外，它可以
灵活地适应不同的任务和领域，只需少量的任务特定数据和参数。



MLM的缺点是需要更多的计算资源和时间来进行预训练和微
调，因为它使用了双向或多向的网络结构。它也可能遇到预训练和
微调之间的不匹配问题，因为在预训练阶段使用了掩码符号，而在
微调阶段没有。


![image](https://github.com/user-attachments/assets/c1fc1f48-d3cc-4902-ac76-f5c6af52dde5)

图1-5 掩码语言模型架构
# 1.2.3 前缀语言模型和编码器 - 解码器结构
前缀语言模型和编码器 - 解码器结构（Prefix and Encoder-Decoder，
PED）是一种用于学习自然语言的统计模型，实现了双向或多向的
语言表示和生成，模型架构如图1-6和图1-7所示。前缀语言模型
是一种在输入序列中随机截取一段前缀，然后根据前缀预测剩余部
分的任务的模型。编码器 - 解码器结构是一种将输入序列编码成一
个向量，然后将该向量解码成输出序列的框架。PED这样的语言模
型通常使用Transformer等深度学习技术来建立复杂的语言表示。

![image](https://github.com/user-attachments/assets/f3058bd9-c237-4981-b8ec-20940acff4b7)


图1-6 前缀语言模型架构 图1-7 编码器 - 解码器模型架构


PED语言模型有很多应用，例如机器翻译、文本生成、文本摘
要、问答系统、自然语言推理等。PED语言模型可以作为预训练模
型，将双向或多向的语言表示应用到下游任务中。著名的PED语
言模型包括PaLM、UL2、BigScience等。


PED语言模型的优点是可以充分利用输入序列中左右两边的上
下文信息，从而捕捉语言的深层含义和关系。它也可以利用大量的无
标注文本进行预训练，从而学习语言的通用知识和规律。此外，它可
以灵活地适应不同的任务和领域，只需少量的任务特定数据和参数。
它还可以生成流畅和连贯的文本，因为使用了编码器 - 解码器结构。


PED语言模型的缺点是需要更多的计算资源和时间来进行预训
练和微调，因为它使用了双向或多向的网络结构和编码器 - 解码器
结构。它也可能遇到预训练和微调之间的不匹配问题，因为在预训
练阶段使用了前缀截取，而在微调阶段没有。
# 1.3 初识ChatGPT
## 1.3.1 ChatGPT的原理
ChatGPT是一个使用文本进行交互的生成式语言模型，由OpenAI
发布于2022年11月30日。该模型推出仅5天就收获了100万名
用户，引起了行业内外的广泛关注。ChatGPT在推出两个月后，其
注册用户数量达到了一个亿，是有史以来最快达成该成就的产品。


值得一提的是，“ChatGPT”是一个具有多种含义的名词，它
既用来指代“https://chat.openai.com/”这款基于网页的聊天机器人
产品，也用来指代该机器人背后的大语言模型。本书中使用
“ChatGPT”指代该对话机器人产品背后的语言模型。
## 1. ChatGPT的训练
ChatGPT的训练过程大致可以分为两个阶段，即基础语言模型
训练阶段和对齐（alignment）阶段。基础语言模型的训练方式与其
他生成式语言模型的训练方式相同，而模型对齐训练则是ChatGPT
模型训练中的创新之处。


在基础语言模型训练阶段，模型从大量的文本数据中学习语言
结构和知识。这一阶段通常以自监督学习的方式进行。开发者需要
从网络上收集大量的多样化文本数据进行预训练。通过观察上下文
关系，模型不断调整内部权重，最终能够理解和生成合乎语法结构
和语义逻辑的句子。基础语言模型的训练已经在本章前面部分介绍
过，这里就不再赘述。


对齐学习是ChatGPT拥有强大问答能力的一个重要原因，它
让语言模型与人类的需求（高质量地回答用户问题）对齐，从而能
够更好地回答人们提出的问题。在这一阶段，模型通过有监督学
习和基于人类反馈的强化学习（reinforcement learning from human
feedback）进行微调，以便更好地满足特定任务需求。这一阶段主要是借助人类标注的对话数据对模型进行微调，让模型学会输出对人类“有用”并且符合人类价值观的内容。通过微调与优化，模型会变得更加灵活，能够以自然的方式与用户进行交流，回答复杂问题并完成多样化的任务。

ChatGPT使用基于人类反馈的强化学习来对齐模型，主要包含以下3个阶段。

（1）使用有监督学习对基础模型进行微调 这一阶段首先要让标注人员创作出一些合理的问答对数据。标注人员需要根据要求创作出一些问题，并给出他们认为正确的回答。有了这些数据，OpenAI就可以使用之前的自监督训练方法对模型进行微调。经过微调之后，模型在回答问题方面的能力就可以得到提升，也可以说经过微调的模型能更好地与我们的需求对齐（因为我们的需求就是模型能够回答人类的问题）。

如图1-8所示，OpenAI可以让标注人员去创作出若干个问答对。图中有两个问答对的示例，第一个是：“世界上最高的山是什么？”答案是：“世界上最高的山是珠穆朗玛峰。”有了这样的问答对数据之后，我们就可以使用与语言模型训练阶段相同的训练方式对模型进行微调，在ChatGPT中，这个微调是以GPT-3.5模型为基础进行的。

图1-8 ChatGPT对齐训练第一步：使用有监督学习对模型进行微调

![image](https://github.com/user-attachments/assets/7d60e22e-aeff-4526-9c8a-788d8a223bcb)


（2）训练一个奖励模型 奖励模型是一个用来判断答案质量的模型，其输入是问答对数据，输出是对答案质量的评分。奖励模型的训练也离不开标注数据，为了提高标注数据的利用率，OpenAI没有直接标注问答对的得分，而是要求标注人员对一组答案的质量进行排序。在这一阶段，标注人员首先需要选取一个问题集，问题的来源包括标注人员人工撰写和OpenAI的API调用日志中收集到的数据。得到问题集之后，再使用第一步中微调后的模型为每个问题生成多个答案，最后再由标注人员对这些答案进行排序。具体过程如图1-9所示。 

