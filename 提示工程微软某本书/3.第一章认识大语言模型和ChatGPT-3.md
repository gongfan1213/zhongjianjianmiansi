![image](https://github.com/user-attachments/assets/eb3f03df-ddf3-41b2-a47f-9c34684b23e3)


### 图1-9为奖励模型标注数据的过程
标注人员通过OpenAI API提出问题，如“世界上最高的山是什么？”“请帮我写一个搞笑的段子” 等。调优后的模型针对问题给出回答，如对于 “世界上最高的山是什么？”，有回答A1：我们一起去探索；A2：圣母峰；A3：珠穆朗玛峰；A4：世界上最高的山是珠穆朗玛峰，其高度是8848米。标注人员对这些答案进行排序，这里A4>A3>A1=A2 。


![image](https://github.com/user-attachments/assets/6d2e3ee4-2d46-4569-bd96-def431b0fd42)


### 图1-10 奖励模型：使用问答数据和答案的排序信息训练得到的模型
有了上述标注数据，就可以训练奖励模型。奖励模型通常以简化的语言模型为基础进行训练，使用问答数据和答案的排序信息（如 “世界上最高的山是什么？” 及其不同回答A1 - A4和排序A4>A3>A1=A2 ）来训练。 

### （3）使用强化学习算法对调优后的模型进行进一步训练
OpenAI使用强化学习方法 “自动” 对模型进一步优化。强化学习是智能体与环境交互，学习使长期奖励最大化的策略的机器学习方法。以训练狗为例，狗是智能体，驯狗人和场地等是环境，狗根据环境反馈（如得到零食或拍打）调整策略。


强化学习与其他机器学习算法相比有以下特点：

1. 训练数据源于智能体与环境交互，有监督和无监督学习依赖训练数据集，且有监督学习需数据标注。

2. 智能体在与环境实时交互中学习，有监督和无监督学习常在离线数据集训练。 

3. 奖励常具延迟性，需考虑长期策略和奖励累积。

4. 智能体通过试错学习找最佳策略，有监督和无监督学习通常无此过程。 

5. 需在探索（尝试新行动）与利用（基于经验做最优决策）间权衡，有监督和无监督学习通常无此权衡。


ChatGPT使用强化学习训练时，程序从预定义问题集抽取问题，输入调优后的模型生成答案，再将问题和答案输入奖励模型评分，利用评分优化模型，具体使用PPO（近端策略优化）算法。

![image](https://github.com/user-attachments/assets/676217f9-f3a6-47cb-b413-eaa56c669c47)


### 2. ChatGPT的推理
ChatGPT是生成式语言模型，根据输入词序列输出下一个词的概率分布。以 “中国最有名的歌手是谁？” 为例，多次提问会得到不同答案，如答案1：中国最有名的歌手可能是邓紫棋；答案2：中国最有名的歌手可能有很多，但是其中一位非常受欢迎和尊敬的歌手是周杰伦等。

系统输入问题后，模型输出下一个字符的概率分布，如输入 “中国最有名的歌手是谁？” 后，“中” 出现概率95%，“是” 为1% 等，按概率选字符，第一个字符确定后，连接输入再输入模型，多次迭代后，因概率分布逐渐平均，答案变得多样。还可通过调整温度等参数权衡生成答案的多样性和稳定性。

### 1.3.2 ChatGPT的应用

1. **搜索引擎——必应（Bing）**

2023年2月7日，微软将ChatGPT相关技术集成到必应，为用户提供对话式搜索新体验。必应根据搜索引擎信息回答问题，如输入 “今年NBA的总冠军是谁”，先搜索关键词，再根据结果生成答案，答案中会引用网址辅助确认真实性。

![image](https://github.com/user-attachments/assets/fb82b855-97cb-45ce-bf84-ef9e77df5f21)


2. **语言学习工具——多邻国（duolingo）**

引入多个AI特性：
 - **语法错误纠正**：利用大语言模型识别语法错误并给出修改方案，帮助语言初学者提升写作能力。
 - **解释我的答案**：基于GPT - 4推出，帮助学习者理解答案正确性、亮点、不足及改进方法。
 - **角色扮演**：作为语言陪练与学习者对话，指出错误并给改进方案，提升外语交流能力。

3. **智能数据分析工具——Viable**

是AI驱动的客户反馈分析服务平台，使用ChatGPT的摘要和推理能力从海量数据生成有价值的分析报告和商业洞察，可自动化处理用户反馈数据，节省人工成本。

### 1.3.3 ChatGPT的挑战

1. **回答的正确性难以保证**

ChatGPT多数回答正确，但早期数学能力差，虽经升级仍可能在生僻或复杂问题上出错，如早期版本将世界上最高的火山答成珠穆朗玛峰。缓解方法：一是优化模型提升正确性，但现阶段受技术和硬件限制难以完全解决；二是使用提示工程，从相关文献抽取答案保证正确性，如必应问答功能。


![image](https://github.com/user-attachments/assets/a259f967-2a21-4b45-a3c0-0a06a216cd05)


2. **模型不包含最新的数据**
   
ChatGPT训练后参数不变，无法获取新信息，重新训练成本高。解决方法是使用提示工程提供上下文信息让模型据此作答，如必应搜索等应用。

4. **资源消耗过大**

ChatGPT参数量巨大，GPT - 3最大参数量达1750亿，存储需约700GB空间，训练和推理成本高。虽API调用价格降低，但对AI应用开发者仍可观。构建训练系统成本高昂，阻碍更多公司参与模型研究开发。缓解方法是使用规模更小的模型，如Meta公司的LLaMA模型参数量降低到70亿。

### 1.4 其他大语言模型

1. **文心一言**

百度推出的大语言模型，是国内较早的大语言模型，是 “百度全新一代知识增强大语言模型，文心大模型家族新成员”，可对话互动、回答问题、协助创作，提供网页应用对话和百度智能云API调用两种访问方式，中文知识问答性能较好，综合实力在国内前列。

2. **讯飞星火**

科大讯飞发布的大语言模型，除网页应用访问和API调用外，还提供手机App和微信小程序，集成500多个垂直领域助手，提供海量示例指令集，方便国内用户使用。

3. **Bard**

Google推出的对话式人工智能服务，基于大语言模型LaMDA构建，与ChatGPT类似基于Transformer架构，但使用有监督学习训练，可访问最新互联网数据生成答案，截至2023年6月不支持中文。

4. **LLaMA**

Meta推出的开源大语言模型，有70亿、130亿、330亿和650亿等不同参数量版本，训练数据集庞大，因容易获取且性能优异流行，130亿参数量版本性能可与GPT - 3媲美，但它是自监督学习训练的生成式语言模型，未经过ChatGPT中的监督学习或强化学习训练，回答问题能力相对较弱。 



### 5. Alpaca

Alpaca是斯坦福大学在LLaMA的基础之上使用了大约5.2万条指令进行调优的模型。Alpaca也是一个开源项目，其模型、训练代码和训练数据都托管在GitHub上。不过由于版权（LLaMA的版权归Meta公司所有），Alpaca并不是一个完整的模型，而是一个增量的权重，需要结合原始LLaMA模型才能使用。 

Alpaca并不是性能最好的LLaMA微调项目，但它是一个相对较早的尝试，并且是在有限的硬件资源（4块A100显卡）下完成了70亿参数量语言模型的优化，为后续的工作起到了一定的启示作用。其他基于LLaMA的开源项目有Chinese-LLaMA-Alpaca、Vicuna和Koala等。 
