好，那么我们就开始企业级agent开发实战营的第一节课，叫大模型时代的agent开发方法论。今天这个内容其实会分成两部分，我们重点在第一部分就是叫做agent的应用开发指南。从这个内容大家应该看得出来，其实是偏一个总纲类的一节课。我希望通过这节课我们不一定一上来就要赶紧写代码，这样就变成了一个着眼于细节的一个课程了。其实我希望通过这节课，大家能够整体性的了解。就像我们学习用开发实战营和微调一样。我们先有一个总体性的认知，把这个知识的架构给建立起来。建立起来之后，我们在后续的学习过程当中，就可以对照着这样一个agents的核心技术战，不断的去深挖，去按照自己的需求在开发过程当中去点自己的这个科技树知识点。
整个agent应用开发指南其实也是希望从另一个维度来跟大家做分享。因为现在市面上有很多的人都会去讲A线的开发其实是一个没有什么技术含量的活儿，或者说A的开发非常的乱。他的理论知实也是非常的粗浅，除了一个reactive以外，好像就是说的好听叫百家争鸣，说的难听一点就是这个群魔乱舞的一个开发状态。
但实际情况agent的开发还是有很多理论的支撑，以及我们值得学习的开发的这个范式的那除了agent开发本身以外，很多人一聊agent就会想到南茜。但除了南茜这一年半以来，agent整个开发的生态又有一个什么样的演变？如何去把一个agent开发好？我们要做到所谓的企业级的生产级的agent，它有哪些核心能力需要去搭建？这个其实是我们希望通过这个开发指南这节课，让大家有一个系统性的认知，就有点类似于我们学前面两门课的时候，第一周会有很多偏理论的部分。其实agent也有很多理论。而且这个理论不是所谓的像论文一样的理论，而是落到可以上手实践这个级别的理论。
最终一个a gent的开发好之后，我们也是需要能够把它部署起来的，并且能够支撑生产级的部署。那agent的生产部署平台又有哪些？这一年的发展有哪些生产部署的平台是值得我们花一点时间去了解，甚至是深入学习的。
最终agent部署好了，绝大部分的同学开发agent他的直观感受就是我开发好了一个命令行工具。这个命令行可以通过python启动。但是启动起来之后，我们缺乏一个可视化的前端，怎么样能够提升它的交互，能让它让普通的人也能够去享受到你开发的这个agent的能力。同时我们在开发测试阶段，有没有可能把我们的agent打包成一个docker容器，让它能够一键去部署，然后在其他的不同的服务器上都能够快速的去使用，并且分享给其他的研发的同时。
这个是我们认为在agent开发过程当中外围的一些关键技术。我们也会在三个项目的进展过程当中，不断的去加深它的外围关键技术和它生产部署的一些能力。最后，我们会把这个大模型时代的agent开发方法论，以我跟ChatGPT的这个聊天去作为一个实践的分享，让大家了解。如果我们真的要做成这种艺人团队或者艺人的创业公司，这也是现在大模型火起来之后，在海内外非常流行的一种说法。就一个人就能够担任一个产品的全链路的一个工作。那他具体要怎么做？其实一个很重要的方法就是去利用像ChatGPT这样的大语言模型的应用，用它来撬动很多杠杆，提升你的生产力。
好，我们接下来就正式开始今天的内容。第一个部分，agent的应用开发指南。在聊agent的这个开发指南之前，我们还是再简单讲一下什么叫agent。Agent是一个随着大语言模型火起来之后的一种新的APP，或者说一种新的软件。不同的时代我们对于软件有它专属的名称，去代表它的这个核心的一些特点。像我们看到的web的应用，在2000年的时候，有搜狐、搜狗、新浪网易等等的一些门户网站，他们是以这个静态网页开始，后来做了很多的web端的一些优化，也诞生了很多web的框架。那后来，这些应用都被叫做web的应用了。那随着移动互联网的发展，我们看到安卓作为一个开源的操作系统，它虽然基于linux但它自己在上面做了大量的新的功能。然后安卓的发展，智能手机的发展，使得很多APP，我们现在叫APP，就是各种各样在智能手机上面的软件程序，变成了一个大家每天都会高度使用，重度使用的一种软件形态。
AI agent，其实它本身也是一个软件，只不过这个软件跟前面两种形态的软件有一个本质的区别。这个区别就是大模型所有的agent都离不开它的驱动的核心，也就是我们的LLM。这个LLM就跟下面咱们看到的这个动图一样，这个LLM的能力直接决定了这个agent的下限，就是它的能力的下限。如果这个大模型它本身是非常强的，你就算再怎么烂的这个agent的研发，它也会保证一个底线的，不会变成一个非常奇怪的响应的形态。但如果你的大模型本身不够强，那不管你怎么样去调整你的提示工程，包括agent设计里面用到的一些核心能力，它都会有局限性。所以这个大语言模型作为现代agent的核心是非常关键的。大元模型本身现在我们能看到它也是处于一个快速发展的状态。从18年的GPT bert，到我们现在使用的GPT4、cloud 3.5，包括我们看到的最近出的金巴兔等等lama 3，这些大模型其实是以一个远超mobile时代和web时代的迭代速度在演进。
因为大语言模型的能力提升了，所以我们看到下面这棵树，这棵树其实就是大模型能够给上层的agent提供的各种推理能力也变得越来越强。包括我们看到它的交互能力，它的多模态的支持，这个都比原来我们感受到的web和mobile要快得多。所以我们总结一下，AI agent是一个软件，这个软件区别于以往的软件，它的核心是用大模型来驱动的。因为用大模型来驱动，所以原来很多程序员和产品经理硬编码的一些软件逻辑。在agent里面其实可以通过大模型来在特定的环境下去判断，然后产生一些特定的交互和结果。然后这个过程当中重要的一点就是因为有大模型，所以我们会充满了环境的感知，数据的收集，以及基于这些数据来进行决策的一些提示工程和流程。好，这个是agent。
Agent的理论其实也是一个非常近期，就最近一两年才演变出来的整个agent的迭代。其实我们能看到，现在的这个react这篇论文应该已经被我广泛的提出了很多次了。在不同的这个课程和场合里面，大家如果去看过这篇论文的话，大家可以看到最下面这一行是他的论文在active上面的链接。这篇论文是非常值得大家去阅读的，并且它也不长是一篇很短的论文。
React这篇论文其实是2022年提出来的，并且是在年终，也就是ChatGPT出现之前先有了react这样的一个理论。所以我们叫agent的早期范式，是由react来启发的那GPT其实它的真正到众人眼中，被称为聚光灯下的明星是ChatGPT。在22年的年底11月左右发布出来之后，大家了解到原来现在的大语言模型非常强。但是在没有ChatGPT出现之前，开源社区能够使用到的大模型就是GPT3。并且还不是谁都运行得了这么大尺度的这个大模型。所以大家都在想怎么样去提升模型的响应结果，提升它的生成质量。
React就是首当其冲提出来了这样的一种高级的框架。这个框架其实是把大模型的两个能力给结合起来了。一个能力叫做推理的能力，reasoning trace，就我们说一个大模型通过我们学习提示工程，这也是我们预前面的一些有预热片给大家提供的两节课里面应该有讲过的。如果咱们有一些没有上过这个前面课程的同学，可以去看一看。通过像思维链，提示工程等等这样的一些技术，可以显著提升模型的生存质量。但是有一些任务，我们用agent是一个软件，它要解决我们的实际问题。
有一些复杂任务不是简单通过推理就能解决的，它一定需要大模型去调用一些外部的能力。因为大模型本身在22年的时候只具有文本生成的能力，多模态的大模型还远远没有在22年变成一个现像现在这样很多人都可以去访问的这个状态。那么怎么样能够调用外部的一些工具？所以我们能看到那会儿在APP only里面有像stay can，web GPT这样的一些早期的用大模型去调用工具的，我们叫项目或者实践。这些CK和web GPT用大模型去调外部这种单次调用的模式，最终在react这样的一个框架下面被整合起来了，我们叫做reasoning加上action。
既能够让大模型通过推理的方式去研究我现在的下一步决策应该做什么。同时也让大模型作为一个大脑能够去调用外部的各种工具跟环境去交互。交互之后从环境当中拿到一些反馈的结果。然后这个反馈的结果再进一步去决策，指导我们的大模型下一步应该做什么。
通过这个框架，其实我们会有这个两层的感知，第一层的感知就是大模型是整个react的关键。大家从这个图里也能看出来，右边的这个图里面整个大语言模型，这个LM语言模型其实就是我们推理和调用的这个核心。如果它出了问题，这个raft就会崩溃掉。这个也是我们在应用开发里面，经常用棉签去调用各种agent的时候会发生的一些情况。所以大模型是一个核心。
但同时这个理论框架其实也有一个缺点，就第二层的情况，我们发现他不够的落地，他提出了一种思想，提出了一种框架。但这个框架没有一个可落地的，比如说像棉签也好，或者说像更细节一点的这个推理到底怎么推理，这个跟环境交互具体应该怎么样交互，这个交互过程我们如果用过像auto GPT这样的agent，就会发现非常的消耗token。那是不是要无限的去走这个循环？这里有很多在实操环境当中的问题被暴露出来了。所以22年的这篇论文，到了二三年中有很多人去做了对应的实现，包括我们的应用开发实战引领，也讲过各种各样的实现。但是到了24年我们就会发现，简简单单通过reasoning加上action，是无法去完整的描述一个agent的。这个就是我们企业级agent开发实战营，想要通过这两个多月的时间，跟大家一起去学习了解最新的agent开发到底是一个什么样的形态来进行的。最简单的一个AI agent的一个形态，其实就是按照我们刚刚描述，可以用这样的方式来进行抽象。
而这里的LLM加上prompt，其实就是我们在年轻人里面学习的最经典的最简单的一个欠。就是大模型加上一个提示模板，也就是我们的LLM欠。在能欠的这个0.3版本即将发布了，在0.3里面LM chain也被彻底的应该是遗弃掉了。我们也会在这门课程里面，在南券0.3发布应该是在一个月以内，一个月左右的时间。我们应该会在讲第二个agent项目实战的时候，把年欠的这个0.3版本的更新作为前置内容，再教给大家怎么样用最新版本的能来实现我们后面的agent。
第一个agent项目，因为它相对来说还比较简单，不会用到很多年前的高级特性，我们可以逐步的通过这个课程让大家去了解。好，说回来，这个最简单的AI agent的组件，其实我们看出来它其实是符合react的这个流程的。从环境里面去获取各种数据，通过各种各样的传感器，然后由我们的agent以一种特定的提示策略，比如说我们在南阡里学过的这个plan and execute，baby AGI等等，这些都是属于它的提示策略。这些提示策略决定了我们这个大脑，agent的这个推理引擎会基于数据做什么样的决策。
但是从刚刚的描述也能看得出来，不管是plan and execute，还是baby AGI或者auto GPT，还有各种各样的比如说什么zero shot react这样的一些在南泉里面已经预定好的agents，大家会直观感觉它非常的多，很杂。不知道怎么样能够去捋清楚，又有这个规划加执行这样的agent structure，也有这种自主代理的alt GPT，还有各种各样别的这种agent。到底我们应该怎么样去选？基于什么样的逻辑去选择？这个其实是我相信很多人很多同学开发一阵子的时候会遇到的一个实际问题。接下来我尝试梳理了一个agent开发的核心技术站，也就是我们现在看到的这张图，agent开发的核心技术站，我们去把agent类型捋清楚，这个捋清楚其实对于我们了解agent的。
开发范式和他的这个理论进展是非常有价值和帮助的这幅图其实我们是今天这节课的重点，我们会围绕这幅图揉碎了掰开了给大家讲一讲。但是不可能讲的很细，因为这是一个outline，整个这门课会把这里面的内容绝大部分覆盖掉，不一定把每一个模型和每一个开把框架都覆盖掉，以及每一种类型的类型覆盖掉，这个不太可能。但是我们可以通过学习举一反三，能够很好的通过一点去整整理出这条线，然后大家就能慢慢找到这个感觉了。
其实agent开发的核心技术站这张图，它更多的是聚焦我们我们所谓的不带有这个前端各种这种美化级别的。假设我们要开发一个agent的MVP，它的最小可用的这个产品的版本，有哪些核心的技术是需要我们去了解的，然后我们做了一些高度的抽象。最底层的这个模型服务，像大家应该是在各种自媒体文章里面看到最多的，也是现在卷的最厉害的。今天这个模型发了新版本，明天那个模型又出了新版本。
模型服务这个是最好讲的一层，我们把它称之为模型服务。是因为绝大部分的同学去使用模型的时候，是不太会说我自己就把这个模型部署起来了。更多的是我去调用这个模型的API，或者说这个模型已经变成了一个产品。例如说ChatGPT。但是我们作为一个agent的开发来说，我们不太会直接去使用ChatGPT作为我们的后端引擎。实际上OpenAI也不允许。
更多的时候，模型服务我们是指把一个大语言模型封装成了一个API的服务。我们可以通过API的请求去访问这个大模型，然后拿到大模型的生成结果。当然这个过程当中，可能我们自己还需要维护很多的其他的能力。比如说上面提到的memory记忆的能力等等。所以我们看到这个模型服务被切分成了左右两部分。左边这部分是一些闭源的模型服务，面向商业化的一些模型服务。比如说atheros c的这个cloud 3，以及OpenAI的GT4，这些其实都是目前来看整个闭源的商业的大元模型服务里面最强的两个了，top 2了。
开源的其实是对于我们来说很友好的，我们看到有啊中间这个小羊驼，这个叫欧拉玛，是一个大模型的托管平台。这个平台也是在我们的课程里面会灌穿始终，整个三个agent的项目，我们都会同时支持调用闭源的模型服务和开源的私有化部署的这个模型的API。只不过可能我们一开始会先讲闭源怎么做，再讲开源怎么做。
考虑到一部分的同学不一定有GPU，同时我们这些开源的模型它是怎么被托管起来的？它本身是一个模型的权重，是由这些特定的公司发布出来的。比如说我们看到所谓被称为欧洲的OpenAI，miss OAI他们一直在以MOE架构去发布新的这个模型。然后金巴兔也是google在5 6月份新发布的一个第二代的，他们的大模型的系列。然后微软其实一直也在做大模型，他们的这个C3也是一个小尺寸的，能够做到非常小的尺寸，还有不错的性能。然后像meta就不用说，应该这一轮的大语言模型的开源核心就是围绕着meta的lama展开的。
国内的我也挑选了两个，一个是通义千问，一个是deep sac，当然我们不会说要便利所有的大模型这个权重，我们会挑一两个作为教学。让大家知道怎么样能够通过alama和hugger face hub去用你自己的GPU，或者说你在这个公有云上面租的GPU服务器来搭建一个私有化的大语言模型的服务。让他提供rest的API，你就能够去请求调用了。
好，模型服务这一层很清楚能够讲明白。上面这一层其实是比较复杂的。我们看到agent类型，按场景技术和智能我划成了三道线。这三个其实是有重叠的，他们并不是说完全不同，完全不一样的，这肯定是不是的，只是我们切分这个agent的维度不一样，我们观察的视角不同，我们分成了三类。这三类今天我会逐个给大家去讲一讲，让大家了解。希望通过这节课，大家未来再去听到各种各样的叉叉agent的时候，不要被扰乱了。我们还是关注它的内涵，关注这个agent到底有什么样的能力，是它是面向什么样的场景，解决什么样的问题。
整个agent开发的这个核心技术站之所以能够这样分层的去迭代走到今天，其实也有很多人做出了这个理论上的一些知识，包括我们开始提到的像baby AGI auto GPT这些早期的探索。O GPT就是GPT4刚刚发布出来的时候，也就去年3月份，GPT4刚刚发布出来的时候做的一个实验性的项目。通过这些早期的agent大家就意识到child thoughts这种提示工程，思维链这种提示工程，包括多次的去做我们叫做few shot这种prompt，都是可以让我们的大模型的生成质量提升的。然后同时RGB t还做了一个很好的提示工程的设计，就是把复杂问题拆成小问题来执行。这些其实都为后续比如说复杂问题拆成小问题分领域来执行。像我们提到的这个后面会讲的market agent多智能体，也都是沿着这个思路去做出了更细致的一些控制，以达到更好的生成效果。
然后除此以外，n chain的发展其实非常重要。因为有了能欠大家开始把模型服务层和上面的提示工程能够解耦了。有了这样的一个中间层的设计，不同的人可以聚焦不同的这个领域。在上层做提示工程的人可以在门线上玩各种各样的花火。从最早的我们看到各种各样的欠的嵌套，LM chain，rotor chain, transform chain等等。到现在能欠已经转向做这个rn ables，就是我们所谓的表达式语言，通过这样的一个方式来进行应用的开发，这些其实都为上层的agent类型的迭代提供了更多的灵活性这些灵活性我们待会儿会去讲，他们是怎么样演变的，那这些其实都非常有意思，我们通过这节课能让大家整体性的了解。其实有理论支撑的，大家千万不要，尤其上完这门课之后，还是辽AG的，就只能知道有南茜，有RAG，这个其实就非常不专业了。
好，我们接下来来看一看agent的开发范式有哪些，通过这三个不同的维度来切分了解。好，agent的开发典型范式我们首先讲一讲通过场景来做区分。这个也是我们上过应用开发实战营的同学最最熟悉的一种regent类型的划分方法。这张图应该也是非常熟练的了。
我们学习了南茜的同学应该了解了，在南券的模块设计里面，其实他把很多不同的功能模块去做成了不同的组件。整个能欠的设计理念就是通过组件的高效组合，像排列组合一样，能够诞生出各种各样的有意思的agent应用。就比如说我们看到在南券的这个A生态系统里面，它的memory部分，就是记忆存储这部分有各种各样的向量数据库的对接集成tools这边也是不断的在提升。从最早我们看到的各种搜索引擎的对接到后来的各种数据来源的对接，以及我们看到刚刚提到的plan这部分，有各种各样预实现好的agent的提示策略，auto GPT等等。这些不同的设计其实都能够使得我们在特定的应用场景里面找到开箱即用的能欠的agent。这个是南茜做的好，也是他当下具有这么多follower和开发者拥簇的一个巨大的原因。
通过应用场景，我们可以把AI的agent按照这个维度去做一个很有意思的分类。而这个分类其实也是最像这个人去考虑问题的时候，基于常场景来做分类的一种方法。我们在应用开发实战营里已经讲过了，通过应用场景其实可以把我们的agents分成三类。第一类叫做action agents，就是我们最简单的这个agents。它的核心就是你可以想象就是有一个简最简单的助手，他功能单一，他帮我去完成一种特定的工作，比如说天气的查询，比如说生成一个特定的circle等等。或者说我们在智能家居的场景里面，你可以跟这个小爱同学或者siri去交流，去完成一个特定的任务。这一类我们叫做action agents。第二种其实是非常的吸引人的，非常fancy的，叫做模拟代理。这个模拟代理的重点，其实就是我们可以把智能体扮演成一个角色，这个也是因为大模型底层能力的提升，给上面agent提供了发挥的空间。
在这个GPT3.5GPT4提出这个message chat model之前，其实我们的大模型一直是一个文本生成或者叫自回归的模型。你给它上文，它生成下文。但因为有了GPT3.5的这个开了一个先河，让大家发现其实我可以针对对话，针对这个chat去做专门的微调训练。使得我们的大模型它理解什么叫角色，甚至理解不同角色的目标功能是不一样的。那么这个时候我们看到我们去调用这些新的chat model的时候，我们可以给不同的这个对话里面设置角色。甚至同样的角色我可以有多个用名字来做区分。然后这里面不同的角色在一个特定的沙盒里面就能够去做我这个agent之间的交流了。其中的代表就是斯坦福的这个智能小镇。
第三个其实是一个长远目标，目前来看还比较难。它完全需要我们的大语言模型迭代到一定的程度之后，才能够很好的去实现所谓的自组织人体。这个自组织人体也因为它非常的遥远，所以在应用场景这一类分类方法里面，通常它就变成了一个很难落到生产这个环境里面的一个空中楼阁，因为大模型非常的强的时候，我才能够知道每一个目标我都要怎么样去执行才能落地。它相当于变成了一个开放式环境里面的超强的一个人工智能。几乎可以说如果我们真的实现了自主智能体，那AGI也就实现了。所以当时的auto GPT和ABAGI有一个巨大的高开，但是随着这个时间大家发现他们好像也没有那么强。其实他的理念是好的，但大模型还需要迭代，它需要有更强的理解能力和更多的工具调用的能力的整合。这个是我们基于应用场景可以去很清晰的去做一个划分。
像我们刚刚提到的action agent，比如说我们这种行动代理工具调用，在用开发实战营里面，我下面有这个来源，大家可以去。如果没有上过这个课的同学，也可以去通过这个来源直接访问到开源项目。像action agent，我们做过天气的查询，也做过circle的生成，我们做的时候还没有这么多fancy的名字，现在都有一个专门的领域叫NL to circle，就是自然语言到这个circle的这个指令。当时我们是在circle light这个非常轻量级的数据库引擎上面，加载了一个公开的开源的一个数据库的数据集，然后这个数据集里面是跟唱片，跟音乐人相相关的那我们通过这样的一个事例，让我们的大元模型拿到了整个数据库的schema，他知道了数据库里面有多少张表，每张表有多少列，各自的列大概是什么样的含义。然后我们再提这个需求，比如说这里就问这个。Top five artist by number of tracks. 
这样的问题。那正常的这样的问题，如果我们给到一个软件的时候，这个软件其实它需要有对应的接口去响应它，才能去查询这个结果。换句话说，不管它是有一个前端界面做一个按钮，做一个提交的框，还是在后端用一个命令行工具的方式提供了一个特定指令，它都需要自己把这一段circle指令写出来，我们才能够让我们的这个用户去随意的提问，然后通过逻辑的判断段引导到这个接口或者说这个API上面。通过action agent最大的好处就是只要这个模型他理解了这个表的整体结构和sigma的含义，其实它就可以动态的去生成circle了。以前每个程序员需要去编写的一段的circle的逻辑。也就是说我们经常提到的找junior的这个后端研发是一个circle boy，他天天做的事情就是CRUD。这个CRUD是直接查询数据库，或者通过后端的API再去查询数据库，通过ORM的方式。现在有了action agent，其实这部分的工作量就能够被我们的agent自动的去执行。
在这里当它落地的时候，在国内会有一个比较残酷的现状。就是我们会发现国内的数据库表设计其实做的不是特别的规范。同时表的这个命名也是一个比较相对来说不是很规范的一个现状。所以这样的这个action agents，当我们在NL to circle的场景里面的时候，我会建议如果你是一个新项目，那你可以让ChatGPT直接就从数据库表的设计上就给你开始一起协作了。就比如说你的表应该有几张表，每张表当满足特定的需求的时候，让他帮你去起一起这些表的名称，列的名称，那会好的很多。在这个时候，这样的新项目是完全有可能用action agent来帮你去实现很多数据库查询的工作的，就不需要你根据一个一个的需求再去写对应的API了。
第二个就是我们提到的斯坦福的这个虚拟小镇。一开始这篇论文提出的时候是非常多的关注，当他后来开源之后，也同样有非常多的人去给他star，现在应该也是有这个我印象当中应该有上万的star那这个项目，其实就是斯坦福的一个团队，他们把25个a agents 25智能体放到了一个小镇上面。这个小镇，当然你可以去搭建环境了，如果咱们有游戏开发的同学应该就很清楚，其实做这个游戏开发就是做一个沙盒。然后做的好一点的有物理引擎和交互。复杂简单一点的，不需要你去操作。这么复杂的这个操作的时候，就是有一些边界。
在这样的一个沙盒里面，做了25个agent，这些agent其实他们自己会交流。并且某种程度上来说，如果我们给他设定，其实这些agent在交流过程当中他是没有概念的。他不知道对方是NPC，他也不知道什么叫NPC，除非你教他。
在这里面我们看到诞生了一些很有意思的现象。就比如说这个小镇其实是有这个上帝视角，可以去设置一些内容的。比如说他可以设置突然某个人家里着火了，那这个时候你会发现这些agent他观察到了环境的变化之后，它就比如说我们看到下面这个有一个着火的一个很小的图标，大家到时候可以放大了看。其他的agent观察到了这个现象之后，他甚至会停下自己手中的这个事情来救火，或者说来找办法来救火。这个其实是一个很有想象力的事情。这个研究方向现在有很多的像微软等等这样的公司在投入。因为不管我们是做游戏开发，还是未来去做各种各样的剧本，NPC的设计，这都是一个非常有意思的研究方向，它现在也开源了，大家有兴趣可以去关注一下这个领域，这是一个作为模拟角色的一类agent。
第三类就是我们看到的这个自主智能体了，自主智能体的代表当时就是我们提到的auto GPT，这个也是在我们的应用开发实战性项目里面有对应的jup notebook。大家可以去访问一下，去了解。这个RGB t它的实现在南茜里面看来是非常简单的。因为就像我们提到的nanchang，它的价值就是给了很多开箱即用的agent。这个开箱即用的agent背后其实是因为能欠实现了各种各样的tools。像我们这儿看到的tools，以及它对接了各种各样的大模型，比如说GPT4。然后同时它也实现了各种各样的memory的集成。那这里我们有一个vector store，也是直接去集成了一个向量数据库，然后这里使用这个相似度的带阈值的搜索方法。最终我们通过各种年前已经预定义好寓实现好的这个组件，就能够直接去实现一个auto GPT的使用了。
这个RTGPT的使用，我们可以问他一些特定的问题。背后我们通过打印这个LT GPT内部的日志可以看到，其实充满了大量的提示工程。这幅图其实是我刚刚notebook的执行之后的一部分结果。这个结果我们去在应用实战营给大家按照这个源代码程度去解读过。这里我们再简单提一下，这里的这个内容其实非常提示工程的这部分的技巧是非常细致的，也是需要咱们不断的在agent研发过程当中去学习和研究的。通过这个提示工程我们可以看到整个咱们的能实现的auto GPT。其实它是分段分模块去给GPT4提了很多的任务和要求，当然也分角色。
我们看到在最左上角这部分有一个system是南茜版本的alt GPT，最开头的这个提示词，他有提到这个GT4你是叫什么名字？是一个什么样的角色？是一个assistant。然后最重要的一点就是我们看到所有的这个复杂的agent里面，它都会有各种各样的推理和这个action的交互。然后在这个过程当中，我们为了去调用工具，我们抽象出了一个东西叫做指令。就跟我们使用命令行一样，有一个叫做command的东西被抽象出来了。那在command里面这个提出来了各种各样的command，有一种特殊的command。是用来终止他的思考的那这个是尤为关键的，所以被放在了最开头的歧视策略里面。
我们看到最终在第一段描述里面这边有写到，如果你完成了所有的任务，请务必要使用这个finish command去结束咱们这一次的调用。不然你想象一下没有这个特定的设计，这个GPT4就会一直被不厌其烦的被你调用，然后去生成各种各样的中间的思考结果，当然OpenAI是乐见其成的，你就使劲用它就好了。但是对于我们的这个程序的运行和提供服务的人来说，这是一个巨大的开销。可能也会产生很多冗余的token，这个是非常关键的。对于我们去设计像以react这种范式为主的agent，必须要注意的就是这个停止的command要非常highlight重点提出来，接着我们看到紧接着这个finish command里面就有一个goals目标。这个目标其实就是前面提到的所有的任务，各种各样的任务。
这个任务当中的这个目标跟他是一个什么关系？其实在早期的时候也不清楚。但随着澳洲GPT做的这些探索被实践之后，其实我们后面会看到基于这种智能化程度的这种分类方法里面就做了一些区分了，就把目标也提出来，做出了一种明确的抽象，就这个目标到底是什么概念？这个目标又应该怎么样去达成？不应该让这个大模型像alt GPT这样去拍脑袋自己去想，有的问题他刚好撞上了，就能把这个问题搜出来或者说解决出来，思考出来。通过推理还有很多问题，他就陷入死循环了，那这肯定是不好的。所以后续这个agent理论的迭代也提出了像类似于效用函数，反思等等这样的一些技术出来。
好，有了目标之后，我们下面看到的这个限制条件，是为了给这个大语言模型在生成各种各样的推理逻辑的时候增加了一些限制。同时我们可以调用的toss各种各样的工具。在comments这个段落里面也有这个提示，有搜索引擎的功能，有写文件的功能，有读文件的功能。当然最重要的有这个finish的这个two可以去调用，有这四类tour是可以去调用的，包括它可以使用的这个资源，然后怎么样去评估我们的每一个步骤，这个performance evaluation。
然后下面是对它的返回结果的一个约束，就比如说我们大语言模型生成的结果。最常见的就是大家会发现聊着聊着它就变成英文了。如果我们是以中文在跟他交流的话，这些其实都是因为大模型本身它的上下文或者memory不可能无限的去记录你的内容。甚至可能因为像open a的，现在GPT它的用户特别多，它会去压缩一些资源。这个时候聊着聊着他就忘了他在用中文聊天，是因为他记了太多历史的冗余信息了。
比较有用的一种提示方法，就是在你的提示工程的偏尾部的一些位置，去给出一些返回格式上的限制。比如说这里的返回格式希望它是一个Jason的格式，然后返回格式的这个博士他给了一个参考示例，这就是我们在理论篇的时候给大家讲过提示工程。还有这个zero shot、one shot、few shot给参考示例一定是比没有参考示例要好得多的。这个提示工程到现在也都是屡试不爽的一种技巧。然后他甚至还写了这个response能够被python的这个Jason loads来解析，就是另一个约束的限制，因为python的是一个特定的用来解，然后你可以认为是这个解码Jason格式的一种python函数，那通过这个限制，更好的能让GP4知道我的response format是一个什么样的节省格式。
然后后面是他的进一步的搜索的结果了，最终得到了这个答案。就是我们看到右边他收到了一些结果，结果2023年的成都大运会，中国的这个金牌数量是多少？这里调用了的这个command叫做search，也就是搜索引擎。这个搜索引擎最终收到了一个结果是103，对，这个结果就是103枚金牌，是中国参加2023年的成都大运会的一个结果。然后最终他又去调用了red file，我们看到右下角掉了第二个command，就把这个结果写到了一个文件里，这个文件就叫2023年的成都这个大运会中国金牌数量的一个TXT文件。里面的内容就是中国赢了103个金牌，在2023年的成都大运会上面，open的模式是force，就说明它不是追加，如果之前有就覆盖掉里面的内容。
这个是alt GPT去完成一个我们交给他的任务的时候，内部可以去执行的各种各样的提示工程。首先讲这个事例是希望大家了解aut GPT作为去年4月份出现的一个自主智能体的代表性，它是有非常多的可取之处的。大家不要盲目的去听从很多的媒体的声音，是说LGBT不行了，这一年没有什么进展，其实远远不是的。就真的深入去研究过这个领域的人会发现它的提示工程可能不一定能解决所有的问题。但是它的提示工程，提示策略的提出，对于agent理论的演进，对于我们去设计后续的因为这个目标实在太大了，就像一个终结者一样的，像钢铁侠的贾维斯一样，这肯定做不到。但是如果我们降一降我们的要求，如果我们解决一些特定领域里的特定问题的时候，那么它的一些设计思路，其实工程的设计思路是值得学习的，也是值得参考。这个是r GPT带给我们的一些思考，也是后续各种各样其他的细分类的agent可以带来的一些学习的借鉴的点。
好，我们接着从技术的角度再来看一看，我们的agent现在又走到了一个什么样的阶段。其实从技术的分类来看，现在的这个agent的发展，大概有这么六类典型。而这个总结这六类典型其实是林茜的开源社区总结出来的，有这个chat box，聊这个，这应该是最常见的以ChatGPT为代表，聊天机器人，然后我们做规划的机器人planning，marty agent，多智能体reflection，这个带有反思能力的这个智能体RAG，这个应该是中国大陆大家聊的最多的RAG，evaluation做评估的，就能不能做一个agent，它带有评估的一些能力等等。这六类，我们在南茜的这个开源社区里面，其实都有一些参考事例，也是我们后面应该讲第二个，A型的实战项目的时候，会带大家去有代表性的去学习一些的。
那这幅图我们基于技术实现的角度，对agent的可以做一些分类，其中我们看到像chat works里面不仅是有我们的客服这样的一些情这种设计或者说这种实现。就它的第一行customer support，不只是有这种客服售前或者说售后的机器人。其实我们的代码这一类code assistant，包括各种各样的代码机器人，也都可以用chatbot这种技术去做实现。因为你可以想象一下，不管你聊中文、聊英文辽C语言、聊java、聊python对于大语言模型来说，其实本质是没有区别的。然后在它的训练集里面，其实现在代码也已经变成了一个训预训练数据集的比例越来越高的一个过程。
首先你得知道，代码不可能跟自然语言在一个量级，它更多的可能是跟科研论文的比例是一个量级，甚至要多一点点。因为代码本身也是人类的璀璨文明当中的一个细分类而已。所以聊代码或者基于代码去做chatbot，也是现在很火的一个研究方向，并且它是直接使用了大模型的内核的能力，不需要你在上面做各种各样的花朵。只要你训练的代码，然后你又有这个chat的专项的微调，就可以去做code assistant。
第二类是现在很火的一个新的研究方向，叫做marty agent system，多智能体的这个系统这个多智能体的类系统的其中比如说我们可以逐步的去把它变复杂，这个复杂过程可以参考着我们去年讲这个提示工程提示学习的那个套路。我们提示工程也有一个由最简单的GPT3，GPT3提出了income text learning，在上下文中学习，然后提出了一些简单的提示工程的技巧，直到后面出现了思维链，我们的这个self consistency以及trial thoughts，各种x of sorts就出来了。那么marty agent system你可以理解成其实就是在原来的提示学习基础上，又演化出来了更多更细粒度的这种agent的设计，待会儿我们可以去细看一下，他们可以对照着学习。
第三个大的类别就是RAG，然后所有的这些RAG都可以支持本地的这个大模型的版本，就是我们不只是调GT4，你也可以去调这个私有化部署的RAG。因为RAG1个非常重要的点就是知识库，而知识库通常来说又是有数据隐私的一些考量。所以这个又通常会跟欧拉玛等等这样的一些大模型的托管管理平台结合起来去搭建这个agent。
Agent其实从最早期的，我们在开发营里面讲过这个sales咨询顾问这样的一种形态。到最近应该有一个很火的词大家都听过叫grah RAG，就是把这个图的一些计算机里面，这个图不是图像，这个图的一些经典的特性引入到了RAG里面。像这儿提到的这个adaptive agency，包括creative和self这4类不同的RAG，其实他们都或多或少的用到了这个图的能力。所以graph RAG它其实不是一种RAG，它也只是一种实现特定RAG策略的方法或者框架。那么待会儿我们也会去看一些典型代表，RAG要planning agents，这个是我们之前看到的plan is excuse的。就是一个典型的就通过我们其这个规划能力上面的一些技术实现的差异性，可以去有不同的planning action agents，然后反思我们的不同的反思甚至批判，就是我们在提示策略里面去设计一些这样的东西，也可以做出一些不同的agent。
其中又以这个language agent tree search，这个LATS待会儿我们也可以去讲一讲。它可以算是我们在学习tree of sorts，就是我们的思维树这种提示工程的时候，其实讲了各种各样复杂的方法，当时在开发实战营里讲的还是很细，就这个tree of source到底怎么实现的？分成四个大的步骤，还有有生成函数、评估函数，评估函数有离散和连续两种情况等等。这么复杂的提示策略，如果我们把它转换成让大模型自己跟几个agents的小弟来做沟通的话，其实会简单很多。这个LATS就是这样的一种做法，把原来我们在一个大模型内部做的这个解空间变成了大问题拆小问题，小问题再由专门的agent去解决，这样的一种很有意思的理念。然后评估也是一类很有意思的分类方法，具体我们待会儿再来看一看。
好，那么有了基于技术实现的这个类别之后，我们应该相当于打开了一个新的视角，就是不同的技术特长可以演变出一些不同的类型，其中我们最熟悉的应该就是销售顾问了。我们通过GT4生成的数据搭建了一个知识库。然后利用GPT4作为我们的chatbot的大模型核心，然后驱动了这样的一个聊天机器人。这个聊天机器人也是咱们当时一个实战项目，这是属于典型的一个chat port的agent，并且它也比较简洁，用蓝芊去实现它的话也是一个小几十行代码的一个工作量。
那么RAG我们刚刚有提到，有很多各种各样的graph的RAG比起我们刚刚看到的这个房产销售这种RAG，它其实是一个开放性的。当时留下了一个开放性的可扩展的一个接口，就是让大家去判断当我们在向量数据库里面没有命中的时候，没有任何召回的时候，应该怎么样去进行回复。这个CRG created纠正性的这个REG，其实它就是通过这种所谓的纠正性的策略去实现的一种我们叫特定的RAG类型。
这里其实就是回应了一个咱们做sales content的时候，一个比较明眼就能看到的一个设计上的缺陷。就是如果我们去做向量数据库的检索的时候，只能用一种特定的检索算法和特定的阈值。那一定会有出现要么就是检索太多，结果太多，要么就是毫无召回的一种情况。那这个时候怎么办？有没有一些好的策略让我们在检索的时候，能够尽可能的去把知识库的这个内容挖掘到位。既不会在一些高频的问题上找出太多的结果，也不会在一些低频的问题上面颗粒无收。这个CREG其实它的背后是有一篇论文去做理论支撑的，只不过nine graph把它做了一个对应的实现。这里我们看到各种各样的node，包括这个检索的node，打分的node，都是我们看到在nine grave或者类似像graph RAG里面，它也是用这个graph来做设计的，这些不同的节点去采用这个图的方式，在节点上面去做一些特定的操作，怎么样去做操作呢？
通过这个流程大家应该能看出来。就比如说我们在刚刚的那个事例里面，我们用GP4生成了一些数据，然后这些数据当然它是问答。然后用户在我们的radio这个前端里面去提问，提出来一些问题之后，有的时候他就是没有相关的文档，没有召回。那这个时候我们其实是不知道该怎么办的那所以CIEG就做了一个介入，他在我们去检索之前，去打个分，去给咱们的这个你可以理解成把我们的这个特定的问题去做了一个评分。这个评分是基于我们的知识库来的，然后这个评分会直接指导我们假设这个不同的问题，高频的问题，可能这个分数就会高一些。就相当于我们假设老问这个小区的交通之类的问题的时候，我们要求阈值就不是0.8，可能要到0.85甚至0.9这样的一个方式去做设计。但这create函数本身也是可以再去做细化设计的。
我们主要是今天把这些理念关注给大家，后面我们有机会再给大家细讲这些特定的实现方法。这个时候我们需要在一些高频问题上把这个分数打高一点。就可以筛选掉一些原来可能已经过了阈值，但我们也会被它拿掉的一些方法。但我们直接去使用top k这种检索策略肯定不行。因为并不是每一个问题你直接用top k都是好的，你还是要有一个相对来说有一个阈值值去把把关的那对于一些比较低频的问题，我们可以用这个gray的再来控制它。好，如果这个时候我们发现有一些文档，它是检索出来之后，它这个质量并不高，那我们可以直接就移除掉，通过这个打分。这个时候如果我们移除完了之后，发现啥也没有了，那么这个就变成了一个最终没有任何，就是相当于你如果啥也不干，是有一些召回的。但这些召回可能是一些垃圾信息，或者说它的相关度不够，或者说不满意的一些答案。
通过你的grade移除之后，最终什么都没剩下的时候怎么办？在CRAG里面，他想到了一个方法是说在这种情况下，我去重写一下这个query，然后同时我去网上搜一些答案，就比如说我的库里现在没有这个答案了，我怎么样我都不可能通过大脑推理出来了。这个时候我们经典的各种各样agent里面的策略就可以被引到这个rng里面。但我实在没有答案可找的时候，召回被移除完了之后，通过web search可以获取到这个答案，并且这个答案甚至可以再加回到我的知识库里面来。那这样的一些工具现在也都被这个预定义好，可以开箱即用，在nine graph里面，所以这个核心在这里，我们看到的rewrite这个query，然后第二类就是这个self RAG，他其实就把刚刚我们看到的这个纠正性的RAT用到了极致。
甚至在这个CIG之前，还有一个别的方法去解决一些幻觉的问题。简单来说就是把原始的RAG的你拿到这个检索的结果，通过大模型去润色整合给到用户答案。这种方式改变成不断的去，我们不叫质疑，叫评分，反思这样的方式去过滤过滤一些低分的答案、不相关的答案，有错误的答案。通过这种方式不断的去改正我们的这个生成结果。所以在这里每一个分支其实都可以作为我们可以去介入RAT生成结果的一个关键节点。通过这种方式，只要我们判断出一些比如说没有相关的检索的文档，或者说出现了幻觉，或者说这个答案不符合我们的要求，有相关性的一些方法去评估等等，都可以重新来写这个question，然后走这样的一个流程。这个叫self的RAT，这个也是number up开箱即用的一种agent实现了。
除了刚刚我们看到的这个REG这个类别以外，这种planning做规划的agents也有很多。其中有一个很有意思的实实现一种典型的事例，就是LLM的这个compiler，我们叫LLM的。我不知道这个compiler翻译成什么比较好啊，大家可以理解一下它的内涵。就是说我们现在已经把大语言模型拿来做成agent了。然后agent又要解决各种各样的复杂任务，甚至他可能变成了一个服务。那变成了一个服务之后，有好多任务都需要去他去解决。甚至一个目标本身在一个任务的这个复杂任务面前，也被他拆成了多个任务，多个小任务。
这是我们做A证的时候经常会遇到的，把一个大问题拆成小问题，就像我做这个周三举的例子，就把大象装进冰箱，这是一个任务。但这个任务在落实的时候，变成了三个任务，开冰箱门，大象塞进去，把冰箱门关上，那这个时候，你就会发现开冰箱门和这个关冰箱门是简单的把大象塞进去特别难。那么在内部，其实这三个任务已经通过DAG叫有效无环图。这是一种经典的计算机的图的结构，就像无环图，它是可以通过拓扑排序的方式梳理出一个任务的执行顺序的。大家有兴趣了解经典的计算机的这个算法和数据结构的时候，可以去看一看。
通过这种有向无环图可以排出一个顺序，甚至可以通过这个DAG上面带权重的这个边去找出哪个任务是最耗时的。我们可以找到这些任务去加快加极限。就像我们这个我不知道现在还有这些什么什么是加急的服务，就加钱可以加快一点，类似这个意思。LM compiler其实就是不断的通过这个任务的获取，以及用户的反馈和响应，去不断的去调整这个执行任务的顺序。因为有的时候他们可以同时选多个任务去执行，我就选择那个执行之后效益比较大的，通过这种方式来做。就像我刚提到的，我就先把这个大象塞进冰箱，这个任务得抓紧去做。可能我在开冰箱门的同时，我就开始在找怎么样把它塞进去的方法了，是这样的一种典型结构，通过这种方法我们可以去提升规划的能力。
除了这个以外，其实反思也是现在包括文达老师提出的agent workflow这种更新的我们的大模型的这个agent怎么研发。当然agent go flow现在还没有特别好的开源框架去做整体性的支撑和落地，所以我们不会去过深的去讲它。当然在这个课程的进行当中，如果有对应的一些好的框架出现的话，我们可以去做介绍和引入。
反思和评估其实也是一种非常重要的提示工程。实践，我们刚刚提到的LATS language agent tree search就是一个典型这个语言代理处搜索，这是GPT给我的一个翻译，我觉得它可能也不一定能表达它的完整含义，它是直译的。它的一个逻辑其实就跟我们讲的这个trial thought比较像了。简单来说就是我们通过这个LETS它自己的这个迭代过程，其实我们能看得出来这幅图里他不断的在通过生成，然后自己再评估反思一下，我现在是不是做的足够好，有没有别的一些方式再来去做这个不断的把我们的解空间能够迭代到一个很好的状态。
这个比起我们之前看到的tree of source的实现来说，它有一个巨大的好处就是我们大家如果不记得trial sauce，可以再去翻一翻当时的那个算法是怎么设计的。Chef salt里面需要把原始问题给它，你可以认为它翻译成另一个非常做成这个搜索的问题。然后同时还需要再去做出对应的两个函数，一个是状态生成函数，一个是评估函数。但在LATS里面其实就不用了，让大模型他自己来做对应的选择。然后你也不用去想很多的解空间的一些深度等等各种各样的问题。这个是LATS，我们看到相比早期的这些提升，也其实也没有特别早trial south就去年这个时候的一年前的这些提示工程它的一些新的优势。而这些优势其实就是一个DNA双螺旋的进展。
第一是大模型它本身的能力提升了。去年的这个时候GP4才发布出来没多久，然后也没有像拉马3，然后这个cloud之类的模型去卷它。所以它推理能力肯定比现在要弱很多的。那如果在今年我们看到这个大模型上面，反思成为了一种可能。同时也是因为这些提示工程的算法和各种各样agents的提示策略的落地，让大家发现有各种各样的好的提示，其实这个策略可以被大模型内化回去，然后用模型本身来做判断。而不需要我们无限制的去把经典的计算机的算法也套进来了。不用我们再去搞深度优先搜索或者说广度优先搜索。
Marty agent是当下来看更好的一种策略，而且随着大模型的迭代，我觉得这个方法应该会更广泛的能够得到运用，因为它有一个很重要的逻辑就是分支，就是我们看到各种各样经典的计算机算法里面，分制一定是一个经典。并且像这个应该想个什么词呢？也不叫万金油。它是一个非常经典并且非常好用，而且广泛使用的有生命力的一种思维方法和解决问题的方法。我们看到大模型的底层训练有MOE，用不同的专家的参数和模块去学习不同的能力。在上层的agent其实也可以用类似的思路来解决问题。
大家可以想象一个agent的应用程序里面，当我们有这个marty agent的时候，其实是一个好事情。就相当于你想象一下人的管理也是一样，我们有一个公司的团队，他要去解决一些特定的问题的时候，如果你的团队只有一个人和你的团队有3个HC那你肯定能做的事情是不一样的。那有3个HC你就有三个人，这三个人可以是不同的岗位。比如说一个前端，一个后端，一个产品经理。那这三个人可以做出来的事情肯定你只有一个前端，或者说只有一个产品经理，他只能写这个PRD文档，没法写代码，能解决的问题要多得多。
当然我们可以说人是有学习能力的，就像agent也有学习能力。你让这个产品经理去学怎么写代码，怎么写前端的代码，怎么部署后端的服务，他也能学。但是他肯定没有三个人的战斗力强。
这个人的比喻就跟我们做agent是一样的。Agent其实就是我们刚刚聊的那一个的人。这个agent有什么能力取决于你给了他什么样的提示词，提示工程。那你很难写出一个完美的提示工程，让这个agent同时兼具三种能力。因为大模型还没那么强，就底层的这个大模型还没有那么强。你可以理解成就是你这个人的这个智商还没那么高，他没有什么开眼就会的这个水平，那大模型的智商到超级高的时候，也许他啥都会了，那你也不用太复杂的提示工程了。
所以基于这样的一个背景，我们就需要让我们的刚刚出场完的这个大模型有不同的角色设定。这个角色设定是在agent的这个层面上，然后不同的agent当然它就有不同的任务了。比如说有这个researcher，它就是专门去调各种各样的网上的搜索引擎，有一个chart generator，可以去实现各种各样的图表，就举个例子，他们都有call方法。简单来说就是他们都能调工具，调各种各样的工具有的是调搜索引擎，有的是调这个。比如说这个图表生成的可视化的一些工具，他们可以共同跟root去进行通信。
是不是有点像我们之前讲的这个router chain，我们当时提过router chain里面其实是一个前面有一个，我印象中应该叫原连欠实现的router chain的一个原模板。原模板里面通过两次的这个我们叫做解码，变成了一个条件选择的一个提示工程，给到最前面的这个router chain。而root chain后来可以根据我们每一个后面的这个LM chain的提示工程去自己去决定谁来干这个活。
但root chain它有一个比较麻烦的点在于它的实现原理。我们当时也讲过，它的原模板里面其实写的也很好了。它的这个原模板里面描述了我后面有destination chain，不同的destination chain有它自己的能力描述，就相当于每一个destination chain就像我们去调function call的时候有对应的这个function的描述一样。但是这种router chain它的适应性并没有那么强，因为它受限于一个模板，更受限于后面LM chain的这个描述。那LM chain的那个描述就是一句话，他也不能写太复杂，router就判断不了了。
那现在的好处是说，后面这个AM chain我们直接就把它做成一个agent，甚至一个agent它还能调工具。那就不只是说有一个router chain能够路由。后面有个数学老师，有个英语老师，有个生物老师，大家都是回答各自的问题，因为当时的那种感觉让大家觉得有一种多此一举的意思。因为其实背后的M券都还是文本生成的能力，它并没有提供额外的能力，也没有去调度。但假设我们后面的这些新的agent可以被调度的agent有别的能力，有two的加持之后，那这个rota的价值就可以被无限的放大了。所以marty agent其实是在router chain的基础上又往前进了一步，让我们的不同的agent可以再被一个root去进行调度。这个其实是所有的market agent的最简化版本，也可以说是原型。
一个agent就变成一个领域的专家，就跟我们的大元模型的MOE1样。一个experts被激活的时候回答的就是一类问题。未来我们也许有一天可以看到这个MOE和上面的这个market agent可以都在更进一步，也许就能做出更轻量级的模型去解决各种各样复杂问题的一种形态了。
刚刚提到的是两个agent，一个router来进行判断。既然有两个agent，我们很容易想到就可以有一堆的agent。当agent的数量上升之后，这个rotor还是很痛苦的，他不知道怎么样去判断。这个时候有一个比较好的解决方式，跟我们刚刚聊到的键其实是一样的，就是agent的这个定义。就下面这一堆agent的定义尽可能的是能够不重合的，就他们解决的问题领域是不重合的。然后这个代理监督员用一个能力比较强的大语言模型来决策不同的这个agent到底应该怎么做。可以说是刚刚two agents的一个进阶版本，这个进阶版本更多的是在supervisor这一侧用更好的提升策略来进行决策。
好，第三类其实是我们按照智能的方式来进行划分的。这个按照智能的方式来划分，其实是应该是今年开始一个非常新颖的一个划分方式。它更多的就把agent的差异聚焦到了底层的大模型的差异上。你的这个大模型越强我的智能化程度肯定就越高。因为大模型可以提供的能力也就越多。当然也有一些辅助的，比如说记忆的能力，也是可以被划分到智能这个维度里去的。
那么接着来看一看，按照这个维度来讲的话，我们有一个经典的分类，按照智能程度的不同，我们可以把几个核心能力，比如说决策的这个能力。Action、记忆的能力、memory、规划的能力、planning, 还有这个是不是有学习能力，这个完全就是跟底层大模型相关了。这四个维度的有无和有了之后它的程度去分出这5种不同的智能程度的agent。
接着来看一看最简单的这个agent，我们可以看到其实就跟我们最开始看到的这个AM chain是一样的。简单反射代理flex agent这种代理类型极其的easy，它其实就跟我们function后基于action agent是一回事儿。只不过他可能可以去做一些特定的设计，就是有一些特定的条件动作。比如说房间里有灰尘的时候，这个清洁代理去工作，这里它不限制于是一个单agent的一个设计。就整个我们左边看到这个agent，它是一个应用。这个应用里面也可以有多个agents，这样就可以去做各种各样的复杂设计了。
比较简洁一点的是，我可以设计成一个agent，但是我设计一堆的规则，就相当于我们把if else这种原来写代码的这种判断做成了一个condition action的规则。这个规则可以有多条，这多条放到一个agent里面。这样你可以少几个agent，多几条规则。然后只要这个模型的水平还不错，它是能够基于条件去做判断的。这种模式跟我们function call action agent就非常像了，这是最简洁的一种简单反射代理，它没有任何的记忆能力，也不基于历史的上下文去做这个规划，当然也没有学习能力。这个核心就是我们这里看到的condition的action rules。
第二类我们叫做基于模型的反射代理，model best reflect agent，它的主要区别就是在这儿我们看到有一个内部的状态，这个state它比起我们刚刚从这个传感器这儿拿到数据，就去基于规则去做这个，或者说基于条件action这样的规则去做进一步的决策之前，它有一个内部的可以观察环境的这么一个状态，并且还可以持续的去跟踪这个状态。那这个是我们看到的基于模型的反射代理可以做的事情。其实我们落到提示工程或者它的提示策略这个维度，就相当于它不再是只编写了一堆的规则。而是让我们的大模型他会去把之前的一些结果，不管是聊天记录也好，或者是action反馈得到的一些observation，或者feedback，存到我们的向量数据库，或者说存到我们的内存里面。这个状态会跟接下来当前的这个新收集到的数据一起作为它的一个决策依据，这个是我们叫做基于模型的白色代理。
第三类就是目标型的带go based agents，这个其实是它的灵感就来源于我们刚刚提到的auto gbt。从我们说从这一种分类方法来介入，其实它就开始把这个核心能力逐步加进来了。大家去想象一下，从最开始的只有基于条件来执行，到第二个阶段我们有记忆力了，这个阶段我们开始有规划的能力了。
为什么要规划？是因为我们有一个目标，这个目标是不是简单的通过给个提示词拿到结果就结束的。在刚刚的model base的这个里面，它也不是简单的一次的交流，它可能会有一些历史的经验作为参考。但是在go base的这一类agents里面，它其实已经可以考虑长序列了。因为它是要很多个步骤才能解决的。但他可能不一定像alt GPT那么长远，就什么都能执行。但是他至少把goals作为了整个agents规划里面，这个规划换到实现这个层面上来说，就是它的提示工程，或者说围绕提示工程展开的一些研发上。
有这个golf。这个其实是把原来的基于模型反射的这种能力更进一步，可以用更长的序列来考虑一些复杂问题。所以我们能看到在刚刚的这个流程里面，它新增加了一个ghost的。
同时，他不再是简单的把咱们的状态和这个历史问题给到what the world is like now这个流程里，而是他在做一些我们叫规划和搜索，就有点像我们开始看到的planning agents一样，但具体取决于我们怎么做这个planning的策略。他会问what IT will be like if I do action a，那他也可以同时去问，what if will IT will be likely I do action BC等等等等。这取决于我们的提示规划这部分到底是怎么做的。用一个数，用一个self consistency或者别的方式都有可能。甚至像360，他们直接做了多个大模型，从多个大模型的这个结果里面再来做判断投奔都可以，这完全取决于planning具体怎么设记了，所以这就是我们通过不同的维度去划分agents类型的时候，大家可以把思路打开，举一反三。然后把很多飘渺的这些概念能够拉通去想的时候，能够整体性的去理解一些事情。所以go based agents核心就是在普通的这个提示词上面增加了记忆力，增加了memory，同时开始去做一些规划了。
第四类就更进一步，我们叫效用型的代理，utility based agent。这些代理他就不再只是说有一个目标了，还要考虑这个目标到底怎么做才能做好。因为我们在auto GPT里其实就已经吃到了一个这个吃到吃一堑长一智，就已经吃到了这一欠了。就是当我老是去有一个go要去完成的时候，我又会陷入一种比较被动的状态。就是这个go它就是完成不了，怎么办？比如说我们在这个流程里面看到它有一个what IT will be like if I do action a这样的原始的一个流程，但它这里增加了一个新的效用函数。这个经济学里面应该经常会用到的一个概念，大家也经常听到一个词叫边际效用递减。
效用函数是非常好的一个用来评估我们当前的action产生结果的一，包括我们开始看到各种graph的RAT，其实也都这个逻辑，它增加了各种反思评估。本质上就跟这个效用函数是一回事儿，只不过它是一个函数的形式，还是以规则的形式来做反思而已。当我们看到他去做了这个目标的拆分之后，他又能够去有多个action来做这个选择的时候，增加了一个效用函数来评估到底哪个action做出来之后是好的。所以这个效用函数其实是用来干这个事情的。大家可以看到这五个不同级别的agent其实是逐步增加了核心能力的。
第五类其实就跳出了前面的这个框架了，它有点类似于我把这个玩法做的完全跟完全完全跟开始不一样了。我可以假设我的这个大模型的能力可以不断的去提升，就我们的大模型底层这个大模型的能力可以不断提升。同时我们的agents也就能够不断的去提升。所以他提出了一个概念叫learning agent，学习型的代理。这个学习型的代理在原来的框架之外，拎出来了一个新的模式。这个模式其实它的底层的框架核心就是我们刚刚提到的market agent system，还有多个不同的agent在工作。这个工作有点像我们各种线上系统里面的这种online learning的状态，就是在线学习基于用户的各种数据反馈，它可以不迭代模型，但它可以迭代agents，迭代知识库，迭代knowledge等等。所以通过他设计了我们叫评论员，然后问题生成器等等这样的一个逻辑。
核心的价值就是当我们有一个问题来了之后，我们可以去评估这个问题。然后可以从历史的这个数据里面拿到一些知识，然后可以把我们要做的这个问题抽象成一个特定的学习目标。然后这个学习目标还可以通过我们不断的使用这个agent补充各种各样的知识。然后未来当我们去遇到同样的问题的时候，他可以给出一些最佳实践的答案，最终通过这一个复杂的流程来进行环境的反馈。
但这一类learning agents现在还比较早期，可以作为一个大家作为一个了解。但核心的这个实现其实还是前面四类，我们的这个简单的反射代理，基于模型的反射代理，目标型的代理、效应型的代理。这四个类别其实他们基于智能程度是一个由浅入深，能力逐渐增强的过程。然后这个过程也是咱们agent核心能力不断被植入或者说引入到这个agent研发流程里面来的一个过程。好，这个就是我们从三个不同的维度，从这个场景应用场景，从它的技术实现，以及从我们刚刚看到的它的不同的智能化程度，大模型的智能化程度去划分的一个三种不同划分方法。让我们去对agent的这个类别有了一个系统性的了解。
接下来我们来讲一讲agent的核心能力，就是我们不管它怎么划分，它的核心能力其实是没变的。就像我们那些基础学科是没变的。它上面可以按照不同的，比如说按照经济学、按照科学、按照数学，按照不同的维度可以去做这个世界的结构。但是基础学科是不变的。那么agent的核心能力，也就是它的基础学科到底有哪些，以及这些基础学科怎么落地，需要有一些对应的开发框架。我们下一个小节来讲这些内容。
好，在正式讲这部分内容之前，我们来十分钟的答疑。正好我也喝点水，看大家有什么问题我们在评论区里提一提。我这边能看到，我也在这个评论区里。大家有什么问题吗？大家可能之前没有系统了解过agent，不知道其他agent有这么多东西，是吧？
如果平时想跟进AI或者agent相关的前沿发展，建议关注什么门户或者论文吗？这是一个很好的问题。我觉得还是我一直以来建议还是关注人，就是有一些这个领域的人是非常厉害的，但有些公司比较厉害。像我会关注什么呢？比如说像这个年倩，然后OpenAI，包括伊利，包括刚刚走的这个open I的高管等等，他们的推特你是可以去关注的。
然后第二个就是那个叫啥这个公司特定的公司，就比如说我们看到这个领域里面有很多的初创公司是做的很好的，南倩就不用说了，他肯定很活跃。然后还有很多在不断融资的初创公司，他们也会讲一些新东西。但这个新东西我们需要理性的去看啊。因为今天我就看到有一个新项目被发出来了，叫agent k。我不是特别看好它，它会像去年的order GPT1样，会是一种方向。这个方向是什么呢？Agent的K这个项目它就是说我可以用marty agent这种system去做一个agent，就跟GPT s有点类似，我做了一个market agent的system，它的设计目标就是用来给大家去做这个agent。
第二个是什么呢？第二个就是关注一些这个领域的前沿的公司，就像比如说像年前肯定就不用说了。然后还有很多咱们的初创公司，不管是国内还是海外的，也都在在疯疯疯狂的卷这个agent的赛道，待会儿我们后面会讲开发框架的时候会提到他们。
但是在看这些东西的时候，一定要比较客观理智的去去看。也是接下来我们要讲的这个核心能力的重点。就是agent不管它上面开出什么样的花，这个核心能力基础学科是它的扎实的基础，包括我们看到吴恩达老师提出来的agent agency workflow，它其实也是在这些核心能力上面去引进去排列组合的。这个核心能力如果我们能够去去聚焦，看到在这一块有什么比较有意思的成果，是是是更重要的。
然后开始我提到的有一个项目叫agent k是今天在在全网比较火的，尤其是外网。但这个项目它就像去年的auto GPT1样，它可能不一定有能上生产的这样的一个稳定性。但他的这个idea肯定是达到了很多人的痛点的和痒点的。他就做了一个marty agent system。
然后这个系统它就是你输入一个需求，它直接就给你生成一个agent的代码。那你可以想象，肯定能生成一些好的demo，就跟LGT能解决一些特定问题一样。但什么硬件都能做吗？这肯定不行，对吧？就是你你没有办法去造出一个超过你能力的生物一样的，就是这样的一个逻辑。
然后有个同学问刚刚讲的agent都是一些思路，不是框架对吗？不是，就是我们看到的场景技术这些分类，它其实都是有落地的实际项目的。像场景里面我刚刚就举了三个例子。然后像技术的这个，因为场景它不会有框架的场景，就是一类场景，这类场景里你可以有各种各样的发散的东西。那么技术这个技术的排列组合就很多了。
然后我刚刚提到了它的来源是nine graph，所以刚刚按照技术类别的那个大表，你们现在应该都有课件了，都是有特定的实现的。我们会在后面的部分，在合适的时候给大家讲那些特定的按照技术类别来划分的这个agent要怎么样去做。因为那个能力其实挺简单的，没有那么复杂去掌握的。你甚至自己可以现在就去预习，然后按照智能化程度来划分的，这个会偏这个方法论一些，因为它就跟场景一样，但它又是从智能化这个程度去把能力逐步去叠加的这样的一个分类方法。这个智能化程度的划分，其实跟现在温达老师提的这个agent for flow有一些重合比较高的部分。因为他聚焦的就是什么反思等等这样的一些能力维度，但它底层的其实还是四个核心能力，也是我们接下来要讲的。刚刚有个同学好像问这节课要讲多久，这节课应该是还有1个小时，将近1个小时，我们可能到九点半左右就结束。
有个同学说到了一个商业化公司的这个agent的编排的产品，这个不太好发表意见。对，因为这个对。在marty agent当中，通过大模型来决策和路由不同的agent如何决策的？是否会涉及到多个大模型协作？首先agent和大模型是解耦的，所以当你用marty agent的时候，当然每个agent他想用什么大模型都行。在auto GPT里面我们就已经试过了这个推理用GPT4，action用GPT3.5，这是比较经济实惠的一种做法。这个一定是解耦的。我刚刚就提过了，底层可以MOE来解耦模型参数，也可以在agent层面上去解耦不同的LLM在multi agent里面，当然不同领域的问题可以用不同的ent有的问题它用小模型就够了，有的问题它就是得用大模型，这是非常常见的。如果你所有的agent最后调用的是同一个LLM的API，甚至还是私有化部署的那你显然这个模型的那这个agent就会非常频繁的去调用这个模型，那这个模型其实就会成为性能的瓶颈。
能把其他agent开发框架和nine grap对比一下吗？面试的时候需要，我感觉你这个问题可以直接把你想要对比的框架URL丢给ChatGPT，让他来帮你对比，甚至可以生成表格。公司刚起步，项目少，积累少有什么推荐或者不推荐的agent吗？你这个推荐你得给我一些input我才能推荐，不然我不知道你想要啥，就没法推荐。结合知识图谱的agent相关的技术，后面会重点详细的讲一下，应该不太会结合知识图谱来来详细讲。我知道这个是一个研究方向，但因为我们做的这三个A政策项目已经大的方向定下来了。你可以看一看我们的介绍，然后这三个agent的项目也有它扩展性横向扩展的部分，但很难一下扩展到知识图谱去。但我欢迎在咱们的agent上面上，你去比如说把new for j这种知识图谱的框架嫁接进来去扩展。比如说我们ChatGPT可能就需要可以有知识图谱，能够把这个PPT做的更好。那这个其实是可以接到我们的已有的agent的代码里面来的。
周三的课应该是八点开始的对，周日才是七点开始的。多个agent协作的时候，每个agent返回的结构可能不同，并不是文本级的结构，可能是个DSL。那么在协同时需要做上下文的合并，这个有什么好办法吗？这个同学我不知道有没有学过南茜应用开发的课。
比较好的办法就是你的memory部分存的东西尽可能是一套语言或者说一套格式。或者说同一个知识库里存的是一套模式，一套格式。那你要解决DSL的问题，就是通过类似于auto的poser这种，在输出之后就马上通过output poser来进行解决，是比较好的。当然你也可以每个agent都有自己的memory，那你DSL的那个agent就保留DSL。那你要跟别的agent协作，那你肯定得处理一下，再再给别人，不然没法通信。就跟我说中文，你说英语，那怎么都没法通信，至少有一个translator，但是你跟同样说中文的人之间，你就说中文好了。
一个企业级A级的项目大概有多少代码量？你的这个量化指标很有意思，就是这个完全取决于你要把这个花雕的有多好。简单来说，如果只是把这个agent的核心逻辑实现，可能就是一千行上下，就算多的了。对，但是你比如说你要把我们第二个项目languages mental，你要扩展到N种语言，那你就要写一堆的提示工程。然后N种场景是不是也要有提示工程，然后ChatGPT，然后还要支持各种很花哨的PPT模板。那是不是还要开发一些工程的代码？这个就后面的那些部分就属于可以完全基于你的精细化程度去去要求的了对。
好，那我们说回来接着往后讲，待会儿我们讲完了再再来再来QV。好那我们好，我们接下来来讲一讲agent的核心能力和对应的开发框架如何落地。我们看到这个技术站里面的最下面那层和最上面那层，我们都已经通过前面的内容给大家梳理了一下了。那模型没有讲的特别深，给大家做了一些简单的介绍。模型要讲深，可能就微调的那个课会讲的更深一些。大家有兴趣可以去了解，包括nama的预训练是怎么做的，mixture这样的MOE是怎么样，这个MOE的技术是怎么演进的等等。但是我们agent就更多聚焦到agent的技术核心圈来，agent的核心能力其实现在来看，还是我们在这个红框当中圈出来的这四大能力，planning规划的能力，这个规划在上面三位，不管是从场景的划分，技术实现的划分，还是智能化程度的划分都有出现过。整个planning其实就是去拉出这个大模型智能化程度差异的一个关键点。
就比如说大家可以想象一下，同样的planning的提示词的，你给一个两B的模型、7B的模型，13B的模型，包括这个70B的模型到几这个几千亿的大模型。其实同样的，其实提示词做做出来的这个planning，他们的结果是千差万别的。因为这个本身就是在考验大模型的。我们在react的结构里面考验的是他推理能力。但因为planning已经不只是推理了，它还会引入到我们刚刚学到的，比如说什么规划、效用，然后这个目标等等这些被抽象出来的概念。这些概念大模型如果理解得到，他的规划就会做得好。他如果理解不了，你就不可能做得好。
第二个，memory这个我们不做过多的展开，因为这个memory更多的是向量数据库这个技术垂类里面的各种技巧。在人群里面我们集成了大量的向量数据库，可以是直接存储到内存当中的，也可以是持久化到我们的硬盘或者说到我们的这个GPU的显存里面，工具也是工具是我们在用开发实战引领就给大家普及过的各种各样的工具可以调用。然后如果你使用不同的开发框架，它已经集成好的toss也是不一样的，那像林茜它可能集成的工具多一些。所以我们可以两三行的代码调一个搜索引擎，调一个什么数学工具库等等。
那么action其实就是配合这个planning来的，就我们的执行决策，就具体要做的这个action要怎么样跟这个planning发生关系。所以我们把这四个核心能力再一收缩，你就会发现planning的简化版就是reasoning。那么简单的planning加上action就是我们的22年的。只不过后来我们看到这个agent的技术在迭代了，所以有planning加上了memory，加上tools，再加上action。然后这四个能力的核心支柱也在不断的演变，才演变出了上面我们看到的各种各样的不同的agent类型。但这些核心能力最终要怎么样落地，还是要通过我们的开发框架来实现。这里我们待会会简单介绍一下，不会给大家深入去讲，并且大家反复之前有人提到过的两个框架，我们今天也给大家提一提。比如说这个lama index的这个微软的semantic kernel，经常有人问他们跟南茜比怎么样，巴拉巴拉的那我们待会也可以看看这俩框架到底是干嘛的。
好，我们接下来就来讲讲这个核心能力和开发。刚刚提到的这个planning memory tools for action，其实也有很多的人都去做过阐述，比较有名的可能是open I的研究主管lidia问他的一篇blog里面写过，其实跟刚刚我讲的这个逻辑是类似的。大家已经如果好好理解了前面的三种类别的这个分类，再来看planning部分，就会理解了为什么要有这个子目标的分解、反思、改进，其实都是落到了不同的维度上面去。对agent的这个技术结构，比如说子目标的分解，ghost然后反思改进，可以把它理解成我们的在通过技术实践里面的反思，也可以理解成我们在智能化程度里面的简单反射，基于模型的反思等等。他们其实最终都是通过planning这根支柱来实现的那他们的底层逻辑也是大任务拆解成小任务。那么同样的大模型去多次累计的去解决这个被拆解的小任务，就能完成一个大任务，这个是合理的，并且被验证了。
Memory也是一样，我不需要每一次都使用memory。但是当我的这个问题它使用了指代词，或者说可以有这个参考答案的时候，有最佳实践的时候，那直接使用memory肯定是更快的。Tools就不用说了，这个完全是跳出这个大模型的能力之外，给它相当于加了各种flag in，加了各种插件，就跟我们经常看高达之类的，给他做了各种各样的这个装备。
Action其实就完全是在前面三者的基础上，基于这个大模型的本身的水平来做出的最终的结果就是这个action。这四个就构成了我们的AI agent的基本框架或者说核心能力。这些核心能力开发框架才是最终落地他们的在代码层面上的一个载体。
比较常见的开发框架，这里我们重点讲前三个，就是我们看到的能券，然后lama index和这个semesta kernel，这些不同的能力都有它不同的载体，像action比如说OpenAI，它的这个大模型本身也支持这个to our calling，连茜当然也支持to school。那么anthropic cohl都是啊这公司也都做类似的事情。Memory有很多公司提供了这个向量数据库的服务器，我们重点关注的是这个platform。
当然现在这个架构图正如这个图里写到的，它是AI agent基础设施的早期状态，所以聪明的同学可能就知道后面还有最近的状态。我们先从早期状态看啊，因为framework这一层，开发框架这一层还比较稳定，并且出现了一超多强的这个状态。这个一超就是袁倩，那多强就是后面这些跟随者都想要蚕食他的这一层，就是开发框架这一层的一些份额。但其实都没有能够干掉南迁的一个状态。但南迁本身也有问题，这个是技术迭代过程当中快速发展带来的那我们看到这个AJ的开发框架，南茜其实是咱们应该最最熟悉最熟练的。他我给他下的一个定义是，今天的年轻应该是首个，并且到目前为止应该还是唯一一个覆盖了从agent的开发测试到部署的一个全生命周期的应用框架。
这里的这个agent我们主要就是指刚刚提到的AI的agent，然后林茜其实它的结构非常清楚，当然很多人在吐槽她现在库越来越多了，这个没有办法。因为最早的年欠想要做的事情就是一个agent的开发框架。但现在的南迁，但他也有别的名字去代替，使得有不同的使命。现在的能生态，其实他就是想做一个全生命周期的框架。因为他也是一个融了资的公司，他应该融了几千万美金的这个投融资额。所以他也有他的股东压力，他也要去这个商业化。
所以大家能看到在右边这幅图里面，非常清楚的有这个OSS的这个标签的都是开源软件，open source software，这个南茜是n graph，也是刚开始看到的各种技术实现的这个agent就是nine grave，有直接已经实现可用的版本。年欠内部我们把它展开的话，其实就是原始的一个年欠的项目，被拆成了几个不同的python库，包括核心的年欠，然后这个chance应该会在0.3版本之后逐步退出历史舞台。而由这个新的年前core，也就是我们看到的年前expression language，年前的表达式语言来代替，原来的这个chance就会逐步变成我们的这个runner ables这样的一种抽象。
然后原来的这个基础组件，包括我们的model IO对接模型，然后各种各样的提示模板，包括我们刚刚提到的out of the powder，都在这个community里面。REG这个检索的部分，包括agents可以调用的各种tools，也都在community里面。因为这些都是严格意义上来说都不能影响agent的开发的核心。就像我们开始看到的这个分层一样，模型未来就是会有无数多的模型，当然它还会有一个收敛的过程，最终肯定是比较少的模型活下来了，但是它都不属于A型的开发框架的内核，它都是它底层的这个大模型，理论上应该解耦，所以它放到了community。然后检索其实更多对应着memory的能力，我的检索目标其实是一堆知识库，这些知识库都是给我提供记忆能力的。那么突兀里，同样的它其实跟那个action是有一定相关的。就我们的各种各样的决策，借助拓能做的更好。所以这样的一个架构是目前我们看到的最全的一种agent开发框架的架构了。
我们也期待0.3看到内嵌能不能做的非常好啊，它迭代很快，它每天都有这个新的版本发出来。所以我们第一个A的项目就是做了一个github的哨兵，就是我们一些快速迭代的开源项目，我们去能生成他的一些日报总结，然后这些日报总结我们甚至可以埋一些我们关注的点。那么nine graph就是我们刚刚提到的marty agent。就未来多个agent的系统可以通过n graph来进行实现。在内部通过点和边的方式去定义不同的功能。这我们到时候讲到的时候再展开，今天就不细展开了。
第二个就是index，lama index其实它的前身叫做GPT index，它不算是一个开发框架，但我们把它都放在这一层了。它本质上更多聚焦的是数据，某种层面上来说它不局限于agent，它是为大模型的各种各样的应用程序去打造的一个数据的框架。所以它提供的很多组件都是聚焦在数据这一层的，有点像我们在能欠当时的基础模块里面介绍的data connection那个组件，就我们讲过年前有一些基础组件，比如说model IO，data connection，包括chance等等这样的一些基础组件。Agent也算。
Nama index其实更多的是把data connection这块卷的特别多，所以它提供了像这个数据连接器，这个结构化的一些工具，然后输入输出的这个数据能够做得更好。更好的有这个formatter，然后高级的一些检索接口去对接这个向量，当然它同样也能跟外部的一些应用框架去做集成，它的目标其实就是帮企业对焦的是聚焦的是这个企业。能够把企业里面的一些高价值的数据资产，快速的高效的去做集成和转换。然后把它们能够加载到生产级的智能应用里面。所以它有点局限在以RAG或者类似于RAG以这个知识库为中心的这一类LAM的应用里面。
它的自由度、灵活性其实是没有像n graph chain这么高的。当然连线被人吐槽也是因为他太灵活了，所以什么都能做。以至于学习的这个门槛曲线太陡峭了，大家不太容易快速上手。那么index它的好处就是说我就是只做数据检索方面的一些优化，然后尽可能多的去支持一些数据结构，然后同时在外部的这个集成上做好一点。比如说支持各种各样的格式，PDF、PPT，然后支持各种各样的应用程序，比如说notion，snack等等。他是通过这种方式再选，所以你会发现他跟南茜不在一个主战场上面，他切出来了一块小的蛋糕，然后在这个小的蛋糕里面他在深耕运营。当然它的迭代速度肯定是没有能欠那么快的。
它的劣势也很明显，就是它比较单一小的这个赛道里面去去深耕，但是速度迭代的速度还是没有那么快的。它的开源社区和它的支持也是相对年轻来说比较少的。比较适合去做一些你要去做推荐系统，做数据索引或者做RAG的时候，检索优化的一些场景的时候，可以考虑它。但是如果你要去做marty agent，它它没有办法给你提供太多的帮助。这个是lama index。
第二个就是大家经常会提到的这个semantic kernel。其实我在以前的一些时间，一些不同的地场合也都做过回应，他跟南茜其实也不是一个层次的。这个项目。首先smeha kernel它是微软开源的一个项目。微软开源这个项目它的目标很简单，就是他想要帮这些developer开发者更好的去集成和使用这些AI的新模型，甚至一些其他的不是大模型的AI技术的一些框架。就干这么一个事儿。然后他的进一步迭代的这个模式，其实在他自己的这个官方文档里面也有。
我把两个图做了一个整合，其实你可以看到他其实希望说中间这个logo就是semantic nal。它其实就是说你的代码在上面各种各样的语言它支持的比较多，它有很多的SDK，然后通过smeha kernel你就可以去调各种各样的AI模型了，尤其是一些新的模型，它支持的比较好。包括他自己的微软自己出的这个C三等等。
把其他的一些AI的应用，可以通过它去去整合起来，它还提供了各种各样的回调，过滤器之类的机制。所以它特别像南茜最早期的一个定位，因为南茜早期定位就是帮助开发者快速的去调用各种各样的AI model。你自己就不用关心这些model到底它的SDK是怎么调的了，有这个南线帮你搞定，但南线现在已经远远超过了当初的设计目标，它一直在迭代。你像各种agent按照不同维度的实现，包括这个market agent，包括这个agent的部署等等，这些都不是semantic kernel这个框架的目标。所以semantic kernel你可以理解成是一个能欠零点几的一个版本的竞争者，但他不是未来想要往这个方向去做的，不然微软也没有必要去做一个graph IAG来去跟nine graph去做这个竞争。所以大家可以这样去理解这个semantic。
好，我们接下来看一看生产部署的平台，刚刚我们其实了解了核心能力有哪些，然后有三大开发框架都是在这个核心能力上去做了一些不同的深耕。其中的南茜肯定是根源最深的，因为他是是覆盖了全生命周期的那我们刚刚只讲到了它的开发周期，那么它的部署测试的周期有没有一些框架能够去帮他解决呢？其实是有的。
我们看到把这个开发框架和模型服务放在一起来看，也是一个很有必要的视角。我们要理解一下，这个agent的核心是由大模型来驱动的。而这个开发框架本身它不是一个大模型。它更多的是方便大家能够去调用各种各样模型服务的一个中间件或者中间层。底层的这些模型服务最终还是需要我们来去一个一个去去研究和对接的。
那只不过是说这些开发框架他们做好了很多通用性的一些工作。最后还有一些什么工作需要咱们来研究呢？可以举两个例子，大家可以想一想。第一个就是说假设我们的这个应用场景是私有化的，是一个数据隐私要求非常高的场景。那显然现在我们看到的模型服务的左下角就是闭源的。这些海外的服务器就直接被pass掉了，他们是无法使用的。我们绝大部分时候只能使用开源的这部分模型了，甚至开源的这部分模型。
据我了解国内的一些特定领域的国央企业，也是只能使用国产的这个模型权重的，像这个llama，这个金马兔等等，都不一定能直接使用，可能还得备案。针对这样的一个场景，我们无论如何，首先第一步要能够获取到模型权重。Hugg face这个在模型微调那个训练营里讲的太多了，我们这就不再赘述了。但欧拉马是我们之前没有讲过的，有很多人一直想要学习和问答。这个我们会在企业级agents这个实战营里面会花时间给大家讲。并且三个agents的项目我们都会用欧拉玛去搭建不同的私有化大模型的服务。
所以这些开发框架最终调用的大模型的服务，假设是在这种数据隐私要求高的场景下面，它就不再只是一个开发框架就能搞定的。它还需要由我们应用开发者，agent开发者自己再去部署一个大模型的服务。所以当你考虑到这个层面上的时候，你可以在开发阶段通过调GPT的API去做测试。但是到生产阶段你还是得自己搞定模型的部署的。所以这个模型的部署，我们可以叫做agent的hosting，它既包括agents这个应用程序本身，也包括host的这个大模型，这一块其实是有很多的工作我们还需要去做的，那具体怎么做呢？待会儿我们可以去给大家看一看有哪些这个主要是欧拉马，可以提供这样的一些便利，那也有别的。
第二个，就是说假设我们在这个过程当中，我们开发，我们部署了，然后我们线上出现了一些问题，我们需要debug，需要去评估怎么办？这个也有一些对应的框架可以去进行解决。好，这个就紧密了，就对比着咱们刚刚看到的左边这个早期的AI agent的这个基础设施和现阶段AI agent的基础设施，当然也不可能列得很全。
刚刚很多同学问，应该去关注哪些公司或者领域？其实这里有一些公司，大家是可以去看一看的，然后可以去twitter或者海外的一些平台，一些常见的平台去了解他们有没有经常的发生，然后就能很好的关注到一些新的信息。这里我们重点看一下刚刚提到的framework，其实是啊这一层由最早期的这个刀耕火种，这个手撸的阶段，我们只看到了开发框架。到现在开发框架的周围也已经有越来越多的生产部署的一些方案和平台出现了。其中我们把这个生产部署给它高亮出来，重点看一看。
我们会发现除了framework以外，agent的hosting，agent的evaluation，包括开发者的工具都已经逐渐在完善。有很多的创业公司都在做类似的事情，或者说开源项目。那我们就来分别看看hosting和这个evaluation要怎么去做，这个hosting我们可以首要去关注，可能如果只是去去解决我们私有化大模型的部署，变成一个API的话，欧拉马应该就够用了。并且现在的大模型的公司和这个团队也都会第一时间去支持这个欧拉玛。像这个google的金马two刚发布没多久，我就记得他们支持了这个欧拉玛。然后像类似的像达玛微软的C3也都是如此，所以。
我们会应该是在第四节课左右，会去去教大家用欧拉玛去调用。因为我们前面会先用警惕，那么欧拉玛它就是用来帮你去下载运行管理大模型的一个工具和服务。目前也应该是这个领域最受关注的一个项目了。
它的运行很简单，然后它支持两种模式，一种就是命令行工具，我们的第一个agent也会一样，支持多种启动方式，命令行工具的方式，直接可以通过这个pull就把模型权重下载下来，然后就运行它，也很简单，就变成了一个命令行的工具了。那第二个，就是我们把变成一个服务，变成一个rist的API，通过serve的方法就可以启动启动这个，我们可以认为你可以启动任意的这个大模型，但是他都可以通过server这个接口，就把整个私有化的这个模型的权重变成了一个对外暴露rest API的一个服务了。所以我们看到这里可以去在本地部署的这个nama 3.1里面去访问它，去获取对应的这个结果。
你可以通过generate方法，去用这种简单的文本生成的方式去调用它。提供一个prot。也可以通过chat的这个API，通过message这种聊天模型的方法对它进行访问。这两个也是从OpenAI开始的，GPT3一直都是这种generate的这种调用方法。一直到GPT3.5推出之后，check model变成了主流。并且现在也越来越多的大模型开始支持这个chat模式了，可以支持多种角色来进行更复杂的agent设计。
Nana m其实是年欠生态提供的一个跟欧拉马类类似的一种做生产部署的框架，它是支持南茜应用的快速部署，就像我们左边看到的，通过这个跟fast API的集成，包括跟pandey的数据验证功能的集成，可以快速的把南茜的应用变成一个大模型的server。比如说我们下面看到的，它把这个anthropic和这个GPT3.5的这个turbo，都可以通过一个newer给它加载起来，然后通过这个不同的路由去进行访问。在右边，就是python客户端的一个代码，它可以同时去访问不同的这个路由，就可以通过这个就很符合。
开始有个同学问的，有同学会去想怎么用一个agent去调多个大模型，或者不同的agent能不能调不同的大模型，其实都可以。好，那模型的这个agent的评估，其实在应用开发实战营里有提过。就是这个nice miss SS，它是一个单独的独立于年轻人去使用的一个平台，那这个平台也支持私有化的部署，或者说支持官方的类似于云的这种方式去去注册和调用。然后他提供了可视化监控和全面评估应用平台的能力。它的私有化部署应该是需要海外的公司才能使用。对于绝大部分的个人开发者，可能都需要在他的平台上去注册一个账号。
然后把这个nice miss的这个key放到你自己的agent里面。他就会去把你的一些调用过程当中的链路记录下来。那就可以在平台上面去看到它，甚至你还可以通过平台去调试重新去调用这些大模型。因为它跟连茜是深度集成的，就比如说我们这里看到的这个一个chat模型，它在next mix的平台上可以给出这种对话流的形式。即使你不是一个ChatGPT，就只是一个简单的年前的chat model，也可以做这样的一个模式，并且给出你一些有效的信息，方便你去第bug告诉你这个调用产生的整个链路的时间是5.13秒，5846个token。然后在不同的环节消耗的时间是不一样的。
比如说整个RAT花了0.7秒，但是生成这个chat OpenAI，就调OpenAI的这个chat model，时间花了5.07秒。所以如果你要优化的话，优化的重点在哪里等等。然后next mix的这个evaluation，它也有它自己的一些特定抽象。这个学过应用开发实战营的同学可能就比较熟，是我们当时加餐的一个内容。他在他的整个next mix的平台里面定义了数据集，然后这个评估器，任务和这个交互这样的一种四个大的模块。就跟我们把原来的经典软件测试的一些方法论，引入到了agents的测试里面。但它的这个evaluation展开很复杂。后面我们在具体的一点的开发里面，如果用得到，我们再给大家做深入的介绍。
这里主要是给大家做一个总览式的一个介绍，包括RAT，我们选择任意一种特定的agent，它都会有特定的组件被激活来使用。好，那么agent除了我们开发它的内核以外，还有哪些外围的技术是值得我们去做研究的呢？其实有很多，我们这里重点看一看它的前端和容器化部署的能力。
这个radio是我们已经在很多地方都使用过的这个UI了。其实radio除了我们看过的stable diffusion这种样式以外，chatbot也是我们在rng里面使用介绍过的。而这个chatbot其实它不只是能够支持简单的聊天，我们大模型能够生成的任何结果都能在这儿去显示，就包括这个模型生成代码等等这样的一些结果。类似的其实还有很多的样式，比如说各种各样的下拉选项，多选等等，包括表格。这个在我们后面去做第一个agent的时候，会给大家深入去讲radio的各种组件应该怎么样去使用，包括这种图表的生成，做类似于股票预测等等。假设有更复杂的前端，我们会介绍使用这个streamlet这样的一个前端框架。这个也是在大模型的前端领域非常火热的一个比较知名的，比radio更加灵活更多样式的一个前端框架，会在后续的一段时间做介绍和学习，他能支持的样式就更多了，包括各种各样的dashboard，包括他自己还有一个专区做大模型的这个应用商店，gallery。
里面也有一些成熟的的趋势。大家可以看到比如说像专门做max增强的max GPT，那么二的chatbot，包括大家经常看到的一些南线的stream net也都有啊。那怎么样去好的开发状态下的部署，是我们提到的容器化的东西。我们会在整个课程里面都会教大家怎么把这个agent用docker的方式部署起来。这个docker加上这个南茜open extremement，也是一个非常常见的容器化部署agent的这方案。
实际情况我们在dock hub上面会看到南券的更新非常慢，很多的同学可能都不一定会了解到南迁自己还传了一个多个镜像。但因为南茜的迭代速度实在太快了，可以想象一下他可能每天都要发几个版本，所以他的镜像其实维护的并不好。我们会在这个agent的这个课程里面教大家怎么样去打包，怎么样去写到file。然后把自己的agent变成一个可以快速共享的一个多块镜像去方便部署。好好的。好，那么我们这个。
时间。
原因，今天的内容可能就讲到这里了。然后大家有什么问题我们再来答疑，可能身体不是很舒服了，我们可以把GI的这个小节再放到周三去讲。好看，大家有什么问题，我们来QA再再挑一些问题。
Ra g对文档评分是通过大模型还是一些其他技术？通过大模型为主。但是你说的其他技术可能是指它的一些提示工程。
对有没有什么大模型agent方向的公司适合加入的，这个要看你是国内还是海外的公司了。对，可能我觉得你要是支持remote的工作的话，在海外的一些初创公司可以了解一下。你包括像年轻人等等这样的一些公司都是有去开放职位的。然后国内的这个agent的开发，其实不是一个特别好的生态，就可能还不如你能做出一些知名的，也比较知名的。就你能自己比如说这个课的三个agent能融会贯通去做一些扩展之后可能会更好，就已经超过绝大部分国内的agent开发的公司了。然后国内的大厂其实也都没在卷这个东西，国内的大厂也都主要在卷模型。
Java技术栈需要补一点python的基础语法，但是你只要跟他GPT去交流，也都可以学会的，他会教你python。Lama 3可以在mac上部署，这个得看你是什么mac了，你如果是超大内存的mac是可以的，就是卖了就一秒钟蹦几个token。准生产环境部署用什么配置？GPU比较推荐民用级，没有这个民用级的说法，只有消费级和企业级的卡。对，然后消费级的卡，我不知道你的这个准生产环境又是怎么定义的，反正4090那肯定是性能很强的，但它的稳定性难说。因为你加载了一个大模型，和打游戏不一样，大模型就会一直占用显存，还是比较消耗资源的。这个时候长期跑就跟挖矿一样，这个卡能请多久不知道。如果有条件肯定还是用企业级的卡，这样就算坏了，英伟达也会保修。
Java在agent项目里面干什么呢？不能干什么。你可以学习一下python nama和X什么influence各自适合的场景。没听过这个，你可以跟前GPT交流一下。然后欧拉玛的场景其实说的比较清楚了。对，就是管理下载和运行私有化大模型的。国内如果没有卷agent，是否agent实用价值不高？这个结论我觉得好奇怪，国内也没有卷GPU，GPU价值高，国内也没有卷操作系统，操作系统价值高。
南茜lama index和semantic kernel可以组合使用吗？没有必要，就是从能力的角度来说，南茜包含了后面两者的能力，为什么要组合他们的必要的？刚刚我就提过了，lama index的这些能力是对应的年轻人data connection这个模块。那个男劝佛界不是官方的，然后更新速度也很慢，所以出了问题。如果你用的比较深了是很尴尬的。
看还有什么问题。Agent开源项目的地址是指什么？刚刚有个同学问，agent开源项目的地址是哪个A型的开源项目？
Agent key那个项目就叫agent k不是key，就是AGENTK。你在google上搜一下，应该就能搜到了，就是AGENTK。对，可以搜一搜。
我们答疑到九点半，可能没吃晚饭，所以有点比较累了。我们可以周三再把后面这一小部分补上。学习型的agent有没有哪些热门项目可以关注一下的？没有，我刚才讲这部分的时候就说了，他还很早期。没有，对我也准备去重新买个路由器，可能这个路由器有点问题。这个学习型的意见真没有，因为它很复杂，要运行起来也很难。我觉得它可能会有下一代的更更可落地的一些演进方式。它就像是两年前的react一样，还很早期。
周六实战训练营是指AI com的线下的吗？应该是有一个目录的，会跟应用开发实战营的内容比较像。对。
这个有一个小任务，就大家所有问这种知识型的问题，其实都可以直接去问ChatGPT或者问google。对，会得到更更细的回复。然后cozy其实现在很少直接提了，因为整个字节的大模型都转向大包这个品豆包这个品牌了。
生产级的部署，欧拉玛够稳吗？其实是这样理解的，就是欧拉玛的价值是方便的把大模型运行起来。而稳不稳这个事儿其实得靠别的东西，说docker比如说这个cob natives来进行。
如果你资源够多，因为稳的前提是资源多，对吧？我不知道这个逻辑你能不能接受。就是稳定的前提是你有足够多的资源，你可以做这个比如说多个负载，load baLance，然后你也可以做这个异地的多活都有可能。但他前提是建立在多资源多。然后如果你想要说我资源不够，但是我一旦出了问题，我能被快速识别出来，然后又重新拉起，那这个多其实就能做到了。
知识库的构建有什么讲究以及好的实践吗？这个取决于你的应用场景。你看我们专门把agent它也划分了几类，就你的应用场景里面，你的这个知识库最终到底是提供的什么东西，参考答案还是什么东西。如果是答案，那最好是你的这个场景里面的这些答案。是能够你自己有一个人工的数据，梳理出来一定的规律。或者说你人工搞了一大堆的数据，让大模型帮你梳理规律，然后你就知道你的知识库应该怎么建设了。比如说特定的分隔符，特定的分割方法，特定的长度区间等等，甚至分层的这个分割方法。很多内容都没听懂，你没听懂很正常。
这节课是一个outline，是一个总纲提纲清理的东西。它的知识量很大，但是它可以成为你后面研究的一个知识结构，所以你不需要全部听懂，但是你把这个知识结构你应该听懂。对，就是那个技术栈。对，就是大模型它是一个性价比的问题。就是对于很多人来说，你做特别简单的任务，你不需特别难的大模型，特别大的大模型。因为它是有成本，所以agent跟模型解耦是肯定的。然后多agent的时候，不同的agent用不同的大模型也是很常见的。传统的NLP. 
周几开始上手。
实践理论有些枯燥。那个同学这个同学你说的不是特别认同。如果你觉得今天讲的东西特别枯燥，那你还是需要补充一些这个理论知识的。如果只上手，你的天花板挺低的。
其实因为你想象一下，你就钻到这个代码的细节里去了。但是其实很多技术的发展你了解不了。整体的一个框架的话，有很多代码的方法，其实他生命周期并不长。我其实是希望教的这个东西，让大家未来即使有新的技术出来了，大家能抓住它的本质，也就能够理解新的技术其实有的是换汤不换药的，有的是灌水的，有的是真的有了新的突破。但是你要把那个底层的根儿抓住，那个基础的部分抓住，你才能彻底掌握。不然就全部都是被媒体牵着鼻子走的。
智能体中开始的识别输入是打招呼还是问题，还是任务？一般是用大模型来做的，还是机器学习模型来做？这个我没看懂，这个同学你问的是什么意思？就是你这个问题听下来感觉是刚加入这节课，就是agent是一种APP对吧？你想象一下，你把这个词替换一下，APP开始的输入是打招呼还是什么，就很诡异，对吧？就agent它就只是个应用程序，然后我们今天花了很长的时间给大家讲agent是什么？它的核心能力是什么？按照不同的方法论来分类，可以有哪些类别，他又是怎么演进到今天的。
好，那我们今天就先到这里。我们周三的时候再再把这部分和那个开源的对对github开源项目的这个哨兵，第一个agent和大家一起讲，那个也会更连贯一些，就从怎么样有这样的一个项目，包括这个项目它的不同的分工，然后到我们这个项目第一个版本，连贯的一起来讲一讲，感谢大家。
