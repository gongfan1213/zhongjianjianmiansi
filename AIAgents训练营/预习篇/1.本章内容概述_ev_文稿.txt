	各位同学大家好，接下来我们进行理论基础篇的第二节的学习。这一节的学习我们主要分成两大块，一块是讲我们的GPT这个模型家族，这也是现在最火热的大语言模型，我们通过四个小节的分享，让大家理解GPT的模型是如何从18年开始到现在，一路发展到今年2023年的一季度。四月份的时候，出现了GPT4这样的一个多模态的模型。这一路过来其实有很多的技术侧的变化，数据的变化，包括我们大环境的变化。然后ChatGPT作为第一个出圈的AI大禹语言模型的应用，它到底哪里做的非常好，它赢在了哪里？这个非常关键，GPT4为什么成为了一个新的里程碑，那么它的这个牛逼之处在哪里？这个是我们GPT模型家族的部分。
	接下来我们会去分享提示学习，就是我们的prompt learning。在上节课我们初步的分享过一些关于bert和transformer注意力机制相关的一些内容。但是我们都知道自从ChatGPT出现之后，这个应用是需要人跟他用语言来进行交互的那这个交互的语言，现在我们都把它叫做problem提示词。这个提示词本身有没有一些技巧工程化的一些手段我们可以去学习，这个是毋庸置疑的。提示词本身又分为了好多种不同的领域，它都有它自己的提示词的一些思路和技巧。
	但是从这个术的层面我们往上跳脱一下，在学术界大家是怎么理解这个提示词呢？我们不是说这种今天我想到了一个黑化这个提示词很好用。而是说在一些学术层面其实有过一些研究和探讨。就比如说思维链，这个可以算是我们骑士学习的开山之作，叫chal salts，他第一次让大家理解怎么样去跟大语言模型交流，就人怎么跟大语言模型交流是有思路和套路的那思维链是一种接的多路径的推理，self consistently这种自洽性的提示学习手段，这种推理手段是一个更好用的，更稳定的一个拿大语言模型结果的一种方法。
	接着我们要处你非常复杂的问题，有没有一些好的思路。这个时候普林斯顿大学的一个团队发表了一篇论文，很有意思，叫tree of sorts。大家如果了解数据结构的话，就会知道我们学习数据结构的时候会学什么列表、队列，接着会去写比较复杂的像这种堆栈数。其实数据结构的这些思路，包括像搜索的一些经典的计算机算法。当它们移植到大语言模型的提示学习这个领域的时候，就会依然能焕发出这种经典算法的优势，这种经典的数据结构的优势。四位数就是这样的一个典型代表。