	大家好，我们今天来讲一讲AI大模型应用的最佳实践。在学习了我们前面一周的理论课程，然后又理解了什么是embedding，什么是我们的模型API之后，今天我我们正式进入到了大模型的应用最佳实践。
	在学习这节课，其实我们会分成两个部分。一部分是怎么样把我们的大语言模型目前学到的，比如说这种messages chat completion API这样的一种对话型的API，把它使用的体验做到类似于ChatGPT1样，能把他的聊天记录也给记下来，复刻一些HIGPT的体验。第二点就是说我们都知道prompt是生产力，那么怎么样去用好我们的prompt来提升GPT模型的使用效率和质量。下半节课我们会去讲function calling。就是在六月的时候，ChatGPT OpenAI推出了这样的一个新功能。在我们能够为ChatGPT或者说为这个GPT4GPT3.5这些先进的大语言模型去设定不同角色。譬如说我们的system assistant还有user，这三种不同角色设的指令以外，在六月份的时候又推出了这个function in，就是让我们的大元模型来判断在什么时候去调用外部的功能函数或者说API，这个是一个新特性，我们也会去做进一步的介绍，包括如何使用，然后有两个小的demo教大家去使用防眩功能的功能。
	好的，我们首先来概览型的向大家介绍如何提升GPT模型的使用效率与质量。主要是这几个技巧与原则，就是我使用GPT以来的一些经验和最佳实践给大家做一个分享。第一点就是要学会使用角色的设定。我们在使用ChatGPT的时候，其实最近有一些customer应该叫customer instruction。这个功能在ChatGPT的部分用户上面是作为预览型的功能，可以给大家去做设定了去测试。其实就是一定程度上开放了system这样的一种功能，但它更多的是对你的输入和返回做了一些约束。大家如果有这个权限的话，可以去看一看现在GPT里面的customer instruction。
	但我们今天讲的更多的是从开发的视角来做分享。因为真正去使用GPT去开发的时候，更多的是使用chat completions这样的API。在使用这个API的时候，我们在上节课有教过大家怎么样去使用不同的角色，然后为它注入不同的指令。所以我们从第一点和第二点其实是有相互关联的，就角色设定和指令注入。
	大家还记得在GPT3这篇论文的时候，有提到一个概念叫income tax learning，就在上下文中学习。在上下文中学习演变成了3种不同的prom的方法。比如说zero shot，one shot和few shot。这三种不同的prom的提示词的方法，其实是有不同的定位的。比如说就拿这个没有参考示例的zero shot来说。对于zero shot其实大家还记得论文里它最上面一行这个叫任务描述，换句话说，这个任务描述其实就是我这里想讲的这个指令的注入，就是在开头注入一个现在这个提示词的主要任务是什么？你要完成什么样的任务？比如说这个指令注入给它是一个主题创作，它是用来做文本生成的。
	这个是最早20年的时候，大家能够意识到的一种和大语言模型交互的方式，就是给他一些任务的描述。但是当我们出现了角色这种能力之后，尤其是以GPT4为主的这种多角色设定的能力之后，你这个指令注入可以跟角色搭配起来用。就比如说我们的system这样一个系统级别的角色，它的优先级其实是很高的，并且它是可以常驻的。在你的每一次交互过程当中，system的这个指令它的提示值其实都是可以单独拎出来。这样有一个好处是说，如果你的上下文特别长，那有一些上下文已经不需要再传给大模型了，又浪费token，又可能超过上下文的限制。那这些不需要再持续维护的user和assistant的这个问答的对话，就可以从你的messages这个序列里面去把它移除掉。
	System是一个主线任务，它可以一直保留，并且它的长度通常不会太长，这个是很重要的。在我们使用这个GPT4的时候，需要去用的一种技巧就是角色的设定，以及每个角色有不同的指令。那么system这个角色通常是把你的主线任务埋进去，并且最好给他一个身份。就比如说哲学大师，那他可能回答的任务就跟哲学相关。这个我们会在待会儿的事例当中给大家做一些实际上面的一些操作和体验。
	第三点就是说问题的拆解，通常我们看得到一个ChatGPT的模型这个应用或者说GPT4的模型，它能够解决一些生活当中我们遇到的一些日常的问题了。但如果你给他一个复杂的问题，他可能不一定明确的知道你到底要他干什么。就像你招了一个新员工，你一来就让他解决一个相对复杂的问题，他可能是一脸茫然的。但是如果你能够把这个子问题做一个拆解，就像我们在工作当中会用KPI，会用OKR。你给他做完拆解，那这个新员工就知道，原来领导是想要1234有这几个步骤。你按照这个步骤来，每个步骤会拿到一些结果。这个结果可以直接递交给这个领导，或者说递交给我们，对吧？就我们就是GPT的领导，那么他就会比较好的能够理解你的意图，然后去分步骤的执行你的任务。
	比如说debug，就是我们的代码debug或者说有一些多任务的场景都可以使用问题拆解这样的一些技巧。还有就比如说分层的设计，在创作一些比较长文本内容的时候，他可能一次回答不完，那你可以分层次的去提问。包括我们去生成一个代码仓库的时候，也是这样一个逻辑。这个分层提问的过程就像我们理论课讲的这个叫做思维数，或者说自洽性推理这么一个概念。我们只不过这个时候在论文里面是由大模型来做这样的多个步骤的拆解，构造这个思维树。但我们在分层设计去提问的时候，其实际是由我们自己，就我们这个提问的，或者说我们这些开发者们来设计到底怎么样分层的去提问，一步一步的去问，根据他的反馈再做调整。然后对他的反馈，我们根据他的反馈的内容，再跟他去做交互。这个过程是由人来把控的。
	但在进阶篇的时候，我们会去讲AI agent，就是AI的智能助理。现在整个AI智能助理的发展方向就是把我们来把控的这个主观的步骤改成由大语言模型来把控，由他来判断这个结果是什么样的。其实这种就是已经是一种思维数的实现了，因为思维数其实核心就是大语言模型来判断和解决这个解空间里面到底有很多很多个不同答案的之后，我要不要再深入去解决，或者说我要不要去换一个路径去做探索。这个事情交给大语言模型来做，那就是典型的AIA电子思维。
	还有一个就是我们的编程思维。我们在使用这个大语言模型的时候，其实我们一直在使用自然语言，在跟大语言模型交互。我们说的是人话，我们把人话交给大语言模型，让他给我们一些结果，这个是一个跨时代的一个进步。
	很多年以前，其实我们连编程语言都没有，我们没有python没有加我，我们只有汇编指令，我们只有指令集。那个时候人是极度痛苦的。大家就可以想象大机器和人其实是两种生物。这两种生物要做沟通，其实就是我们在往中间走。最开始我们造出这个机器的时候，机器能力很弱。所以我们只能用非常硬的东西，比如说这个汇编指令指令集去跟他交流，我们得往他那走，这样他才能理解我们的需求。
	逐步随着软件，随着操作系统的发展，我们现在编程语言越来越高级。我们不需要去写汇编，我们有C语言，后来有C加加语言，后来有更高级的编程语言，抽象出了面向对象，比如说java，比如说像python这种胶水语言，就更自然语言化了。这些编程语言的发展过程，高层次的编程语言就是为了屏蔽低层次的概念。那我们会发现这些高层次的编程语言就更好学一点，因为它更像人能理解的概念。那直到现在我们今天发现，我们已经可以没有编程语言了。自然语言本身变成了一个编程语言。这就是为什么说大语言模型有跨时代意义的一个另一个侧面。
	因为我们没有写过代码的人，居然可以用ChatGPT这样的一个应用程序了，就是因为他现在开始向我们这边走了。以前是搞计算机的一小部分人向机器靠拢。现在是机器足够智能之后，向绝大部分人靠拢。向这个行业外的，不是计算机这个行业内的人，各行各业的人，全行业的人，机器来靠拢他们了。因为那些行业的人以前是不会接触编程，这个是一个非常大的进步。
	具体要怎么落地？在今天这个环境下，就是怎么样使用我们的prompt，把prompt当成一种编程语言。我们待会儿会去简单的给大家做一些示例，就比如说在from的使用过程当中，我们也可以构造像编程语言里面的代码。里面有变量，有模板，然后也会有一些常量，就我们的正文。整个能圈的核心其实就是把prompt当成一个编程语言用到极致。所以它会有提示词模板，会有动态注入的变量。把这个提示词模板当成一个一个的函数来使用。
	那我们今天的示例里面。我们会使用GPT4这个模型，然后把我们的prompt当成一个编程语言，用来写一个函数。这个函数是用来评估模型输出的质量。
	接着最后这一点也是在GPT3开篇之作就提出来的。Few shot的思想就是一个万金油一样的逻辑。就是如果你能把你的任务描述清楚，并且你能给一些参考示例，而且这个参考事例跟你的任务是强相关的。你别给的参考示例其实跟这个不搭嘎不相关，那肯定是没有用的，甚至有坏的影响。那给一些参考示例是一定能够帮助大语言模型生成更好的结果。因为你的参考示例给它提供了或者说规范了它的推理路径以及它的输出的样式，就比如说我们待会儿会看一看用GPT4来构造训练数据，用来构造我们要进一步去做模型微调的训练数据，这个在我们的进阶篇的实战销售机器人的这部分，也有去用它构造一些可以存入相应的数据库的数据。好，那我们下节课就来尝试来使用这些技巧和原则，来使用我们的大元模型。