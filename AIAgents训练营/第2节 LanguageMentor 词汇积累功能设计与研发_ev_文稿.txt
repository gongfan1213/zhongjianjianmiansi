	大家能看到吗？hello. 
	我投放了，但是我不确定咱们现在那个画面正常吗？我觉得。
	咱们现在多少人在现场？那在线上的打个一，评论区我看一下现在多少同学在第十四节课，应该是还在坚持参加我们的直播。我这个挂灯好像是吧？
	我怎么一直在闪？
	我靠，关了。
	我还是有不少人的，因为这应该是国庆前的最后一节课，很多同学可能请了假的，现在都已经出去玩了。对，非常开心我们能在国庆前最后一次在线上相遇。对我剪发了，因为我明天也要出门了。对，好，那我们就正式开始今天的内容。今天也是language mental这个agents的最后一节课。好，今天我们讲language mental词汇积累功能的设计与研发。照惯例我们先讲一下今天的主要的内容分成几部分我们通过目录能看到，其实可以分成三大块。
	第一块是海口照常我们在学习网易他们做的这块用虚拟人加上agent的新全新的一种去学习英语的应用形态。现在多多邻国多邻国也在做类似的一些事情，只不过他们的游戏化设计会更强。那在hy apple里面我们知道有两大功能，分别是对话和场景。如果大家深入去用过海口就会发现，其实在场景的功能里面，还有一个细粒度的，我们把它叫做二级功能，叫做背单词。
	所有的同学都知道，英语里面最基础的你要学的东西就是单词。你知道有哪些词常用的单词。但是这么多年来我们都逐步的自己可能或多或少的在生活和工作当中用过英语之后，你发现只背单词是学不会英语的。就是你你记下来了一个的单词，其实跟人学语言的这个过程，尤其是母语是相违背的。所以开口包括我们今天要做的0.4版本的这个词汇积累的功能都是如此。
	背单词肯定是要在实际使用当中去背这个单词，或者说去学习和掌握这个单词。而任何单词其实我们在像我小时候，因为这个教育资源的问题，它不是很发达。那个时候老师教大家就是背单词，我印象中还有各种各样的小红书，是那个时候是真的小红书，就是什么新概念的英语四级单词、六级单词、牛津初阶、中阶、高阶、雅思、托福全都是红色的，不知道为什么。然后那里面全都是单词表，然后一个一个的单词里面会写这个单词是怎么拼写的，有哪些中文的含义，以及它可能会有不同的时态和这个语态上面的变形。如果是动词的话，那这样去背其实很低效率，所以海口肯定不是这样设计的，我们待会讲讲他怎么做的。
	第二部分就是prompt，因为prompt其实是做agent的最核心，也是它最基础的，最能体现，我们如果是把自己当成一个工科或者匠人的话，就是你手上功夫能体现出这个水平的一部分了。那么我们把词汇积累，借着这个词汇积累的这个功能，我们再来深入理解和学习一下这个prom的设计和最佳实践。因为我们再下一个就国庆节之后学习的这个chat PPT，其实它更多的就不是在这个prompt上面去像language mental一样做这么深的prom设计。它更多的是怎么把不同的模态，因为它有涉及到不同模态的模型整合起来，通过能欠的这套生态。那么在language mental里面，其实prom的重心非常大。这个通过代码，通过我们这几次课大家应该也都能看得出来。那prompt除了我们前面两节课，逐步的再让大家去动手深入了解这种长的prom的怎么写。有一开始教大家从跟GPT去做交流，然后到上一节课给了更详细的一个逐步迭代，让大家去做实践，让这个也是咱们必须要去提交的作业，就自己再去拓展两个场景。
	到这节课，我们在跳出来系统化的去了解一下，对于一个已经用过一段时间prom的同学来说，还有哪些可能是你遗漏掉的prom设计过程当中的一些技巧，以及我们用这个词汇积累这个功能来做最佳实践，进一步的分享怎么去做一个长的，然后能够支撑这个多轮对话的agent的。第三部分是更多的是偏向实践了，我们上手的一些工作了。我们的V0.4的设计与研发，主要是三大块的一个迭代，对应的这个代码也都提交到我们的课程项目了。大家可以去看一下release notes，或者在agent hub上看一下中文版的版本记录，主要是三部分。
	新增了一个词汇积累的一级tab，因为它因为我们整个用的这个radio是属于一个one page的应用，单页应用。我们不去做二级菜单和二级的tab了，就没有必要。我们就在整个0.4版本的这个用户界面上会看到有三个tap，分别是场景，单这个对话和单词。那么单词就是我们新加的这一部分，同时因为我们新加了单词，单词的学习，背单词、词汇积累，这样的一个新的type页背后其实还是大模型去驱动的一个agent。所以我们的language mental其实会有各种各样的agent。这些agent在场景那个功能模块的时候，我们已经做了一次迭代了。
	在0.4版本我们正式用python的这个python native或者更加python语法的这种方式去做了一次改造。大家知道在python里面有一个抽象类叫做ABC，它就是一个包括南茜早期也会用这个ABC去做它的鸡肋。我们实现了一个所有agent的鸡肋，包括场景对话和单词，我们叫agent base，在agent base上面去快速扩展各种个性化的，就是不同type页的，或者到type页里面不同场景的，都可以去套用这部分的agent模块。
	然后第三个就是考虑到未来大家会对language mental去做进一步的扩展。如果你没有去更换前端，仍然是使用radio的话，这里把radio模块的代码也去做了一个单独的实现。之前的radio我们都把它放到了win点PY这个入口文件里。在0.4里面我们把它去做了一个拆解。简单来说就是不同的tab页在radio用户界面以及这个用户界面上背后调的这个agent。年前的agent其实都是完全独立的。
	大家可以去想一想我们的场景对话和单词，也就是0.4要实现这个功能。他们前端页面长得都不一样，布局不一样，加载的video组件不一样，然后这些组件调用的chat port也不一样。本质上他们没有必要在一个面点PUI里面去维护，因为他们之间相关性很低，甚至是解耦的。所以我们把不同的tab页做了不同的代码去单独做维护。未来如果你要去再做扩展，也方便去做对应的实现。同时面对PUI也会变得更加的清爽，你就更能很好的去未来对前端页面如果是继续基于radio去做改造的话，就更方便。好，这个是今天的主要的这节课的内容。
	接下来我们来进入到这个具体的学习。第一部分就是深入分析这个eco的背单词的功能。这个背单词的功能在哪儿呢？我不知道大家是不是现在还的用户，反正我现在基本上每天把他的羊毛是薅光了的。因为他每天有大概10 10轮免费对话，那么我们来看一下它在哪儿，首先大家要知道这个i cho他九月份的时候就已经可以去换虚拟人了。然后除了有一个虚虚拟人需要额外VIP才能用以外，其他都可以换的。就比如说我们之前都叫echo，在这儿我们换了一个Sherry，这个井陉是按照他的人设的话，是在是在纽约长大的一个什么什么女生，那么这个Sherry一步一步怎么样跟这个人物形象去做背单词这个功能的应用呢？
	同样的我用这个红色的框去给大家把路径找出来了。首先在场景里面，我们之前给大家展示的都是各种各样的预定义的场景。当然它也可以自定义场景，这个就需要会员才能去深度用了。这儿有一个这个应该是动画顺序的问题，这有个背单词，然后背单词进去之后，还可以有单词本，有各种各样的单词本。那么这个单词本，就是你从右边你能看到右边和下面一堆的各种各样的面向考试，面向各种各样类型的考试的单词里面去。你先学学完之后可能有一些单词你是不是很熟悉的，你需要再加深去记录的。这个就模拟了一个线下的场景，你可以去记到你自己的一个单词本上，就像错题集一样的。
	整个链路其实是有一个我总结下来有三个特点。第一个特点就是本身我们看到这些单词本都是需要去专门做数据积累的。雅思然后雅思不同类别，托福不同的高频的不同类别四六级的考试，面向在校大学生，PET的这个高频，这个PET文章中应该就是多邻国做的一套考核标准。
	整个这部分其实是充分去放大了网易有道的数据优势。因为海口是网易有道下面的一个产品，而网易有道大家如果了解这个公司其实非常的强，他们一年的营收也是几十亿人民币的。然后他们除了做开课以外，还做了一系列的跟全学科，就不只是英语这个学科相关的教育类的产品。然后在背单词方法这个地方，其实我们去做一个对比就知道百词斩我相信绝大部分同学也用过，我了解过一些数据，他们差不多月活的用户数也是在千万的一个量级。那百词斩的这个背单词的方式，他们其实都在借鉴。和这个模仿多邻国的一些设计。那么百词斩的最开始的这个爆款和能够成功是100天打卡，然后跟你的朋友们去PK，谁记得快可以去像这个游戏一样的，类似于这个王者荣耀什么的，你跟同学对战之类的这样的一种方式。但它本质上还是背单词，就是给你一个单词，给你一个含义，你去选，最多说给你一个sentence，这个单词用在这里合不合适？
	但是hecho的背单词方法其实类比于百词斩这一类产品的话，其实就是一个全新的一套背单词的方法。待会我们可以去看一看。而同时它的目标导向也非常清楚。比如说面向雅思的词库，面向托福的四六级的，这个是我们看到这个海口能够去很方便的去让你把自己的词汇量提升的一种做法。
	那么具体怎么用？我们看到在这里选一个特定的单词本，然后可以再选一些特定的单词，就是你在50个词里面去挑，最多挑十个。挑十个词之后，但你也可以少挑一点，就比如说我们这儿只挑了前五个，在这儿我们能看到第三个这个截图页面，产品截图页面，你能够看得到，选出了五个单词，就是前五个。然后这前五个单词它会也会生成一个类似于我们在场景功能里面看到的有目标，然后有角色的扮演，然后也有挑战，那就所谓的任务。
	我今天在用的时候还触发了它的一个bug，就是在目标这一侧，我再反复的去选单词。因为你挑选单词只要你不开始对话，是不会消耗你每天的额度的。然后我其实特别想知道它到底是low base去做的这个对话，还是说通过大模型有可能会去生成一些新的对话。这其实是两套技术路线了，比较这应该叫从结论来看，他应该是用大模型生成的。因为比较有趣的是在我反复测试的过程当中，它其实爆出来了一个bug。但因为这是人家生产及商业化的产品，我就没把那个图放到这里了，大家可以去试一试。简单来说就是它的目标这一侧的前端渲染出现了一些问题，我可以把它放群里，回头就大家会看到他的这些目标里面的这些内容文本其实是动态生成的，根据你的选择来的。
	然后特点当然就是这里所说的最大的特点就是它的最佳实践。它成功的最佳实践是要在场景当中去学单词，而不是一个一个的去背单词。只要套到这样的一个模式里面来，之前的场景功能就完全可以复用了。只不过它会比这个场景功能做的更难一些，或者说有一些差异度。就是他要在对话过程当中高频的去用到这些单词。就是说我不是跟你闲聊了，我不是说在我们0.3版本和0.2版本里面做的场景功能。我只要跟你聊天，不管我用什么样的单词，只要我达到了我沟通的目标，一步、两步、三步几个挑战就结束了。在这个背单词的这个功能里面，它是必须要用到这些单词的，他也会去做一些检测，然后这里也比较方便去做两个智能体去进一步完成这个任务。
	我们来具体看一下一个实车，这个是我今天去用的时候的一个实际的手机上的一个截屏。大家也能看到，其实还触发了一些bug，让我们来细看一下。首先我们进到这个场景里面，我们可以去选择选择五个特定的这个词汇，然后开始测试。在这儿他其实就动态在生成这个内容他有提到他是他是一个经验丰富的项目经理，我是一个策略规划师，还是两个角色。然后他他扮演的是一个项目经理，但他知道自己是个AI box，我是一个学生，但同时我在这个对话里扮演的是一个策略规划师，然后目标就是有这三个沟通的目标。这个可以大家可以想象在agent workflow里面它就能复用一些。对但是在这个机器人生成的具体的每一段对话里面，其实是可以有额外的要求的，就是去用一些特定单词来生成内容。如果做多智能体能能更好的去约束它。好，那我们接着往下看啊，如果我们点击这个开始对话，他就会有这个Sherry来。
	跟他沟通。
	这儿是开了骑士模式，关闭了听力模式的。当我们使用这个听力模式的时候，他就不会再给你显示他说了什么，你就只能听那我们就按照他的提示回复了一段sharing，你这里大家发现bug没有？就是这里是一个很神奇的bug。这没办法，我只有这么多额度，我没办法再录一个他没有bug的。我这个也说明一个好事情，就是呃首先按照我的实测，就是80%以上的情况，这个还产品是能用的，并且是很不错的体验。但是它也有一些大模型的通用问题，就是包括我们现在这套0.4版本集成的这个系统提示时里面偶尔也会出差错。因为这大模型的特性带来的，除非你去做非常多的前处理和后处理。
	这儿大家如果去细看，就发现这个Sherry这个虚拟人也好，这个air box也好，就犯了一个很常见的错误，就是角色的混淆。他先跟我打招呼讲，嗨alex，就是我可能是那个策略规划师的名字叫alex然后他扮演的那个角色是Sherry。但我跟他回复完之后，他继续跟我讲，嘿Sherry，i'm doing great. 
	是我操，就感觉他把我可能回复的一种就这里这段话感觉应该是我回复给他的，但他可能因为某些原因，内部的原因就出错了。那这里我就想就着这个去深挖一下，看看能抽到什么地步。跳转，这里我就继续再跟他沟通，然后他我不知道这里是他有意而为之的还是怎么回事，我这里就没有按他的提示来继续跟他沟通了。比如说我会跟他说，oh no, i'm alex, you are share. 但这个Sherry我发音我自己去自己测了一下，应该还蛮准的。但他就是不把这个词给展示清楚，他就写成sorry，我不知道是他自己做了一些处理还是。
	怎么回事。That's okay. So what do you think about the efficient or. 
	他就无视了我这个问题，就继续往后去推进了，这里应该是做了一些强逻辑。
	Oh really what's the power. 
	像这里，你看我继续说，我说你是Sherry，但他就会用sorry sharing，但是他就不会说是share。我不知道这个是他自己测出来，这是一种容易让他整个造成崩溃的一种做法，还是怎么回事？显然这里我摁住说话，然后语音识别到文字，然后给到那个大模型之前，他一定是做了一些前处理的，以保证这个对话还能继续进行而不至于崩溃，这是我自己的一个判断，大家也可以去试一试，应该是有机会触发的。这儿我还在看有没有可能我直接打字，但他不给我机会，他不让我打字，他他只能让我语音输入。所以我这儿是尝试了之后，最后就应该还是只能语音输，还是说我可能有打字的机会，大家可以去研究研究，我自己找了半天没找到怎么手动输一段话。有可能是按右边。
	这个to compliment the project。Team member. 
	这个应该是开了tiny模式给大家展示一下。在这里有一个tiny模式，这里有个小的沟，这个模式打开之后，其实它就不会给你显示它的文字了。好，那我们可以继续推进。这里我不知道是什么什么原因，就他他的语音识别出现了很多的问题。
	sure. So how do you think we can value the content project? 
	这样他就强行去去推进整个沟通流程了。我们把这个对话提示打开，就能看到这个对话提示的生成和它的给你的回复。其实本质上应该是两个agent在进行操作。这样的话其实你可以进一步降低这个跟你对话的agent它的性能上的要求，因为这是两个独立的工作是。
	Problems and a decision, and of course, their attitude and work as they are important to. 
	这里稍微展开讲一讲，就是我说是对话提示和他来回复咱们，或者他模拟扮演的这个角色。两个agent的好处非常明显，就是当我们去用第二个agent专门来做对话提示的时候，它的任务就是基于已有的单词组去回应。咱们现在的这个我们叫老师也好，叫Sherry也好，就这个Sherry这个checkbox的问题，就相当于它的输入就很干净，就是这段历史的你跟他的对话记录，并且他的任务就是给出一个可以紧接着回复他的这句话的一个内容，然后同时给出中文和英文的版本。
	如果是在背单词这个功能的这个环境下的话，就是需要尽可能的把这个单词组给加进去。然后单词组可以离线的去进行，或者说不叫离线在这个大模型的prom之外去进行维护。因为它生成出来的这这些内容，一开始都是基于你选的这几个单词，这个在产品内部是完全结构化的数据。好，这里我们可以继续去跟他沟通，其实就是我跟他就按照他的这个提示去进一步的进行交流，这儿我们就可以稍微跳过一下。
	We can make sure everyone is working on something. 
	这个real meeting，然后我也念了这个real meeting这儿我不知道为什么今天它的这个识别模型就出现了很多次问题。这里就很很有意思了。我们再来看，就今天因为各种奇怪的问题，反而暴露出很多high echo内部的实现的可能的一些实现的技术方案。我们明显看到为什么我坚信对话提示是另一个agent甚至说它有一些REG在里面呢？就我们明显看到在前面，我用这个语音识别输入了一段或者说念了一段内容，就前一段的提示叫做这个regular meeting。Regular meeting are definitely helpful。We can also encourage open communication. 
	我念了这样一段话之后，就按照提示念完之后，它其实是识别出来了。因为这一段内容就是他识别的结果。但这段结果不知道为什么给到这个Sherry的时候，他说他的耳朵出问题，这个是很神奇的，就说明这儿一定是工程化团就工程落地的这个团队，非AI的算法这个团队有一些地方没有去优化到最好的状态才会造成。因为这里的按住说话加识别，很有可能用的是我手机本地的一个算力去完成的一个识别。绝大部分现在的不管是输入法还是APP内置的这个语音输入，都支持对应的这种识别功能。对他识别出来了，但是没有成功的发送给对面的这个AI这个或者叫chatbot没有发送给他。所以他会说他的这个耳朵有点问题，没听到。
	Could you hit me with that one more time？
	他是希望我能再说一次，但这个时候对话提示却好像是已经听到了。然后接着再往后走，大家如果去看这个对话提示的内容的话，这边他已经在写了这个exactly，I think it's important to regular check. 就是他们的输入源甚至都是不同的。因为对话提示直接就看到了我在本地已经识别成功的这个regular meeting，这里正好去分析软件和它的实现原理，这个应该是一个很有趣的过程。我相信所以我们看到对话提示的生成这个agent他能拿到我在本地成功识别的这段话，他当然也拿到了sorry，my ears must be taking a break, 也拿到这段话，但这段话权重并不大，因为他听到了regional meeting，所以他给出了一个提示。只不过这个提示其实是Sherry应该说的就完全的错位了。
	大家去去体会一下这个过程，这个是只要咱们做AI的agent，至少到2024年2025年这个位置，我觉得都需要去通过workaround，通过工程落地，通过各种技巧去解决的产品问题。只要一旦发生了错位，因为大模型其实它是在模拟对话，他并没有真的知道这段话应该去谁来说，谁没有说他是按照流程一步一步的就去做这个事情的，他还没有到那么高层次的抽象。尤其是这里应该用的是开源大模型，按照他们的说法用的是有道自己的这个子曰，所以这里的提示变成了提示shary，然后最后他还问这个what about you？Do you have any other suggesting for improve, for improving team team CoOperation CoOperation? 这个应该是由Sherry说出来的，然后我就很好奇能不能再再深挖一点。
	但很遗憾的，这个免费的额度就用完了。所以其实大家也能看得到，即使是已经商业化做的非常好的这个产品，在大模型的这些问题上也都需要不断的去优化迭代的。一个是积累数据，另一个就是在工程侧的各种优化和一些兜底了。
	Sorry, can repeat. 
	这里就很神奇，我们看到这里我想再看一下对话提示会发生什么。结果刚好就到这个免费的轮次用完了，我们看到他这个对话提示是给出来了一段，为了进一步印证这个对话提示。和Sherry是两个agent，就是他们的输入数据应该都是不一样的，就是他们的user input都是不一样的。所以你看我继续问他就是you see you missing what I see？他上面写了他他耳朵出差了，耳朵没听见，能不能在给我一些重点的信息在一下，那这我们就写到UCU。Missing what I see, but the hint is strange，seems that you here. 这儿应该是识别的出了问题，因为我当时有一些背景音乐，然后这儿就很神奇的看到了Sherry的回复，就是sorry，I didn't quite catch that. 
	他的意思就是他其实根本就看不到那个提示。所以整个我们看到hi echo的技术实现的方案应该是一个agent跟我们对话，然后给他的输入的prompt。绝大部分的情况下，应该就是一个场景化的描述，以及它的主要任务，跟我们在场景功能里面做的是类似的。然后他的对话提示提示的这个功能应该是直接抽出来做了一个独立的agent，这个agent可以拿到完整的历史对话。然后这个历史对话可以进一步的去帮助尤其是这个LVE新手用户，去更好的推进这个学习过程，学习的这个流程。
	但同时也因为他这样去设计，其实进一步降低了他对大模型算力的要求。因为如果把这一个事儿，就咱们是两个事儿放在一个大模型里去做。他如果把这个拆成两个事儿，让两个不同的大模型去分别处理的话，其实会进一步降低他的要求，甚至他可能可以用一个3B左右的大模型就完成这样的工作了。那对于他的成本是一个非常大的一个降低。
	这个是关于咱们看到的背单词的这个功能，最终一句话的结论就是，首先百分之八九十的情况还有很多是能用的，并且在在线的虚拟口语教练的这个赛道上，他就是现在中国做的产品化程度最好的。只不过大模型本身，尤其是开源的大模型，或者说他们的自身自研的这个大模型，是有一些难以百分百去解决好的输入造成的这个问题。所以只能通过咱们在产品上不断的去优化数据，优化工程才能够去迭代，所以是有优化空间的。从这个结论来看，其实这个赛道市场很大，然后最强的产品也都还在面对这样的问题。对于大家如果感兴趣，不管是做学术的分享，还是你自己想要做一个更小的一个垂类需求的一个创新创业什么的，这还是有机会的。
	好，这个是关于hi echo的背单词的功能，大家有一个了解了。那接着我们再来学习了解一下这个pro的设计。我们已经在开发的这个实战营里面给大家讲过chrome的最佳实践，但更多的是面向ChatGPT的，就是在ChatGPT里面有哪些最佳实践可以去使用。这个小节我们希望结合着这个词汇积累的这个language mental的功能模块去进一步的去看一下。如果我们作为一个已经有prom使用经验的人，要怎么样能够去深挖一些可能之前我们知道，但是没有做的特别实诚，做的特别扎实的一些技巧和最佳实践。
	首先第一点就是我们都知道RTF了。当然如果还没听说过的话就有问题了。RTF应该是一种非常典型的prom的结构。那除了RTF以外还有很多的结构，只不过这个结构是最简单的。然后可以在上面再去做plug in，去做扩展。就比如说我们有角色，有任务，有最终生成的格式和样力，那是不是还可以给这个角色除了任务以外给他加技能包，比如说skills。
	在最新的就本周OpenAI的advanced voice mall这个模型发出来之后，其实有人就越狱的方式去获取了。但这个也是他自己生成的，他他说我自己的这个提示是这样的，但是不是百分百，也不好说。因为它的temperature肯定是设置的大于零的，但大概意思其实是有的，后面我也宰了一个截图。所以不管是我们去学它，还是ChatGPT去给他的，或者OpenAI给HIGBT以及其他周边的这个功能模块去设置对应的brand，都会去非常好的用这种结构化的设计。而其中最重要的其实就是这个角色，就是这个肉其实是非常关键的一个好的肉，就是你给这个prompt里面的这个大模型去设计一个非常好的角色，或者说去给他明确一个非常好的角色，是能解决80%的问题。
	我们采取了在language mental里面用到的一些prompt，都在我们的项目课程项目的product目录下面。我们看到这里其实肉都是它最开头的这个提示词部分。然后在这里面我们看到最上面的这个row u an english teacher name巴拉巴拉help students are accumulate vocabulary through new teaching task。这个其实就是我们0.4里的这个词汇积累的提示词当中的角色设定的部分，更简单了。因为0.4的这个是几乎我大部分是有一半以上是我不断去调手写出来的。
	下面这两个分别是0.3版本里面我们看到的场景的这个功能里面有两个已经实现好的场景，分别是hotel check in和job interview。在这两个场景里面我们能看到这个job interview，就经常他会聊着聊着他忘了自己是一个english teacher，就是因为我们这儿故意去留下了一个角色的身份上的差异，这样大家就会知道，他一开始设定的角色不再是english teacher，不再是英语老师的时候，他的回复的这种模式就会不一样。就是到今天为止，大家去尽可能去用一些新模型的时候，你会发现尤其是像OpenAI的一些新的模型在迭代的时候，他的角色其实是做了大量的预训练去强化这个角色的认知的。包括一些知名的人物的因都已经被越狱给用出来了。就是我刚才讲到的这个advance the voice more。
	所以不管是文本类的大语言模型，比如说OY或者GPT4，还是刚刚提到的这个voice more，他其实都在把人物甚至一些知名人物去做一些学习和映射，让他更好的。其实人也是这样去学习东西的，所以这个是非常专业，也是非常重要的一个技巧。那么为什么我们去设置成professional interview的时候，没有unix teacher？好，这里大家去细想一下，其实英语老师这个角色的场景是非常明确的，并且它的边界也是比较明确的。同时他的场景是很具体的，就是英语老师的主要这个角色他的工作是很具体的，他教的那些内容有考试的这个要求，作为一个他任务的边界。但是一个专业的面试官，其实他的边界是相对模糊的，然后它的范围也是非常宽的。所以这个角色他就是没有english teacher。好，你不管怎么样去调，就相当于这个起步一样。
	举个不恰当的例子，我们都知道人种优势，就是你是一个中国讲黑人应该没有种族歧视。因为你是一个黑人或者非洲裔和一个亚洲人或者亚裔在田径运动，比如说在短跑这种事情上，它就是非洲的人种，它就是有优势天然的优势。我想说的就是english teacher和这个professional interviewer就是这样的差异。你后面再怎么努力，你是能赶上的。比如说我们的苏炳添、苏婶，比如说刘翔能创造记录，但是他得花特别多的功夫。所以选定一个特别好的角色，应该就像你用这个代码的时候，你有一些比如说像spring有一些标准化的模板代码。像这个你做PPT你有一些模板，那你写prompt应该也有一些御用角色，这个角色是你试下来之后是非常好用的，一定就得记下单，网上有很多在分享。
	然后这个角色你能怎么样去判断它？一个比较重要的条件就是你把它就当成一个人来看的话，他的边界，他的任务是不是足够的明确并且聚焦。这个是关于角色这个事情的，大家要去深入去看的话，是这样的一个理解。
	然后我们刚刚提到的OpenAI的这个这周发布的advanced voice mode的提示值的一个越狱，这是它的开头的部分。我们看到他是怎么去给这个adv advance ed voice mode去设置的系统提示时提到USI GPT large language model train by OpenAI based on the GPT4 architecture。接着又来一遍，UHIGPTA helpful VT and funny companion，you can here and speak. 
	因为这个模型它不是一个文本模型，它是一个把whisper跟TTS结合，甚至在做的更好的一个模型。这个需要每区的苹果账户或者非大陆的安卓的账号，应该就能去商店里面直接下载最新的ChatGPT的APP。然后你如果是plus用户就能去用，所以我明天要飞到国外去用这个功能尝试。
	然后在这个提示词里面，其实我们能看得到，就是角色的强化，它是可以多次的去去讲的。就是你可以讲你是一个英语老师，然后你的功能或者说你是怎么样的，你是一个英语老师，你是怎么样的。因为这种这个就是人就算是人去做演讲，大家如果知道的话，奥巴马是一个演讲很强的人。他也会用这样的强化的方式去让你get到他的观点，或者说他想要表达的那个重要的一些信息。同样的在系统提示词里也是这样，就是大家可能得转变一个思路，就是你得花功夫去琢磨这个提示是到底是怎么玩的。他比你去琢磨能欠迭代了几个版本，然后next graf又怎么样了，那index怎么样了。
	昨天我还今天早上，今天凌晨几点钟的时候，我还看到点上又新火了一个框架叫ELI，是OpenAI的前员工出来做的。然后他就吐槽，这个我们都可以摊开来说，因为国内的媒体应该很快也会去转载了，说这个南茜太复杂了，然后他可以几行代码就可以去完成一个大模型的调用，并且设置一个特定的形式词。其实这个讨论是很没有意义的，因为我也在下面去讨论评论，我说秦南茜的0.1版本就长这样的，然后是因为他想要做的事情越来越多，所以他做的越来越复杂了。当然能欠肯定有他他值得诟病的地方，就是他的抽象程度太复杂了，甚至很多人都说它过于抽象了，然后over design，但是这些东西你了解就好，这样我一直以来的观点，它是个工具，而且这个工具你需要去关注它。我一直讲这个agent的开发框架，这个生态站位是一定是兵家必争之地的。然后现在我们看到这个位置是有一个我们不能叫巨头，但是有一个早期享有先发优势的生态。比较难签，所以我们保持关注，但不用天天去刷他的API又怎么样了。所以我现在也没有急着给大家去讲0.3怎么样，然后他自己也还在疯狂的刷文档，我们在language mental里面使用到的这个runners with history这一套，在三天前的时候，他的官方文档还在0.3要怎么样。
	但是今天我看到他的0.3版本的这个部分的文档就已经写到了。如果你是用的0.2点，好像是0.219之后的版本才能用这个功能。同时如果你在0.2系列已经用了我们language mental这一套抽象的话，你在0.3是不用迁移的。因为它会平滑的直尺，即使它会有一些其他的改造，所以这个是本质就是大家得得抓一下。然后你知道这个东西在A点的开发是目前迭代最多，非常好的一个生态，但它有问题，OK就这样了。然后把更多的精力分一部分给到prompt的这个技能提升上是很重要的，这也是为什么大家看前段时间那个汉语心结一下就火起来了，那个也是提示词的技术本身很强，同时cloud的模型也很强能诞生的一些好的成果。包括我们这个language mental的项目，大家也能感受得到，其实能欠框架和python部分的这个要求没有那么高。但是这个提示词的好坏能明显看出差差异。
	好，那么接着往后研究，就是这个prom的这个结构化设计，除了角色以外任务就不用说了，这个是大家用的最多的了。因为你就算没有学过prompt设计的一些技巧，我们其实天然就是在用任务。在GPT3开始我们就是这样用的，让他干活，所以我们任务这个部分不去展开讲。
	第三部分的format，通常这个format还会附带一个词叫做样例example，这里其实就已经是我们的词汇积累的prompt。我们在格式与样例这个部分，通常会显著的把格式提到一个比较高的，或者我们叫一级的这个提示词的级别。然后同时会给出一个这个format应该它是长什么样式的，就像我们这儿看到的这个vocabulary representation。这个我待会儿会去细讲，大家会看这个封面的很很密集有很多。这是我手撸的，所以大家会看的很诡异。但我们这个小节就希望大家能够去习惯写这样的东西。你写的多了你就知道其实这个技巧也就那么回事。
	然后这个是format，这个format如果你和这个大模型一样看不明白的话，那最好就是给他一个example。你把这个format和这个一个example对照起来看的话就非常清楚了。比如说这个number world，然后这个中文的含义，它的词性，这个speech可以有磁性的意思，是一个名词动词还是一个形容词。那这里用prompt实现了一个条件判断的意义，那我们待会儿去细讲。然后下面有英文的含义。通常其实经常说英语的同学，我经常看英语材料的同学就会知道，去理解一个单词最好的方式不是去看这个chinese mining，而是去看这个definition，就它英文的这个表述，它到底是个什么意思，它的内涵是什么？
	然后一个例句，一个sentence example，比如说companies must in innovate to stay，c答对，这个是我们在0.4的language mental里面，我们去对话之后，这个chatbot会给我们呈现的。我们要今天掌握或者说这会儿要掌握哪几个单词，包括这里的这个five new words，也是可以去调的。你调成十个，他可能就在第二个步骤里展示十个，这个是重点，就是我们用format要关注。如果是非常复杂的format，尽可能的给一些example，给个样例。
	接着我们就来看看刚刚这个复杂的format都有些什么样的技巧，我把它称之为format的进阶，格式的进阶。这个进阶其实主要就是两点要抓住。第一点就是我们都用的是自然语言，我们都在说这个自然语言，然后不管你用的是中文还是英文，都是人话。但是这个人话如果我们只是听，其实是听不出格式上的特别之处的。这个格式就是指特殊的字符，我待会儿会给大家展示十种不同的特殊字符的一些典型的使用场景。Case study，在prom的设计当中的这种特殊字符，就是能够让你更好的让大模型去理解你的指令，以及你的内容应该要以什么样的方式去结构化的输出，甚至它能够体现它能够表达出一些像循环条件判断，甚至语义化的一些结构整理的能力。
	第一个是在在讲这个之前，第一个就是大家要习惯用markdown这个标记语言，你用熟了markdown其实你就能够证明明白为什么会有这些特殊字符了。因为在markdown里面这些特殊字符就是用来表达格式的，它天然就是接起来的。大家如果懂markdown的语法的话，markdown用特殊字符去代替排版，代替layout。在prom里面这个是类似的用这些markdown里面的类似的这些特殊字符去表达一些格式上的含义。比如说双星号在markdown里面其实就是有点类似于我们的黑体加粗的这个作用。那么在你的prompt里面如果设置了双信号包裹的一段一个词的话，也是类似的一个作用。当然你是把它放到format里面，还是把它放到1 example里面，还是把它放到指令里面，它带来的作用是不一样的。
	然后这个也是重点要去用的。我们都知道在markdown里面用这种三重的反引号是一个代码块或者文本块的功能。就像我们这儿看到的，这里其实是两个三引号包裹的这个模块，一个是中文，一个是英文。甚至这个三重反引号的，因为它是一组，它的上面是可以写写你是什么。比如说是python是节省，是text the plan text，是mark down，是任何这个是markdown的语法。
	这个东西是已经被渲染的格式了，它的未渲染的格式其实是长这样的，然后我们就能看到这个部分它的未渲染的文本其实就对应着这儿的形态。所以这个二它加粗了，它变成了一个黑点标题。是因为它有三个井号，这三个井号就变成了三级标题。而这个三个井号这种井号因为它太常见了，我就没单拎出来了。
	其实在我们的整个系统提示词里面，当你的提示词很长的时候，它也是一样的。就越高级别的heading就是一个井号，那就是一级的指令，两个井号就是二级的指令，所以我们的最大的几级指令就是RTF，但是RTF内部可不可以再嵌入的去做更小级别的标题呢？这肯定是可以的，包括我们的无序的这个列表，也就是一个短文件去去分出来。像这里一个短线线用途就是加粗的，但这个是我们用来做说明的，这个不是提示词，是给大家讲特殊字符在我们的prom里面的一些应用。那这儿我们看到刚刚的这幅图里的示例，然后下面这里是可以再去加，就红框这一部分是被再去加特定的标识符的。你这个代码块或者这个文本块具体是个什么样的内容，然后尖括号也是非常重要的这这个其实从XXML就是这个标记XML markdown HTML，这都是属于标记语言。
	在互联网最早期的时候，web 1.0的时代他们就已经逐步存在了。但markdown可能诞生的要晚一点。他们就是有一些你可以认为像普通话一样的概念，在这个网络数据上面留存的。所以这个大模型就拿这些数据训练的，你去学普通话是一个必要的事情。只不过以前我们学的都是人跟人交流的语言。现在学front要去逐步去学一些网络上面的这些协议栈，就是不同的协议，不同的渲染方法的语言。这个监控号其实就在我们的这个词汇的积累模块里面有一个典型的应用。
	大家如果点开任何一个单词，或者单词示意的解释单词的这么一个页面的话，不管是有道的、google的，还是我们做的language mental的，它都会有一个重要的部分。就是我们学一个单词，如果它是动词的话，你必须得知道它是有不同的。我不知道专业的这个叫什么，叫一个什么样的表述方式，就是它的形态或者他的这个就当他用第三人称用这个进行时用过去时用不同的时态的时候，它会长得不一样。但是我们不可能做一个背单词或者词汇积累的功能。他只教你动词，你只背动词，你不背名词，不背形容词，背副词，这个不太现实。
	这里就有一个问题，就是大家想象一下这个单词是由大模型去随机想的。当然你也可以做一个词表，就像网易一样，你做了一个词库，然后每次你可以人去护理学也行，那如果我们简化一下，让大模型来随机选几个词然后来做的话，那这个词它就有可能出现任意词性的单词被大模型给挑出来。挑出来之后，如果我们的提示词里面的这个format部分是很死板的去写了一个。如果没有这个弱为动词这个监括号，只有后面这部分的话，那就会出现一个很神奇的事情。就是你在让大模型给形容词和名词也去造这些不同的形态的变形，那那他造不出来的，然后你可以去实测一下，我测过，他会去比如说有一个这个名词，那他就会把现在的这个，然后它是一个，我记得还有这个countable和uncountable的名词，它是可以数的还是不可数的。如果是可以数的，它可能会分is，然后过去变成words。然后如果是个形容词，它会写feeling fails。
	它如果是一个表示这个情感的这种形容词的话就很诡异，所以你必须要去做一些特定的处理。而这种尖括号就是用来作为这个条件判断的一种非常常见的特殊字符。然后占位符也是一样，就是我们看到的face holder，它也可以用尖括号来做表达。所以这里就会涉及到一个我们刚刚提到的格式进阶的两个重点的。
	第二点就是每一种特殊字符它本身都不是唯一的语义的。就是不是说这个监控号只能做条件的这个表达，他有时候就是可以用范围符，但什么时候是条件，什么时候是占位服务，其实是由你写这个prom的人决定。比较好的做法就是在你的整套给大模型的系统提示池里面，你的同一种特殊字符尽量是或者说最好就是你的表意是统一的。不要在你的一整套提示词里面，你的监控号一会儿是用在条件判断的，一会儿又是一个plays holder的占位符。占位符你可以用别的符号去替代。我不知道大家能不能理解我的这个意思，就是你要有一套表意统一的特殊字符来形成整个的提示词是非常友好的，然后这样大模型也能更好的去理解。兼括号在你这一段可能几百字的诗词里面就是一个if if then的作用。而特殊字符可能是用这个别的方式去包裹着的，这个是非常重要的。
	第二点，那么好，尖括号除了尖括号以外还有方括号。方括号通常就是可替换的模板变量。就比如说我们刚刚说的place holder，其实用尖括号可以做place holder，用方括号也可以做place holder。而且方括号其实更常用，就像我们看到的刚刚我写的那个vocabulary presentation，大量的方括号就是用来做替换的模板变量的。并且我们在刚开始学这个开发式战役的时候，在南茜的from template里面，大家应该也能广泛的看到各种各样的方括号。
	然后除了这个以外，还有一些换行的，这个是我们在用ChatGPT的时候应该大家都经常会用的。我们可能跟一次CIGPT的对话是给他一个context，给他一个上下文。最常见的比如说你把一段代码丢给他，然后你用一个这样的横线，这个横线在markdown里面也是用来画横线的。我们给大家在前面几节课讲nine graph的这个还有南线的主拍摄的时候，就拍ter lab里面就充满了这个横线。因为我在里面加了大量的文档说明和注释，大家可以去看一看，那里就有很多的横线，就是帮你去组织内容，就跟翻页符一样，或者说就是类似的这个功能。然后如果你是用来做这个加代码注释，或者帮你debug的话，那它很好的能够去区分context和你下面的指令，还有单信号的这个用法，单信号它可以轻微的重要性的表达在markdown里面。
	单信号大家如果用过的话，应该是斜体。我们如果用word，用PPT用的都都知道。对于一个字体可以有一个b bold加粗，还可以去做这个斜体I变成一个倾斜的。然后这个就像下面这样，特别注意大括号，这个用的也很多。这个大括号它叫做动态变量的站位，这个也很常见的。
	我不确定我们在前面的这个场景里面，其实当时有一个很典型的例子。就是说我们想把提示跟咱们的内容生成放在一次对话里面，让一个大模型去生成。然后其中我们当时就有这个example in english，example in chinese，那个其实就是一个占位服务。但他好像没有用大括号，好像是用的这个别的括号，好像是中括号还是什么的。但这里的点是什么呢？就是它是一个动态变量的占位符的意思就是它可以让大模型去一部分程度上去理解它的语义，就像这里的student name。
	如果我们在前面没有在提示词里面去告诉他student name，但是我们告诉他了他自己是一个老师，然后他在教学生，然后在学生跟他的交流过程当中，比如说我就说了一句my name is这个jack。然后那他就获取到了这个上下文。然后这个上下文因为历史记录全部都会丢给这个大模型，再去不断的生成内容，那就会知道这个student name叫jack。那他下次生成的时候，它其实能把那个价给填过来的。这个是不需要我们写代码去完成的。包括类似的这里的word，这个word其实每一次生成的都不一样，然后你其实不用去想一堆的方式去描述，只要你能够包括这个标意表意的统一的特殊字符，包括你的整个提示词里面有一些特殊的词，就像那里面的input variables一样。
	这个词它就是专用的，它像一个变量一样。它同样的也都知道这个word用花括号标注出来的就是前面的vocab cabul的presentation里面动态生成的那几个词，或者一个具体的词都有，都可以直接让他去替换的这都是大模型本身带来的一些优势。然后竖线它就像一个单选或者多选一样，这个我们在大家如果有意向可以说我们在那个part of speech，就我们生成这个词汇的那个生成五个单词的那个词汇描述那个部分就有一个part of speech。然后后面是这个动词、名词、形容词也送的类似这种选项分隔符，然后冒号、标签建制队，然后双斜杠，通常是一些注释和说明，是用来引导的，但这个用的相对较少一些，大家可以去试一试。它没有那么通用，但前面的绝大部分都是很好用的。
	在这里我们总结一下来看，就回到这里一个示例。这是一个简化的版本，更抽象的版本。没有不是我们最终用的那个提示词，但是可以把我们刚刚讲的一些典型的特殊符号给它抽出来让大家去看啊，而且是用的中文。
	这里我们能看到，最典型的就是这个间括号，可能大家用的比较少，我单独拎出来把它称之为一个所谓的高级技巧。这个技巧其实它的本质就是就整个这个词汇展示的这个部分，它的本质其实就是我们刚刚上一个部分学到的十种不同的特殊字符。当然还有很多很多我们没写到里面的，比如说井号，比如说其他的，它本质其实就是一个特殊字符的组合使用。
	那它这个组合使用的要点或者关键就是你的语义和格式的一致性。就是要保证你的语义和格式是一致的，就不要出现尖尖括号。这会儿在做条件判断，那边又在做place folder，这是不好的。类似的不要这个两个星号在这儿是用来加粗文本的，在另一个部分你又变成了一个占位符，所以你得想明白你到底在这个提示词里面，你需要多少种特殊功能的这个prompt。有的就是条件判断，有的是用来做加粗的，有的是用来做动态占位符的，有的是用来做这个结构上面的分隔的等等。那整个这里的一个典型的高级技巧，就这个动态和条件逻辑的应用，其实就是这么一个含义。大家可以去仔细看，他把尖括号变成了条件判断，又把这个动词的变化形式用竖线的或者说用这个逗号这个封号的方式去做了一些特定的处理。
	然后我们接着再往后看啊，就除了刚刚讲到的以外，整个这个language mental里面的提示词有一个巨大的挑战，就是绝大部分的时候我们去设置一个系统提示时，它是RTF。然后它的task部分会描述要做什么事情，format部分会描述这个事做完之后应该以一个什么样的格式去产出，就结束了。然后它通常是task部分描述的内容。你在这一次跟他调API也好，对话也好，他他是要全部做完的。但是在language mental里面，因为它是一个多轮对话，所以很多时候它是只完成一部分的内容，它可能只生成了今天要学的几个单词，然后剩下的内容或者说剩下的task的这些任务，是在后面不断的对话过程当中去完成的。
	包括我们的前面0.3版本开发的场景功能也是一样，只是我们没有去深挖它的，是想让大家先尽可能的跟这个TIGPT或者类似的产品去交流。先你先多造一些这种长的提示词出来，你去感受，然后再回过头来去了解这里面发生的一些原理或者说一些技巧。在这个时候，一个比较典型的方式就是你需要去做这个多轮对话。那在这个多轮对话里面怎么样去体现这个多轮？
	第一个就是在最终的这个任务和这个format的部分，你是要去做一个你可以认为叫做分步骤的工作流程。然后在这个分步骤的工作流程里面，有一些步骤其实是循环的。你可以想象一下这里我会举一个典型的例子，会有两页，一页就是这个第四个步骤，一页就是第五个步骤。
	第四个步骤是在紧接着我们选出来有哪些单词之后，要开始一次对话了。这个开始对话他要做的事情是他要说明一个场景，就是我要简要介绍一下我们今天要学这些单词的这个场景是什么。所以你看第四步它会有一个，首先他对第四步整体的一个描述数叫做start simulated conversation and hints。就是开始这个模拟对话，然后有提示，然后解释一下这个步骤。就是首先需要简要的介绍一下这个场景和双方的这个角色，在我们这个模拟对话里面，去开启这个对话dialog。然后下面就是一个三重反引号包裹的一个示例format场景说明，然后这个人是谁啊提示的例句，这里面用中括号来表达。Hint，an example of student read response using at least one of the world. 
	首先这些都可以再去优化的，没有说这个是最终的标准答案，这个大家要记住。所以这一个部分第四个步骤其实它会执行一次。就是如果它正确的被理解的话，说一个场景说明，然后开启这个对话。
	接着我们在第五轮的或者说第五个步骤里面会去讲，它是一个multi run的interaction，就是多轮的一个互动，这个多轮的互动是怎么怎么解释它呢？就会看到这里有这个engaged in a back and false conversation are encouraging the student to use all words，provided这个words就对应着前面我们生成的那些words。Each round should be thought for design to ink CoOperate one or more of the new recovery inc words。这个其实就是但这个地方也可以再调，你可以想象一下，就是有一个words，这是我们要学的单词组。这个单词组里面有一些已经在前面的对话里用到了，有些还没有用到。那它的格式就跟刚刚明显不一样，它不需要再做场景的说明了。并且我们在这个代码块里用这样的一个，我这个应该叫小这个应该叫什么点就这个就是半角的英文字符里面的点点点去包裹。
	通常也可以用来去做像伪代码一样的去描述它前文是什么，first round dialog，当然你可以用别的方式可以描述成前面的这个对话都行，然后这里就会写张国鹏说了什么。然后其实例句这其实是本来想留给一个作业，但考虑到我们其实整个课程的作业很多了，就没有去做成必选了。就提一句就是整个词汇积累的提示值50%以上是我在不断调出来的。
	但是它没有调到一个说完美的状态。因为它最终也取决于你用哪个模型，用哪个IT之后的模型。但在我们现在使用的这个nama 3.18B指令微调的量化版本上，它还是绝大部分时候是能够胜任的。但我也非常鼓励和希望大家能够在这个学习过程当中不断的去调去试，这个非常关键。
	大家不要想，其实只是一个哪抄一段下来就能使劲用的，这个很不科学。对，就相当于你想学编程，但是你在网上找了一段代码，敲这个搂过来，然后你认为你就学会编程了，这个就很不科学，对吧？然后你会发现其实是很好玩。然后同时它的各种特殊字符的上限低得多，它还它当然也涉及到一些设计模式的事情，就像我们聊的RTF这种prompt framework。但它终究来说它还是简单的，只要只是你可能需要克服的一个点，就是英文就是尽可能的用英文会比中文好得多。但他也不是不接受中文的，只是说中文会对模型的要求更高一些。这个就是所谓的分布流程来结构化设计整个工作流程。这就是完整的我们的词汇积累这个模块的prompt。
	我们能看到有R有T然后这里的F其实被放到了这个，你可以理解成这里的task 123456理论上或者说这个123456更像是一个task，但我没有这么去做，是我自己实测下来的一个原因，实测下来的一个结论，就有一个最重要的点，就是touch的这个prompt它的响应权重太高了。所以如果你把这个task去描述后面所有的，把format只是放在123456内部的话，会出现一个很大的问题。就是至少在这个nama的8B这个尺寸的模型上，它会一次性把六个步骤全部做完。
	但这显然不是我们想要的，但其实task的实际含义就是这样，就你让我干个活儿，然后我给你123456全干了。但到我们的这个场景里面，其实我们是希望他能分情况的去干活。所以这个时候的task会更戊戌更更像O更像OKR里面的O，或者说更像一个大的目标。而具体的123456是他去完成这个目标的时候，可以去做的一些流程步骤。这个也是一个偏实际去做的时候的一种技巧，就分享给大家，让大家能够有一些了解。好，这个是我们能看得到的深入去。
	再挖。
	一下这个prompt要怎么去用的一些最佳实践的一些分享，希望对大家有一些帮助。好，那么接着我们就来看一看language的mental 0.4版本具体做了些什么事情。这他的0.4版本的不他的就我们做的这个0.4版本的页面，我取了一些很生动的词。第一个就是把原来的场景训练和对话这些东西就简单了，就叫场景和对话。跟海口一样，然后单词那就是单词，背单词点进来就闯关背单词目标是不变的，就是学习主新单词，然后通过在对话当中去高频使用这个新单词去理解它的含义和用法。然后这里我还设计了一个额外的按钮，本来这里应该是叫做清除历史记录，在场景和对话里，我把它做成了下一关，就是模拟成跟海口跟多林果类似的一些体验。
	就是你你可以在这儿跟他先开头聊，给你五个单词，当然这个单词数量也是prompt里面的一个占位符，你甚至都可以把它提出来，提出来之后做到radio的前端组件里面来。那这样，你就可以选每次要多少个新单词，然后这个新单词就丢给这个大模型，数量就丢给大模型，然后它就会给你一些不一样的单词组，数量不一样的单词组出来。这里我们就能看到这个动词，这个形容词，形容词这一次给的的形容词多一点，待会我们可以去试一试。然后第三人称的单数，然后它的英文的这个定义，一个例句，那我们去跟他聊的时候，他会先给你一个这样的东西，再一步一步的生成一个结果。那我们接着就来实际看一看它是怎么运行的。
	刷新一下。
	这个是场景对话单词，然后我估计这个模型应该unload出来了。先放大，这里应该得得稍等一下，还在加载。
	刚加载进去，稍等一下。
	这个prompt在vocabilary study prom，大家可以在在github上面看到，应该是渲染过的版本。呃。
	0.4已经发布了，大家可以去看一下，然后在这里prompts更新了the cabinet study future。是涨价的row task bombing 1234566个步骤。好，这有一个。
	let's do IT. 
	但一般不会这么说，我想试一试它会不会出问题他这儿会写。Welcome，i'm张国鹏。Your language mental. Today you will learn five new works as below. 
	这儿来的我们可以看到，我用githa的这个界面给大家做展示，这样你们就对上号了。这背后还有一个，我们看到在在这儿他输出了第一段话，这个第一段话哪来的？我们就从这个123456来看就好了。首先我们给了他一个六步的要做的事情，具体去完成这个task。这个task就是介绍这个新的单词，鼓励学生场景式的对话，来只让他学会具体怎么做的。第一步就是introduction，introduce role and task。然后这里有一个welcome bar up your language，mental. 
	Today you learn by new work left below. 所以这个部分其实他指令跟随做的很好，你要想改这个你就改这儿就好了。然后第二个就是the cabinet representation，这其实是动态生成。
	我们看到第二部分其实是一个词汇的展示，那presents captain read the following format，然后这是他的format，这个是他的example，这个我们刚刚有讲过，number就这么写，它其实是能理解的。然后word，然后中文的含义，然后part of这个speech用斜线和竖线都是可以的，然后整体用一个中括号包裹，就说明你可以想象成这个part of speech和这里面选择出来的整体的结果是作为一个特定的词，就是这个world。所以他这段话的描述就是最终这里会放一个单词，是从他们仨当中选出来的。
	这个就是我刚刚说的条件判断的动态逻辑，就是if world world如果它是一个动词，第三人称，然后现在过去过去完成时态，然后这里它不是一个四选一，而是四个都要有。这个是一个重大区别，所以我就用了一个这个应该叫分号，用了一个分号来分隔，所以它会有四个都在这儿，而不是说四个挑一个，那这个是蛮大的一个区别，大家看啊，就这个这个这个圆括号其实是有分组的功能。然后我们相当于把整体做成了一个大的一个分组。因为会出现一些特定情况，是这个分组都不存在。比如说我是一个名词，那这一行其实都可以不要了，所以if这是占用一个圆括号的用处作用。然后接着就是这个是加粗了的，我不知道大家能不能看出来这是加粗了的，这是我们的definition，然后我们的例句也是加粗了，然后这个是一个一个ample，然后具体的这个example我们就可以举一个实例。长这样的，这儿其实还有可优化的。
	经过我的测试，首先我实现了一个下一关的功能，这个我待会儿会去讲怎么实现的。它会整体又生成一遍新的从头来过这六个流程，但这其实挺难的，要让大模型理解这件事情，为了让他理解这个复杂的format组合，其实给了一个特定的实例。但是你会发现它的绝大部分时候他第一次你跟他交流的时候，他都会把这个带上这儿其实是一个大家可以去优化的点，有很多种方式去解决这个问题，一部分是这里可以再调，一部分就是去提升它的多样性等等。这个大家可以作为大家自己的练手了，那我们就不再去做过多的讲讲的这个部分了。
	然后你看这里还有一个就是这个以上就是我们今天要掌握的单词，现在让我们开始通过对话来熟练使用。这个是这里的部分，我们看到这儿，以上就是我们要掌握的单词，这个是用example来描述的。我就希望他能够真的说出这段话。因为我考虑到这一段英文之后，如果输出的是一个英文，可能大家会蒙圈。
	而且还有一种情况就是我要给大家讲的，在这儿理论上我是希望第一次对话就只到前三个步骤结束就好了。因为第四个步骤是一个需要confirm要确认的一个动作，但是当我们给的这个词有所不同的时候会不一样。比如说我这只是打一个招呼，嗨，就像我发在这个群里的这个分享一样。我只是打个招呼的时候，他大概率只会到第三步。但我们说next do IT的时候，他可能会理解成已经可以到这儿了。这里我们可以做一个小实验，就是我们尽量模拟大家的去测试的体验。假设，对。
	这里。假设我们把这儿给干掉，重新启动。
	好，然后我们跟他闲聊，这种说嗨。我们看会发生什么，还是把日志打开。
	会，反正整太久了。
	还真有可能，大家给大家讲太久了，他应该又卸载了那个模型。
	差不多第一次加载在T4上要小一分钟。7768，现在加载进来了。这下应该真实在跑推理了。
	这个就是一个可以被验证的事情。我们看到这里这个日志跟他一样，我就关掉了，我们看到他其实就当我们跟他闲聊的时候，他其实是没有推进这个六个分步骤的时候，他大概率会出现前三个步骤的回复，然后以方便我们可以进一步去做这个事情。就比如说这是他刚刚这些都不变，但这单词有变化，对单词有一些调整，但第一个单词没有变，就我说的大家可以去练手的部分，然后我们可以接着再跟他聊，比如说这个。比如说OK I do IT，那看他会说什么，理论上应该就走到这个第四个部分了，他这边就会开始，并且他只走到了第四个部分，他也没有擅自的去走much run interaction场景说明，然后姜国鹏提示例句，URA Young, 年轻的企业家或just need a new一个新的时尚品牌。我说了一大堆，然后alex White inspiration就是说一大堆，然后我们这儿就先简单一点，我不在这个课上教大家用这个产品学英语了，我们就按照提示例去先往后走一走，看他会怎么样去验证。Really，I think the story of how we innovate, 这个innovate就是我们要今天掌握的第一个单词innovate。
	然后fashion productive s will be a great catalist，这也是我们今天要掌握的单词对，硅化剂，然后the new policy cats这个也用到了，或changed in the industry，然后他就继续回我了，那我们这可以继续。当然大家知道，如果把这两个任务拆成两个agent会简单很多，大家有兴趣可以去做一做，march agent，我们就不再在language mental这个项目上去做过多的扩展了，然后这儿我们就可以继续聊，inner with new Better一大堆，可以继续聊。但是。这里其实你大家如果去细看，这个功能其实是对于使用者的要求是最高的。他其实是要求你本身英语水平是还不错的，你才能用这个东西。因为他他的这个用一个特定的词，本身就需要你再给他周边搭一堆的词，所以这个就看大家的实际情况。如果你要把改造的更好用一点的话，就是你可以加更多的提示。但是这个多轮的步骤其实就要往里面埋一些，这个多轮提示的这个要求是有点挑战的，有点tRicky的。好，我们看它最终执行到了第六个步骤，就feedback做出来了。
	因为这个feedback是我们这儿有一个要求，我们看第六个部分。Once the student has used all world from the vocation ary list in their conversation history. 这个是很重要的，这个是对于一个大模型来说他能理解的。什么叫对话历史conversation history，然后这个we can release他也能理解。而且通过words它强化了这个概念，provide feedback with the following format, following的这个format就长这样的。
	有一个comprehensive score，一个整体的评分，一些可以矫正的用法，一些更地道的表达，就是这里的这部分，这部分就是我们的第六条，那写到整体的评分满分，因为这就是他给出来的对吧？有没有需要纠正的用法？没有，已经非常好了，但是如果你不按照提示例句来，你可以自己感受一下。我自己的英文水平现在肯定是达不到5分的，我觉得我能达到两三分就不错了。
	然后这个地道的表达，比如说这个original，是我们在跟他聊天的过程当中用到的表达。I think we need to innovate new production method that are both the environmentally friendly and cost effective. 就环境友好的，有高效的、性价比高的更地道的表达，或者说更native speaker的表达，visual的就是改革我的这个产品流程，去让让它更加的绿色和更加的对预算很友好。其实两个没有差太多，可能original更加的官方，更加的official。这个就native night更更像这个没有那么正式，更更像更像私下的工作的讨论，而不是公开发言的这种用词。
	然后你再看到这个第六部分的这个描述，其实同样是用了上面的这些tricks，这些其实是的tricks，word，然后correction word correction，因为这部分我们没涉及到它的标准提示来回复的，所以就没有。然后这个分数you are you are scored out of total。然后这里有一个native的表达original，native neck students sentence for improved sentence。对整个这一套提示词是值得大家可以去深度理解再去，尤其是了解各种各样的这些。我们叫特殊字符也好，叫叫tricks、叫花招也好，就是你你真的把这些东西都消化之后，你是也能写出类似的这样的提示词的，而且不需要要花特别多的时间，可能我的话就是一个多小时去把这个东西做完。如果你的话我觉得可能你甚至你熟练之后可能做的比我还快。
	那么这个下一关是什么呢？这其实是一个所谓的游戏化的体验，也呼应着这个闯关背单词，这个是什么呢？我们先体验一下，它应该不会挂，点一下下一关，那它会发生什么？
	怎么办？来了，给了新单词，看见没有？给了一些新单词，这里是我想给大家留的一些可扩展的点就首先当我们去点下一关的时候，这套系统提示是没有变化，我唯一做的事情其实非常的简单，就是把刚刚的历史记录清空，就是把那个conversation history给清空。然后同时用next do IT来开启这个新的一个station也好，新的一个对话也好，你可以这么理解。然后这个提示词是足够稳定的，它能够反复的通过这些词去完成这个六个步骤。所以是很很美妙的一个事情，可以让大家去针对它的前端再去做进一步的扩展。
	并且如果你想要把这个事儿做得更好一点，真的去实现所谓的游戏化的闯关的体验的话，你可以把刚刚的那五个单词都记录在这儿，然后可以让他看到今天已经学了多少个单词，巴拉巴拉都可以。而且当我去使用这样的一个操作的时候，你会发现它的example里面的这个事情他被处理好了。他第一个不再是innovate，而是resonance。然后这五个单词肯定跟刚刚是不一样的，这个就需要我们的temperature稍微做一些调整。我用的是0.8，跟之前一样，大家共享的这个。然后因为是let's do IT，这个大家已经看过了，他会多走一步，走到start这个部分，我觉得这个也很合理。
	因为下一关的时候我们已经不需要害了，我们就是要开始学了，所以直接就可以走到场景说明里面来了，我们现在要学的是这五个单词，给了你一个场景直接开干这么一个逻辑。这个是0.4我们新增的这个核心功能。然后我们先把它的它是怎么样运行的一个界面，然后demo给大家看完之后，我们接着再去看一下具体的代码去做了哪些调整。除了刚刚说的词汇的积累的这个主功主体功能这个feature，我们把它给大家做了一个live demo的展示以外，让大家了解到它其实是还模拟了一个游戏化的体验，能闯关。然后它依赖于的是一个很稳定的system prompt才能实现这种事情。以前可能要写好多代码去你想象一下去去完成刚刚说的那些事情。但现在其实代码就是那个vocabulary study prompt。
	接着我们再说两个优化性的enhancement的这个0.4版本做的事情。第一个就是这个agent的迭代，这个特指agent这个module这个模块的迭代。希望让大家能够在，因为这是最后一节门头的课，希望大家能在这个上面再去做扩展，去做各种各样个性化的agent。那怎么做呢？我们的代码agent这个模块重构主要是实现了一个agent base。这个原件的base是我想做的，而不是一开始的由这个GPT4O给出来的那个抽象的所谓的base scenario agent agent的那个抽象那个抽象没有什么实际作用。但是我们通过这几个版本的迭代，我们发现agent有一些共通的方法，是可以共享给所有的三个三个核心功能的agent的，就包括我们这儿的conversation scenario和这个vocabulary。那么这个agent base用的是就python的这个ABC这个抽象类，抽象的鸡肋，提供我们所有agent的共有功能，这个大家可以去看代码应该很清楚。
	然后举个例子，就比如说我们的场景和我们的vocabulary这两种agent，他们其实在真正去用到这个agent base的时候会略有不同。大家想象一下这个scenario agent它其实是有二级的功能的。它在场景下面还可以再去选具体的场景，就是在前端的这个场景这个页面下，那个tape的页面下，还可以通过radio这个单选框组件去选择不同的场景。并且它的实现是每一个单选框组件背后都是一套chatbot，包括它对应的history的机制。
	如果你要做持久化，也有持久化的C型ID配合着场景名称甚至用户名称。那么scenario r我们就没有把它就跟这个work vocabulary放在一个抽象里面了，这样也是方便大家在做扩展，因为有可能咱们会把cabinet agent做成两个agent的形式。咱们如果有同学动手能力强，应该也不难实现的。你把number number number那套套过来就OK了。或者你做成两个chatbot，你在我cabinet ent里面再去造一个self hint chatbot就好了。
	然后在scenario里面，它的start new station要解决的问题就是我会切场景。切场景之后，我还要去管理不同场景下的history。而对于我们刚刚看到的vocabilary study agent，就是我们的词汇积累背单词的这个agent还要做的是下一关，那点下一关的时候要restart这个station。
	所以大家会看到这里，我会把他的history取过来之后clear，这clear方法是林茜原生提供的，就是在这首先我们上节课讲过这个history背后，其实就是这个get station history返回的一个base chat message history的list。这个抽象是有自己的clear方法，也有他亦不清楚的方法。如果你对话特别长的话，或者说你是把它存到这个数据库里的话，可以用异步的方法，就A开头再加一个，这个是南迁的标准的一种命名习惯和方法，然后把它清除。清除之后把打我还会在第八个级别的日志打印出来，让我自己能看到有没有清除成功。当然同样的这个conversation agent也是一样，不过他几乎就不需要再自定义什么新的方法了。
	然后这个是我们能看得到的就agent迭代之后的好处。如果你现在要去扩展个性化的agent，如果你是要去把vocabulary study agent去做扩展，就在就在这个class下面去做扩展。如果你是要去扩展scenario agent的不同场景，其实就像我们之前讲的一样，你不用做任何别的调整。其实就是去给他新造他的整个场景下的系统提示词。
	然后有一个开场白就去描述他的那个chat box，去跟这个学生也好，模拟的这个人也好，有那么五句或者十句，这个甚至都不限制的。因为他是从杰森里面用random方法取了，就你有一个初始的引导语，这个js里面放这个。然后我们在这个vocabulary里面也是一样，我也给它做了一个简单的引导语的描述。好啊，那么我们接着往后看啊，第二个enhancement重构是这个规律，这个页面简单来说就是不同的type下面的布局和它的回调。包括我现在也用了这种像事件监听的机制，就那个下一关其实是我们在讲规矩，那节课其实提过一嘴，但这节课我们把它用过来，就是所谓的事件监听的这个event listener，就是监听的机制。
	当我去监听下一关那个按钮的时候，那个组件的时候，它会做什么样的操作，其实看代码并不难我们看到在刚刚我们看到了agents这个模块，taps这个模块是新增的我把原来的，首先我们原来有一个通过在这个面点PY里面定义了很长的一串radio的代码，其实布局的代码。然后在那里面，我们看到有一个radio blocks，然后下面有with tab waz tab。那在0.3版本里面的那个with type是两个，在0.4版本里面又新增加了一个单词。然后如果你把那些三个全部放在这儿，你会发现你的win点PY的规定的代码会非常的复杂。那一个比较好的方式就是首先他们本身就是完全独立的，所以我们把这部分的代码去给他单独用不同的PI文件去进行独立的维护，独立的维护它的前端和后端的部分，去解耦它的不同功能的模块。那么现在的命点PUI就只有这十七行的代码了。如果你连日志都不想在面点PY输出的话，你还可以再少一行。就第五行的这个LOG，这个全局的日志实例的模块，这些都不需要。
	那么这个是main点POI，那对应的那三个tab长什么样呢？其实这是那三个tab的，分别是对话场景和单词的。其实就是把原来我们最核心的VGR tab，用一个create对应的这个tab方法去封装起来，就是python的with上下文也是可以通过这种函数的方式去嵌入的。因为整个python就全部都是函数。所以你只要没有把function和corners的这这个方向和对应的function的结果整合，你其实都是可以很方便的去去整合你的单代码的那这里我们就把三个tap页放到了不同的模块里面去做处理。甚至未来你的这个比如说你的vocabulary tab要做更进一步的迭代，你还可以再把它的前端跟后端去做拆解，所以这个是也做了一个调整，大家可以去了解一下。
	我们先把homework work给讲了，再再来再来看啊。这个homework是两个，应该这么说，homework有一个必选的和一个可选的。而这个必选的这个作业里面有两条，首先我们在github city高级功能与生产及发布这一节课的时候讲过，生产及发布很重要的一个事情就是单元测试要有啊，自动化的测试脚本要有。但在那节课我们也讲过，其实它的单元测试的代码全部都是由chat PT生成的。而且languages的代码结构其实更加简单。所以我希望大家能把它的单元测试的代码和自动化测试脚本的代码给做好，然后最好还能提一个PR到课程项目里面，如果做的最好的我也我觉得有可能就合并到我们的这个版本分支里了。
	然后同样的就是容器化的这个部分，我们其实也讲了，用t GPT可以生成一个door file，然后甚至生成一个build image的需要脚本，然后去完成一个跟自动化测试脚本的CI流程。这个是咱们的homework。然后这个prompt的改造，因为它很难去量化大家做的好不好，我就没有把它变成一个homework，不然助教的老师，企业老师会很难给大家改作业，他不能人肉读一遍就知道哪个prom的好，这个就很tRicky。但是单元测试和dog fell是一眼就能看得到的。然后大家也可以把它build好的镜像的运行结果给到这个TA老师，他就能看到。
	然后有一个可选的这个是我本来是想把它放到正式的内容里，但我最近在考虑安全性的问题。因为他跟face毕竟是一个美国的公司，然后把我们的一些东西发布到space，万一有的同学是有一些，因为他他其实会要求你把代码也提交过去的。万一有些同学把一些安全的，就是安全要求非常高的，像APIK什么的就发过去了，这个就得不偿失了。所以可选这个大家可以去去研究。
	首先hugin face它有models，有dataset，有各种space。是它的托管的一个平台，而且它提供了免费的资源。只不过这个免费的资源，只有我没记错的话，应该是二核16G的CPU，然后你是可以在上面免费跑去托管你的这个服务的。但如果你要用GPU的话，它是需要付费的。然后它的GPU是它首先大家现在对商业应该有一定了解了，它会有两种付费机制或者说收费方式。
	一个叫订阅制的，你可以升级成hugin face的pro用户，那这个时候他会给你一个dynamic GPU，就是动态的GPU资源。简单来说就是它有一个资源池是动态的。如果这个时候有富余的GPU出来，你的那个space里面要用GPU就能给你分配一些。然后如果这个时候资源是很紧张的，你就跑不了你的space的这个应用就跑不了。然后有了订阅之后，就能享有这个GPU的动态的免费资源。
	然后同样的他跟AWS的合作很深啊哈根face，因为我跟AWS也很熟，所以知道这个事情。他们最早的云平台其实就是AWS，现在也开始支持其他的一些公有云了。所以它的space里面也支持你去选各种各样的硬件hardware，就跟网吧里面的机器一样，按小时收费。但无论如何，这个hugger face是一个非常好的社区，像我们熟知的这个stable diffusion，包括很多纹身图的产品，都是在hugin face space上面被大家所熟知的，包括像大模型的天玑版LLM leader board也是托管在航运face face上面的。
	上面的这个服务特别多，大家可以可选的去研究这套流程其实很简单。对，这个是homework。好，以上其实就是我们这节课的主要内容，核心是这个prompt代码的这个结构，大家应该一看就理解意图了，其实是很简单的一个重构，agents和我们的然后和我们的这个这个没变，我们的面点PY做了一个改造，这里留了一个in IT点。PY是考虑到大家如果未来要去扩展agents的话，有这样的一个PI文件在这里是很方便的，能够把把agents变成一个可导入的包。
	好，以上就是我们今天language mental 0.4和深入理解prompt设计与最佳实践的这节课的内容。好。看大家有什么问题，我们可以来交流。
	System prom是项目启动的时候加载到程序里的吗？这个你看代码，我跟你说是，首先什么时候加载，什么时候启动都是代码决定的对吧？你看一下agent base什么时候会用system prompt，不就这段话吗？No, the prompt这个我们在上节课讲了蛮多的。然后什么时候会运行这个load prompt，你就去看在它在这个agent的构造函数里面就会去调用。
	那什么时候去构造的它呢？在面点PUI里面构造的它吗？在面对PUI里面构造的。但你看现在没了，为什么呢？是因为不同的tab构造的是不同的agent，那我们就不需要在这儿去导入所有的乱七八糟的包了，就可以在不同的type页里面再去导入自己的agents，那这样就完全解耦了。你就在the vocabulary type里面去导入这个vocabulary agent的定义，然后在这儿去实例化。单纯用提示词来让。
	大模型。
	控制对话的具体流程，具体效果怎么样？这个同学你的问题我没有办法回答你就是效果怎么样？就是现在效果这样。对，然后我只能说这肯定不是它最好的效果，它还有上限，因为这个模型也还用的不是特别强的模型，是一个只需要7GB的显存就能去运行的模型。
	单词解释的明细列表前面的小圆圈格式在prom怎么定义？这个同学是不是不用markdown？我强烈建议大家从今天开始就要用markdown，应该我写的第一本书是拿markdown格式写的。真的大家得用markdown给大家看一眼markdown这个格式真的很好啊。
	来第一是我们看到在prom里面这个小圆圈的标准的名字叫做on order的list无序列表。什么叫无序列表？就短横线就是无序列表。然后。比如说我们的type A。这就是。
	这就是无序列表。然后这个地方是长成这个实心的圈圈，这个地是空心的圈圈，是取决于他以什么样的方式去渲染这个圈圈。对然后markdown的语法，我觉得现在都不用去看别的网站了。我觉得你让ChatGPT教你应该都行。对，因为这个属于太太古老的东西了，但是他自己也有一些所谓的，我不知道现在哪个是所谓的官方教程，那余方并没有那么多，我感觉这就不是官方的，应该是某个人搞。对，没有那么多语法。然后列表的语法。
	无序列表这吗看见了吗？
	对那我刚才想说的这个第一本书其实就是这么写出来的，叫做我现在没有把ping上来了，大家可以去去看一下，这个叫做。Turns a low in deep. 
	这个没有开源的，只有第一张这个出版社要求，比如说我们看到这个。
	就这么给到出版社的。现在出版行业都是这样的，包括这个超链接的图等等。大家包括这个表格，大家还是多多了解这个，那还挺好用的。我们说回来。单词解释的明细，这个说过了，判断prom的设计是否已经达到生产级水平有什么原则吗？测试工程。对，首先生产级就是一个比较务虚的词，你的生产力最终要通过测试指标生产指标来量化，那你最终就可以落到测试工程里面。
	你看一下我们讲那个github city，就是我们homework里面说的对生产你是怎么定义的？里面有提的比较细。举个最简单的例子，就是你认为hi echo到没到达生产机。如果到达生产机了，今天试出来了bug，那大家怎么评价？就所有的程序都是有bug的，人也会是出错的对，但是你要定出指标来，我们才能聊生产机。但这还可以再优化一下，这有一个缩进，但这不太影响太多的这个事情。
	还有什么别的问题吗？
	流程化多轮对话的场景，用提示词来解决问题，还是用类似number的流程来解决？这个我刚刚说过了，这个同学就是nine graph的，没有流程。Nine graph是一个开发框架，nine graph的流程是通过你自己定义的这个结构来决定的，就是graph的这个结构。
	首先我说过，你如果不想把这个问题一下上升到你自己都不想去做，你觉得特别难。你可以不用bra，你可以就用两个chatbot，就是我们这里实现的chatbot。在base里面这不就是个chatbot，你可以就用俩chatbot来做。你专门做一个提示的prompt，然后他跟这个chat work打辅助，开会也这么做的。我觉得从我对它的深度使用和测试来看，它的提示语是不需要说不同的场景，不同的单词组合。我还要再去给他动态生成它的提示的，这个就专门做提示的。这个chatbot的front应该是固定的，就是基于上下文，然后和一些动态的输入去生成提示语，中英文的两个版本。那就够了。
	然后如果你要再去做这个细腻度的流程，比如说刚刚这个123456，你要用graph来做，我觉得这样是不对的这是一种错误的做法。就像很多人讲lama index什么，rng他做非常细粒度的节点，我觉得那就是条错的道路，他们迟早会回来的。首先RAG是一个中间的过渡的技术。然后这个过程当中数据处理的工程是有很多细节。但是这些细节为什么要用图来做？就是标准的数据处理工程就已经做的很好了。你要把它搬到图上来，把这些离线的工作这是不对的。
	然后如果你是在线处理的时候，有很多流程要做，尽可能的交给大模型去做。因为RAGR和这个A是最重要的，R和G是最重要的，就是去知识库里检索和做这个大模型的生成是最重要的。而这里其实就是prompt要做的好，知识库要做的好。
	如果在RAG的线上流程里面还有那么多，你要通过graph去指定它的各种盘条件判断或者什么的，那肯定是有问题的。这个对话也是一样的，你没有办法去判断这个人他会说什么，那你非要你自己写一份else，而不是交给大模型去做一个else，就很奇怪对吧？然后如果是交给大模型去做一个else，那其实就是你的prom要做的足够健壮，而不是说我这个prom搞不定了，我再造一个agent，他去应对另一个。If我再造一个agent去应对另一个衣服，那谁来判断给哪个agent呢？不还是from吗？这个问题没有本质变化。我提议做两个agent是因为这两个agent的功能是非常明确的，可以区分开的，甚至是一个开关可以在前端去做的功能。它不需要大模型去动态判断走哪条边，我不知道我表达有没有足够清楚。
	这个这个prompt是首先我给了我要做的事情，然后这些东西，这些特殊字符我让GPT4不让o one mini生成了一版，然后我在上面又改。如果你硬要按贡献度来说，我觉得我应该做了90%的事情。这个OI mini做的第一个出版是帮我把这个格式排出来，就是加星星、加task、加format。然后这里的六个步骤几乎都是我重写的，除了第六条我没有写，没有去改，这个他做的很好，OMM你做的很好，然后剩下的前五条我都重写过。然后肉它做的很好，然后肉我稍微调了调task这个部分它描述的很好，我们也去改。对，是，所以基本都是我自己写，那没多少字。其实你看多少个字，那能算吗？那算不了。
	这有多少个字？有什么好的数字的软件吗？算了，不数了。那大家还有什么问题吗？
	我不知道这个是数字是啥意思，这个2756吗？有这么多吗？我还以为这个是别的统计方法，有两千多个字吗？我刚才其实看到这个了。这就有两千多个字，我觉得没有。只有两千多个字吗？我知道哪有，我记得OpenAI有个tokenizer。他叫偷坑，偷吭啥来着？线上的就偷坑来着。我记忆力还可以。
	对，我们看看如果用text的ADA002的这个ebing模型算多少个字。卡了吗？不让我输入。
	坏了。还没加载进来，好像快过年快过快过国庆了，每次这个时候每天都很。很难受。圈圈转的。
	那他还有什么别的问题吗？还真是2756个字符，703个token。这个character不是world字符串。703个token作为它的system的这个prompt，还给剩下的聊天留下了七千多的长度。因为我用的这个模型是最高支持8192。这里。
	对他这个2756，我知道它就是指的character，它不是那个字符。他会把这堆东西都算成这些特殊字符，什么乱七八糟的会算算进去。其实我想知道是那个token 703，这边这个数字。
	刚才使用的markdown的工具有很多，这个是我用的比较久了，但我知道有很多应该现在做的比他还好。绝大部分编辑器都支持，你哪怕用这个VS code，它都支持，它就直接一键就可以。这个是current，这个不是VS code，VS code是支持的。Curl好像不行，我没装。可能对很多这个叫type a，是比较轻的。单单页编辑比较方便，有很多对那个大家自己去研究。
	好，我看大家已经最高支持8192 nama 3.1的mod card上面写的有。对，咱们用模型要先访问它的model card。欧拉玛那节课有讲，大家一定要去看它的model card，上面有写。好，那大家没有。对对对，那就对，这个同学说的对，是TXT的原因。是的，是没毛病，因为它本身也是一个VSQ。好，大家没啥问问题，我们就国庆快乐，大家多练练手。对的，VS code这个地方就可以直接渲染，你就能看到。
	对，好啊，国庆快乐，我们多练练手。这个agent还是得手上才能见功夫的，好吧？那么就这样了，感谢大家。