	Hello, 大家能看见吗？画面是不是正常的声音，声音能听见吗？
	这个没有评论。
	大家先能能看见对吧？然后是播放的状态。好，行。
	OK好，那我们就正式开始。好，我看应该大家都进来了，那我们就正式开始今天这一节课的学习，今天应该是第十节课，我们讲使用nine graph构建多智能体。Marty agent这个也是我们教大家用这个nine graph，包括他的基础知识以及实战的。
	第二节课我们一共nine grave的基础部分，就这两节课，所以大家可以抓紧这个时间，这两节课也算是一个过渡和打基础。这节课我们会分成两部分，第一部分是在上节课的基础上上节课我们讲了nine graph的一些基础知识，就graph它是怎么来的，参考了哪些前辈的设计经验，NF的核心抽象有哪些？作为或者说network的运行，以这个计算机的图数据结构为核心。那一个图数据结构它的核心的对象就是节点这个边，还有其中传递的数据，在graph里面被称之为状态state。那么这节课我们希望能够把lang graph的使用再完成一个更深入的学习，所以取名叫开发进阶。
	这个进阶主要就是两个部分的能力的提升和延展，第一块就是工具调用。在学习南茜的时候，包括大家用其他的一些框架，我们都会知道agent，他要能够去从大模型变成agent，其中有一个最重要的点就是有工具。大量的工具跟大模型的结合，使得一个基于大模型的应用变成一个可能，这个应用现在就被称之为agent。
	那么在nk graph里面怎么样去调工具，第二个就是我们在上一节的实战里面讲了，用n graph h去构造一个chatbot。这个chatbot在graph里面也是一个节点，叫chatbot的节点。这个节点我们第一部分实现了一个大模型的对话功能，就是一个基础的chat OpenAI的实例。第二部分我们给它增加了一个工具，也就是一个搜索引擎用LLM with tools这样的一种形态，也是一种很经典的N的形态，构造了一个新的节点叫check port的节点。但是我们在讲这个number of也好，在讲这节课要教的marty agent也好，最核心的一个词是agent。但是在第一个时代里面，其实我们没有把这一部分给大家深入展开，我们是留在了这一节课去做这样的一个介绍和上手。Agent本身它跟普通的这个大模型绑定一个tools比起来，是不是应该还有一些额外的自由度和灵活性。这些在这节课我们的设计里面会给大家去做一一的介绍，并且在人群里面我们可以实现一个agent。
	但是这个agent如果我们要去把它打开，把这个黑盒子打开，去做进一步的调试和自定义，其实是相对来说比较麻烦的那如果要用南茜去实现多个agent，然后完成他们之间的交互，几乎也是很难做到的。但是，在nap里面这件事情就比较简单了，这就是我们今天要的两个重点。第一个就是在nap里面怎么样去调拓，第二个就是在network里面，我们怎么样去把agent变成一种agent节点，然后这个节点还能够有多个不同的节点是不同的agent互相之间能够交流，能够去交互的去查看和调用。最后我们会以一个多智能企业协作的例子，来跟大家把上面开发进阶的所有的讲到的知识去整合在一起，去完成一个实战。
	好，我们就正式开始今天的内容。首先我们来看一看这个nine graph的开发进阶。在讲nine graph的这个工具调用之前，先带大家去温故一下这个南泉里面关于agent的知识。也考虑到有的同学可能没有去上过我们的应用开发的这个课，里面其实我们一直在用这张图去做介绍，很经典。在人群里面其实所有的信息都是用链条的方式在传递，而这个传递的过程在能券0.2以来，这个表达式也出现之后，通过管道的方式在底层大家都实现一个统一的running协议，然后使得我们就能够去用相同的接口去传递数据了。
	而agent作为其中一个最典型的核心模块，其实有很多的可以延展去讲的点。这里我们时间角度时间的原因，我们就只讲两个方面。一个就是agent作为一种大模型为核心的应用形态，它最关键的是大模型得足够强。大模型决定了这个agent的底线和他的上限的一半，上限的另一半由他的工具集来决定，所以其实对于一个agent来说，最重要的就是你用的大模型越强越好，你用到的工具集越丰富越好。但是在南茜里面我们会发现这个工具，一个大模型要去掉一堆的工具是很难的。
	在我们讲年欠的这个agents设计原理的时候曾经提过。当时我们是给大家讲过这个agent它的实现在能欠的内部，其实是通过提示策略来实现的。比如说react这种策略，open I的functions，这是一个典型的function calling，现在都称之为to calling的这样的一种提示策略。还有这个self ask research，其实就是一个大模型加上搜索引擎这样的一种提示策略。这三个不同的策略其实就像3种不同类型的agent，他们也搭配了不同的tools，这个应该是比较好能够捋顺的。但是这里有一个点，就是我们可以单独的把这三个agent实例化出来去实。但是他们如何配合着去协作呢？其实南茜没有办法帮我们很好的完成这件事情，这也是我们要用nine grape的原因，当然这个我们会在后面的今天后面的内容去给大家讲明白怎么样用的话实现。
	但另一个维度就是能欠的优点就是已经有这么多的开箱即用的tools了。就比如说我们看到的任倩在官方社区里面公布出来的已经可以直接开箱即用的tools，其实远远不止我这里贴出来的这些内容。这些tools其实对于我们只用单一agent来说是非常方便的。比如说我们看在上节课我们讲过，chatbot要去接这个搜索引擎。在我们的n graph内部有一套标准的作业流程，我们已经讲明白了。那么在南线里面，如果我们要去接一个搜索引擎，其实也有一些对应的工具，开枪即用，可以去直接去完成这个实例化。就比如说刚刚我们提到的self ask research这种典型的提示策略，它就有一个对应已经实现好的agent。我们看到这行代码里面有一个agent type。Self ask research就是相当于我们通过初始化这个agent这个方法，可以直接去实例化能欠这个框架已经帮我们预先定义好的agent这样一个策略。
	然后这个agent要实例化，最关键的就是三部分的参数。我们看这个地方，第一个叫tooth，就你给了这个agent什么样的工具集。第二个是给了他什么样的大模型。这是我们刚刚提到的要做一个agent最关键的两大核心支柱。第三个叫做agent type，这个背后本质是一堆提示工程，就是我这个agent要运行起来，我给这个大模型什么样的一些提示词或者说提示策略，让他把我给他的前两个参数，也就是工具和大模型能够很好的用起来。因为这个算是软的东西，通过提示词能够去把真正给到的这些模型和工具串起来，让它在合适的时候知道用什么工具，以及什么时候停止我的这个调用。
	这个是用年欠去实现一个带有搜索能力的agent的一个代码，其实非常的简洁。但这里我们会有一个疑问了，就是年前已经做了这么多的工具了，这一大套的工具，甚至他自己有一个工具集，一堆的tools。我们在刚刚讲chatbot实战的时候，其实是用了另一个搜索引擎。然后还有很多的同学就会去有疑问，就是有没有别的搜索引擎的这个工具我可以用，以及这个搜索引擎的工具在能嵌里面和能grave同样是搜索引擎，这个工具在调用方面有没有什么差异，背后的提示工程又是怎么样在运作的？No grave能不能去复用之前能确定义的这一大堆工具，不只是搜索引擎，其他的工具number能不能复用，这个其实是一个很明显可以做到的事情。
	我们看从能券0.2发布以来，整个能券的技术社区、技术生态的眼镜，其实是按照这幅图里面的架构设计在做规划和迭代的。显然nine graph和nine chain都是属于agent开发框架这一层，也就是我们这里看到的最下面的这个开发框架层。这两个不同的agent开发框架，他们其实是可以共享我们这个中间组建这一层的各种各样的第三方集成的工具的，就包括但不限于刚刚提到的搜索引擎的工具以及一些其他的工具。
	最上面的这个network cloud其实是整个我们的agent部署的一套解决方案。并且它是可以支持这个商业化的，就不只是一个，跟下面一样的开源的项目，而是变成了一个平台服务。而且这个平台服务比这个nice miss相对来说还要更偏向于生产端，就部署这一端。Nice miss可能还更多的是偏向从开发或者说从设计产品设计到研发到调试，到测试评估这一流水线，或者说包括监控，整个一站式的产研的平台，算是nice miss的定位。而next mix上面的成果其实更多的可以通过np cloud去进行托管。
	这个是整个现在南京未来发展的一个我们。目前可以看得到的一个很明显的趋势了。所以能欠跟能grab肯定是可以调用很多共享的这个工具的。只不过问题是怎么调用，对吧？就我们从逻辑上来说，从这个宏观的这个角度，从这个社区的长远规划来看，包括技术站肯定都是可以调的那怎么调呢？这是一个问题。这个问题的答案可以由自顶向下的去思考。
	在上节课我们讲了graph，它的核心抽象是核心的对象是一个graph。这graph分成了state graph和compile graph。是状态图和编译后的状态图，或者说编译后的图。
	状态图定义了一张工作流，在工作流里面有点有编点，是一个一个的就是node，就一个一个的这个节点，节点里面是真正要去执行的计算操作和逻辑边是约束了整个工作流的执行顺序。工具显然它不是顺序号，工具是一个计算操作，是一个逻辑上的操作。所以工具肯定是节点，我们要这样的思路去考虑问题。其实很多以前学过的知识是能串在一起的，并且是能举一反三，触类旁通的。所以要在nine grap里面调这个工具，肯定得把它变成一个节点。那现在的问题就变成了怎么样把工具变成节点，那么好很好的一个命名，把工具变成节点，那我们就把它变成工具节点。这个很直接的一个秘密就是能在他自己的预构建的抽象叫做two node。
	我们在chatbot里面其实没有使用这个tor note，没有去深不用它。我们自己定义了一个basic to note，去完成了自己去完成了这个工具的调用。但是在今天要去做的这个食材里面，我们会重度的去使用这个to note，to node本质上它其实就是你可以理解成它跟我们之前这个定义的那个check bot都是节点。因为只有节点才能去真正执行一些特定的操作。然后它既然是一个节点，我们讲过的这些知识再反复给大家去做强化。
	任何的节点它要接收的第一个参数都是上一个节点，它有状态转移，就上一个节点执行完之后的那个输出，那个状态要作为我现在新接收的这个节点的输入。我的所以我会从graph当中去拿到最新的这个state，最新的这个状态。然后既然如此的话，其实只要我们能够把状态，因为状态是数据，是最终这个图当中交互协同的信息。只要能够把这个状态表示清楚，我的two能接收上一个node来的这个state，那么就可以去把它加到这个图当中。这是符合我们已经学过的这个知识和认知的那two node现在我们知道它肯定可以去加到节点里面，无非是要把state对齐，那two node有什么特点呢？它跟这个普通的node比起来有几个好处。第一个就是这里特指预构建的这个tor node，就是我们可以直接from import的to node。这tor node它本身是是完全目标设计这个tor node的目标就是用来做工具调用的，可以比较方便的去根据这个图当中的一些状态，去自动调用这个指定的工具。
	什么意思呢？就是我们已经看到了在check point里面有大模型绑定一个tools这样的一种传统的agent的做法。在LLM with tools这种绑定里面，其实整个大模型它没有真正的去调那个工具，跟南茜里面还不太一样，能切里面。
	因为它内部是一个黑盒子在运行，它不会展现它内部的运行的迭代次数，以及中间的结果，所以它不可控，但是它开箱即用，但是你要把它往生产级往深入去做，你很难去改造。那nine graph跟它刚好相反，你的每一步执行都要按照图的定义来走你不能自己在内部瞎折腾。甚至还悄悄的调了个工具，我都不知道。所以我们在chatbot里面就会发现它的这个设计是chatbot带了工具之后的第二部分的这个的版本，它可以由chatbot去生成，我要调工具。
	但真正的工具调用发生并不是在chatbot，而是在我们自己自定义的一个叫two的节点里面，这就是真正在grap里面，我们要去完成一个工具调用需要适应的一个过程，就是你要想象一下，所有的可执行的操作都得在节点里面去完成。而那个大模型本身它就只是一个大模型。工具是工具，那显然你要去执行那个工具，那一定要有一个工具的节点，这个是工具调用的一个设定。所以它它既然是一个单独的节点要去获取信息。然后他整个流程当中，其实有很多可复用的部分，就可以通过to node来完成，然后说no的。第二个好处是说，他把原来能券当中的一些工具可以跟他去做兼容，就能直接去调了。第三个好处是说它可以去完成一个所谓的并行工具调用。
	什么概念？你可以想象一下，就是每一个工具都是一个node。那假设你要在你的应用里面，你的agent应用里面做十个工具，那是不是就得有十个工具节点？比如说一个节点是搜索引擎，一个节点是我们今天会看到的，因为我们代码也传上去了，就是这个python的这个沙盒环境。一个是这个circle query，就是生成这个circle的那这个也很神经病，对吧？
	就你想象一下你的图本来应该是非常结构清晰的，这个图里面都是一些关键步骤，你可以允许有子图的存在。但是图的一级一级的这个节点，这个节点应该是颗粒度比较粗的，是跟你的业务逻辑这一层是匹配起来的。但你放了这么多工具，甚至有可能假设我们是marty agent，你有三个agent，可能这三个agent还会有共同调的这个工具。那这些工具是同样的节点还是不同的节点？比如说你有三个agent，agent ABC都会去调索引擎，那么这个搜索引擎的节点应该是一个还是三个？如果我们去深入想这些问题，把这个逻辑掰过来，你就会发现其实还挺麻烦的。所以to note还有一个功能，就相当于你可以把它想成它就是个可这个壳子是一个节点，所有的工具都可以丢到这个壳子里面来，这壳子就叫做node。所以把原来的这个工具集的执行，只要我是满足在graph里面我的state的这个数据结构，我就可以把它丢到一个叫for node的节点里。
	那无非就是说最终我要调用它的时候，再跟这个特定的agent的节点去做协同，去做对应的关联和调用就好了。但无论如何，它有一个收口的效果，就是你不用把所有的图都放到这这个，或你可以把所有做的错误都放到这一个节点，而不需要定义N个错误，这个是它的第三个好处。第四个就是它会有一些错误处理的逻辑，然后这些错误处理的过程中间值你又可以在next mix上面直接查看到。这个是two node的几个好处。所以我们总结一下，就是在nine graph里面要完成to calling，其实就是这样的一个节奏，就是你有一堆的two。这个two通常来说两种情况，或者说两种来源。
	一种就是连券里面开箱即用的这个to node是做了兼容性处理的。就比如说我们的搜索引擎，大家一行代码就引入进来了，跟南茜里面的使用体验差不多。唯一的区别是在南茜里面你引入进来了，那个agent就自己在背后掉了。而在nine graph里面，你需要额外多做一步，就是你需要再建一个tor node的这个节点，就艾特到我们的图里去。然后原来的那个agent它去调那个ta node，然后tor node，再把那个结果返回给调他的那个chatbot或者说agent。所以在nine crapy里面，我们把tour就变成了这样的一个步骤，由to变成一个to node，然后to node的结果其实就是to calling的达成。
	就我们想要完成工具调用是在to node去完成的。然后它的结果会反馈给谁去调用它，或者你也可以把反馈给其他的人，这个都可以通过graph来指定的。而这个突破除了开箱开箱或者说能欠开箱即用的这些预定义的突破以外，在能欠的框架里面就支持这个图案。
	装饰器在n graph里面也是一样的。或者换句话说，就是你可以理解成任意的一个python的函数都可以通过to装饰器变成一个to node可以调的工具。你可以想象一下刚刚那个流程就是tor node的上游是一个tour，但这个tour它不是一个抽象的概念，不是一个工具，那这个就太泛化了，而是一个在冷却里面可以被他调用的工具。这个是一个特定的抽象。那这个特定的类抽象，其实就是用兔子装饰器可以把它转变过来，就跟我们刚刚那个图对应起来了。那它如果变成了一个to node可以调用的工具，那就可以走到我们刚刚的那条逻辑线里，那就可以加到这个节点里加到节点里之后就可以由我们的其他节点去调用它。
	在这儿就是一个把任何python函数变成我们的graph可以调用工具的一个示例。比如说我们要获取当前的天气，就一个python的函数，然后在上面加一个to o装饰器。我们要获取一个城市列表，也是类似的一个方法。最关键的其实就下面这两步。有了这个装饰器之后，我们构造一个toss列表，就是我们有哪些工具要加到to node里面，我们构造一个python的列表，然后这个列表里面的元素就是这个函数。再把这个函数通过to node这个构造函数放到我们的这个或者说变成了一个two node的实例，最终我们还需要把这个to node加到图里面，然后这个是一类最常见的操作方法。
	那怎么样去调这个to node？我们看这里是一个比较典型的示例，也是我们在chatbot里面的日志其实看到过的。首先我们这有一个叫做message，message with single to call是一个AI的message。这个对象大家应该比较熟。A message就是在chat model。这个chat model就是对话模型里面，由这个大模型生成的信息，通常叫AI message，然后这个也比较符合实际情况，就是我们的two通常是由模型来发起调用的。
	就像我们在check port里面一样，有个模型他要去调一个特定的工具，他要发起一段其实就是他生成了一段信息，这个信息由谁处理而已。在人群里面，由他自己来处理。因为他有react reasoning action，他reasoning出来了，他要调度，action也是他自己干的，他就直接去掉了那个图。而在graph里面，我这个大模型reasoning出来，我要调一个two。然后他调它的话就是直接从它这个节点执行到了下一个节点，也就是two的那个节点。所以我们再看它生成的这个内容，通常是长这样的。它的AI message正常如果是给人看的话，是放在了content这样的一个键值队里面，这个key里面。但是如果是要去调度的话，它其实会放到to cos这个特定的key里面。
	然后在整个大模型，像OpenAI，像isotopic这些公司的大模型里面，他们现在也把to call也是做了一个单独的role，一个单独的身份。但跟肉有有一些不一样。就是因为我们经典的这个系统，然后这个大模型我说system，然后AI，然后这个human这三类message其实都是自然语言，但是to our cost其实更偏向于给给编译器，给解释器看的一些序列化的结构。就像我们下面看到的这个是一些类似于标记语。那这里我们看到to cos里面放的这个结构，其实是很像我们在应用开发云里面学过这个function calling。而实际情况下其实也是这样，林倩在做的这个脱口和OpenAI，现在把from calling整个这一套都迁到了他自己的assistance这一PI里面。
	然后在assistant CPI里面，他也把这个名字也强化到了to call，就工具调用。大家都是用这样的一套结构去启发也好，或者说去引导大模型去生成这样的结构。而这个结构大模型自己可能像OKI自己的拆GPT，它可以用这个结构去完成拆GPT的的调用。
	如果我们自己要构造一个agent那你就是一个大模型。那你要做OpenAI在c GPT里面做到的那些工具调用的逻辑，那你可以用连茜，也可以用连挂，其实是这样的一个大的背景OK。所以我们如果要去调度，那我们就得把这个信息给到位。
	怎么给呢？其实就是这样的一条信息。你可以想到这条信息，这条message是要给到刚刚我们构造好的two node的节点。因为我们的不同节点之间其实传递的都是信息。像我们看chatbot一样，不同的message一路传过来，然后只要这个message的结构是对的，我就能处理。那two node要处理的结构，其实就是长上面这样，它是一个AI message的类型，然后它的to cost是它要重点处理的内容。在这个two cos里面他要重点去看这个是哪个函数，要用什么参数，然后还可以去校验一下这个to go ID，因为有可能出现了同名，但是这个ID不一样的这个情况来去做校验，所以这四个建制队其实是下面我们看到这个two node in work传进去的重点要处理的信息。它的返回结果其实就是长这样的，它会有一个two message对应着AI message、平板message和system message。Two message就是tool的结果。
	我们在chatbot的这个代码里面，其实已经手动构造了一个two message。大家如果有这个有印象的话应该还记得，没有印象的可以再去翻一翻这个代码我们自己定义了一个basic to node，然后在basic to node里面去调用了这个搜索引擎，然后把搜索引擎的结果封装成了一个tool message。然后这个two message的content，然后name to call ID，就是三个最重要的参数返回，这个hunt其实就是我们的工具执行结果，name是我们的工具的这个name，然后ID就是这个工具的这个ID，当然它也可以一次性支持多个。我们看到就是在其实在这个OPI的function calling里面也讲了，就是怎么样给他多个工具，让他根据情况自己去选，或者说根据我们的输入的这个用户的问题，然后大模型消化之后，然后他再看我要调哪些工具。这儿其实是一个典型的react一个叫什么执行过程。那这样我们就假设这个执行过程已经执行完了，现在大模型已经执行完了，就生成了这样的两条突破的内容。这其实这个two cos这部分里面的to cose这些建筑队，也是大模型生成的。然后这个to go本身就是大模型的一个能力指标，也有专门的基准测试。
	假设现在大模型生成的这个结果就是我要调两个工具，分别是我们定义的刚刚定义的这两个工具，get cool list cities的这个get weather。那就是得调两下，那调两下没问题。咱们同样是把这个信息给它发送进去，invoke这个方法就执行一次，然后执行完了之后，我们会看到它的返回，其实就是分别调用了这两个拓，然后把结果也整合到了一起，放在了一个message里面。然后它的顺序也是跟前面有一些对齐的，我们也能看得到。所以其实这个就是two node本身带来的一些优点，你可以想象一下，它既给我们提供了非常好的可控性，同时它也相对来说能利用原来能签订好的各种工具。然后它的使用，其实你整明白里面的逻辑，你再看它的代码并不复杂，然后大家都是通过messages来进行传递的。
	好，如果我们要把它跟对话模型结合到一起去使用是什么样的呢？就像我们在chatbot就我们上节课的这实战里面用到的这个模式一样。我们不再去自己定义一个to node了，我们直接就用预构建好的这个也能看到它是从哪个包导进来的，就是叫做nine graph的preview。这个模块里面可以直接导入to note。
	如果是这样的一个方式，其实很很简洁了，就是直接可以把我们的这个，当然这里得重点说一下，不是每个大模型它都支持这样去使用。因为我刚刚说到了这个突破本身是大模型的一个能力。这个能力是两个方面，一个方面是这个大模型的训练，使得它能够很好的生成我们刚刚看到的那些序列化的to go的内容。同时他在negative里面还去做了适配。这两点都做好了，他就能够直接通过这个方式去调用to o，你看这里其实没有做任何额外的设计的，跟南迁已经反向像这个cloud 3，然后这个GPT4O命令4O命令4O4O命令都支持。然后这两个这些chat mode，这些chat model，你去直接绑定这个tools之后，然后用two node去调用是直接可用的，并不需要我们再手动的去定义一个basic to node了。
	那个basic to node的那部分代码在上一个实战里引入，其实是想让大家理解，to o的执行是在一个单独的节点上，然后它的这个内部的执行逻辑是那样的，然后真正我们在使用non graph的时候，其实可以直接用to node去覆盖掉basic to node，我们手动定义的那部分的代码。好，to node其实还可以跟像react agent去做一些结合。举一个最典型的例子，就是我们在这儿看到，我们做一个相对复杂一点的代码。这个图里面现在大家看nine grape的代码，我不知道熟不熟练。其实要看n graph的代码，一定要从这个状态图或者工作流开始。状态图我们在中间这部分看到，它先定义了一个message state。Message state其实是一种特殊的state ground。这个message state就是整个graph里面传递的都是跟我们之前学过的这个大模型相关的，就是对话模型相关的这些message的信息。
	然后我们看到在这儿添加了一个node叫agent，还有一个这个node叫tools。然后加了这个三条边，第一条边就是一个虚拟的开始节点到agent。所以我们可以想象有一个start，中间是一个agent加了一个条件，边这个条件编是从agent。到秀的continue。那么我们知道这个熟练的同学就知道这个条件边的第二个参数是一个函数，我们会进去看。而这个函数最终返回的就是这个agent的，到底他要往哪跳转，那他要往哪儿跳转呢？
	现在整个python 3以来，包括这个number对于类型的要求越来越严了，所以通常都会有这个类型标注。那么一个类型标注的导入，或者说这个类型标注的使用，最常见的就是会导入这个python的标准库产品这样的一个包。这个typing包导入进来之后，导入这个literal，其实就是你可以简单理解成这个返回的结构，就是这个字符串的这个结构，然后它的返回结构还是做了这这就是他对他的这个函数的返回做了类型上的一些检查，那他的返回还是一个像枚举一样的这个类型。
	要么是tools，要么就是end。End很好理解，就是agent直接就执行完了就结束了。Tools就是我的agent下一个节点是tools。所以就看这个should continue这一行的定义，你基本就能把脑海中把这个图想象出来了，当然你也可以直接display一下，这个tools其实又加回了一根边，从tools到agent。所以你可以想象就是agent和tours之间其实是一个环，然后这个环从agent到tools是需要条件边来判断的。然后从tools回到agent是一个必然发生的顺序执行的过程。因为tools的执行结果是to message要还给那个agent，然后再有那个agent的下一步的路由，也就是这个sued continue去判断我要不要结束。如果结束，那这个图就走完了。
	如果没有结束，那当然就continue，那他是不是需要continue呢？就看这个continue内部的定义了。比如说首先我们取了这个message，是从state里面取出这个messages的这个key。这个key我们应该挺常见了。我们在chatbot的代码里面已经反复打印过它了。Last message就是这个里面的最后一条。然后这个最后一条里面如果有to cost，那就说明要调用它，那么就返回一个tools。这个返回一个tools就相当于这个路由函数，就路由到了toss。
	那么这个条件编在这个时刻，因为它动态生成的在这个时刻的决策就是agent到S反之就是直接到end，这个是比较常见的一种操作模式。然后agent其实就是core model这部分我们就能不去细看了，就是一个调模型的一个操作这是在这个to node跟agent和这个协作或者说结合之后比较常见的一种应用的范式。大家可以参考一下，尤其是这里的这个类型检查这个liver的引入，其实是非常有必要的。大家如果要自己去实现这个条件编，或者说动态的判断的路由函数，这是一种常见的做法。好，刚刚其实我们讲的是很基础的内容，花了很多的时间让大家把这个思维逻辑给掰过来。后面我们会稍微快一点，让大家去看到这个代码具体是怎么实现的。
	最后我们再来试，在check port的代码里面，我们其实是用了一个LLM with tools的方式，用大模型加上搜索引擎去构造了一个节点，我们在这儿可以看到这部分的代码就是初始化了一个chat OpenAI GPT4o omi，这是一个chat model。这个chat model的band tools绑定了一个tool，这个tool是啥呢？是但这里没有导入进来。这个tools其实是我们大家去翻代码能看到，是我们从南茜里面去导入的一个搜索引擎。搜索引擎其实本质上就相当于我们已经用那个two装饰器去转换过了。那玩意儿就是一个可以在能grap内部被2 node接受的一个节点，只不过我们这儿没有去用2 node，然后把它绑定之后，我们这个节点内部就变成了LLM with tools，跟刚刚我们看那个类似，然后定义了一个节点。当然最后把这个函数，也就是我们要加到图里面的这个节点做了一个返回，就是LM tools，invoke，去执行他上一个状态给他的信息。这个是我们在这个chatbot第一个项目时代你看到的。
	而这里的这个Better tools的形式其实是跟能券的这个工具调用的形式是很像的。但它背后的执行其实是完全不一样的。在南泉里面这里做了这样的操作之后，其实我们直接去真正使用的时候去invoke它，通常就会执行完了，就会给你一个结果了。但是我们在nine graph里面还不行，你还得给这个工具再造一个节点。
	我们再反复强调一下，这个是一个本质运行方式原理上的一个不同。要把它加到这个只是一个大模型聊天的一个节点，那真正我们去执行这个工具的时候，大家还有印象的话，其实是还加了一个toll的节点。这个toll的节点就是下面这一行代码，这个to node。这个tor node是我们自定义的一个basic tor node。大家可以看到左边是这个的代码，这个basic tour node里面其实是模拟了一个to，就是标准的ta node的这个操作流程。
	然后在chat work里面我们定义了一个叫做LLM with tools的一个实例，然后这个实例它会生成刚刚我们在前面一个小结里面看到的，也就是这一页的内容，它会生成一段AI message。我找一下，应该是在。这里其实我们的chatbot这个节点，它的LLM with two，它最后一条如果他真的要调这个工具的话，他的最后一条信息应该是生成了一个这样的to OQ，然后生成好的这个to call会给到我们的下一个节点，也就是这个tools的节点。然后这个tools的节点会拿到这个信息再去做处理。这个处理其实就是把这个提前我们已经这个定义好的错误去做一遍调用，这儿挺高亮框出来了。然后在真正在这个措施内部才会去完成这个工具调用。
	调用完成之后会还给chatbot message。并且这是一条实线，说明只要我们去用n graph调用工具的时候，你的一个节点产生了这个AI message里面含有to call，就会调用到to o的节点。这个可能是一个条件判断，是根据情况来的，由大模型去判断到底要不要调，要调的话就生成有to code这个内容。然后一旦调用之后，这个tools的节点，一般来说会直接返回给调用他的这个节点，除非你去手动做了一些更改。
	这个我们待会也会看到，其实是可以做更改的，这个也就是它自由灵活的一个特点，但同时它的默认行为也让你不用操太多的心，能让你直接完成一次闭环的调用。刚刚我们在这个chatbot的项目实战里面已经看到了左边这幅图，就是有一个start chat about tools。And然后这个chatbot，大家去回忆一下，我们因为整个的craft的概念抽象可能有点多，我们尽可能把这个事儿变得是一个像乐高累积木一样，你只要一步一步按照这个逻辑去旅，也是很容易捋顺的。
	刚刚我们看到的chat board，其实它是一个check model的实例，然后给它绑定了一个toss，我们构成了一个check port的节点。但这个节点其实是很弱的，怎么怎么弱呢？大家想象一下，就目前我们构造的这个节点，它其实就是一个没有提示策略的带有工具的大模型。它离我们所谓的比较通用的agent还是有距离的。
	那么怎么样把这个节点变成了一个agent的节点？我不知道大家有没有去想过这个问题，就把一个所谓的LLM和tools变成一个agent需要什么？大家可以去想想需要什么。我们做课我做这个课件的时候还是花了很多心思的。需要什么？我们看这一点，在能切里面其实就有答案。
	把一个LLM和tools变成一个agent还需要什么呢？还需要一个提示策略，需要一个agent type对吧？需要一个比如说你是要self ask research，你还是要这个react，还是要open a的function calling，你其实就需要的是这第三个参数，你需要一个提示策略，你需要一堆的提示工程。那这个提示工程就是我们把chatbot变成一个agent的需要完成的最关键的一个参数。那我们待会儿再来看看怎么样把这个提示工程给他做到刚刚我们说的chat port上，就相当于我们集齐了agent的三要素，我们的大模型，我们的tools，我们需要的提示工程。
	好，那我们接下来看看怎么样去构造一个agent的节点，而不再只是能够到chatbot的节点。要构造一个agent的节点，我们顺道就把这个多智能体给讲了。因为我们只造一个，难免出现学习路径上的偏差，有可能他就没有这个通用性。那我们这次就直接讲，比如说我要构造两个，看看要怎么样去构造它。这里我们就提到了一个所谓的基于agent node的模板去构造多字体。我们提到了模板，它有点类似于工厂函数，或者说我们在两千里面学过的提示词模板。这个提示词模板其实是很很核心的一个抽象，并且它几乎就成为了整个不同agent之间的核心。我们待会儿去把这个逻辑捋顺了，一点一点大家就能明白了。
	首先我们看一下我们要做的这个多智能体是什么样的一个智能体，在第一节课的时候我们也聊过这样的一张图，最简单的多智能体就是两个智能体，to agent协作，two agent collaboration。这个图里面大家不用关注最上面的user，这个user其实是就是我们人这个人这个用户，就这个用户丢进去了。第一段话，第一句话他有点类似于我们在我们用nine graph的那个做方法画出来的这个图里面的start，就是那个虚拟的开始节点。然后它同时也承担了这个结束的节点，因为它的第一个步骤叫first go to researcher，就是start。然后这个第一步骤其实就把用户输入的这段input丢给researcher。最后我们看到rota有一个if final answer，就是是不是最终答案了，如果是的话，它就结束了。那这个时候user那个位置又变成了我们的end，就是结束的那个虚拟的节点。
	对，可以先这样去去看这个图，然后我们自己要完成定义的这个内容，其实就三个节点，router都不是节点。大家可以去去想一想，这个就对应着我们今天实战的这个代码，还有它的这个图。整个里面其实就三个节点，一个是researcher，这是一个agent，一个是chart generator。在右边是第二个agent。第三个是最下面的这个call to，或者说叫tall node，是第三个节点。这个节点是一个预构建的节点，就是我们前面讲过的to node是可以from import进来可以from import进来的那整个这个流程我们可以看一下，除了第一步以外，后面的流程完全是根据用户的问题和你使用的大模型以及它的提示策略来决定它的执行顺序的。
	这里我们可以看到整个两个智能体的协作要完成的一个工作。它的设计目标其实就是当用户去提出一个问题的时候。比如说GDP的一个过去十年的数据，或者几个国家的GDP的数据，这些数据首先大模型内部大概率是没有的，那么需要由这个researcher agent去完成数据的采集。这个数据的采集如果它自己有，它就直接生成了，大模型内部就直接生成了。如果它没有，它就需要去连接这个搜索引擎，去查网上的这个信息。那这个时候你就会发现他要去查搜索引擎的时候，他会怎么做呢？他会去call to，然后call to之后，这个to还会把这个结果返回给他，这个是一个比较常见的流程。
	好，在这个过程当中你要注意的话，你会发现researcher它是怎么到coto这来的呢？他没有直接过来，他后面接了一个叫rotor的路由函数。所以你可以直接的想象一下，它是通过路由的函数到C2这来的那路由的函数会怎么判断它要到Q2呢？我们前面的知识已经讲了当他的AI message里面有这个call to的时候，它就会过来，就跟前面其实一样的。你可以抛开那个chat generator去看，跟我们前面的那个check port的结构是一模一样的这是一个最典型的nine graph的agent to code这个workflow，然后你同样的你把researcher给干掉，看右边这一半拉也是完全一样的一个结构。
	Chat generator也可以去调two，不它调two不是调的这个搜索引擎，它调的是一个沙盒环境，就像我们在这个开发营里面，其实当时做过一些有意思的例子，就是让大模型生成python代码。然后我们想验证这个python代码能不能用，可以导入一个特定的python包。这个python包是一个在我们的这个python进程里面去执行这个python代码的一个包，这个就是恰今天要干的活。他会去导入一个这样的工具。这个工具其实更多的是要让它生成这个chart，也就是图表。那要生成图表，可能它就会生成一些跟meta product lab相关的一些python代码。它也可以通过这条线走过去，然后这个call to这里就有意思了。
	我们之前看到的都是一个agent的节点，调多个two。这个时候这个toll节点其实它返回调用方就行了。因为只有一个agent节点，所以可以直接返回给它去调用。但现在我们有两个agent节点，还有好多个two。那那这个two应该给谁，给哪个agent，其实就变成了一个问题。所以我们会发现在这个多智能体里面，通常它会比单智能体比起来要多一个法，就是在这个state这个维度上要多一个类维度的内容。这个内容其实就是是谁发给你的信息，就是这个真的是谁。就相当于你这一次的这个two node执行完了，你执行完了之后，你应该把结果还给谁，你就看调用的时候传给你的那个sender是谁就可以了，就可以完成这个闭环了。
	然后在这个过程当中，还有一个就是这个rotor有一个continue，这什么概念呢？其实也好理解，你可以把把右边的这个chat generator先用手给遮住。然后你想象一下我们在这个check point里面的典型的流程是什么样的。就是你就我们的这个chatbot什么时候要结束聊天对话，其实是可以有一个条件判断的。这个条件判断就放在rotor里面，如果这个判断要结束了，那从researcher到root就直接结束了，还给这个user也就是N的节点了。但如果他发现我现在这个还不能结束，那你需要干什么呢？无非就是几个原因，一个就是researcher的这个数据储备还不行。那这个时候不行，你可以通过你的提示策略来控制，然后他要么就是我自己去反复生成，要么就是我先思考，就像我们在上节课调这个搜索引擎的时候，可以让它合并成把多个想要，这个没有在上节课讲的，应该是我自己的项目。
	简单来说就是你可以通过提示策略。因为你本来要调搜索引擎，然后这个搜索引擎，它去生成query，要生成给搜索引擎的关键字的时候，其实它怎么生成的，取决于我们直接导入的这个搜索引擎的工具，它怎么写的提示词。你也可以在你的这个researcher，这个agent tor再去写一些提示词。这个提示词可以去控制它。比如说尽可能的把相关的问题放到一次检索里面，然后通过比如说我要问这个我们问过些啥来着？我想想就比如说你要问一个特定的的信息，然后这个信息你可以问它是什么，在哪里，什么年份，你可以一次性把这三个词放到一个query里，用空格分开，那这样搜索引擎可能给你的结果是OK的。
	因为搜索引擎本来就返回多条结果。所以可以通过这种方式在researcher这边就能首先能够自己去转圈圈。这个图我们看到过，然后他也可以去转一个下下半拉的圈圈，就researcher router到一这个圈圈，它也可以从researcher到rotor结束这样的一个圈圈。当然我们要做多智能体。刚刚我们聊的所有的这个图的执行的工作流顺序，都是由rotor去动态决定的，这个是一个频繁大家直觉可能也是多智能体有魅力的地方，但是刚刚所有的这些描述都是一个智能体自己内部在玩。这个researcher跟这个chart generator之间还没交互，那他们之间会怎么交互呢？其实我们就要看这里的这个rooter的这条路线了。
	从researcher的message往上到了root然后这里我们可以看到这个rotor到chat generator的下面有一条线，下面这条线呢叫做if continue，and state sender等于researcher，什么意思呢？就是这个chat generator它得到了一条AI message，然后这条AI message他的发给他的这个。因为当我们rotor判断完之后，你可以想象成rotor就不存在了。它是动态牵了根线，相当于就从researcher直连到了chat generator这个chat generator会知道是researcher发给他的，然后他会去判断，我现在拿到了你的这个信息。你的这个信息显然不是一个，而是a message里面的正文content。你的这个content到底有没有我要的数据？因为这个charge generator的其实只写的是我拿到有效的数据，我去生成一张图表。
	那如果他判断你给我的数据不对，或者说你给我的数据信息不够，他甚至可以去打回，但这个也是取决于我们的这个怎么写的。它可能返回一个特殊的结构返回一个特殊的结构，researcher这边看到了它就可以接过去，就跟下面这条线一样，给我们画了一个我也不知道这个叫什么福，就是一个八字形一个八字形的一个流程。所以整个这个图其实远远比大家想象的可以发生的执行顺序要多很多。
	大家可以判断一下，如果我们问的一个问题，这个问题压根都不需要涉及到chat generator的话，他那条线甚至是完全可以不被触发的那就是一个标准的跟我们前面看过的这个chatbot类似的一个work flow。但是如果你问的问题显然需要有chat generator来完成的话，那就可以出现先画小圆，再画八字，甚至再上去这样的一个流程，所以会比大家想的这个要稍微复杂一点。但是从理解了它的原理之后看，代码其实是并不复杂的。那我们现在再收回来，逻辑上面我们捋清楚了，知道他这幅图大概是怎么样的一个运作了。把刚刚这个逻辑大家回头，如果这个没整明白的，可以再再反复看，反复听一听，然后再映射到代码上。
	现在需要解决的问题就是这样的一幅图，我们有三个节点需要定义，这个two node是最简单的，因为我们的nine grap已经帮我们预定义好了。那researcher和chat generator应该怎么样去定义？这个是我们接下来要解决的问题。怎么解决呢？很简单，先造一个agent node出来，这个agent node是怎么造出来的呢？我们看一下它的这个设定，这个agent node其实我给它的这个定义，它是一个辅助的函数，它不是真正的这个node，它是一个壳。这个壳子定义了就像我们去去造这个runners类似的一个设计，只不过它比roundtable要更高层次的抽象底层可能同样是最终会调到round able协议那一层，因为它用了一个moke，那整个agent node这个函数就决定了我们这个agent节点它的输入有三个重要的输入。
	一个就是这个state，这个是只要我们是个node就得有state，然后是没有办法去改变的，这个是一定得这么写的。第二个是agent，第三个叫name。所以这个agent node它本身它的真正的执行逻辑就是那个agent。这个跟普通的一样，它真正的这个node的执行是在第二个参数，是它的这个函数主体，或者说它的操作符，它的执行的逻辑都可以。第三个是名字，就我给这个A镜头agent node的一个名字。因为最终这个agent node它只是一个python函数，这个函数最终还是得加到我们的图里面，它才会真的可以被我们的number去调度和执行的。所以名字很重要，不然你没名字，这个图像都不知道画什么，是这样的一个设定。
	而返回的是什么呢？返回的是一个字典，字典里面有两个key，一个key叫message，一个key叫sender。因为我们是多智能体的一个图，所以我们刚刚提到了返回的结构是很重要的。然后这个message就是我们的信息，就是标准的信息，这个节点当中的A检测又是怎么来的呢？这个其实是我们的所谓的智能体模板的一个函数，这个函数是用来创建一个agent，也就是我们刚刚看到的那个agent node里面的第二个参数。因为我们要造好多个智能体，所以我们希望有一个统一造智能体的方法，这样也很好去排查错误。然后如果我们照这个智能体的方法是统一的，也很好去去统一去做修改。这样的一个方法我们可以看到它的代码其实很简单，就三行，然后最终返回了一个这样的一个结构。
	我们看一下这三行代码，第一行其实是构造了一个聊天模型的提示模板。提升模板里面会写也是一个乐于帮助人的AI助手，然后跟其他的助手一起协作，然后使用这个提供的工具去推进这个问题的回复。然后如果你已经你不知道这个，比如说你完全不知道这个完整的答案是什么也没问题。然后这个玩说了一大堆，反正最终有一个很重要的一点，就是如果你或者任何其他的助手知道最终的答案了，需要把你的这个本来的回复先回复好，就你的response。然后在这个本来的回复的最后加上一个final answer，就perfect your response with final answer，然后the team就知道要停下来了。这个team就是指所有的agents，然后you have access to the following tools，然后就是你可以调用的工具，是这些，有two name，然后每一个two有自己的系统级的提示词。那这样的一个操作去做一个智能体模板函数里面的系统提示词。这样的话，如果我们有些工具没有给它设计，或者有一些去调这个agent的时候，没有去给他设计系统提示词，它可以用这我们写好的这个东西，然后把这个系统消息的部分和这个工具名称，也都插入到我们的这个提示模板里面，最后我们返回了一个这样的结构。
	这个结构大家应该现在在看是比较熟了。就这个结构首先这有一个管道操作符，然后这个结构其实就是用我们的能量的表达式语言去构建一个最经典的一个agents。Agent就是有提示工程，有大模型，有工具。然后按照这个流程，就是我们的用户输入会首先去format我们的提示模板。
	然后提示模板被format之后会变成一个真正可以用的提示词。这个提示词再给到大模型。大模型本身它也绑了一堆的工具，它再来判断我是自己去调一些工具，还是我怎样，这就是一个LCEL在我们的night grave里面非常常见出现的一种操作。
	好，那么接着我们再看这俩节点是怎么定义的。首先这两个节点为了谨慎起见，我建议大家自己去去实现它的这些相关的agent的时候，有可能的话不要用官方的文档里面那种，就每一个特定的agent也好，或者节点也好，都临时的去写一个check PNI或者说对应的什么check model的实例。而是还是有一个专门的地方去统一的配置和管理。你到底用了哪些大模型，甚至这些大模型从成本或者各方面的考虑也可以用不一样的。然后不一样的参数，这也是比较靠谱的一种做法。
	然后这儿我们要定义两个节点，一个是researcher，一个是这个chat generator。然后我们看到这个research的agent，首先去调用了这个create agent来创建我们的所谓的agent就我们的这个智能体的实例，它需要三个重要的参数，我们的大模型，我们的这个工具和系统提示工程。这个跟我们南茜的agent实例化初始化完全对应起来了。我们再强化一遍，做一个agent最关键的三要素，大模型、工具和提示工程。在nine graph里面同样是按这样的套路去操作的。然后唯一的区别就是它的执行是在单独的一个to note上去完成工具的执行的，或者说工具的调用的，所以我们后面还会看到这个research的the researcher，它还有自己的工具的节点预定的这个two node跟它去关联。在这儿至少我们把它定义好之后，把这个加到我们的图里，待会儿下面会有那个加到图里，会让我们的这个search researcher的这个agent能够去进一步去构造出一个节点。
	这个agent的节点这儿可能会有很多人看的比较迷惑，不过没关系，我写了比较详细的文档，待会儿我们看代码的时候能够看，主要是有一个python的语法堂，叫做function tools里面的这个partial。它是干啥的呢？你可以简单理解是这样，就是我们把agent node当成一个鸡肋，这个鸡肋不是，是这个基础的类基础的类。然后这个基础的类有三个参数需要去咱们在实例化的时候要去填，填我们这第一的要去这个三个参数，state agent和name。然后state我们没有办法把它这个是不能说在这个还没有调用它的时候就传进去。因为这个应该是在图的执行过程当中由上一个状态传给你的。但是agent和name其实是可以复用的，或者说可以及时构造的那这个function tools partial的用法，你可以简单理解成就是我就把它的agent的这个参数先给它传进去了。
	这个时候我的这个research node其实他就已经相当于它复用了agent node的这个函数里面的所有的逻辑了。只不过它的这个函数不需要再去传agent，因为他已经给他传好了，就是research agent。那他也不需要再去传name了，他就传。因为他已经写好了这个researcher，所以整个research node真正要运行的时候，也就只需要传state了。
	是这样的一个功能，可能用嘴来描述比较难以描述。你可以理解成它其实是继承了agent node这个函数里面所有的这个逻辑。同时又把它需要去在这个运行它的时候，传入的三个参数当中的两个都已经设置好了。所以那两个参数也就不用再传了。然后未来就只需要再传一个state。
	所以有了这样的一个思路，你可以想象chat note也是类似这么干的，它创建好了，它是实例化好的一个agent，叫chat agent。工具不一样，模型也可以不一样，system message肯定也不一样，然后name也不一样。所以但他们的agent node部分的逻辑是完全一样的，这个部分的逻辑是完全一样的。所以我们再来细看一下这个部分的逻辑到底是什么，这个部分逻辑就是进来之后用对应的这个agent，这agent在research note和在这个research node和这个chap node内部是两个不一样的agent。但是他们都支持这个in work方法，这个时候就很很能理解LCER这个南茜的表达式语言0.2。
	为什么要去推这个round able协议了？因为大家就是能够用统一的invoke方法去执行。那这里就有很多可以去去去满足我们agent实现的时候要去做的各种各样的设计了。所以这个地方的agent in work本质上是调的，你到底是哪个节点，我就用的哪个节点的agent然后调他自己的in work，然后调的时候，这个state也是他自己接收到的这个state，然后拿到了这个result，然后如果这个result是一个team message就不处理。如果它这个不是，那么就把它变成一个AI的message。然后这个AI的message还进行了一些处理，其实是把生成结果里面的一些key给它拿掉了。这个我们待会儿也会在我们代码里看到类似的结果。
	所以我们再看这幅图，就特别好理解了。这个researcher和这个chat generator到底怎么定义的？他们首先都是两个特定的agent node，只不过这两个节点他们的名字不一样，但他们内部的处理逻辑抽象出来都是一样的。就是拿到状态invoke执行，执行之后，如果是正常的输出不是要去调这个错的话，就把它变成一个AM message，然后还可以去争进行一些字典上面的这或者说输出结果的一些后处理。其实就是这样就可以完成它的定义了，然后也能复用。
	那它们的差异主要在哪儿体现的呢？在那个k agent的部分去体现的，就是我们在create的时候，一个用了搜索引擎的工具，一个用了python的这个RPL的工具。然后提示工程不一样，chart generator的提示工程写的是create clear and user friendly charts based on the provided data。然后咱们的这个researcher的提示工程是before using the search engine，carefully think through and could clarify the query，uh conduct AA single search。说一大堆。
	所以这两个agent其实主要就是我们看这个create agent里面三要素，大模型我们目前用的是一样的，然后这个tools不一样，system message也不一样，那这个system message就能够去复写了，所以是这样的一个逻辑。然后这里的这个prompt的这个partial就跟我们刚刚看到的外面的这个用法是一模一样的。然后我们再回过头来看，其实这就是一个很底层的一个小技巧，就是这个prompt他怎么干的呢？他其实在这里面把system message去给他做了对应的替换，就这里的这个system message，然后这个two names也去做了对应的替换，其实是这么样的一个操作。好，这个我们不是主要的这个核心逻辑。大家回头也可以如果对这个python的语法堂感兴趣，也可以看看我们的代码里的文档。
	接着我们在最后把这个实战部分的代码再给大家讲完，接着要完成的一个问题就是我们刚刚看那个画八字，这个智能体节点间的通信，到底我们的state是怎么定义的？这其实定义了一个agent state，一个所谓的智能体节点间的通信。这个state会比大家想象的简单很多。就是你可以想象我们的agent node最终return一个啥呢？Return一个字典，字典里面有两个key，一个叫messages，一个叫cinder。所以我们要在节点间通信应该怎么样去定义state呢？就是定义刚刚我们跟agent node一样的这个结构就完了。这个是我们去做多智能体的时候，要去在因为我们把节点和编辑讲的比较多，这个state讲的少。
	那我们现在回过头捋顺了再回过头来看the state也很简单，就是你的node返回的结构是什么样的，你的state就定义成什么样子。然后这里的发送消息的这个智能体就不用说就是一个stream，就是那个节点的名字node name。上面的message其实就跟标准的这个message是类似的，就是我们在节点之间要传的那个正文。然后其中它是由这个base message上过应用开发业的同学应该有印象，这个base message就是我们在南茜里面的chat model，实现了各种像AI message、human message、system message to message的鸡肋就是这个base message。然后它是base message message的sequence。是因为我们在信息创新过程当中，他他聊天信息越来越多是这样的一个逻辑。那这个Operator add就是指就append上去，跟我们在check more这个bot里面使用的那个方法，其实本质上是一回事，是他追加上去这个信息这样的一个逻辑。
	好，那么这个state整明白了，我们再看two note怎么定义，在刚刚我们的两个智能体的节点我们整明白了，那么下面的那个two node要怎么做呢？这儿其实分成两步，一部分是定义工具，一部分是把工具放到to node里。大家想一想，第三步就是去掉那个to node，我们有一幅图，就三个步骤，to not to call. 那么to先整明白这个搜索引擎跟chatbot里面，我们用了同一个搜索引擎tavi search，然后每一次搜索最多我可以返回五条结果。然后这个python的可执行的这个沙盒的一个工具是我们自己去用to装饰器去封装的。
	简单来说就是这个python的RP工具是允许在你的python进程里面再去执行python代码的。所以这个python RPL的方法也不复杂。大家看一下，其实就是一个try，里面去用RPL去run我们传给他的code，他就只有接收一个参数。这code是什么呢？是大模型生成的python代码，由这个函数来进行执行，拿到了一个结果。就像我们在OpenAI free star，也就是应用开发的这个。这个实战营里面给大家用大模型生成了什么快速排序，归并排序之类的代码。其实当时也是用的这个包，其实可能很多人不记得了，可以回头去翻一翻。
	这个IPL run完之后，可以返回一个结果。这个结果它如果是成功执行的，因为它有try catch，如果我这个沙盒环境里面执行这个代码没问题，就说明首先这个大模型生成的代码是没有语法错误的，其次它的执行结果是成功的，不没有出现一些比如说被零除什么的这些数执行的错误。那么这个result就可以直接返回一个成功执行，执行了什么呢？有一个python的code，然后有一个标准输出，标准输出就是这个python代码执行的结果。另一种情况就是运行过程当中报错了，那就直接把所有的exception就打印出来，然后最终返回的结果是什么呢？是这个return string是怎么样的？
	就是上面我们拼装好了，成功执行了什么样的python代码。比如说我们入参code也会打印出来，然后这个code执行结果也会打印出来。在这之后再另起空格，再另起一行。就是if you have completed all task，respond with final answer，这个final answer第二次出现了，这个final answer很重要，就是如果这段话给最终他也是要返回给掉他的two的。可以想象一下谁来调他的呢？是那个chat generator来调他的。所以相当于如果这个chat generator收到了这个工具的结果，那么他就可以去判断他是不是完成了所有的工作。
	如果是的话，这个charge generator就可以进一步返回这个final answer。而这个final answer会在我们的路由函数里面作为整个工作流的一个结束判断，那么就结束了。所以其实最终这个是在哪儿结束的，这个final answer是非常重要的一个咱们要去看的关键词。把它变成了一个stop world的一个停止条件的一个词。那么有了工具，工具变成tour node，这是一个基准。这个什么标准操作了，就把你已经定义好的tools变成一个列表，列表由to node去实例化，就变成了一个to node。然后再把这些node加到我们的这个grab里面就可以了。
	那要定义这个graph，所以最关键的是节点我们已经整明白了，接下来就是边，就我们的工作流这个flow到底是怎么怎么去设计的，就是要把这些节点组织起来，组织起来最关键看这个rota函数是怎么做的。这个rota函数这也就把我们刚刚在前面讲的那个也有一个literal，去去做这个国网。我们可以再再回看一下那一页，让大家有个印象。在那一页其实也给大家。
	讲了。
	这个是。Literal是在。我看一看。所以就是我们的two node的一个最佳实践里面其实也有写。就是哪怕是一个agent他也会出现这种我到底是结束还是去调工具的一个判断。然后这里会有一个路由函数去做这样的一个基准，这个叫什么基操？那么在我们的这个两个agent里面，它它就同样了，其实这个是可以直接套娃的，我们可以看一下这个这里，这儿其实它在call to和end之后又加了一个continue，这个是它可以返回的第三种情况。所以这个router任何人去调他的时候，他都有三种情况可以返回。
	首先他要获取到他，因为他是一个牵红线的一个人，他在节点跟节点之间会造出一些动态判断的或者说动态生成的线。那么这个router首先当然要获取这个message，然后如果这个message里面是有to court，这个我就不再回到前面的这个课件，这个已经反复强调过了，就它是一个AI message，AI message里面有to call，to call里面有序列化的多个key，有name、type，argument之类的。它只要有to call，那么就返回to call，然后如果是有final answer的，那么就直接返回了。
	这个第二条就是我刚才讲的很关键的，就结束了，这个整个工作流结束了。如果既没有突破又没有end，那就continue继续去执行，继续执行。就我们开始看的那个画八字的下面两条虚线就是continue。
	Continue里面的sender不一样，它的这个操作逻辑也不一样。所以这个rotor整体要做的事情就很清楚了。首先它最关键的一个作用，它在帮我们叫agent去判断它现在能不能调用到这个工具，因为只有当这个agent的大模型生成的AM message里面有to call的时候，它会路由到那个工具节点。然后如果这个agent节点它的生成结果里面包含了final answer，那么rotor也会帮他直接去结束整个任务。因为已经判断达到了最终结果，除了这两者以外就是最常见的状态了，就是持续在continue。
	就比如说我的这个节点生成了一个AI message，然后这个message它并没有生成任何的工具调用的内容，也没有这个to code内容。那他会干嘛呢？就像这儿，他并没有去调这个突破，也没有去往上结束，那他干嘛呢？他就去画那个八字了。比如说researcher他传了一个message给到rotor，然后这个rotor他看了一眼没有to call，也没有final answer，它就会走下面这条虚线，它return一个continue，然后这个return是一个continue。同时它的这个sender是researcher，因为是researcher发给他的，那这个时候他就会把这条信息给到chat，就chat generator，就这么一条逻辑线，这个是非常清楚的。
	在root内部就三件事儿。当他返回continue的时候，就是两个agent互相在递信息。当他返回的是call to的时候，那他就会去调当时的那个sender的agent，去调他的to按照他自己的这个逻辑就走一个小环如果他有final answer，那就直接整个这个流程就结束了。
	我们把代码看完之后，再回过头来看这个图，其实是非常清晰的，这个工作流搞明白了之后，我们看到这个条件编的逻辑其实加起来也就简洁很多了。因为这个条件其实就是把我们刚刚看到的那些剩下的部分给补上。就是researcher他要去连这个rotor，下面有对应的三种情况，然后chat generator也是连这个路由的函数，有三种情况。然后这个coto它跟上面两者略有不同，刚刚上面那两个是完全对称的。
	大家去想象一下，就continue是连对方，就是我从我这个agent跳到你那儿去，end就end，call to就call自己的to，那只有那个call to略有不同，这call to是干嘛的呢？他他要干的事情就是首先他自己就是CTO这个节点就是他的第一个这个入参条件边的第一个入参就是自己。第二个就是我的这个调就相当于我动态要去判断这个路由的函数，就跟root一样。在这儿用了一种简写的方式，就是这个路的函数的逻辑就是谁调的这个我就返回给谁，所以就走自己的这个环。就是这个nmda可以实现的一个很好的思路，就是我的researcher掉了我自己，我就还给researcher charge generator。掉了我我就还给charge generator，就实现了这样的一个基于我的我传给我的这个就是谁把信息给我，我就还给谁，就实现了这样的一个动态路由，这个是我们的call to实现的一个条件边。所以整个muti agent的或者说我们两个智能体的协作，就没有一条实在的边，所有的边都是动态判断的。所以这也是我说nine graph的精髓所在。
	就是你只要其实工程做的足够好，你选了一个合适的大模型，然后你的tools搭配的是到位的，其实它的这个上限是非常高的。以上就是我们可以去用number up做的这个agent。如果我们要去做多个智能体需要用到的全部的知识点和对应的功能，还有API了。然后如果我们要去完成这个to code调用，在南内部跟南茜最大的区别就是它需要有一个专门的突破节点去完成这个需要一个专门的突破节点去完成最终的调用，而不是说像这个年轻人一样，他在内部就完成了这个事情的执行了，你就无法去做控制。
	好，我们接下来去实操一下，看看怎么样去用这个land up实现多智能体的协作。行，好，我们我们先留五分钟的时间，大家来提问。大家有问题吗？这个提问之后，我们再来实战看一看代码，让大家先把逻辑给捋顺了，把他的这些抽象概念的设计的目标意义，以及他为什么要这么做给明白了。其实你后面自己看很多代码都很easy。
	有个同学问为什么不创建两个to node的实例？这个问题我前面讲的时候提过，你想一想，你这个逻辑会有一个很大的漏洞是什么呢？就是你天然认为agent和two是一对一关系，并且大家还不会有overlap。但你现在假设你想一下，这个researcher如果他要同时用这两个tool chart generator也要同时用这两个to按照你的想法是不是就得四个node节点，四个工具节点了，还是你准备怎么做？
	这个同学你可以思考一下，这是一个很很值得玩味的事情。就是为什么要用一个to node来解决这些问题？包括如果我们做了那么多to node的，它的这个动态路由是不是也很难写，你要判断多少东西对吧？然后这些to node的本身它内部的工具是无状态的，一个无状态的节点就不应该有多个，因为多个就有多个to OID。你说你调哪个to OID呢？你让你的大模型也增加了负担。
	为什么不创建两个to node的实例？那你创建两个to node实例，你把哪个加到图里呢？还是说我没听懂，你创建两个to node实例，你只把一个加到graf里面吗？那个不加入吗？
	千万二可以直接用吗？Instructor版本的输入格式是不是要和官方对齐？我不知道这个问题的上下文是什么，这个同学我不知道你说的直接用是什么概念。如果researcher调tools没查回来数据会怎么让继续查tools查，不然直接continue画图是不是报错了，他会自己查的。这个同学你想一想，他会自己查的，他会自己查的。他会自己查的，他就跟跟咱们chatbot里面这个逻辑是一样的。
	我印象中拆货应该是造了一个圈圈吧。
	没有我是在在3 creation里面。对，就这个得得去设计一个环。确实现在的这个应该是没有圈的设计，我搂一眼圈researcher然后。
	我印象当中，对对对，是我我得应该这么说，就是他没画出来这个环，是因为这个圈其实就是那个环，这就是一个环，就是他会怎么去处理这个逻辑呢？就是你可以想象成我用这个大图，这个researcher它message给到这个rotor router，会去调tour。Tour给他一个结果，这个结果如果不满意，他可以继续call to。
	对，然后他为什么可以继续去去call to呢？是因为在提示词里面，我们写了。首先你要仔细的想一想，你要给搜索引擎提的问题，然后变成一个单独的去进行提问，然后这一段其实是可以去决策他能不能解决这个问题的。假如你希望他他能够达到你要的这个效果，就是他能够用完搜索引擎，然后拿到了一个结果。这个结果他还有一个是否满意的标准，有一条线。这条线呢决定着他要不要去调那个chart generator的话，那你可以在这儿去再严格的去写一些review的这个提示策略。就比如说你需要去这个问的问题是比如说我们问的问题是过去十年或者哪几年的GDP的数据，你可以通过这个扩拓查出一些相关的数据。但是你想说有可能他查的是不对的那这个时候可以再比如说让他再查一次，然后去校验两次的结果是否一样，这也是一种策略，只不过可能他没有没有那么的经济有效，这儿可能是根据具体问的问题，你得case by case的可以做一些设定，我不知道这个有没有回答你的问题。
	我不知道有个同学一直在说两个猪肉的，然后说各自掉各自的中间的环不复杂。我不知道你现在看起来这个环很复杂吗？这个环其实一点都不复杂。首先因为当你有两个to node的时候，你会发现你的那个图会看着更凌乱。你可以自己试着定义一下，你把那些节点都加进去，然后你把它画出来，你可以再搂一眼。对，然后尤其是如果你的two之间会共用，然后你还需要去做相互的传信息的时候，会绕过某些你认为不可能会共享的节点的时候，会看的更乱的对。
	然后还有一个很重要的原因就是你如果有多个agent会用同样名字的拓，然后你会把他们怎么安置这个to node也是一个问题对。增加第三个agent其实是state是改变sander的名称和新增two就可以。你增加第三个agent甚至他没有错都可以。
	你想象一下，你可以在在旁边再丢一个agent，在agent甚至他不没有去call to，它是一个reviewer。比如说我们刚刚有个同学问，researcher它call to之后的结果对不对？你可以有个reviewer，reviewer它是每次researcher的这个CTO之后的结果都丢给他把review记一下。那review可能要么就在内存里面记一记，要么就有个向量数据库更好，那它就有工具了，向量数据库也是个工具。
	你就让这个researcher准备发信息给chat generator之前，其实是先发给reviewer，reviewer去检测它的这个数据对不对，如果不对的话，打回你researcher，然后对的话，再发给chart generator。然后你做完这件事情之后，你就会发现，这个reviewer的工作，chat generator自己不就能做吗？我不知道你想一想这个事情是不是这个逻辑，所以chat generator的逻辑是他本来就在review，对吧？就是create clear and user friendly charges based on the provided the data。然后本来自己就可以干这个事情，如果他的这个结果干不出来，他可能就是我提供的信息不够。
	好，我们就先继续了。然后我看大家问的问题都都已经跟咱们的这个内容有点关联性比较弱了。那我们接着来看这个代码，这代码其实我刚刚的那个讲解应该大家捋顺之后就很简单了。我们再来看一看，要稍微放大一点。这里额外提一点，就是我还传了一个基础知识的一个notebook，打开它没有渲染，这个notebook其实是长这样的。就在我们的这个目录下面，我待会儿把最新的这个更新上去把它渲染一下。这里有个get book是用来解释咱们的这几个关键的语法，就是跟python有关的，可能不理解的，在这儿有一些更详细的内容。然后这些内容当中的一部分，我也放到notebook里面了，放到主拍的notetwo里面了。
	包括这个partial在create agent和这个research node都有用。就是在这个create agent的内部以及外部都有用过这两个都有这两个地方都有用过这个方法，具体是什么含义，包括一个举例，然后two no的也是一样，就two no de还有一些更详细的，包括它依赖的其实主要就是nine grap。它在nine grap这个包里面，就是nine grab的prebuilt里面的模块的一个预定义的实例。然后就是我们刚刚讲过的一些内容，包括他还有一些这个例子。这个例子其实跟我们一直用的这个pretty friend是完全一样的一个打印方法。然后这个连续调用就是我们在在这儿看到过的。好，这个是关于get book，到时候应该也能查看到。
	我们回到这个多智能体协作的代码里面，这里我们有提到就是整个工作流程，我把它设计成了九个步骤，这九个步骤里面辅助函数有两个，create agent和agent node。这个我们刚才提过了，通过这两个辅助函数我们可以造出对应的智能体节点researcher和这个charge generator，然后工具一个是timely，一个是IREPL的这个python沙盒的一个工具，是分别给他们俩去用的，还要把这两个节点也定义出来，to node的节点也定义出来。前六个步骤我们就把基础的都定义好了，但是前六个步骤做完，这个图还是一片空白，因为我们都还没有去建这个图。那要去建这个图，我们需要什么呢？需要一个graph，我们直接看到这个第七个步骤第八个步骤我们需要的是一个state graph。而这个state graph，他需要有自己的state，这个state就得在这图纸前一步去建立了。所以大家去想象一下，agent的三要素是模型、工具、提示，工程图的三要素是状态、节点边。
	好，那么什么东西可以先定义呢？节点你可以先想清楚那个节点要干什么，因为那个是执行逻辑，然后接着是节点之间的信息怎么传递，这是第七步。我们的state需要提前定义，然后这个才能把图定义好。然后这个图的定义实例化是要基于你的这个state来的，使用它来管理状态的。就是咱们这儿定义的这些都是刚刚课件里有的一些代码，就是整个九个步骤里的关键部分，刚刚在课件里都给大家深度讲解过了。那么有了这个state之后，基于它创建出来的一个状态图，然后从第八个步骤开始，才有了我们整个这样的一个work flow，接着就是把我们前面一些步骤定义好的，比如说我们的researcher charge generator这俩节点加到图里，然后to node加到图里。
	有些聪明的小机灵鬼就会说，那我加进去了，我这个时候直接compile行不行？你可以试一下。对你compile不了，因为这个图没有start和end。其实其实要去做这样的判断非常简单，都是一些经典的图论算法，就可以通过一遍top排序就知道你现在的这个state graph里面到底有多少个联通这个强联通块。然后如果是超过两个联通图的话，这个就出问题了。理论上他们应该是就一个连通图才对，这样才能保证它的这个拓扑顺序是合适的。所以你如果有一些节点他创建到图里面了，艾特进去了，但他没有跟任何的节点去有这个边相连的话，它就变成了一个无法连通的子图。这个是不允许被编译的，会报错，所以你还需要建立边。
	对最后一个在这个定义工作流或者状态图的最后一个步骤，就是把路由和这个边给它加好。并且加完之后一定要可视化出来，确保你的图的执行的顺序是正确的，尤其是增加了这个动态路由之后，一定要确保这个是顺序的。这个continue的打印，一直都会出现这个非空的制服，有知道是怎么回事儿的同学，最好能能提供一下这个修改意见。在社区问了一下，也没人提。如果有知道的可以，但不影响这个执行结果。只是渲染这儿会增加一些不必要的逃逸字符，然后最后再次执行，执行其实是简单的，我们可以看一下这的执行结果，其实是问了一个问题，就是US美国2000年到2020年的GDP数据是怎么样的？然后画一个折线图，用python最后就是把这个图生成出来，图表生成出来就可以结束整个多智能体协作的任务了。
	然后设置了一个最大递归限制，这个是我们在chat port里面没有用过的一个config最大递归限制。然后我们接着来运行它的时候，运行它的时候，你就能看到它有这个human message，AI的message。这就现在大家看这个就懂了，就这个AI message生成了一个to call，然后这个to go里面有这个对应的一个结果，他要去call的是什么，以及code query是什么。这个tool，也就是我们的time research这个tool，它返回的结果是一个tour message，然后摇啊摇一大堆。然后返回的结果之后，拿到了two message之后，我们的researcher就去判断，他从这一堆结果里面，他找到了这个US的这个GDP数据，数据是这样的是这样的，然后这个数据的单位是10亿美金，billion of doors，billions of dollars. 
	然后下一步他要generate a nine charts，用python去可视化这些数据，然后这个是它生成的python代码，python这个是对应的实际的这个python的代码。This code will generate a line chart showing the GDP of the一大堆，然后you can run this code in a python environ vironment。这就会出现一个，我们在首先大家看到他这没有真实的生成这个图在到这儿为止还没有真实的生成这个图。我们的researcher同志和researcher agent它生成了代码，生成了代码之后，它判断我们整个这个事儿做完了，他给了一个final answer，这个final answer，因为它的出现，我们的这个rooter rotor其实是不会在这儿可视化出来的。所以我回到上面这个图，这个rotor因为他看到了final answer，所以他就直接结束了，这里我写了一个说明，是这样的，当然这个同样也是我们要去做的一个作业，因为我自己已经验证过了，是能通过修改一些东西让成功率提升的。
	但这简单说一下，咱们这个流程如果要走完的话，理论上是刚刚的researcher拿到了two的结果，然后生成了一些代码。然后这个代码给到了chat generator。Chat generator去调他的拓，但实际情况下应该是他俩有分工，就是researcher应该只提供数据，提供数据之后，chat generator来生成代码生成的这个代码。这个我去也应该这么也不能讲，只能他智能代码。
	因为他这个过程当中，反正最终给到这个charge generator的tour是那一段python的代码。它俩谁生成呢？其实理论上也都可以，但最终这个chair generator它的tool才能去执行这里的这个工具。
	然后换句话说，如果咱们要去做这个改进的话，其实跟下面的homework有一定关系。这里我们把homework给正好就公布了，跳的有点多，在最后这几页，这个homework其实是啊这样的，第一我们这个代码肯定是已经有了，然后大家可以去自己运行去测试。然后在测试过程当中，我们知道一个agent的好坏就三要素，这个大模型工具和提示策略工具，大家确实不用怎么花太多精力去改了，这个其实是不用去折腾的。然后大模型是大家需要去换不同的大模型，你是能够有明确的体感，知道大模型对于一个智能体的表现的好和差的。这个是大家要去做的一个作业，就是用不同的大模型来运行这个多智能体的这个项目，看看它的生成结果。第二个就是我们的这个chart generator是生成一个图表，有没有可能让它生成一个table或者其他的，就是你可以自己替换一个智能体，把那个chat generator给干掉，然后去换一个智能体之后来当然你也要设计它的提示词和它要用到的工具，然后来运行查看一下这个结果。因为那个researcher反正就是提供数据的，然后另一个你要拿数据去干啥，其实都可以。
	然后第三个，这个是可选的，但是是其实是推荐建议大家去做的。大家想象一下刚刚我们出的那个GPT4o mini，它没有最终执行。是因为他觉得我已经生成了，可以就是我生成了一个python代码，这代码是可以生成这个折线图的。所以我就认为整个事儿做完了，但其实没有，但我们的researcher和chat generator的系统提示写的也比较模糊。所以这个部分其实是可以通过优化它的提示词来实现的，我们的这个就是两个解决方案的两两个解决方案，一种解决方案是优化提示词，然后让他做对应的工作，不要自己在这儿就弹出一个final answer来。第二种就是rotor的这个逻辑优化。现在router的逻辑非常的简单粗暴，就是只要我的message里面有final answer，我就结束了。其实也可以用更结构化的方式去判断结束条件的，就这两个思路其实都可以去提升我们生成这个chat的成功率。
	这个是可选的，建议大家去花时间试一试，这个是能提升水平的。好，那我们回到这个代码，我们执行一遍，让大家看一看这个过程。第一个就是我们还是要把重启一下，让我们的执行结果是。是跟大家看到几乎类似的，在这儿去装一些依赖的包，其实我们前面都都有啊都装过的，几乎像这个冷倩open INS smiths pandas巴拉巴拉的。然后我们。
	这个应该都装好了，执行一下，他应该不会再安装别的了。这个地方很重要，就是咱们的next space的这个tracing v2要一定要设置成true。这个是决定了我们在左边的next mix平台上可以看到的不同的project。这儿我们设置成多智能体协作，在这儿。好。这些key大家如果没有在环境变量里面去设置的话，可以在这儿设置。
	然后这个create agency我们就往下看看，这些都是它的一些辅助的注释，我们就不讲了，我们可以直接去看它的结果来进行分析。这个是定义一个工具，两个工具，然后agent node。定义好了agent node，然后最终要把结果变成一个a message。关于这个AM message的构造，如果有的同学对这个不熟，我这边也有一些对应的注释，大家回头可以自己去细看一下。
	简单来说就是AI message是连线当中的AI模型恢复的一个抽象的类，然后这个类它的构造方法也可以直接去调用的。然后我们这儿就是直接调用的一个构造方法，就跟我们在chat port里面调two message一样，因为在底层的base message就支持这样的一种构造。然后在这儿我们还进行了一些处理，包括把type name给移除掉了巴拉巴拉的那接着我们执行了，我们来定义好两个智能体的节点，一个是research的这个节点，然后它通过搜索引擎的工具和这一段描述，这里其实是可以去做优化的对回应着我们的作业。
	3，然后这个图表生成器它的节点，我们也定义好类似的方式。然后在这里再多说一句，为什么是优化点是在这里，因为现在的问题是他都没有到check generator。所以有的同学如果要去优化它的话，如果去疯狂优化下generator，其实不会改善这条路线的生成率的。因为他他压根就判断的这个机会都没有，没有被被激活。他在执行的时候，好，那么我们这里是关于to node，就是个预构建的攻击节点，大家如果在过程当中想要了解它的话，这里也有对应的一些说明。那么这里我们把两个工具给他加到列表里。
	好，然后大家可能对这个顺序有些还有一些疑惑。就是我们的工具定义在非常前面，而工具节点在很后面，为什么不挨着？主要还是因为这个工具会被智能体给用到。大家可以看一下，就我们在智能体节点里面传工具，是为了让他知道我有这个工具可以调用，然后生成对应的这个to code这个message，然后真正执行它的是在第六个步骤，才会去把它变成一个节点。但是因为第四和第五个步骤都会用到，就我们去定义这个智能体节点，其实就会用到123。
	大家可以去想一想，就是我们的researcher和这个chair generator需要agent，需要LLM，需要这个tools，然后需要这个提示工程提示策略，然后create agent其实是把基础的agent实例做出来。Agent node就是把它变成一个特定的node，所以是有这样的一个依赖关系。当然工具节点也要把工具变成一个对应的可执行的节点。所以是这样的，前六步是这样的顺序，第七步是把它们之间的这个状态给定义出来。那我们现在就回到第六步，第六步。
	字儿。
	对，那我们实行了吗？他已经执行过了。然后我们把agent state定义好，然后这个时候我们去构造一个图work flow，然后往里面加三个节点，我们可以做一个实验，就有的同学就我刚刚说的，如果我们的图都没有这个编译好啊，图这个边都没有添加，会不会报错？看这个这。
	就会。
	很明显的这个报错，就是这个是不可达的，整个这三个都是不可达的。因为这个图连star都没有，所以大家不用担心这个图的拓扑有问题。首先compare能通过就说明图是一个连通图，没有这个孤立的节点，无非是顺序的问题。
	好，让我们定义好路由的函数编的逻辑，然后去编一下。就是我们可视化可以看到整个这个图，其实就是咱们在最上面看到那幅图。只不过chat generator挪到右边去，然后这个two移到中间来，然后这里的虚线是有对应的一些更细节的条件。整个这幅图其实除了start到researcher是一根实线以外，剩下都是虚线。也就说明这个第一步是确定性发生的事件，就是first go to researcher。
	这个是start到researcher这一步是实现是一定的。剩下所有的线都是动态去决定的，根据我们的情况来的，这个就比较明显了。所以实线跟虚线的区别大家应该是清楚的那我们来执行一下，看它会怎么样去生成这个结果。他去检索世界银行数据，拿到结果，生成结果，果然到这儿final answer就结束了。所以这个是omi他做不到，我们换一个问题看他会不会，比如说这个。我觉得可能同样会出现这个问题。他可能还是会自作主张的就结束了。
	这边还在运行，然后左边的number up应该是实时的，能看到结果的。
	果然到这儿就结束了。大家如果要要去看这个代码可不可用？其实咱们这个是我们复制下来的那个。所以这个代码是可用的，所以他自己的这个结束，还有他能说的过去的逻辑。这数据靠不靠谱这个我就不太清楚了，这个可能大家得去再去做验证。现在我们这个homework其实在下面有写，我们可以去做这个第一个作业要做的事情就是我们把模型做一个调整。我们把这个。大模型应该是在这儿去做的设定。
	Restart and run all. 
	执行到这儿了。
	你看这个GT4O就明显不一样了。
	这里报了一个奇怪的错误。首先我们分析一下这个结果，是在这里出现了不一样的输出。我们看到在researcher的GPT s omni的版本里，它生成了一段python代码，然后直接就最后输出了一个final answer。然后在这里我们看到这个researcher它输出了这一段python的代码。然后最终给的这个结论是你可以在这个python的环境里面去用这个巴拉巴拉去执行它。但是没有给出final answer，那就会触发我们rotor里面的一个逻辑，就是他走了continue，然后把这一堆信息，这一条信息传递给了咱们的chair generator。而chat generator他会去调我们的这个python RPL的工具。
	然后这个python RPL的工具，我们开始看过它的工具定义了。他会去执行我们的这段代码。然后执行完了之后，会把这个结果展示出来。当然这个是他要去调的这个信息，这个是他要去调的信息，在这儿会去验证这个执行。然后一直到这儿是它的return，这个是它的return，就是我们看到的这一部分的代码在这个。这儿他最终return的是这个玩意儿。
	刚刚这个报错也是概率性的，这个报错是怎么发生的呢？大家可以想象一下，这个是一个tool是一个tool node。这个tour node理论上它应该要变成一个two message，就是变成最终我们能够u chat generator掉了，他他再把这个结论返回给我们的这个charge generator，然后调给这个返回的过程当中，这些信息都要被变成我们的这个two message。然后这个two message现在应该是格式转换出了问题，可以看一下它的报错。
	Required arguments are post post sequence request uh, selling invalid message name string does not match pattern expected a string that match the pattern invited request error messages file name它没有这个name。这个也可以掐到我们的这个测试里，有去提升它的我们的提示词，然后去把这个概率给做高一点。这个大家可以去在咱们的homework 3里面去做对应的这个设定，去提升它整个图表生成的成功率。理论上这个概率应该不高，我自己试下来应该很多次出现了一次在GT4O里面，我们可以再试一下。把这个temperature掉。
	执行到这一步了。
	这就很僵硬。这里确实做的有点错，这个代码生成的有点问题。这个GPT CO这个模型现在生成的也有一些小问题，换一个这个时间段。再试一下。
	但确实这个提示词写的还是比较简单的，留下了一切大家可以发挥的空间。
	应该是咱们的这个。看一下。有一个AMS sage的字典去除。
	要解决刚刚那个问题，可以指一个思路是在。我们的这个看一下在这个。
	agent . 
	node agent node。这个部分其实还是可以去做一些处理的。现在的我们的这个GPT4O直接把直接在这个位置就把它给代码给运行出来了，然后to call给运行出来了，然后在这儿去验证这个结果的时候，反而没有去把它组装成一个合适的two message。在这个结果的处理那儿，确实是可以再优化一下。现在的agent node是完全没有处理咱们的最后的结果的，就我们看到的。
	这部分。
	所以刚刚我们的最后报错的那个部分，其实就是咱们这个部分没有去做额外的太多处理。但如果把它处理好了，其实是能接回来，然后让它完成整个的调用，这个就留给大家去探索，反正回头我们会在，因为这个作业其实最近布置的有点多，我会在后面找一个空，把这个提示词的优化怎么样去解决好它，给大家找个时间讲一讲。
	现在是尽可能的首先让大家熟悉nine grab的基础概念用法，从chatbot到我们的这个多智能体里面要重点讲的突破。以及去构造这个agent node时候应该怎么去操作。现在这个agent node只是去掉了具体的实际的节点的代码，然后把这个非to message的输出做了一些处理。Two message的输出还没有去做额外的后处理。如果动手能力强的同学可以去把这个agent node再去做一定的扩展，让刚刚的这个charge生成的稳定性做得更高。但如果咱们要去完成这个homework to homework 2的话，其实有可能就不太会遇到这个问题。因为你生成的结果有可能不太会触发到我们所谓的这个to message里面的结果，无法最终构造成要去请求的这么一个结果。
	好，这个是咱们的一个多智能体协作的一个实例。大家如果有时间的话，可以回头再去看一看这个circle agent。这可能我们暂时就不会有时间去讲了，但这部分的代码现在是能成功的运行，也跟这个negative h的社区沟通了，在他们的tutorial里面确实有一定的问题。然后能够解决这个问题的关键，其实是在我们的它也是一样的一个逻辑，有个final answer我简单提一嘴，就是我们看一下它的徒长。长这样，然后之前的一个很大的问题就是其实跟我们用GPT4 alminy自己擅自去结束了整个流程一样。然后之前的这个tutorial的里面的一些设定也是会出现这个query gen，就直接就结束了，都没有去验证这个query，也没有执行这个query，他就没有把这个circle执行好，就拿不到结果。那现在能够去解决它的一个核心的逻辑，就是我们在这个final answer，大家如果在这个位置，就我们在query gen这里，除了绑定一个submit final answer之外，我们还需要去做这个model check berry，去检查这个答案，他还要检查一下这个结果，不然他就直接去提交了。这个应该是官方的tutorial的一个bug，那这个bug现在我也正在跟社区去讨论，看最终他们是什么样的一个方式去解决会更好。
	这个agent的运行，大家可以去实测一下它同样的逻辑，它是用我的这个GPT ominous的这个实例就能运行，然后list一些circle的表的信息，然后他会去判断。这个判断他就做的非常的严苛，是简单来说，我们问的这个问题是，2009年的销量最高的这个agent是谁？这个agent代理就是就代理商的意思应该是我不确定中文应该怎么翻译这个agent比较好，就中介大概这个意思。然后他通过这个查询列出所有的数据库里的表，然后得到了这个数据库的这个schema，然后又展示了这个部分的信息之后，然后由他去判断。他会去check，他发现这个就是我刚刚说的要加的这个model chat query，他会去判断我现在要fix我的这个错误，然后巴拉巴拉说了一堆。然后接着他就去生成了一段这个Perry。
	生成了query之后，他会去去调用，调用之后得到了一个答案。这个答案就是长这样，这个是two message的回复。然后最后的AI message就是拿到这个tou message整理之后得到的一个答案。就是这个sales agent谁在2009年卖的？最多是这个Steve john，然后就是史蒂夫强生，他的总销量是164.34。
	然后现在我们看到的那个marty agent的错误主要就存在于理论上这个chat generator是最后一条AM message。他会把我们的python的沙盒工具执行的结果再进行一次处理。但他没有处理，直接返回。那直接返回那就就会直接请求就会报错，这儿大家可以再优化一下。
	好的，这个就是我们用np去实现多智能体的这个课程的内容，主要包含两部分。前半部分是讲了这个工具调用和agent node的一些理论，然后也是基于我们多智能体协作的这个指南来的。后半部分带大家实际看了一下它的这个代码，然后也运行了一下。希望大家能够在这个过程当中能理解这个np它的设计的原理目标，以及他设计的哲学。就他为什么要这么去做，为什么要把所有的可执行的工作都放在节点上来？最后留的几个homework其实是很有趣的。这个过程当中大家可以去不断的加深对network的了解。在后面我们的第二就我们整个训练营，企业级的这个agent的训练营的第二个agent language mental里面，我们也会用到这个grab，也是一个逐步加深使用这个name up的一个过程。好。我们来看一下有哪些问题。
	发现结果不对，会再次调tools。现在的代码不会不是现在的代码，不会是现在的提示词，它不会这样做，就他现在的message没有要求他做这样的检查。
	这同学你想一下，就是现在是这样的，首先two message都没处理，你看一下，还是这个地方。就比如说比如说我们的这个researcher他掉了搜索引擎，搜索引擎给了他一个结果，那个结果就是这里的state。这个state他他拿到这个结果之后，他其实啥也没处理，他就直接返回了。然后如果如果他去处理的话，其实你再结合这个researcher的提示词，这儿是可以去做一些这个工作的那现在包括这个charge generator也是一样的，就是因为他们调完工具的结果是没有去处理的，所以会出现比如说researcher他就直接跳了。然后咱们的这个叫啥来着？那个chat generator也就在最后生成的那个部分就报错了。是这么一个情况。对。在增加第三个agent的时候，state只改变sender的名称和新增的two就可以，router只增加判断，这个其实取决于你要怎么去设计这个work flow。就开始那个ZZF的同学提的问题。
	看大家还有什么问题吗？我好像没看到新的问题。最后一个问题，9点38了，这都三四十分钟前了。
	这儿确实得再额外处理一下才好。
	把它换成大家还有什么别的问题吗？
	Text to circle可以上生产。不同数据库的circle语法都不一样。
	自然语言生成circle靠谱。我不太理解这个同学问的这个点是什么概念，这个不同数据库的circle语法都不一样。你说的不同数据库是什么级别的？是指这个no circle和这个circle吗？还是指什么？如果是指都是关系型的数据库，大部分的语法是一样的。而且语法其实是大模型自己必训练学的，他不太需要咱们去去纠结这个事儿。其实。如何测试确认marty agent设计无误，这个跟所有的软件测试一样的，就需要准备一批测试数据，然后你可以在nice miss上面去查看这一堆测试结果。
	靠提示词生成的结果似乎无法预测，其实是可以的。这个temperature可以用来做控制，就是我们真我我们在这儿看到这个temperature，对这个temperature可以达到的效果就是相同的输入，它给你相同的输出。
	看大家还有什么问题吗？
	为什么agent之间的判断通过路由而不是通过提示词判断？不是同学，这俩是俩维度的事情，并不矛盾你想一想，对，就这个。提示词判断提示词干提示词判断啥呢？提示词生成的结果给到路由本身不就是提示词在，或者说不就是大模型在判断。他们俩组合在一起只是大模型生成的结果加上路由函数，这两者组合在一起只是为了去确定下一个应该到哪个节点去执行，走哪一条工作流。所以router他并没有去完成你说的所谓的判断的工作。它是配合着这个researcher或者chair generator的输出结果，包括这个tor node结果来生成一条实线的边。
	这可能得再回头捋一捋，因为它这里面的概念可能第一次如果去接触图数据结构，然后之前又没有怎么用南茜，会有点不太能理解他为什么要这么做。所以前面才花了很多时间给大家讲明白每一个它的抽象的概念是为什么会被定义出来的那部分的内容大家应该得好好去去反复看一看，应该就能get到它的设计初衷了。行，那咱们今天就到这里。
	这个homework大家记得看一下，是有这两个部分。一个部分是不同的大模型运行一下，最后有一个最终的结果，可以生成一个表格。然后如果很不幸那个GTCO也没跑出来，可以你你再可以试试别的一些模型，包括国内的一些模型。
	然后第二个就是这个chair generator，大家可以替换成一个别的智能企业，然后这个应该会简单一点。然后第三个就是一个可选的，大家可以学有余力的同学，我建议多做一做第三个作业。这其实是能提升你的硬实力的真功夫的。就是提示词应该怎么改。然后那个two的这个返回结果没有做后处理，天然就会造成这个失败的情况。那应该怎么样去做处理？是不是researcher和check generator的后处理可能还可以做的略有不同？那如果是这样的话，不复用那个agent node也是OK的。
	就这些其实是咱们可以去在接下来的，因为我印象当中接下来应该是中秋节那一次是跳过的，好像会有一周的时间，应该是周日不播，要到下周三，也就是有七天的时间。大家可以把next one好好在这个时间多深入搞一搞。好，那么咱们就先到这里，大家有问题我们群里再交流，感谢大家。