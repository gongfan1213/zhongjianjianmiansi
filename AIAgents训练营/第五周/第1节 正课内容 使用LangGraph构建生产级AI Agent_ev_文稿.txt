	现在应该正常了，我重启了一下这个直播的软件也正常。我试一试，大家看看。
	刚刚直播的OBS的软件好像卡了。对我重新推流之后，它还是卡的，就重启了一下这个OBS，现在可以吗？大家看一下现在的页面能切换了吗？可以是吧？好好行好，刚刚这个bug很神奇，那我们从这一页开始。得。没有故障，对吧？我先把我手机这一侧留着。好好好，得从这一页开始。好啊好，这个就nine graph。我们我们来整体系统性的了解一下这个native的框架是什么？为什么它值得我们花时间来学习，它区别于其他的大模型应用的开源框架，有两个重要的特点，一个是有状态，一个是多角色。
	有状态其实是跟无状态相对的。我们在AI的应用开发的这个时代引领，其实也开发过一些大模型的应用，但很多其实都是属于无状态的。这些无状态的应用，它通常来说不需要你自己去维护历史记录，没有记忆的功能。可能是一次问询或者说一个问题。经过了这个agent内部的多轮的react的流程。但是一旦执行完成之后，这问题也就结束了，就像是这个auto GBT，它其实本质上也是一个无状态的，除非你去给它增加memory的功能。但你增加了memory功能之后，alt GPT这样的自主智能体就会暴露。
	第二个问题就是因为他自己的整个流程是一个无法人类参与和介入的。大家如果上过我们AI的这个应用开发的同学，应该看过这个to GPT的源代码。因为我们有一节课的实战，就是去解读auto GBT的源码。在那个解读过程当中，我们了解了它的提示工程是怎么做的。然后他在这个过程当中，充分的利用了这个react的这种agent的这种范式，然后让我们的一个复杂的目标能够拆成多种子任务去执行。
	好处是说人几乎不用参与，坏处也是人无法参与。就我们去真正用过agent或者开发过agents的同学就会发现很多时候在某个中间环节中间步骤的时候，你的大模型可能生成了一个结果是有偏差，甚至完全就是方向就不对的。但这个时候，在普通的南券的框架，就是我们之前上节课讲过的南券的基本的框架里面，人类很难直接去介入，因为我们没有办法给这个agent的实现去增加一些控制逻辑的。控制逻辑就比如说循环分支。而在这个nine grap里面，其实这是它的重点。它通过引入图数据结构，能够实现循环和分支。这个在我们今天的这个实战环节，就下半节课的时候，大家应该能从代码的这个层面有更深的理解。
	第二个好处就是多角色。我们都知道像character AI这样的公司，其实他们是充分利用了大模型的角色扮演的能力。我们在第一个agent里面，其实这个项目实战里面也是践行了这个提示工程里面关于角色任务格式这样的一个RTF经典的最佳实践的一个落地。角色扮演一直是提示工程里面非常重要的一个点。但是如果要去实现一个复杂的agent，其实你会发现这个过程当中，你需要引入不同的角色来帮你共同完成这个任务。就比如说我们在前面的课程里曾经给大家介绍过的多智能体的协作。
	一个researcher，一个chat generator，researcher负责用网络搜索引擎的这个工具去检索我们问题相关的一些信息和数据。然后这个charge generator是负责去调用python的可执行的工具，然后把我们的数据加上我们能够生成的代码，然后用这个chat generator去实现一个python的沙盒环境，去生成一些图表。这个就显然要有两个不同的角色和不同的代理了。这里的技术的点就在于，第一他们要绑定的工具不同。第二他们的这个灵活性，包括他们的安全级别也都不一样。这个chat generator是非常严苛的一个沙盒环境，它能够执行的python代码一定是经过了充分审查的。不然它就会被一些有这个想法的人去注入一些不必要的代码，然后导致一些安全问题。
	所以这里也就涉及到了nine graph的第三个优点，就是可以人类参与和介入整个nine grave。它是一个图的数据结构，每个节点都是在独立的执行和管理自己的这个任务和工作。那么人类的介入是因为整个nine graph实践里面，它实现了一个类似于我们人类写代码的时候，去单步调试的这个断点。去做整个开发过程当中，如果你需要去做调试的话，你通过打这个断点程序可以一直执行到断点这个步骤，然后等待你的进一步操作。
	Agent也是一样，因为它已经实现了循环和分支，所以我们可以人人为的去控制这个agent内部的一些关键的节点。然后甚至在一些节点里面去加上这样的断点，然后这个断点可以用来检查当前AI生成的结果是不是符合预期，如果不符合可以要求它再次生成，或者说我们发现它再次生成无论如何都做不到我们的要求的时候，可以直接替换为我们人类想要给它加入的内容。然后最后一点，就是他跟南茜的集成，它其实跟南茜在整个技术生态上是同一层。只不过南茜面对的是一些原型的开发，能够快速实现一些AI agent的原型。而这个next grap它的复杂性更高，灵活性也更高，同时它的API也更底层更low level，所以他能够去做更加精准的一些控制，整个n grave的设计其实是受到了很多前辈们的启发和影响。
	其中这个predial和apache的beam，其实分别给nine graph带来了很多有益的借鉴。前者是在分布式循环的模型方面是一个先驱，也是google的重要的技术成果，第二第后面这个beam其实主要是在持久化和一些流处理能力方面，给这个network提供了一些有益的启发。然后network x其实是在数据结构的定义，怎么样去引入这个图的数据结构的同时，还能保持有一个灵活的控制接口，这个是network x给我们的net graph带来了一些参考建议。这里我们简单讲一下这三个框架，让大家对这个nine graph的师傅们或者说借鉴的这些前辈们有一个初步的了解，也就能够去理解，因为很多同学可能不太能够，尤其是非计算机专业的同学，不太习惯这个图的数据结构。而图的数据结构是有它的一些应用场景和优势的。
	第一个，我们提到的这个predial，它其实是google在非常早期的时候开发的一个大规模的图处理框架。它的这个框架就是为了就是为了去高效处理各种各样的图。数据结构的应用场景也比较明确，像社交网络的这个关系的分析，大家经常清楚的这个几度网络，包括这个web的搜索算法都使用了这个框架。它的核心特点，其实就是能够用顶点来或者说用这个virtual driver顶点驱动的这样的一个模型来表达我们的这个应用场景。或者说表去去表示我们现在这个应用场景里面要解决的问题，用这样的一个方式来表示我们的这个应用场景和进行计算。计算就是他自己使用的所谓叫super style这个机制来进行快速迭代的去进行计算。并且是支持分布式的，因为它的整个google的web搜索算法要覆盖的这个节点数太多了。
	南券在这一在这个框架上面的借鉴，其实就主要是两点。一点就是这个迭代式的计算模型，在整个人n graph的图的定义过程当中，它支持循环迭代，包括这个for back，毁掉，这个其实是net graph。在我们去处理复杂一件T的时候，去便于我们有一些复杂的业务流程，可以用这个graph去进行对应的实现。
	第二个就是它的并行和这个分布式计算。其实主要是映射到了n graph里面去处理这个marti agent，包括这个多个节点的流程时，能不能去做并行计算。因为有的时候我们学过这个图的数据结构，就会知道这个图的top计算，或者说这个top排序。你会发现从比如说从一个起点开始去计算的时候，它并不是所有的节点的计算。因为它是像水波一样的，一步一步的去做迭代的。但它不是说每一个步骤都只能计算一个节点。在某些步骤里面，比如说我们用类似于这个广度优先搜索的方式，按照层次来进行计算的时候，你会发现某一个层的时候，其实大家是可以并行的。并不是全部都是依赖关系，这些都是number的借鉴到的一些好的地方。
	第二个就是这个beam这个项目，阿帕奇的beam是一个统一的批处理和流处理的框架，它提供了一套简洁一致的API来构建一些复杂的数据处理管道。这个其实就跟我们上节课讲的LCEL已经有一些像了。它的主要应用场景就是在一些像实时数据的分析，日志的处理，这种是流数据的处理上。Nine graph其实主要就借鉴了它的统一的批处理和流处理的模型。
	我们看到整个nine graph的基础，我们提过基础，其实最底层也是用了LCEL，就是我们的年欠的表达式语言。而年欠的表达式语言的核心是它的ronal协议，我们在上节课的时候已经给大家介绍过了，这个表达式语言的核心是这个round able协议，running协议。让我们每一个人欠的基础的对象都实现了这个。或者说都实现了这个协议之后，都能用统一的一套接口invoke stream batch，而这些接口就能实现单次调用，我们的流式调用和批量调用。
	然后我们所有的对象之间都可以通过这个数线这个管道去进行连接。而管道的连接其实在表达一些复杂的逻辑的时候就没有那么好用了。所以我们用图的引入去表达复杂的结构。但是图当中的节点仍然是这些基础的对象。所以图当中的这些数据也就能够用统一的接口去进行调度和使用。在错误恢复和持久化方面也进行了一些借鉴，它的各个状态可以去获取它的history的state，就是它的这个图的执行的历史状态，也可以获取到这个图的当前状态，这个图的下一步应该是做什么。这些都是能在bm上面有学到的一些启发。
	Network的X其实是一个用来创建操作和分析图数据结构的python库。有的同学应该都听过这个network x因为它离我们的这个时间线会更近一点。它其实整个这个库它就是专注在图论算法的实现和图结构的可视化。包括一些知识图谱，非常常见的一些知识图谱的项目，都会用network x作为它的前置依赖。它的典型场景就是经典的计算机图论算法，比如最短路的算法，我们的这个图的遍历，网络物流等等，包括社交网络的建模，我极度的好友关系。整个nine graph在network上面借鉴的其实就是这套接口和图数据结构的定义。
	通过参考network x这个nine graph设计了一些用户友好的图的操作方法，包括怎么样去定义分支条件循环等等。我们待会再去学习n graph的这个API的时候，大家能够更好的去了解。包括它灵活的这个控制结构，精准的对某个步每一个步骤都能够去进行控制。然后还能够对这个，因为他的代理其实本质上就变成了一个的节点。只不过这个节点可以有一个图的依赖关系去进行执行，那它就可以长成不同的节点，因为图里面本身就更自由的一个结构，这个我们待会儿去实战的时候，再让大家更更深入的去理解。
	好，那么除了nine graph以外，还有哪些项目其实也借鉴过这些前辈们像这个阿帕奇的这个giraffe，google的cloud data flow new for j这都是比较有名的项目，他们都也各自借鉴了，刚刚我们提到的这三个前辈，关于这三者，大家如果有兴趣可以去深入学习。这里我列了一些可以深入学习的参考资料，那这样我们就不再展开了。给一些想要更好的去了解n graph的前因后果的同学，给一个参考资料。
	好，接着我们来逐步的就落到这个negative的学习上了。我们知道他参考了很多前辈，也知道他的设计目标的这个是为了复杂的agent。那么在落地的时候这个图到底是什么东西？考虑到有的同学没有学过这个计算机的数据结构的课程，我们有企业的这个PPT去给大家做一个简单的介绍。
	图其实是一种数据结构，跟我们说的图像是两件事儿，就我们经常会提到的这个image和这个graph是完全两个东西。那么图的这个数据结构，其实是非常常用的。在我们生活当中用到的各类APP和web应用里面，其实都有图数据结构。然后图数据结构它本身的基本元素就两个，一个就是点，一个就是边。在这个数据结构里面，这个点有时候会被称为节点或者顶点。它通常是用来表示一些数据的，或者更抽象一点，就是特定的领域或者业务上的对象。这个边其实就是用来连接这个节点的线，表示的是一些特定的关系，或者说一个交互的顺序。
	就像我们上面看到的这个图，有两种，这就是图的三种基本类型，上面这两种是无向图和有向图，这两者之间的关键差异点在于方向。就在无向图里面，两个点的连接是没有主动或者被动或者先后顺序的，没有任何额外的属性，只有一个连接的关系。所以在无向图里面，两个节点之间的关联只有两种，一种是我们有连接，一种是我们没有连接。这就是我们左上角看到的无向图的概念。
	那么有向图的概念，其实相比无向图它多了一种关系。大家可以想象一下，在有向图里面两个节点之间，当然它同样是基础的，前者的表示的颗粒度是有的，就我比如说C和D之间是没有连接的，没有关系的。A和C之间是有连接的，A和B之间也是有连接的。但是这两点这两条边连接的关系是不一样的。假设我们这个箭头是一个执行顺序的话，那么我们可以看到A和B之间是先执行B再执行A那A和C之间是先执行A再执行CB和CA之间没有关系，但是A它跟B的关系和A跟C的关系显然是不一样的。
	因为它有了一个顺序，这个顺序至关的重要。因为在nine graph里面，它的执行顺序其实就像这里的有向边一样。它有一个跳脱于这个普通节点以外的特殊节点，叫做起始点。Start也有这个结束点。搞过图论的同学都知道，有很多经典的图论算法都是去凭空增加一个起始点，然后去方便整个图的计算。因为增加一个起始点之后，可以通过拓扑排序去得到一个很好的执行顺序了。这个是无向图和有向图的关系。
	还有一类图在这个数据结构里面非常常见，叫做带有权重的这个边。就我们想象一下，我们天天都用的这个打车和地图软件去计算你从一个点到另一个点之间的耗时和距离，其实它就是一个典型的加权的图，在它的这个内部去存整张地图的时候，他不需要去把这个地图里面的每一个它带有POI，关键性关键地理位置，或者说兴趣点的地方去变成一个图的形式存下来。这我说的图的形式就是这个像素，或者说图像的存下来。
	它更多的是以图的这种数据结构，graf的结构来存的那在存的时候，假设在地图上面有两个点，它真正在存的这个其实是像我们下面这个加权图一样的，是带有这个距离信息的。比如说从你的家里面到这个地铁站，然后地铁站到出就从上次从家附近的上地铁的地铁站到最后到单位的出的这个站的这个地铁站，再从那个站点到单位。它可能涉及到了四个关键点，这四个关键点之间的距离肯定是不同的。但是因为有了这个图这种数据结构，复杂的这一段描述，其实就只需要存下四个关键点，再加上三条有权重的边就够了。它就能够还原出来那个地图上的拓扑关系。但是它最终的位置关系可以再有一个别的数据结构去存，就它应该标在哪个像素上或者矢量的这个位置上，所以带有权重的边也是一种很有效的表达能力的体现。
	它可以用来在像我们刚刚提到的，在交通领域里面去做这个距离，然后路线的一些计算。当然也可以把它变成一个成本。比如说在这个运筹学里面进行这个任务的排期等等，这都是加权图的一些典型的应用场景。
	在nine graph里面其实主要用到了有向图，然后它甚至实现了我们有向图当中的这个环。在有向图里面其实有背景的有这个计算机背景的同学应该就知道，这个有向图里面也要分有向无环图和有向的有环的这个图。那么无环图它的拓扑结构更加的简单。但是现在的nine grave最新的一些更新，也已经能够实现像这个D节点一样的这个字环。
	这个字环的应用场景非常的明确，就是我们开始已经提过的一个大模型。生成的结果如果不满意怎么办？我们又不想说前面生成的都放弃了，我们也不希望拿着这个不满意的结果继续往后生成。这个时候你可以去做一个检查的设定，它如果生成的结果有问题，比如说报了error，或者说有一些关键字包含了或者不满足，可以让它再生成一次。那再生成一次，其实就是继续执行这个D节点。这个低节点你可以设置一个循环次数的上限，或者设置一个整个图的执行的一个总次数，这个都是nine grap里面可以去操作的，整个图的数据结构我们刚刚通过这个分析大家应该也都知道了，有各种各样的应用场景，像导航的这个系统，知识图谱就更不用说了。然后我们的项目管理，各种运筹学里面的排期排任务等等。
	图数据结构的优点其实是非常明确的。虽然它很抽象，但是他的这个能力是跟普通的数据结构比起来是不在一个量级的。我们的关系型数据库也好，或者说我们手动人工去定义的一些自定义的数据结构也好，通常来说都不如这个图的表达能力强。在表达一些物体之间复杂关系，或者说这个agent内部多个代理，或者多个角色之间的执行顺序和关系的时候，图是更强的。然后它的这个动态性和灵活性也非常好啊，就比如说我们在之前讲过这个rotor chain去实现条件判断，sequences线去实现这个顺序执行。在图里面其实这都是非常自然的可以去实现的。你想象一下这条件判断其实就是一对多的关系，然后你通过一些特定的条件让他去执行不同的下一个节点，选下一个节点是谁。这些在这个np里面都有对应的一些抽象可以去做，所以图数据结构是非常适合n graf，这里我们再总结一下就是复杂性，这个图结构天然适合复杂性的管理。
	第二个就是我们要去做复杂的agent，就难免有循环和条件的逻辑。而图的这个结构是支持循环和条件的逻辑的，就像我们刚刚看到的有向图，很方便的能够去做这样的表达。第三就是可以动态的扩展。比如说我们已经有一个AI agent的逻辑，是以图的结构表达。好了，现在我希望在这个AI agent上面再额外增加一个功能，那可能就是在那个图里面找到对应的你要增加的这个功能的节点。有可能他是说要把最终的结果再进行一次格式化，那也就在最后输出的时候再额外增加一个。也有可能是像我们以前做过的一个router chain的例子，前面有一个这个人去做问题的判断，后面跟了一堆的老师，物理老师、数学的老师、计算机的老师。
	现在我要再增加一个分支。那再增加一个分支，在root线里面需要反复的去研究它的提示工程应该怎么样去写，才能让大模型去判断我们的这个问题应该交给谁。但现在其实有了graph之后，你可以把大模型判断这个事儿改成由graph来进行的判断。相当于以前你是只能祈祷，大模型这个问题一定得判断。对这个祈祷方式一方面是你要不断的去迭代你的提示词，一方面就是你的提示词写好之后，你也不知道这个大模型最终他会不会把这个问题正确的路由到对应的这个destination change上面。
	但有了nine graph之后，这个事儿是可以控制的。因为它支持这个条件编，叫这个conditional age。我们待会讲一讲它怎么去做这个条件的。所以综上这个图数据结构其实是非常适合nine graph要解决的这个问题和面对的场景。好，那么有了这样的一个前置知识和对n graph一个形而上的了解之后，我们接下来看一下这个怎么样能够去落地去用它。
	N graph我们要去了解它的这个使用，其实最关键的就是这里写到的几个基础对象，也是它的核心对象。首先nine graph的核心在graph，graph的组成又分为了这个节点和边，就是我们刚刚提到点和边。但是这个点和边是一个一个基础元素，是离散的，点和边整体构成了一个图，然后这个图运行起来之后又有状态。那要把它运行起来，它要从一个静态的图变成一个不可编辑的运行时的一个状态，这个过程叫编译，这就是n graph对象里面的四个很重要的基础对象。
	接着来看一看他怎么怎么去运作的。在nine graph里面，它的工作流，这个工作流就是我们想指的执行的这个流程，叫这个workflow，就我们整个agent要执行是按照一个流程来做的，在这个LCEL里面，我们可以通过管道来定义。但是管道它是一个线性的，我们希望它能够去支持一些非线性的或者说复杂的条件和循环的这样的一些流程的时候用图来表达这个工作流。
	这个工作流由三个核心组件构成，一个叫状态state，这个状态就是指整个图里面共享的数据结构，它可以是任意的python类型，但通常是这个type dick和这个pandects base model的子类，它的这个派生类就基于他们作为这个鸡肋去做的这个派生。那这个就是指这里面共享的这个数据结构，就屠当前的这个状态，我执行到某一个时刻的状态，因为它是支持我们打断点的，然后可以逐步去执行的。所以你可以想象这个图最终在执行的时候，它是有一个当前状态的，你也可以知道它的下一步要做什么。那是这是这个图运行起来的时候，我们知道它有一个状态，那运行的是什么，运行的其实是一个一个的节点。这就意味着我们看这里是我们待会儿要做的第一个实战。
	在这个实战里面，有最左边这幅图是有三个节点构成，分别是start，chatbot和这个end。这些节点通常来说其实就是一个python的函数。因为nine grave它是一个开源的python的库。这些节点里面的python函数，它其实就是把当前的状态作为输入。
	像不像我们学的LCEL里面的那个逻辑了？就我们LCL里面有input schema，output schema和我当前运行可以用的具体的接口，四件套，invoke这个three batch或者说第四种就是异步的这这这个形式。那么node也是一样的，它把这个当前的状态作为输入执行这个节点里面定义的python函数，这个函数可以是python的代码，也可以是大模型的调用，也可以是调用的年轻的community都可以，只要能够符合这个round able的这个协议就可以。那么age就是我们这个边那边其实就是去决定现在有个状态了。这个状态要执行当前这个节点上的这个函数了。
	那么执行完之后，下一步我们干什么？这个就是由边来进行决定的，编的使命就是去决定整个从start开始到N的结束，这个工作流的一个执行顺序，也是一个你可以认为是一个编排的工具。简单来说就是节点是用来干活的，边是我们来决定接下来要做什么的。那么既然有接下来就有现在现在就有状态来进行表示。只要去组合这个节点和边，n grave其实就可以创建一个复杂的工作流了。
	我们看到下面这三幅图其实就很典型。最左边的这个就是只有一个大模型加上提示工程构成的一个聊天机器人，或者说智能客服。用户提问从start开始，chatbot回复回复到这个用户不想跟他聊天了，就退出。
	中间这幅图就是指这个牵挂的其实是可以调用一些外部工具的。然后这个外部工具的调用，其实我们能看到它是一个环。这就说明同样的用户开始提问，提问之后可能有些问题这个chatbot回答不了。那这个时候我们可以选择有一个比如说搜索引擎的two，那这个check pod就会去调搜索引擎，搜索引擎有一个结果给到chatbot，那么chatbot就拿到这个结果整合之后继续回给这个用户。他这个回给用户的动作是chabot本身这个函数里面定义的一个这种对话的这样的一个能力。最终可能同样的用户可以聊到我不想聊了，就结束这个check box的使用。
	除了这些以外，第三种其实就是在我们开始提过这个人工的介入，就假设我们还是以这个搜索引擎为例，我们去查了一些网上的资料，然后查了一下网上资料，可能我们希望在查之前，因为调搜索引擎是有成本的。咱们开发过的同学应该都知道，调搜索引擎是要消耗cota的，有成本的。我们每次去调他的时候，这个之前的agent开发没有用的，grap之前都是大模型自行决定，我要用什么样的关键词去调这个搜索引擎，调几次，去整合这个结果。典型的像我们在开发科里面学过的那几个agent。问大运会是成都大运会是第几届，他就去查，先查大运会是什么，在查这个成都大运会是什么，在查这个成都大运会是哪一年办的，再查是第几届等等。他用了好几次的迭代，而且这个过程当中你很难介入，不同的模型它查的这个关键词和顺序不太一样，由他使用的提示工程来决定的那现在我们可以说，不管你是用的什么大模型，也不管你要查几次，你每次去调这个工具的时候，我都可以中断一下，然后我来检查一下你的查询结果是怎么回事，这一次查询有没有必要查，甚至说可以在这儿进一步介入，变成缓存。就你查了一个热点问题，这问题已经有最佳实践的FAQ了，那你就别查了，我直接把这个向量数据库里知识库里的答案丢给你。
	你就可以不用真正去调那个搜索引擎的工具，而是在这儿直接把FAQ里面的这个答案给到check root。这个就是用这个中断的节点的好处。你想象一下这样的一个能力，如果在agent execute里面，其实是很难介入的，就是人工很难介入的。好，这个是对于图的一个基本了解，三个核心的组件分别是有不同的作用。那我们再来看一下节点，节点具体怎么用，节点其实是真正干活的那个worker，这个节点通常就是一个python的函数，它负责执行实际的一些逻辑或者计算它接收状态，然后作为它的第一个参数。
	就像这儿，我们看到这个首先我们这个地方从南迁core里面调用了这个round table，从nine grap里面调用了这个graph，state graph。待会儿我们会讲什么state graph，大家先简单理解，这个state graph就是我们的图，我们有一个图的数据结构。那接下来，所有的点和边都是往state graph里面加，通过I的方法去往里加。
	好，那么要去定义我们的这个节点的时候，它有一些关键的参数是需要去做这个配置的。我们这里简单提一下，第一个参数就是这个状态本身它的输入。第二个就是它的confide，就对应我们这儿的my node和my other node，这个state是必须要传入的。就上一个状态的这个执行结果，作为我现在这个节点的输入参数，或者说我的要计算和做逻辑操作的这个配置。
	然后这个config是非常自由非常多的。这个config里面可以做各种各样的配置，包括我们跟这个用户相关的，跟记忆相关的，跟这个迭代深度相关的各种各样的配置。我们在待会儿代码的时候可以去详细看啊，你可以简单理解成这个节点我要去执行它的时候，我可以去约束它。现在是要总的执行次数是多少。然后我记我把执行完之后，因为有记忆的能力，我其实可以把执行的结果也存下来。但存的时候，我们知道一个复杂的一点，它不太可能说我只面向一个用户或者说一个问题一次使用。这里就有一个类似于我们前面讲过的这个线程的概念，它叫thread ID这样的一个参数，也可以通过thread ID去区分不同的用户或者不同的问题，它就是一个用来隔离我们的这个执行结果。
	我说这个agent或者说这个图的历史执行状态的一个区分，就不同的策略之间数据是不共享的，那么可以通过CDID来查看不同的用户和不同场景下的历史记录，然后整个这个节点的定义就是通过add node方法，就记住这个方法就好，非常简单。Ad node方法就把你的当前这个函数，这样我们下面看到有一个builder，builder是一个state graph的对象，有一个图的实例化的对象，去调用增加节点的方法，add node方法。那这个add node这就有俩参数，这个ad node的第一个参数，就是我在图里面加了一个节点，这个节点得有个名字。那么第一个参数就是这个节点的名字。第二个参数就是这个节点具体要执行的这段函数逻辑。那就是这个my node，把这个my node的函数放进去other node，my other node一样的，通过other node就可以增加节点，非常的简单，就这一个方法。
	然后边边要怎么加呢？边相对来说要复杂一点。因为我们刚刚看过了无向图有向图加群的这个图。你们大家如果细心一点就会发现，这三种不同的图的类型，节点其实是没有什么事情的，变化都出现在边上面。所以可以想象到这个BN在这个graph的图里面也是有不同的设定的。
	首先我们知道边的重作用了是决定图的执行顺序，也就是这个工作流到底要怎么执行的，甚至它也决定了不同节点之间的通信方式。这个通信方式怎么理解的？就像我们再再反复提到的，就是通讯方式分很多种，最常见的就是invoke和stream和batch。再强化一下就单次的执行，给这个节点到下一个节点可能就是e moke给一个数据，有可能是batch给一批的数据，还有可能是一个stream流失的别数据。这完全取决于我们自己这个节点跟节点之间的到底数据交互是如何去定义的。这个是从我们看到的这个通信方式的一个角度去区分边。
	工作流的执行也可以有不同的边来做设定。当然跟这个添加节点匹配或者说类似的最普通的这个边，也是通过这个方法去添加的那这个方法的添加加的是一个有效的边，是大家看到这个普通的边，我们叫普通的边。At h node a node b就两个参数，它这个A和B就是我们先要加节点。所以大家可以想一想是先加了节点，再给这些节点之间连上这个边。那连这个边的过程当中，这个add age的第一个参数和第二参数之间的关系就是从A连到B，第一个节点连到第二个节点。所以先执行第一个A节点，再执行第二个B节点，然后这是最最常见的，就是我们的普通边。
	还有一些叫做条件的边，它可以动态的去决定我现在到底要连接下面的哪一个节点。你可以想象一下，就是有一张图里面有三个节点，ABCA后面同时连接了B和C那么什么时候我要让A执行完去执行B呢？取决于一个当前在A这个步骤。因为A是一个节点，它执行完之后有一个状态这个结果，可以去对这个结果进行判断。这个时候通常会引入一个叫做路由的函数routing function。这个路由的函数就横在了A和后面的BC节点之间。你可以想象一下，就是中间有一个闸，它就是这个路由的函数，它从A节点的执行结果这儿拿到了这个输入，它是一个中间的一个状态，它也是把状态作为它的函数的输入。
	返回的是什么呢？返回的其实就是B或者C节点，他他来判断我现在的这个A节点的结果应该交给B或者C，那这是一个特定的条件边的节点。第三个就是入口的节点，或者叫起始点，就是整个工作流。这graph的起始点是什么？大家可以想象起始点肯定是一个很特别的点。它在在图论里面，在图的数据结构里面，它通常就是一个虚拟的那这个grap里面那grap里面也是一样的。大家可以看到虚拟的这个star节点是从graph的这个graph模块里导入了一个叫做START的保留字。这个STRT其实就是这个起始点，它没有什么额外的操作。
	这个起始节点的唯一功能就是确定整个图是从哪开始的，它指向的node a那么node a的这个实际的计算或者逻辑的执行结果就作为这个start连接它之后，整个图当中的第一步实际操作。然后这个其实是我们看到的比较常见的几种边了。然后这个多条边就是我们看到的它一个A节点可以同时指向这个节点B和节点C，这个通常是由这个条件判断conditional ages来进行实现的。然后不仅我们的实际节点可以就node a这样的实际操作的节点，我们手通过add node的方式加进去的，这种节点可以通过这个conditional h去一对多去分叉成多条边，那么这个start节点也是一样的。所以你可以想象一下这个start节点如果可以执行这个多条边的逻辑，其实我们第二个agent项目language mental不就可以做了吗？
	我们language mental非常常见的这个产品功能在还没做，可以给大家预览一下，想象一下就是我们设定了不同的对话场景。有餐厅里面的对话，有在机场的对话，然后有在这个酒店。假设随便举例，咱们要出国旅游要学英语，那这些不同的场景，其实理论上都可以是不同的。
	Sub graph子图，然后他们都有一个虚拟的start节点来进行控制。然后这个start节点根据我们用户的设置或者选项，他选了我现在要练习的是这个餐厅点餐，那他可能就从star节点路由到了这个node restaurant，他如果是要去做比如说要去这个酒店订房间，要check in，那等于node这个hotel等等。这就是非常常见的agent的逻辑控制，条件判断。
	好，那么基础的这个图我们了解了，有我们的这个节点，还有我们的边，甚至边还比较复杂。然后状态就是指这个图当前执行的一个阶段，然后这个状态也会作为每一个节点的输入。那么整个这个图要怎么定义呢？我们刚刚都只是停留在了图当中的一部分，就是定义了两个节点，或者说两个节点之间以什么样的关系去连接，或者说增加了一个起始点。
	那这个图怎么实际去执行呢？刚刚我们在代码当中有一个builder，它是state graph的实例。State graph其实是nine graph当中的一个非常核心的概念，其实就是那个图本身。然后states graph实现了ad node方法，add age方法，add conditional ages方法。所以刚刚我们看到那些add方法其实都是state graph去实现的。这些节点和边都是通过它的实例加到这个state graph里面来的。然后state graph它的状态管理就是通过这个状态state，也就是我们所有的的第一个入参。大家还有印象的话，通过node，通过这个状态来管理整个流程当中的数据以及这个上下文。
	然后你会发现既然他都能够去传递这个数据了，所以理论上这个nine graph也实现了历史记录，就是我们每个节点1路执行过来，这些历史上的state，理论上每个节点的state是不一样的，除非你啥也不干，你的节点的函数就是拿到什么打印什么，交给下一位，只要你对它进行一个处理，理论上state都会变化。那这个变化叫做state history，也是可以从这个n graph的这个graph的结构里去取出来的。同样的你也可以去更新状态，这个更新状态取决于你现在这个节点到底是需要什么样的一个数据，你要保证你的给进去的这个数据是它这个节点要的，就跟我们在用LCL的时候，确保这个schema大家是长得一样的。
	然后它的使用步骤很简单。我们其实已经讲了前三步了，首先需要定义一个状态，这个状态其实就是指我们传递的这个数据应该长什么样，也就是说我们开始在state这一页其实提过的，它通常是一个任意的python类型都可以。但它通常是一个type的diction dictionary，或者说这个pandey的face model，因为他要做类型检查，以免出现我这个节点要的结构和你给我的结构不一致的情况出现了。所以它通过pandects在进行state的结构的检查，这个是state，我们要定义一个，第二个就是我们要去定义它的点和边点和边。点就at node边add age或者add conditional age。最后第四步就是编译。你可以理解成一旦我们执行了第四步，这个图就锁定了冻结了。
	这跟tensor r floor 1.0的设计理念也很像，我不知道有多少同学学过这个TF1.0。这个视频课应该也都还在这个时间，好像是会免费开放给咱们这个学员的，应该是有一个月的免费访问。好像在特色flow的这个1.0版本里面，其实也是同样用到了这样的一个graph的设计理念。它叫做数据流图，data flow grab。然后它的整个数据流图里面的很多基础设计跟net graph或者说nine graph，其实跟他是很像的那这个图的编译也是在这个特色bo里面非常重要的一个设定。当然他们的这个效率和这个背后的原理会有一些不同，但无论如何，通过编译的这个图，在nine graph里面，它就变成了一个compiled graph，就是经过编译的图。这个经过编译的图就是可以执行的，你就不能在这个compile graph里面再去加节点和编号，你只能在state graph里面去加。
	你可以想象一下，就是有一个不知道有没有现实生活中比较像的，就是有一个画板一样的东西，你可以一直在上面画。然后小时候我们都画过那种磁吸的画板，你可以一直画。然后我印象当中应该他是有一个开关。一旦你按下去之后，你再拿那个笔画，它那个磁吸是不会再给你有任何的刷新了，你那你那个画板就不能动了。
	这里的compare方法也是类似的，然后这个compile graph在这个nine graph内部，它其实就是一个由stage graph编译执行的一个可编译之后的一个可执行的对象。然后这个compact graph它的实际运行就跟我们的LCEL最底层的这些抽象很像了，比如说我们的流式方法和我们的这个单次调用stream和invoke都是可以在graph上面去调用的。然后这里你就会发现一个很有意思的点就我们前面的这些概念就逐步的被捋顺了。
	我们定义了一个图它被编译好了。它被编译好了之后，我们要开始执行它从哪开始执行呢？从start这个节点开始执行。Star这个节点它执行的时候，我们就提到了，我们希望它不是一个黑盒子，它能一步一步的执行。那怎么执行它呢？通过stream或者in work方法来执行它。
	所以你就可以用一个compare graph的实例，一个对象，然后去不断的调它的stream方法或者invoke方法。它会依次的去执行这个图当中的节点，依次就依的是我们加的这个边的顺序，一点一点的去执行，迭代的去执行，从start开始一步一步的迭代，一次迭代就是一个边指向这个边，从star节点指向了下一个节点，下一个节点再调一次，它就又指向它的下一个节点。通过这个方式，可以按顺序去执行每一个节点。那你要全部执行完，你for loop一下就好了，也都可以一次性执行完。在for loop的过程当中有一些输出，你要去做这个格式化的输出，或者要去做其他的一些业务逻辑也都可以。
	然后同时整个这个compare graph还支持这个chicken point check point或者叫check pointing。大家内部是这个参数，那么这个check point就会跟他的记忆的这个能力能够关联起来，这个我们就今天就不再无限的展开了，就这个时间旅行的这些功能，它取了一个很fancy的名字。那这些功能其实本质上来说，因为有了图，所以你倒着去找它的state就能实现对应的功能了，并不复杂。
	然后这个动态路由比较关键，我们今天会重点来用这个compiler graph，同样它是支持动态路由的。这个我们在讲编的时候就提到了这个动态的路由，就是我们所谓的执行了。比如说我们还是以刚刚这个代码示例为例，有一个节点A，它加了一个条件边，这个条件边接了一个路由的函数，这个路由的函数后面接的是B和C两个节点，那A的执行结果会给到路由的函数，路由的函数根据这个结果和它内部定义的逻辑来判断接下来我要去B还是C这个只有在我们的compare graph里面才能知道。静态的这个state graph是不可能运行这个节点A的。所以所有的动态路由这个条件编都是在compare graph里面才能够真正去执行到的。在staff up里面只是定义了它的逻辑这个应该大家能能捋明白，所以这两者的关系其实就非常明确和简洁了，这个state grab就定义了整个图的这这个结构，并且还定义了这个图里面流动的这个数据的类型，通过state来进行定义的。然后compare agree PH就是这个图编译之后的版本，然后它锁定了冻结了，然后冻结之后你可以不断的给它丢数据，就是我们这个图的起始节点需要的数据。
	如果是聊天机器人可能就是用户的一句话，如果是一个什么circle agent可能就是用户的一个问题等等，通过这样的一个方式去执行这个图，然后这个图是按照我们定义好的这个关系去一步一步执行的，这个就是两个最重要的graph之间的关系。要去执行它，我们再来讲一下执行它的这个过程当中用到的方法。Stream就是我们之前在讲LCEL的时候也用过的流式处理的一个方法。刚刚我们看到了compared graph，假设我们有一个compare graph的实例，就叫grave，相当于grave，那就等于我们的这个state graph compile之后的这个结果。那他调这个stream方法就可以去一个一个的去进行执行。这个也是我们会经常用到的一个方法，作为一个示例放在这里。就比如说我们看到去完成刚刚提到的这几个关键的概念抽象，在单位里面就按照这样的一个顺序就可以实现了。
	一个典型的聊天机器人，我们可以给它加上起点和终点。起点和终点我们在下面这一行，graf builder添加了两条边。Start连上这个chat work然后chat board这个node连上了N的结束的节点。
	这个chat board是在上面我们看到的加入了一个节点叫chatbot。然后它是一个chat board的函数。这个chat board函数其实就是我们的chat model。Chat model就是一个GPT4o mini，然后是opening，它是一个chat OpenAI。Chat OpenAI又是一个实现的runners协议的对象，所以它能够调用invoke方法。然后他们整体又是我们当中的一个节点，这个节点的输入就是我们当前的state，一步一步的这个逻辑。
	确实如果你不习惯这种抽象的东西，你会感觉非常的混乱。但是如果你捋顺之后，你会发现它的逻辑还是挺健全的，并且是值得推敲。而且如果你要做一些复杂的应用的时候，你没有这样的逻辑去支撑，你也很难做好。所以我们再细看一下这个图和左边的代码，就非常明白是怎么一回事儿。
	或者我们从底层再往外看的话，就是我们有一个chat model，他在能欠生态里面就只是一个基础的大模型的对象。这个大模型的对象的in work方法就是丢给他一句，我要交给大模型的prompt。但是我们把这个chat model的对象变成了一个next graph里的节点。而这个节点它需要的输入或者说它接收到的输入就是上一个节点的输出，也就是grap里面的这个state状态。所以这里的check word和和这儿的check model就发生了一个本质的区别。
	从一个大模型变成了一个graph的节点，然后这个节点被我们添加到了图里面，然后我们又给这个节点的前后增加了start和end的两个虚拟节点。最终我们通过这个compare方法，它编译成了一个可执行的graph。这个graph就能够去用stream或者用work的方法去执行了，那当他每次调stream的时候，其实就会去执行这里的这个chatbot，因为它从start开始就执行到这个chatbot。
	好，那我们再总结一下，在nine graph当中去使用我们的图数据结构，我们的节点其实就是具体的一个执行的函数。然后它是输入是我们的状态，边是节点之间的关系。主要是在group里面定义了一个节点到另一个节点之间的执行顺序，以及一些动态的条件判断的或者说动态的路由，去根据你的当前的状态的不同，去设置不同的分支的直流。然后它也支持分布和这个并行，同时因为有了我们抽象的这个状态state，所以消息的传递也就变得非常的简洁了。因为大家都可以通过这个状态构建一个统一的数据的表达，或者说数据的结构。然后接口上，我们又都是实现了runway的这一套stream和invoke的接口。那么这个管道建好了，里面留的这个数据也定义好了，那么自然这个图就能够很顺利的去进行依次或者说分布，或者说并行的执行。
	好，刚刚我们了解了一个最基础的图的概念，以及它的关键的方法和关键的对象。接下来有两个很重要的功能，也是我们在开发agent的时候需要用到的，比如说给这个对话提供记忆的能力，让他记住之前聊过什么。或者说我们刚刚说的断点，让人工能够介入一些特定的图当中的节点。这些进阶的使用在number up里面就变得很简单了。跟刚刚我们了解的基础概念不同，基础概念讲讲的细一点，是为了让大家把基础给打扎实。这些基础打扎实之后，你会发现能够二环是提供了蛮多好用的这个开箱即用的功能的。
	就比如说这个记忆的功能，我们刚刚提过state graf里面有一个检查点机制。这个检查点机制就是用来保存或者说恢复对话的，或者说它不是一个聊天记录机器人，就是一个执行任务的agent。它这个任务执行到某一个节点的状态，也可以通过这个chep point来保存下来。Check point的背后是memory的saver这样的一个抽象，这个抽象其实就是让我们的整个图当中运行的这个agent，或者说这个机器人具有记忆的能力。就能够去支持多轮对话了，就比如说你你一开始跟他说了一个问题，或者你跟他说了一个名字，说了一件事儿，然后他会用这个memory server记下来。然后当你再去提问的时候，如果你开了这个检查点的功能，他能够记住，他会自己去进行检索。
	如果你没开，那每一次对话都是一次全新的对话，他不会去检索历史的这个信息。然后其他的一些功能，我们到用到的时候再说。先在这里给大家展开他有的这个能力，那一个典型的场景就是我们要用它，比如说在下半节要讲的机器人，而且去用它怎么用这个memory server，从nine graph的chek point模块里可以导入这个memory server的抽象。它使用场景有很多。
	在这儿我们是对话系统，那我们现在也应该看这段，这行代码就比较熟了，就是我们的graph builder的come方法。刚刚我们的compile方法编辑图的这个方法，是没有任何参数传进去的。现在我们传了一个memory server的对象进去，你可以很很跳出来抽象的理解它，就是有个记忆胶囊，这记忆胶囊就是memory，就这个memory server的实例，它叫memory。The memory只要给到我们这个图编译的时候，给到这个check pointer，他就拿到这个G胶囊了，那么所有的历史的状态，他都会帮你记下来，并且记的时候还可以分门别类的去记。就比如说我们提到的这个confide这个配置，配置里面这个线程IDC的ID是一，那么我们可以就相当于你可以想象一下这机器人儿它有不同的聊天对象，它是一个服务很多用户的机器人。你可以不同的用户用不同的CID，或者说同样的用不同的问题也用不同的thread ID，这个salad ID可以隔离对话。因为对话过程当中，如果我们的人不一样或者话题不一样，那你把它记下来，其实是纯纯的在浪费token。因为你的token你历史记录，你为了用它，你都会全部发送给大模型的那你如果不做区分的存，那这个就会爆炸，那所有的ID可以用来干这事儿。
	好，我们这个编译好之后，我们要执行它的时候，要用stream这个方法。然后执行它的时候我们希望把这个结果要存下来，对吧？那么现在我们有了memory之后，它就存下来了。但我们还希望它能够分门别类的存下来。这个时候你把config传进去，它就会存到线程一。那如果你把这个stream下一次的执行，然后把这个config里面的线程号改成了别的这个线程，然后你再传进去。
	比如说下面这是调用，假设我的conflict，下面这一行调用的时候，我把它改成了thread ID等于2。这前后两段，其实就在你可以列成不同的聊天对话框，或者说不同的聊天室。虽然他们都在这个图上面，但是因为有了thread ID，所以他们的记忆或者说他们的状态保存就被隔离开了。类似的conflict。还有一些其他的可以配置的执行时候的一些参数，我们到用到的时候再给大家去做介绍。有的同学感兴趣也可以去查一下他的API文档。
	然后接着我们还希望能够中断，能让我们的这个执行能够由人去介入，那怎么介入呢？也很简单，其实就是在compare里面还有一个参数，这个参数叫interrupt before，就是我们就是我们在执行某一个节点的时候，我们可以中断。那么有了interpret before之后，当然它后面接的是一个列表，就相当于你整个这个图里面充满了节点。然后这些节点哪些节点在执行之前要中断，都可以放在这儿。然后我们在编译它的时候，把这个参数传进去就好了，聪明的人就知道了。那有了interrupt before，有没有interrupt after很好，有这个参数我们就不再赘述了。这些东西都可以通过去阅读API文档了解到，就不给大家每一个API都去做便利了。
	无论如何，这个思想很重要，就是通过图的方式去描述和定义我们整个agent的业务流程或者说工作流。这个工作流里面有执行的top顺序，也有一些动态的决策，就是我们的条件边，同时我们还可以去引入外部的工具，甚至我们可以在每个节点的执行前和执行后增加中断，让人能够有机会去审查或者直接替换它的结果。就比如一个最常见的例子，假设这个before就我刚刚提到的chat port，要去检索这个搜索引擎，检查它的Perry这个关键词好不好。或者说这个interrupt after，它执行了一次生成的结果这个生成的结果，这个问题有可能我们已经很熟了，但我们还是希望它生成一下。然后生成之后我们在after这个阶段去中断之后，检查一下生成结果好不好。不好的话就替换成我们预备好的这个内容。如果好的话，也可以把这个结果再存下来，变成一个数据的积累，这都是一些跟你真正懂业务，或者在业务上面做过之后，你能想象到这些功能是非常有用的。
	然后最后我们再花一点时间讲一讲它的landgraf的工具，怎么去调工具，这个工具我们会用到这个搜索引擎，search API在开发一的时候给大家讲过一个server API。这个serve API就是标准的去调搜索引擎的，就其他的一些非大模型的应用，如果要实现搜索引擎的调用，通常也是用的塞尔和API。然后server API是每个月有100次的免费调用额度，我相信很多同学如果用了nine graph之后，你会发现100次调用是太少了，因为复杂的agent，它这个工具的交互次数就很多。像我现在一天可能就要用这个大几百次，那这个就又得付费怎么办？我就看了一下这个nme graph，它自己的这个官方的教程里面，其实是有一个搜索引擎的工具的，并且也在它的community包里面实现了。这公司叫timely，它每个月支持1000次的免费调用，比这个service API多了十倍。右下角是它的这个官网，大家有兴趣可以去注册一下。
	然后这个就是它的一个使用的一个界面，控制面板带sport。然后他的key是你可以实时随时把这个眼睛一点，它就能看到了，比上PAPI更小白化，新手化，当然它也有收费计划，这个是我刚注册的时候的一个界面，最近我这24小时就掉了快300次，就已经很快就要用掉了。整个agent的使用，大家会发现其实会挺消耗token的。
	如果我们要做一些比较难的应用的时候，不得不用GPT4o，GPT4o mini可能都不太行。那么这个时候其实要去不断的去优化一下你的提示词，不能死心眼儿的去去反复执行，就觉得它能变好。还是得想办法去调整你的这个提示词。甚至能够通过修改这个graph的这个stream，去只执行某一些特定步骤，不用每一次都全量执行这样的一个逻辑，这个是我们nine graph的工具。
	这里再额外提一点，就是说我们的调试，就net graph的agent，b南茜的agent天然就会复杂很多，如果你发现这个agent用能欠都能写，那你也没必要引入到graph里面来。用rap的时候通常都是一些相对复杂的逻辑了，那这个时候怎么调试？当然我们可以通过在这个patter里面打印一些历史的日志，我也会教大家怎么打印，然后去看到一些结果。但是它不够直观，并且信息量也不够多。
	A nice miss就是一个很重要的平台。我们在LCEL里面讲过，在network里面我们几乎每个agent都会用到，那再给没有用过的同学再强调一下怎么用，这个在我们这下半节课的两个时代里面也都有啊。最关键的其实就是安装，然后配环境变量。环境变量最重要的就这两个。一个是这个南茜的tracing v2，这个是用来确定或者说用来配置next miss上面，或者说要给这个next miss的平台发送哪些信息。每一个trans它是每个月有1000次的trance，好像是一千次的，没记错的话应该是啊1000次还是2000次的这个trance是免费的。
	然后这个nations project就是我们当前运行的这个agent，它是按project分项目来进行管理的。就比如说circle agent，这个march agent collaboration，这个图toria等等。它是不同的这个项目，是不同的调用站，所以这个项目一定要不一样的名字，跟你自己的这个匿名习惯有关系了这个run就是我们的每一次的这个trance，就我们的或者我们跟踪的这个记录，就你每次运行一遍，它就会有一个计数。那这个run多少次，其实就是它的收费的这个基础单元。然后当然你这个调用花了多少的大模型的服务的费用，这里也会写。就比如说这个多智能体就花了0.548美金，然后这个4KA可能0.16美金，里面会具体去写。这个就用了31万的token，上面可能是35000，价格不一样。
	有可能是因为里面有多个agent，有的agent用的是GPTO有的agent是用的GPT4o mini。那么怎么去看这个next miss？这个复杂的agents就比较直观了，像这里是一个circle agent，但这个demo我没有传到我们的。这个课程项目里是因为他现在还没法很好的稳定的复现这个官方教程里的结果。我也去跟这个社区去反映了，如果回复了正确的解决方法之后，然后也能稳定的复现了，我会把这部分的代码再传到我们的课程项里，也就是OpenAI的这个free star里面。
	然后这个number one我们看到它的circle agent其实是分成了很多个节点的。从最开始的这个first two call到它其实就是一个用我们的自然语言去生成query circle的这个query在执行它再拿到结果的一个agent。一开始他会去调这个first two，然后去list。Table就是去把我们连接的数据库里面有多少张表都list出来，就能获取到整个表的schema。用我们的这个表的结构，数据库表的结构，所有的表的结构。然后完了之后，再去通过这个get schema tour去真正的执行，拿到这个特定的schema。最后在这个第五个节点这儿才开始生成circle query。
	然后生成的这个circle query，我们会分成两条路线。一条路线是它生成的没有错误，那它就会走这个query的检查逻辑，就是它生成了一条query，这个query对不对？走下面这条逻辑就correct query去检查，检查它是没问题的，我们就execute这个query，然后就可以拿到对应的这个结果，结果就结束。当然也有可能这个excute Carry之后，它也不对，那它可以重新生成，然后再来一遍，这个是大环大的这一圈。
	但还有一种情况，就是它生成了这个query，然后这个query生成的过程当中出错了。这个时候他可能就走这个小圈，他都不用去检查query对不对，因为就没生成正确，就再生成一遍走这个小圈，小圈走完之后走大圈，然后最后走到end。这样一个复杂的逻辑，我们如果单靠日志的打印输出是很难看到的。那么左边就可以跟他对起来，大家看到左边这个first to call，list这个table two，然后model get stema，get sima tool query generator query jan. 
	现在这个circle ent就是会在在这儿直接就走到end了。但他其实应该还有一些事情需要去做，他没有很好的生成这个query，他认为这个表结构信息太少了，回答不了这个问题，这个是我们还需要去解决的一个demo。但它这个结构这个图的结构是跟s miss的使用场景是非常贴合的，这个是我们下半节课要去做的多智能体的协作。这个多智能体协作就是我们最早在应该是在开营和第一节课就提过的。
	Martin agent是negra非常有优势的一类应用场景。它其实就是实现了两个agent，一个叫researcher，一个叫chat generator。他俩都能调二氮，调的two不一样。所以然后中间这个其实continue，这是一个条件判断边，只不过他在这个就拍的lab里面，它渲染的时候出现了一点问题，多了一些陶艺制服。大家可以细看一下，这俩其实都长一样的，然后都是continue，怎么这个continue的前后都有一个NBSP的这个就non breaking non blank space，就非空格这样的一个逃逸字符，也不知道怎么回事。大家如果有知道原因的同学，到时候也可以提出来。
	我们把这个是可视化这个图的部分，他稍微优化一下，这个地方做是有问题的，查了很久的文档也没解决好，这个逃逸字符就一直显示在这里，这俩就continue，所以这是一个条件判断。理论上来说就是由researcher他来判断我现在是要要不要去调这个chat generator。然后他们各自有自己的to our不一样，然后最终由这个chat generator或者说这个researcher来判断这事儿是不是干完了。这是一个多智能体协作的实例。
	好，以上就是我们上半这节课要讲的内容，也就是说我们的next grab开发指南。我们回顾一下就是讲了nang grp它的场景是有状态、多角色、多智能体的这个复杂的大模型应用的开发。然后它充分的借鉴了前辈们在分布式的图计算，以及流批的流处理批处理的数据的传输管理，包括图结构的设计，然后灵活的接口方面的一些前车的前车之鉴。然后同时他自己把图数据结构很好的引入到了agent的工作流设计里面来。通过底层的round table，实现了数据的接口的一个统一。同时通过这个节点和边，把原来的这个黑箱式的agent的内部执行逻辑变成了一个可控的，然后灵活的支持分支和循环的新的工作流。然后通过这个stream能够去流式的生成每个节点的内容。按照我们编的这个定义的顺序，那么下半节课我们会来实际的完成两个实战，分别是这个多轮对话的智能客服以及多智能体协作，也就是我们现在看到的这一页。好好，那我们来QA一下，然后再来实操，确保大家现在的概念是理解到位的。
	这个可视化的图是可以自动生成的吗？是的，待会我们就能看到它是一行代码生成的。No grave和cos的工作流向是其实他们都跟前辈们相似，应该这么说比较稳妥一点。就这种设计哲学是不是这个时代的产物？哪怕是TensorFlow都已经把这套玩的很熟了，更不要说在前面的那些东西了。
	所以这也是为了从根儿上回应很多问题。就是这个跟nine graph是不是很像？那个跟F是不是也很像？他们都跟前辈们很像，因为他们都是在前辈们的基础上吸取了一些很好的设计哲学。
	我们课程的agent开发都是基于nine clock吗？不是，我们第一个agent就没有，我们第一个agent面向零基础的同学，没有引入这些复杂的概念。
	N grab的节点的输出怎么在多个节点间传递？这同学能举个具体的例子吗？什么叫多个节点间传递？你是指他们是直连的吗？如果是直连的，直接就能获取他们如果没有直接连接，那就不应该直接传递。就像没有加好友的微信，用户之间是不能直接传递信息的。
	Low的对象都是函数对象吗？能否是类的对象？这个怎么理解？你这个。
	能否。
	是累的对象，啥意思呢？你的这个类的对象是就是指python的class的实例吗？
	如果你是指这个意思的话，那那是没问题的。因为我们说了，它是任意的python函数，不是任意的python对象。就是你想象一下，就是在python里面整整到根儿上就都是函数了。
	Number graph可以同时调用两个节点吗？你的同时调用两个节点是什么概念？能举个例子吗？如果他们不是在同一个层次的，是不允许并行执行的。就是在这里你。
	无法在。
	一个workflow里面同时去调first tour call和Carry，因为他们有先后依赖顺序。我不知道这个有没有回答你的问题。这个ID是随便写的吗？什么规则？这个ID是随便写的，跟你的微信ID一样。对你想怎么取名就怎么取名，但是不要取重了，取重了之后就会把两边的信息放到一起了。
	Nine grab的memory是怎么设计的？每个station的用户都有每个节点的检查点数据吗？一旦一个节点经过了多次什么意思？Memory是指记录最近一次的状态吗？我没太看懂这个同学是啥意思？每个station你的这个session是什么概念？这个词太泛了，我不知道你的这个station是什么概念，哪个层次的station？
	Station就是睡的ID。睡的ID就是睡的ID，它睡的ID是一个技术侧的描述，对吧？它实现了状态历史的隔离，你可以把它用到section user query各种各样的场景里去，不一定是用户的，你一个用户也可以放在不同的sad ID里，对吧？然后你不同的或者说你不是用户的场景，比如说你是一个circle agent的场景，没用户了，那你可以相同的表放到一个CDID，就是它完全是一个技术侧的描述，所以它取了一个跟场景无关的key叫CID。至于这个third ID你想要怎么去放，你取决于你上层的应用层怎么跟这个CDID去做映射。我不知道这么描述，有没有回答你的问题。
	这个同学问了一个好问题，人工介入中断之后，怎么操作流程继续执行或者回退呢？好问题就是首先这个介入，人工介入它本质上就是一次执行。你想象一下，在这儿对吧，人工的介入，就你我不知道这个同学用没用过IDE，用没用过IDE里面的打这个断点，你想象它怎么执行的。就是在IDE里面你给一行代码打下了一个断点之后，你去运行这个程序，它会从这个程序的开头执行到这个断点。这个时候怎么办呢？你只需要再点一下，它就继续往后执行了，直到他的下一个断点。或者说如果你只有一个断点，这个程序就执行完了。
	那这里也是一样，你需要再点一下，那怎么点一下呢？这个点一下其实就是我们刚刚讲过的执行一个节点。那怎么点一下呢？Stream方法也可以，in work方法也可以，取决于你接下来要怎么去这个操作。
	然后他这个memory里存储的数据是什么力度的？每个节点的状态数据都保存一份吗？每个节点的状态数据。首先这个同学你要这么理解，这个状态它一旦执行完了之后，如果你没有用memory它就丢了，对吧？然后你现在用了memory之后，它存的是个什么东西呢？它其实存的是这个图执行之后的，按照标准的这个技术侧的说法叫side effect，就是它的副作用。按照中文的描述，side effect就是你这个函数执行之后的side effect，那这个东西会被存下来。它其实已经跟节点没关系了，它就是这个图执行完之后的整个结果。
	然后好了，既然跟图没关系了，那你总得让他跟有些东西关联上。如果我们没有事的ID那就是混乱的，就全部都在这个memory server里面。如果你现在自己能拎出来，你能分门别类的去做一些划分，那睡的ID就是一个用来划分的依据，跟其他的一些划分依据本质上是一样的，具体取决于你想怎么划。然后你的每一个节点执行的时候，在节点执行的那一刻你可以去传我要怎么把它保存下来，保存到哪个thread里面。我不知道这样描述清不清楚。然后你可以想象一下，如果你有的节点你没有传这个对一，帅的ID等于1，那它就直接丢到那个总池子里面了。如果你明确指定了，那它就会按照帅的ID来分开的去存。
	Memory里面的状态会不会持久化。好问题取决于我们在实例化的时候，这个memory server有没有去做持久化的。这个指定没有的话，他就先用的是短期的这个存储，也就是放在你的内存里的。如果你要指定，比如说把它保存一个文件什么的。那这个时候也可以就在这个实例化的时候，创建这个memory实例的时候可以指定，那我要把它持久化。
	看大家还有什么问题吗？
	大家现在有疑问很正常，因为没有上手操作过。但是这个概念一定要理清楚，这个概念捋清楚了再去看实战的代码。再回过头来看这些概念，应该就有这种豁然开朗、会心一笑的感觉了。
	Memory你的数据能管理吗？比如说删除，没有太get到这个点就删除是想怎么管理呢？删除什么呢？你的场景是什么样的？首先肯定无论如何能删的，能删。对，但我不知道你想怎么删。对，你的管理这个词太太泛了，我不知道你的管理是什么颗粒度的。
	首先比如说你没有指定它的持久化，那你就不用管了，你这进程一关啥都没了，对吧？那如果你想要持久化，那你按照不同的这个thread ID，你可以存到不同的地方，反正它也是序列化的数据。它就是一个简单的就是把logo稍微封装了一下。你可以想象一下这玩意儿就是我们第一个agent里面的那个logo，只不过它分门别类的去做了一些上面的这个设计。
	好，我们接下来实战，实战完了再给大家答疑，这样大家看着代码更有感触一些。
	好，我们接下来做第一个nine graph agent的实战，就是我们的多轮对话的智能客服聊天机器人。我们再来说一下，这个代码是在咱们的大模型应用开发实战里面，这个课程项目里面主要是为了有一些同学没有上过这个课，多指一下这个路径，让他能去学习。上过这个课程的同学，那就不用说你就该复习了。如果有忘记了的部分。
	然后在这个课程项目里面，我们看一下，有一个能券。在能券目录里面新增加了一个叫做nine graph。Nine graph里面有这个chatbot和这个marty agent，多智能体协作。然后circle agent现在还有一些小问题，大家可以不用管它。然后这个chatbot点开之后，这就是我右边这个目录了。就我们的这个chat port开发指南是一个非常全面的指南。我写了很多的文档，去方便大家理解，然后充满了代码解释以及它正常执行应该是什么样的结果。我们待会儿就来深度的去看一看这个指南，这个是大家课后一定要好好花时间去看的，包括查看历史对话什么的。
	好，我们现在就来看看第一个这个指南应该怎么做，左边是这个nice miss，我们跳过来。好，我们重启一下这个就拍它来确保它的执行跟大家到时候一样，把this miss回到这个project页面。好，这个开发指南。放大一点，这边不用这个开发指南，其实我们是作为大家要用能实战agent的第一个项目。
	然后这个项目也是一个最常见的使用场景，就是聊天机器人。只不过这个聊天机器人我们是分成了五个部分，逐步的让大家去学习和了解n grap的功能。也就是我们上半节课讲的那些对象方法以及这个记忆的系统人工介入，这个搜索引擎的工具怎么用，就通过这个check box的开发指南让大家能够整体的了解，我们会从基础的聊天开始，到最后有人工审查或者说手动更新这样的一些功能。
	这个是刚刚我们课件已经介绍过的了，我们的state graph的对象使用步骤，compile graph的对象以及他们之间的关系。然后graph这个compile graph的这个shame方法，它的这个作用以及它的使用场景，包括它的这个用法等等。好，那么我们就只就看到这个graph stream，它它的主要的参数，其实是跟我们其他的这个节点的执行都是一样的。因为这就是去用流式来执行一个节点的方法。所以inputs就是那个state，只不过在我们的聊天机器人里，我们的state长这样，待会儿我们回去看到它是这么定义的那么它的configure就是我们刚刚提到的线程ID然后等等，它是在conflict里面去做配置的，然后这个three mode是指这个返回数据的模式，通常是设置为这个values，就是指流式数据用values来进行设计。如果我们用的是这个节点的我这个图里面，在这个节点用的stream的方法来执行的话，three mode就设置成values就可以了。然后conflict参数是可选的，然后inputs是我们的输入，那么这graph的stream是在下面，我们会反复去执行和使用的。
	好，那我们接着就来实际操作一下五个部分。第一个部分是最简单的构建一个基础的聊天机器人。好，那么这儿我们首先去安装一下，有的同学如果没有在自己的环境里装上next和next miss的话就可以安装。然后为了不让我们的notebook充满这个安装的输出，就是我加了一个这一行指令。简单来说就是除了安装的时候报错以外，只要是正常安装，那应该是不会有额外的输出了，就会正常的执行，就比较干净，因为这个指南已经很长了。在这儿我们为了去开启这个跟踪，我们设定了我们可以取个别的新的名字。这样看它有一个新的咱们的project的出现。
	好啊，这刚才自动刷新了一下，然后我们接着来定义一个state，就我们说的第一步要定义一个state。这个state就是我们的聊天机器人的这个graph里面要传的这个数据应该是什么结构，那什么结构呢？是一个这样的形式，继承至这个type的dict，这个我们在在刚刚的课件里面也讲了。通常来说这个state要么就是继承自这个type dict，要么就是继承是这个pandey的base model，这个type dictionary是一个比较简洁的形式，因为我们的这个聊天机器人其实就是你来我往的这个聊天的内容。每一次这个聊天的内容，其实本质上就是在原来的这个聊天记录里追加一条新的信息。我不知道这个大家能不能理解，get到这个点，是有一个历史聊天记录。
	你想象一下在微信上，然后你现在新发了一条信息，不管是你发的还是AI发的，反正就在那个记录上又追加了一条带有这个身份。那么这个state就表达这个含义，然后我们定义一个state graph的实例，规划好执行一下。那么这个graph builder就是我们现在有的这个state graph的实例了。我们可以在这上面去加节点，添加边。好，首先我们定义一个最关键的节点，就是这个聊天机器人的节点。这个节点的输入是一个state，这state就是我们刚刚定义的这个state，这个类型跟我们的课件能联系起来，尽可能的在第一个开发指南里面足够的细，让大家能对上号这个节点的输入就是state，把这个节点加到图里面，那这个图里面现在就有一个节点了，叫chat board。
	好，然后接着我们往这个图里面再增加两个边。然后这两个边分别连接了两个虚拟的节点，也就是起点和终点，start和这个end，the start和end是在上面这儿导入的一次性。好，我们执行一下。然后我们把这个这是为了刚刚课件截图，把它放下来，应该在下面这行解释里我们添加一下鞭。然后很多同学问这个是不是自动可视化出来的这肯定得自动可视化出来，因为这太重要了。
	然后compile方法，我们现在的compile不加任何的参数，它就会把我们已经往这个grap builder里面添加的点和边给它编译好，然后变成一个可执行的对象。这可执行的对象叫graph，之前的叫graph builder，然后这graph可以调用i python，就是我们notebook里面经常要去渲染一些东西。之前在讲GT4V这个大模型的时候，我们还教大家用过这个，也是在这个模块里i python display里面有个markdown的模块或者说方法，可以把markdown的这些内容在output里面去给它渲染出来。现在其实是需要渲染一张图，那就可以通过这个dw MERMAID的方法去把这个图给渲染出来。这个图通过get graph方法可以拿到，然后甚至可以有更多的样式在get graph的这个API文档里面，大家可以去查一查，编译之后就生成了这样的一个graph。这个graph有起终点，the chat what, 是长这样的，我们一共添加了一个节点两条边。
	然后再添加这两条边的时候，增加了两个虚拟的节点。这两个虚拟的节点大家很明显看到跟我们的正式节点是不太一样的。然后这两个虚拟节点也不需要add node，因为它本来就是在我们的这个graph里面定义好的这个节点，而且没有任何的实际功能，主要是用来标志它的执行顺序的开头和结尾。好，有了这个graph之后，我们就可以开始用它了，可以运行这个聊天机器人了。
	这个运行有下面这样的一个实现，就类似于我们在第一个agent，我们的github city nail的时候，我们当时就在早期版本应该是在0.11的时候就实现了一个通过well处，然后让它不断的能够获取到命令行的参数指令的一个操作。这儿类似的逻辑，我们有一个while处。这个while处是不断的从我们的这个交互界面里面去获取到用户的输入，来实现一个聊天的循环。
	就这么一个具体的代码解释，这里也有，我们来看一看，我们来执行一下我们问的问题其实是一个很有挑战的问题，就是详细介绍一下nine graph的这个项目，这是他上一次的一个回复，我们先不管他执行一下。这里我们看到其实jupiter lab是支持这种交互式的，在output里面是支持交互式的那事儿我们把刚刚问的问题给他，他在这继续执行。生成了一个结果。然后他接着就问我下一行，这个流程是因为我们在这儿获取了用户输入。
	我们看一下代码，user input就我刚输进去的那个user input。然后这个user input拿到之后，如果这个user input是这三个指令，那么就打印一个goodbye，就结束循环退出聊天。我们可以试一下，出一个q goodbye，给我打了一个goodbye，然后就结束了break了。所以这行代码是我们刚刚最新执行的一次对话。但在第一次对话的时候，我们显然不是这三个指令，我们是输了一个。详细介绍一下n grab的项目。
	在这儿我们就看到了是它的关键的这个逻辑，这里这个messages是我们state，就我们定义的这个状态，它是一个这样的形式，messages如果不记得的可以回看一下第一个重要的部分，这个state是我们定义，就长这样子的，有一个messages，后面一个这个list。那么这里也是一样的messages，然后这个key是user，然后value是user。Input value就是我们刚刚从这儿取到的，就是user是它的前缀。这个input的方法就是去取这里的这一行输入，然后它这里面附的这个部分是它的前缀，也就是每一次这里都会输出的user。把它拿到的就是里面的user input，跟第二段也是一样的，是这样的。好，所以这儿也是判断的user input的小写，这儿就直接把user input传过去。
	那传过去之后，调用的是graph stream方法，而这一段就构造出来了一个state的结构，所以他就会去执行，执行我可以打印这个执行的结果。打印这个执行的结果，就从这个event，就他执行之后其实是一个特定的状态，因为它执行完了之后是一个特定的状态，这个状态可以去取它的值，这个是一个比较常见的取它值的操作方法。就因为它是流式生成的，你可以理解成除了在stream的那一下你能获取到它的输出流以外，别的时候要么你就只有把它存下来到memory里面去取。要么就在他执行的那一刻，你截取到了它的输出流可以打印，只要在这两个状态之外，其实你就拿不到他的结果了，因为没有人会去存它了，所以在执行的时候，你可以顺带的去把它打印出来。
	如果我们现在还没有教怎么去记忆的话，可以通过这个方式。我们打了一个前缀是assistant，在里面输入了这个message负一content，这里我们可以再给大家看一下它完整的这个value长什么样。我看一下，在这看就行了，不用重新执行了。
	这个chat wort是我们刚刚生成的next miss的project。这儿目前只执行了一次，消耗了555个token，预计的token开销是这样的，点进去。点进去之后，我们看到这儿有一次并且他这能展开，先给他先，我们能把这个多层次的去展开。大家能看到这个地方是能再展开的，但推荐的就是你直接在顶层这儿跳进去，用这个二级的来查看。
	那在这里面我们看到有一个start，然后这个start的input就是详细介绍一下n graph项目。这它的output这个很合理，为什么呢？因为大家看到这个start它就是个虚拟的起始节点，他就是那个啥也不干的传声筒，但他决定了整个项目从哪儿开始，因为他输入的就是start，他他他这这起始节点就start，然后输入，用户输入就直接给到他了，就给到chat port，这是他的操作，几乎不耗时。接着是chat word这个节点，chat word这个节点的输入是用户角色的。详细介绍一下nine ground项目，因为有用的是这个GPT4r mini，所以它是一个check model，这儿它是个check model，所以这是用户的一个角色。输出的结果是number up，是一个巴拉巴拉。我们可以看到最下面nang graph是一个专注于自然语言处理的巴拉巴拉项目。最后结论是实践的机会，其实我们这一段它还可以把这个输出也渲染成这个mark lan的格式了。这个是我们看到它的一个输出，就对应着咱们这儿的一个结果。
	这个是它内部的一个展开的结构了。我们主要看这个大的调用，那对应着我们这里的这一行结果，所以这个应该就通过nesmith跟他联系起来了，大家可以通过左边能更好的去查看我们这边的执行情况到底怎么回事，包括它的这个时间开销，3.79秒上面生成的内容还是比较多的。最关键的事情是我在这儿也写了一个运行结果分析，我们为什么要做第二部分？就是因为第一部分我们故意问了一个GPT4 omi可能在他训练的这个数据里面没有的问题。就nine grab GPT s omi的训练数据应该是截止到去年的下半年，那个时候nine graph基本就应该是在去年底推出的。所以很有可能的是在他训练数据里面，就算有也是比例极低的。所以他回答的这个nrp的问题，这个答案是不对的。
	他写到这个是一个专注于自然语言处理和图结构数据的项目，他其实就是在猜在蒙蒙这个答案。因为language就跟LP相关，graph又跟图结构相关，所以就巴拉巴拉在讲。然后目标是开发一种新的方法论，将图模型和语言模型相结合。这一看就是他YY出来的，不是它真实的正确回答的一个结果。所以通过这个我们就能看出来，第一部分的这个聊天机器人首先做出来了，也能够很方便的去实现这样的一个逻辑，当然这个是为了循环去做的一个实现。然后这个缺点也很明显，就是在面对一些新问题的时候，他答不上来。
	所以我们就引入到了第二个部分，也就是chatbot。如果遇到了一些他不会的问题，他不知道的问题，可以通过工具。那这个工具我们就直接去给大家点开看一眼。这个TV search这一类工具，其实我就直接引入到了这个next graph里面的各种文档，大家可以去详细的去去看一看。其他类似的一些工具也可以不局限于它就留了这样的一个影子。
	要去用这个工具，要注册。这个我刚刚在课件里也说了，它的官网也很简单，就是这个tvi dot com，然后在这儿去去注册。如果你没登录的话，他就会告诉你要312的注册，我已经登录了，我已经登录了，就可以直接进去了。然后他这儿是这个dashboard，可以去去分析你过去的调用的一个情况。像这样，我过去24小时的平均响应时间是2.2秒，2298毫秒有点久。然后我们可以看这个API，里面有具体的去给他介绍的一些内容，大家如果感兴趣，可以去关注。
	这个tewin是这是这一轮大模型起来之后做的一个专门为大模型的搜索引擎做的一个工具，所以可以关注他们跟deep learn ning也有合作，价格的这个计划，其实大家能看到免费的叫researcher，是每个月1000次API call，不需要你绑定信用卡，你只要有个email就够了。甚至它应该是可以支持用get hub或者说gmail来直接登录的。然后project就是4000次的这个月度调用，差不多就1000次，是十美金的一个价格了，所以还是有一定的让利的。如果这两档去比较它的免费额度的这个价格的话，那大家可以去去了解一下。注册之后，应该是我看一下点这个get started就应该会跳到。
	API. 
	K的页面了。
	进来之后，他就会写当前的计划researcher。然后我现在用了by 56次，一共有1000次。这个是key，点一下这个就能看到了。我不会点的，大家可以自己去注册一下，然后这里就copy，就能复制了。
	然后复制之后，这里就有一个点是什么呢？就是我这儿留了一个模块的代码，就是给那些不太能折腾去拍的lap的同学。这儿其实是有一个功能的，但是首先你需要去安装它的依赖方案去执行就好。执行之后，这行代码的意思就是如果你的环境变量里面没有设置它的话，你可以执行。执行之后，在这儿它会弹一个像刚刚的聊天框一样的东西，你就可以去输入了。我这不会弹，是因为我的环境变量里面已经有了，我重新设置了，然后重启了整个to lab，这继续是注释掉。
	有了这个玩意儿之后，你就可以去访问它的这个搜索引擎同样的从这个community里面，它当然是属于tools去导入这个tavi search，这个search results就是用来控制。首先这个search results是一个工具，是一个next up可以调的工具里面有很多参数，最重要的参数是就他每次能够最大并发搜索的这个结果数，然后构建一个工具集，然后这工具我们可以试一试。这儿又涉及到我们LCL的好了。大家如果真的把LCEL的这个设计理念整明白之后的统一接口设计还挺好的。你看这里是一个to two，同样的跟我们学过的所有的其他的LCEL的对象一样的。它也支持invoke方法，那你就通过它不能直接去调这个工具，我们甚至用中文去搜一下这段话。
	Nine grap当中的节点是什么？执行一下。这里他居然去知乎搜的答案，神奇。好，我们看到他这儿最通过这一个问题，他最多能返回两条结果。就是这两条结果一这里的结果二收到了一个结果。这个结果，我们可以在后台这儿肯定也能看到。首先我们刷新一下。
	258就从256变258了，结果这儿我们就不去不去细看了，然后还是保留英文。这个是medium上面的结论，当然这个也能直接跳转过去。Uh introduced in introduction to nine are a beginner sky. 
	好，那么我们调回来继续往下，工具是可以用的，接着往下走。我们现在要做的事情是什么呢？我们回忆一下，我们其实在开发指南里面教了大家加节点加边。我们又在LCL里面教了大家所有的对象。只要你实现了runners的协议，其实大家都是一样的。
	那现在我们有个工具，这个工具怎么办呢？这个工具是一个什么东西呢？它要怎么加到图里面？其实在这个neg APP里面很很简单直接的一个方式就是工具。谁能用工具，这个是关键对吧？我要把它加到一个什么样的东西上去，那加的这个对象到底是个什么？
	通常来说在nine graph里面，工具要通过band tools绑定工具集的方法去绑定bad tools。那么他能绑在什么对象上呢？绑在大模型上面。
	然后这里需要注意的一个点是说，不是每个大模型都可以绑定工具的。这个逻辑大家也明白，就是不是每一个model，比如说这儿我们用的是GT4 omi，不是每一个公这个模型的实例都支持绑定tools。或者说它可能支持绑定tools，但它不一定支持绑定所有的tools。你可以想象这是两个集合，一个是模型的集合，一个是tools的集合。然后不同的tools它对模型的支持情况是不一样的。所以这个大的tools的集合并不是每个模型都很公平的，都可以去用。等于你这个模型它支持了这个tools，或者说你换过来说也是一样的，这个tools兼容了这个模型或者支持了这个模型，才能够去使用。
	这个逻辑大家也明白，但是有一个朴素的道理，就是你像GPT4O或者GPT4的turbo这种相对来说，应该目前为止还是最强的大模型。它支持的工具通常来说是最全的，所以你会发现比如说你要用欧拉玛，那欧拉玛可能他还没支持这个。就欧拉玛里面的这个包，可能还没支持这个搜索引擎，那你可能就用不了。但是欧拉玛的包可以支持聊天机器人，让你可以用这个逻辑。
	好，所以我们把这个tools就是我们刚刚定义好的这一个工具，给它绑定到这个check model上。这个就变成了带有工具的大模型，LLM with tools, 这个也是在南迁里面就有的经典用法，给模型大模型加工具。那这样之后，我们更新一下这个chat port的节点，聊天机器人的节点，它就变成了我们的LLM with tools的invoke，而不再是chat model的invoke。这个跟我们的第一部分是有显著区别的，大家看一下第一部分是像这样的，我们是直接chat model in work，就直接把我们的用户输入的内容给到大模型大模型去生成一个这个结果，结果就给到用户。现在是我们让。
	这里现在。
	我们是让这个带有绑定了工具之后的模型，他来输他的输入是我们用户的输入，然后再把这个新的全部的节点加到状态图里面，然后我们再来。这里有一个细节，这个先加进去，大家先不管，先把这个加进去了。加进去之后有一个特定的在下面的方法是用来处理这个工具的执行的。
	这里简单我们看一下，这个初始也很全，大家可以想象一下，就是这个大模型它现在绑了一个工具。大模型本质上是可以判断什么时候要去调工具的。但是他要去调工具，他也得把这个信息给传进去，他才能够去实际执行。这儿我们用一下这个to message，就是在这里面也会用到的，就工具的这个message。现在的整个年轻人生态的工具调用基本都是按照这个套路在执行。
	从南茜core的message模块里面调用这个tool message。Tool message的同等级的概念就是我们以前用过的像这个用户的message，然后助手的AI的message或者说系统的message，这个是two message。然后我们定义一个basic to node，一个基础工具的节点，这个节点是干嘛呢？它就是在最后一条AI message当中去执行工具的请求。
	有这么一个节点，你可以想象一下它的能力。就是首先在这个chat model上面绑了一个工具之后，这个LLM with tools它能够做什么呢？他能做的事情是调大模型，然后调了大模型之后，他还有工具可以用。但他什么时候去用，怎么用，其实我们都还没有去定义。那怎么定义呢？通过下面这个节点来进行定义，在下面的节点里面，其实我们就是让我们的这个节点工具节点去获取了这个大模型。
	先生成了一条信息，然后又用户来了一个问题。这个时候可能他需要去判断一下我新起的这个问题，要怎么样去回应了他。有可能是先生成了一个结果，然后又去查询了一个特定的工具，所以这儿我们看一下这个basic two node，其实是一个很标准的做法。大家如果要用别的工具，也都是可以复用这段代码的。它的实现，它的构造函数里面去把它的工具集，它它的构造是需要有一个工具集的toss。现在我们只给了他一个工具，就是这个搜索引擎。它会从工具集列表里面去获取每一个工具的名字to name，然后构成了一个tools by name，其实就把它所有的工具名称拿到了，这样方便他去访问那个节点，那个节点去访问具体要用哪个工具，然后具体去调用这个节点。
	就执行的时候，这个是python的一个语法堂扩方法，就执行工具调用。那这个执行工具调用，它的输入其实就是一个state，一个标准的这个图结构里面定义好的这个state。这儿只要跟上面我们定义好的state匹配上就行了，所以这儿是能匹配上的，然后从这里面就获取到了信息，并且我们要去用AI message的最后一条，所以用的是这个message的最后一条不一。
	然后基于这个信息再去调用工具，调用工具的时候，我们看到这儿它to buy name，然后to call name，就调用一个具体的工具的名称，要找到这个具体的工具，这样用work方法去执行这个工具，这个工具执行的时候要用什么参数呢？就to code arguments，然后拿到了一个to result这个tour result，再把它封装成一个two message，这two message就跟我们以前在冷圈里面调chat model的时候一样。我们的这个check model里面，用户的这个请求变成user message。这个大模型的生成的结果是AI message，我们要做的系统指令是system message。这儿也是一样，我们把工具调用的一个结果封装成一个two message。这tour message就能够塞回去，塞到整个图的这个执行结果里面去，就这么一个逻辑。然后最终返回的就是这样的一个output，这个output就变成了整个列表里面，就他的聊天记录里面的最新的结果。那我们再把这个basic to node也加到这个图里面去，然后名字。
	好，接着我们来往下执行，这个就是我们开始用这个条件编了，就我们开始说的动态路由的这个条件的编。这个条件变其实是用来判断的，来检查我们的最后一条消息当中到底调没调这个工具。如果最后一条消息是包含了这个工具调用的，那么就返回这个tours的节点表示需要去调工具，不然就返回这个end就直接结束流程，这个是这个路由函数它要去表达的或者说是要去执行的这个角色要执行的功能，那我们接着直接执行一下。
	让大家看到这个图，应该好理解一点，这就是这个图的作用。你可以想象一下这个图里面我们先不看toss，就是我们看这有两条虚线，这两条虚线最终它要变成哪一条实线？是这个。
	这个路由函数去决定的，这就是他刚刚这段话的描述。就如果我们这个chatbot它生成的AMS sage是说我要调two，这个时候他没有真的调，他只是生成了一段文本，说我要调这个two。具体调是要在这儿去执行的。因为他在他的message里生成了我要去调two，所以这个路由函数就会把下一个执行放到tools这边来。那tools的结果被封装成了一个two message，还给了chatbot，chatbot拿到这个结果再给用户看。但如果他没有就他并没有一条我要去调度的这个信息的话，那它显然就会直接到end。
	其实就这么一个事儿，里面代码也是这么一个含义，我就不逐一解释了。大家可以去看核心就是这儿，我的最后一条AMS sage有没有to cost的这个调用请求，这个写过有agency同学应该都都了然。然后这儿加了一个条件边，这个条件边就是起点是chatbot，路由函数决定下一个点，终点有两个终点有两个，这样给大家换个行，看得更清楚。
	终点有两个，一个是tools，一个是这个end。那么把这个tools到chatbot这条回去的边，就这条回去的边也给他加上这样一条边。因为刚刚那个路由函数只定义了两条虚线，但是这个tools的tool message，我们希望回给chatbot。对，加加了一个回去的边，然后加了一个起始的边，就从start开始到这个j box，然后我们把它执行一下，执行了吗？执行了，刚已经到这儿了，19号了。
	好，现在我们来实际操作一下，看它是什么样的一个情况。好，同样的在这儿通过一个死循环用来模拟，详细介绍一下nang graph的项目。大家看这儿首先输出了两条assistant的结果，这是它的搜索结果。搜索结果这儿assistant就是去检索了这个叫什么搜索引擎之后的一个结果。搜索结果拿到之后，他最后又整理变成了这样的一个结果。最直观的还是看咱们的nice miss. 
	这个是我们对应的这。
	一行的结果，先把它给退出，那在这儿我们能看得很清楚了。在起始的时候我们的chat box拿到了一个问题，叫详细介绍一下n grab的这个项目。然后他拿到了这个nang grab的项目之后，他去调用了我们的two。然后这个two其实拿到了一些结果，这就是两这个tools的返回结果。然后这个tools的返回结果又给到了chat box，这里其实就已经走了一圈了。大家想象一下，就这chatbot，然后他去查了一下to给他一个结果，老师给了一个结果是就上面的这里这样的。
	两个。
	结果。拿到这个结果之后，其实他才知道那个不是他理解的，就他YY出来的。在第一部分里面，他觉得nine grap是一个要把自然语言和图结构合到一起的这个项目。但其实不是。他查了一个是n grave的官网，一个是nine graph github的主页，他从这个搜索引擎拿到的结果，拿到这个结果之后他就大概有了了解。那他他就换了一个问题，这个是第一次他给搜索引擎的关键词就query那么。这是第二次了这是第二次的这个query。第二次的这个query我们看看他问了什么。
	第二次的这个query拿到的结果就详细的多了，就nine graph n graph项目的介绍和nang graph项目的github，分别对应着他第一轮里面查出来的官方网站和github主页。好，那么这两个就从两个query变成了四个搜索引擎的结果。大家去捋一下，就第一轮询问就11分2，因为它有一个最粗浅的n gram的这个问题，变成了两个问题，一个是问项目介绍，一个是问项目的给他，然后拿着这两个又去掉了一次two，又变成了各自变成两个问题，变成了四个问题。对，这里的output就是这里有两个返回，这里有两个返回，然后。最终的答案是。我们一路看下来到这儿整理成了一个这样的结果，就number up是一个用于构建具有状态的多参与者。在在这儿这个部分是一个用于构建具有状态的多参与者的巴拉巴拉通过这些资源，你可以深入了解，这就是他最后这段内容。
	前面这些其实是中间结果，就是我们有to to 2的输出也放到了这里。但其实它不是这个assistant的这个前缀，理论上应该是tool的这个输出结果，这个输出格式化。我们会在下面几部分再给大家看一下。所以这里我们把这两个部分的结果还专门做了一次对比，当然每次生成的结果不一定一样，但我们可以看到chatbot加上这个搜索引擎的工具之后，这个结果要正确的多。并且给了两个人的资源链接。
	而前面第一部分的这个版本，就是自己编造的一个项目描述，凌乱的多那这里就涉及到我们第一个homework了，就是more，首先运行和测试第一部分的聊天机器人，尝试找到一个无法回答正确的事实性的问题，就比如说number one就是他回答不了的，因为是他训练数据以外的，然后你也找一个，找一个之后，你找到之后去完成第二个作业。第二个作业就是使用这个联网查询的工具，可以是timely，也可以是别的你有的。然后在第二部分的这个机器人上，去测试你找到的那个问题，对比一下生成的结果，就像我这里一样，然后做对应的提交。好，这个是前两部分。那么接下来我们讲一下第三部分和第四部分，在讲这俩之前我们再回答三个问题，然后再往下看，然后我正好再去个洗手间，大家先提交一下要问什么，我来回答问题。
	好，回来了。有个同学说什么项目部署到亚马逊和open shift上面的注意事项，谢谢。我这个没部署到open shift上面，我这就是一个docker骑起来的put lab，然后用了这个GPU服务器。
	大模型如何判断是否调用two依据是什么？这个是一个老问题，我以为我这问题问的挺好的。你可以想一想这个绑定的这个图，我它里面背后干了什么？我说为什么有的模型没没实现这个绑定，这个特定的工具，这个绑定two背后就实现了那些就是你问的问题，什么时候调用，什么时候不调用的那些提示工程。就是在冷却里面这些工具对应实现了一些提示工程，这些提示工程是跟模型和工具相关的。
	可控还是随机一个问题，多次调用可控还是随机这个事情是这样的。首先你可以限定死他要掉多少回。然后这个是在这儿我们会用到的就是那个config里面，config里面有一个这样的参数，我们本来在market agent里面才会讲的，就这个最大递归限制你可以限定死的那这个你就可以限制你的用量了。然后你也可以通过提示工程去设置，但它就无法精准量化。
	拆成两个问题，是因为搜索工具只能拆成两个问，所以他就拆成两个了。然后那个max那个那个max results决定是两个，然后搭配的这个搜索引擎工具的提示工程，所以他就会拆成两个去问，完整的回答这两个同学问题，咱们能使用其他的工具吗？可以，肯定可以，你看一下能能签的。Community就我刚刚给的这个路径。然后我实在是不建议大家用中国的搜索工具，这个道理大家都懂。对，就是它会消耗你的生命。对，很浪费时间。好，我们接着看一下后面几个部分。来。
	好，第三部分和第四部分其实很简单。第三部分就是这个记忆的功能，我们抓紧时间把这个再讲完。记忆的功能，就是我们怎么样让这个聊天记录给记下来。其实核心就是使用这个memory server，那这memory server里面在compare的时候要传进去，然后在执行的时候，这些状态要存下来。存的时候就config，就是我们所有的节点执行的时候的第二个参数。大家去回忆一下，上节课讲过，第一个参数是state，第二参数就是config，这个config本身就支持各种各样的配置，它是以这个configurable开头的两层多层的一个配置的序列化的一个结构一个字典，这个层次化的一个字典塞莱迪，然后里面有对应的这个内容，然后我们来实际执行一下。
	首先创建一个内存记忆的简称，这个检查点不叫内存的这机器翻译的有点差，记得这个检查点，然后执行一下之后，我们再重新compile一下，再display一下。没有变化，这个是看不出来的，它不会影响这个图当中的节点，它只是把节点执行的结果能够存下来，所以这个没有变化，就大家要注意一下。然后这个conflict的配置，其实我们刚刚看到这个线程ID，这个线程ID就是指我们的这个对话流，就所谓的聊天记录或者对话记录，可以通过CDID来进行记录，这个跟你的业务场景有关，具体怎么取？这儿我们假设先把它存到这个斯瑞莱迪一里面，那我们问一个问题，就是用户提问是这个嗨there my named is鹏，然后接着我们来执行一下，我们在执行的时候，我们传进去了，第一个是我们的state，这是这句话，格式是。第二个就是config conflict是只传了一个配置项，就是thread ID。第三个就是我们刚刚说的要用venues，就是string stream more。然后接着我们打印出来看看。
	好，打印出来之后这个就是格式化输出。大家可以看一下，这就是我们的用这个方式去格式化输出就可以了。大家可以直接记住，比较简洁。就每次执行的时候，把这个message的最新一条的这messages的最后一条，然后用pretty print打印出来，就会长这样。
	第一条他按顺序来的那这个就是human message，就是我们的user input是这一行。然后AI message就是AMAC，就是能欠底层实现的这个chat model分human message和AI message，就分别用不同的角色用这个区分出来，这个就是pretty print的功劳，他就干脆活了，格式化输出，然后会写hello鹏，how can I assist to you today？接着我们就问问第二次问他，这个时候我们config是没有变的，所以理论上他记得住，我们来执行一下看看。
	Remember my name？Yes，I remember your name is tom. How can I help you today? 这里我们就会发现一个有意思的现象，就是咱们的打印出来的这个events里面，是啊是没有这个的是没有这个的。
	我们这里执行了一次，其实你想你在脑海当中去想象一下，就是这部分我们刚刚执行的这部分，其实把这个图它执行了一遍，然后没有调工具，就是start chatbot end。因为我们没有再设置一个外出的死循环了。所以这个状态图里面原来的那个路由函数，当然这个需要大家高度集中，别就造成就容易忘这个图里面是有一个路由的函数的，这个路由的函数会去判断AM message的最后一条有没有调工具，如果他没有调工具，他就结束了。所以这里的这一次执行这一次执行这里这一次执行，他当然我说了一句my name鹏，他回了一段，hello, 彭浩，can I assess you today? 这是他的最后一条AI message。然后这一条之后，它其实整个这个图会去往下走去看那个那个路由。然后那路由显然是没有任何的tools call相关的内容的，所以他就end了。
	这里我们再来一次的时候，其实是重新执行了这个图。但是这个memory里面的结果其实是有的，它在线程一里面，这就是要给大家捋出来的一个逻辑，就是这个图是可以被执行无数次的。然后这个memory其实是它游离于你当前执行或者某一次特定执行的。它就是一个你可以认为就是一个像向量数据库一样的东西，只不过它是短期的，它是就在你的这个内存，你可以也不叫短期，是热点数据，是可以直接快速拿到的数据。然后只要你的线程ID是给对了的，你就能获取到那个线程ID里的memory，你就能为你所用，这个memory就实现了。
	那就像这里一样，就是我们去问他remember my name，其实是一个新问题。但是这个AI它是记得我的名字是彭。就是因为这个config传进去之后，整个这个graph它就能找到那个线程ID唯一的那里面的memory。
	现在我们调整一下，假设我们这两段是不变的，我们直接把这个config改成线程ID为2。我们再来问一次这个问题，user input就是remember my name，执行一下。这他就i don't have the ability to remember personal data。这就是直接这个GPT是omi回复的结果。这个地方其实是带了记忆回复的结果。我把这个逻辑大家能不能get到，这是memory的实际的一个用法和功能的场景，它不区分它它没有绑定在某个状态或者某次执行力，它是在线程里，然后这个线程就跟我们数据库里的key或者table name或者巴拉巴拉一样，你可以把它当成一个memory，当成一个记忆的系统去用，然后用线上ID去管理，就这么简单。然后同样的，我们可以去获取到一个grab的这个状态，就是这个get state就可以获取它的状态。
	当然你要获取状态对config也很重要。因为configure决定了你要获取的那个状态相关的各种各样的配置，那这样我们不好看，我们通过pandas把这个状态可视化出来。首先大家要记得这个config是线程一，这线程二我们没有改config是直接手动构造了一个config进去。
	然后这个线程一里面的信息，我们可以通过panda frame，panda的这个data frame给它变成一个表格展示出来就很明显，然后这个表格，其实就是我们线程一里面的存的这些信息。Hi there，my name is鹏，然后对，hello鹏，how can I assist you today? Remember my name? Yes, I remember your name. 
	也就是我们的这一次用了这个config，然后在线程一你给它记下来了，这个也在线程一你给它记下来了。那显然大家如果自己要去做实验，你可以去get一下这个图里面的线程二的状态。然后这个线程二的状态打印出来了，应该就是他了。当然如果你这个come back都不传，那他可能就没了。然后这个是memory，然后我们这个地方它的渲染是直接输了一个DF。然后我们如果要引入人类的审查，其实就是使用interrupt before或者说after这两种参数，在compare的时候去传入这个参数。然后这个参数的value就设置成你要的节点列表，在哪些节点前后进行中断，执行一下，这儿就能看得到这个是interrupt before。
	如果你用the afternoon after，然后我们执行对话，然后在工具调用前中断，这就是two cos看见没？这一段AM message里是以to cos开头的。它为什么会这样开头？取决于我们的tavi search这个tools的工具。这个大家可以去南京community里面去看它的源代码，就跟我们以前去教大家读源代码一样的，那就构造了这样的一个输出的format，然后他只要有这个two cos在我们的这个流程里它就不会end，它会去调tools。因为这有个动态路由，所以现在就走到这个tools。但是这个路由过来之后，他没有直接执行tools，它被拦截了。这个拦截就跟也不叫拦截，给截胡了。
	对，就跟我们路由函数一样。正常是一个节点到另一个节点就直接执行。但现在有了路由函数，节点之间可以动态决策了，先去执行了这个路由的函数。路由函数本来在在它的这个设定里，它执行完之后它就会return到下一个节点。那现在我们又加了一个fok，然后这个钩子又把这个路由函数的接下来的执行给抓住了，他就先把这个打印出来了，就拿到了这一段输出。你可以看一下，那么这里的这个图的这个快照，其实它就是它的下一个要执行的节点。这是一个常用的方法，在没有next miss的时候可以用这个，但我不建议大家去深入研究，它这个是一个是一个点，也是官方教程里面会提到的一个debug的小技巧。
	就是snapshot，就是你可以想象一下有个图，这个图一直在执行，然后你想要知道这个图现在，因为你又可以打断点，那么你想知道这个图现在执行到哪个片段。那snapp shot就是这里的snapshot，就是去获取到当前的这个状态的快照到哪儿了。然后next就是我下一个要执行的节点是什么。因为当你引入了这个断点之后，你要再调一次，你才能够去让这个图继续执行。就跟我们在IDE里面用断点是一个逻辑。所以这儿我们可以看到这个中断之后，他的下一个就是tools，tools就是我们图里的这个tools。
	好，那我们就继续执行，当然这个snapshot的value就是就这个啊就我们现在的这个状态是在最新这这是我们最新的这个快照的状态。Manual的这个message，然后最后一条输出出来结果就跟这儿是一样的。然后大家看到它其实是一个序列化之后的结果，但这个pretty print，它会把它打印成这个样子，我们接着再往下。继续执行。继续执行是从这儿开始的，然后two message这个是他去调了真正的two，然后有两个这个U21关于grab的研究可以参考以下两个资源，这个就执行完了，就a message，因为这个AM message里面没有to cose，所以它就到end了。这个逻辑大家应该捋顺了。
	理解了这个graph之后，当然也可以人工的去修改结果，通过update state方法去更新结果。就相当于我本来这儿要调搜索引擎，我不调了，我直接给你一个结果给到AM message。因为反正它是手动封装成的toll message，那么这个地方也是一样的，就可以用这个方式去操作，它就会把这个就graph就是graph的update state方法去手动去构造，这样也是没问题的。因为本质上我们的这个tools返回给他的就只是一个two message，作为它的一个输入的state，作为它输入的一个参数。那我现在手动去构造一个two message就OK了。无非是说怎么给他，用update state方法去给它就可以了。
	然后我们假设要查看这个chatbot的这个历史对话，要怎么查看呢？就直接给大家看啊，其实可以通过各种各样的筛选机制的方式去做。简单来说是这样，就是你知道了这个一个图执行完了之后，它的状态是保存下来的。并且我们其实是可以通过现成的ID去区分不同的对话历史的，就它的这个memory这个历史的那现在你就可以去把它的历史上的这个特定线程ID的所有的状态拿出来，拿出来之后，再去通过这个便利的方式去获取到他的所有的信息，这是一个比较常见的如果你想不用nice miss你，你就是嫌麻烦或者怎么样的这也是一个叫什么呢？
	这个下册，那就没有这个nesmith工具的时候，你想快速去看的一种方法。就算你没有配置这个next miss相关的环境变量，你就只是用nw它也能打印出来。但它显然没有这边好，是因为这个next mix已经做了很多结构化的显示。并且state并不等于它这个聊天记录或者说工具的执行记录。因为这个state其实就是我们在上节课也提过，就是每一个节点它的执行输出，然后这个执行输出它不一定是有逻辑的，它可能有可能是东一下西一下，但它都会被存在那个线程ID里，甚至有的线上ID管理的不好还会混淆。所以你单纯通过这个是比较难受的，是那也能过滤出来一些信息，就是我们刚刚看到的这里的分两次执行的信息，就中间打断了一下，下面都在这一次性能看到，然后这个是我们手工手动去给他的设定的，就我们用这个手动人工去介入。
	Update state进去的也在这个fd 3里面，因为都在这个config。所以其实就总结一下，我们把这个check box怎么样去实现咱们的所谓的这个图的定义。然后增加memory，然后我们又增加对，在这又增加了这个手动的结果。我们觉得无论是用工具还是模型生成结果可能都不满意的时候，其实都可以通过update state方法来进行操作。这儿我们只是把to message封装成了一个手人来定义的手动定义的一个消息，然后给到下一个节点。所以你想象一下，其实这个地方我们也可以给它封装成一个AI的message。
	假设我们对这个结果不满意，我们其实也可以给chatbot这个节点加一个interrupt after。然后这里就有一个interrup after等于chatbot。然后我们可以对这个check word的这个内容再进行一些手动更新，或者像我说的这个FAQ的介入，然后去刷新这个大模型或者优化大模型生成的结果。这都是一些可以去扩展的，然后都是通过update state方法就可以了。这个就大家可以去自己去研究或者去做对应的扩展。好，那么这个就是我们的ng graph chat board开发指南，就我们去构建多轮对话的这个机器人，然后看看对。
	也很奇怪，看咱们还有没有一些别的关于chatbot的问题。我看了一下时间已经十点了。我们把这个多智能体协作和跟grave相关的一些其他内容，我们再放到周三那节课再去给大家详细讲。因为这个确实是很重要的基础的开发框架，不用赶时间去去去折腾，一点一点把这个基础打扎实。现在看来大家对于chatbot这个开发指南有没有什么问题来交流一下。
	这个突兀的方法可以自己写一个给他吗？比如自己写一个搜索引擎搜索的功能，你自己怎么写一个引擎搜索的功能，你爬虫吗？这个同学你这个思路很好啊，但我觉得很难实现，你要自己写一个搜索引擎。你还是要干什么？
	然后开始问那个工具的这个同学，community你很多，对。如果你只是测试用的话，那你mock一下就好了。你那个node你可以就叫tools，但是里面执行的逻辑你别去调不就完了吗？是不是因为你执行的逻辑还是那个two node来做的？同学你想想，就是你如果想要使，你就在这里面不要去真的调用，你在这儿就mock一下不就完了吗？那个同学问测试不是真的调用的话，在这儿你别调就完了。
	大模型没有记忆，有同学可以复习一下应用开发的课程。然后再回到刚刚说的那个搜索引擎的工具，这里有很多。
	就我们刚刚看怎么来的，这是time research。你就点它的上一级，就是所有的search，并我们以前用的这个google，包括google的这个super这PPI，这全都是你就点一下就可以了。这链接就是这儿过去点一下上一集tools就可以了。大家多看看这个文档，我们课程时间毕竟有限，讲的都是精华，不可能去讲所有的API对。
	Memory有存储上限。来来来教大家怎么看这个文档，当然这个可能得去nine graph的文档。
	哎。
	没弹出来。神奇。看看。
	In never a这里。
	这里有。如果我们要持久化，可以参考一下这里。
	刚才也没细写。这里有。对。就可以用这个。如果你想要结构化的存储，有sl light的这个server。然后如果你想要去用这个非结构化的半结构化的存储，也可以接MongoDB或者这个post gay。
	如果你指这个不想要在这个是就是不想要浪费太多的空间，也不想去管理这些存储的话，可以用这个memory的。这个memory server确实是in memory的。这个server不能叫这个记忆。这个确实之前讲的应该是有一点小的，跟他的这个理解上面的不一样。对，这个memory确实是memory的意思，还不是那个记忆的意思。就整个记忆放在check point to这个key里面，它支持不同的value。然后如果是in memory的这个store，in memory的这个KV store就用它就好了。这里有对应的详细的解释，可以把这个加到。加到这里。
	这其实也有写。给他一个参考文档。
	也。对，是这里对有个参考文档可以去读一读。在这里实际应用当中可以替换成circulate server a server和这个post free server。这个是在内存当中对。好，还有什么问题？
	第一次两条，第二次四条，这个是你说哪个县城？有个同学说第一次两条什么的。用的smith的话，是不是把所有的数据都暴露给平台了？是的，但是你开发测试阶段应该没有什么生产数据。理论上应该用move的数据，但是你要想象一下，本来南这个南茜要构建自己的商业化壁垒，所以他用这个玩意儿。而且我觉得这个问题其实你不用太纠结，因为你想象一下，你用GPT不也把数据给到OpenAI了吗？对吧？理论上这个开发测试阶段你都可以用脱敏的数据。
	可以优化，你可以自定义to，可以自定义兔偶，用兔子装饰器就好了。这个是应用开发课里面教过的，你稍微收一收，这个图案装饰器。看大家还有什么问题吗？关于这个开发指南，然后homework在这里，我这边再写一下。看来现在只能做第一个homework了。这个时间就是我们开始在notebook里面看到的，就运行和测试第一部分的聊天机器人，然后找到一个其无法回答正确的事实性问题。第二个就是使用联网查询的工具，然后测试相同的问题对比生成的结果。周三的时候我们再来讲这个多智能体的实战，看大家还有啥问题我漏掉的。
	Update state必须要配合中断吗？是的，不然你哪有机会去update。你想象一下，你如果没有这个的话。你不就没有机会介入了吗？这个例子就你如果用过IDE的打断点你就理解了吗？就你没有在一个IDE里面打上断点，你一点执行的程序不就执行完了吗？那你哪有机会去介入更改它的结果？是吧？
	一上来就在state当中初始化一个大的文本背景。你为什么要把它放到state里面呢？你把它放到外部存储用的时候再去访问不好吗？你这样不是每一次大模型的调用都要消耗一堆的头肯，这不挺既浪费资源又有影响性能，还可能超过上下文，这个方案。
	大家还有什么问题没有的话，我们今天就到这里。然后大家可以试一试对应的这个内容。然后我们把周三的这个实战到时候再讲多智能体。好看看。
	好，没啥问题。我突然发现最后一个问题，都是六分钟前提的。行，那就大家在群里再讨论，感谢大家，时间我们就先到这里。