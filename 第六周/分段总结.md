00:49 - 使用Nine Graph构建反思机制与多智能体协作

本次分享将通过Nine Graph框架探讨反思机制的构建可能性，以及如何进行多智能体协作的开发。首先，回顾了LCEL的一些新特性及其在Nine Graph中的应用，接着介绍了图数据结构的基本概念，包括节点、边和状态表示。此外，还通过实战项目如chatbot和marty agent的开发，加深对Nine Graph基础开发的理解。最后，讨论了多智能体协作作业的讲评和可行方案，并介绍了OKAI model的发布及其对游戏规则和玩法的影响。

05:23 - 大模型与Agent的未来发展趋势

对话讨论了O一模型及其与GPT系列的不同发展路径，以及大模型如何可能影响Agent的未来。提到了O一模型的访问次数限制的调整和其不断优化的inference效率。进一步探讨了Agent的核心构建要素，包括拟人化角色和岗位设计，并引入了反思机制来确保Agent能够有效协作。最后，指出未来Agent的发展将趋向于更像真实公司内部的角色分工和工作流编排，强调即使大模型变得强大，基于角色的Agent仍有其独特的价值和前景。

09:44 - 大模型驱动的Agent开发技术总结

本次讨论重点介绍了大模型驱动的Agent开发技术，特别是nine grass agent的开发过程中的三个关键要素：prompt、大模型（LLM）和工具。通过回顾从ChatGPT发布以来的发展，探讨了大模型应用的快速迭代和技术进步，特别是从单纯的LLM应用到结合工具（如搜索引擎、GitHub Client等）的联网ChatBot的演变。此外，还强调了提示词技术在工具型Agent，如GitHub Setting Now项目中的应用，展示了如何通过设计特定的prompt与大模型相结合，以实现高效的信息生成和处理。整个讨论体现了大模型技术的迅速发展及其在构建功能强大的Agent中的重要作用。

16:47 - 构建多智能体协作：掌握核心要素

通过回顾和讨论，本对话深入探讨了构建多智能体协作的核心要素，即提示策略、大模型和工具的结合。展示了如何通过这些要素构建和定义各种agent，强调了无论agent的类型如何变化，抓住这三个基础要素是关键。此外，还提到了在不同开发框架中实现这些agent的具体方法，进一步阐述了理解这些技术核心的重要性以及如何应用这些知识来开发实用的AI应用。

19:46 - 构建Agent的核心能力与技术栈分层

本对话围绕构建Agent的核心能力框架展开，详细讨论了包括短期和长期记忆、工具集和行动能力在内的三个关键要素。通过代码实战和理论学习，阐述了如何利用这些能力构建高效的Agent。此外，对话还强调了技术栈的分层，包括模型服务和开发框架的作用，以及如何通过提升各层的能力来优化Agent的性能。最终，探讨了在构建复杂Agent时，如何合理分配精力和优化不同要素以达到预期的应用场景。

24:51 - 构建Agent的差异化竞争力：聚焦Prompt设计

对于开发者而言，构建Agent的关键在于找到应用场景并解决问题，需跳出细节和过程导向的思维，将Agent视为一个工作岗位或角色来设计。在技术生态中，工具和大模型是竞争激烈的领域，而提升Prompt设计能力则成为Agent开发者构建差异化竞争力的重点。通过合理设计Role、Task和Format（RTF），即使模型能力有限，也能通过优化Prompt获得良好体验。RTF是一种有效且有套路可循的提示工程框架，可以帮助提升Agent的能力，是开发者可以专注投入的方向。

31:10 - 市场智能体（Market Agent）的优化与角色细化策略

讨论了在开发市场智能体（Market Agent）时，如何通过角色细化和工具使用描述的明确化来优化其功能。特别强调了在与大型模型交互时，采用精细的提示策略和框架的重要性，以确保生成内容的质量。此外，还介绍了在新的反思智能体设计中，通过定义写作助手（Writing Assistant）等具体角色，进一步优化和明确了市场智能体的职责，以及如何在设计提示时避免过于简单粗暴的方法。

34:51 - 大模型发布对Agent应用的影响与未来展望

随着o one等大模型的发布，传统Agent应用的必要性和未来存在性引发了广泛讨论。大模型通过持续的迭代和增强，逐渐具备了原来需要Agent辅助的多种能力，例如联网、执行代码等。特别是o one在训练过程中引入了多步骤的深度思考（COT），使得大模型能够自行处理更复杂的任务，减少了对外部编排的需求。尽管如此，大模型并非万能，其训练成本高昂且存在特定任务类型上的局限。未来，预计会有更多追随者采用IF加COT的训练方式，但o one作为先行者，其创新方法和能力提升将引领这一领域的进一步发展。

44:58 - 大模型LLM的训练方法与未来影响

对话深入探讨了OKI公司基于LLM（大模型）的工作产出，特别是通过RHF加COT的新型训练方法显著提升了LLM的推理和规划能力。这一方法通过引入强化学习和self play策略，使得大模型在处理复杂任务时展现出更高效和灵活的表现。此外，讨论还分析了planning agents在当前技术进步下的局限性，指出其设计基于大模型较弱的假设，随着大模型能力的提升，这种设计可能会被新的技术所取代。通过结合实际案例和学术论文，对话强调了未来大模型发展方向的挑战和机遇。

53:30 - 基于角色的市场代理设计与反思机制

长期视角下，基于任务的代理设计存在局限性，核心问题在于任务难以精确定义且不同能力的大模型在任务分配上有矛盾。因此，未来市场代理设计应从角色能力出发，明确每个代理擅长的领域，通过赋予特定角色任务和格式（RTF），并适配相应工具，构建高效协作模式。这种基于角色的代理设计适用于从小型创业公司到大型企业，确保任务分配基于角色而非单一任务。此外，引入反思机制，通过生成者和反思者两个代理的互动，前者生成内容，后者提供建设性反馈，以提升生成质量。这种模式优于仅规划和执行的模式，更稳定且可控。人机协作是关键，通过在反思过程中引入人类干预，可显著提高模型性能并产生有价值的训练数据。课程实战部分将通过构建反思机制的智能体，进一步探索这一理念。

01:00:24 - 大模型与Agent开发技术的未来趋势及问题解答

本次讨论回顾了Agent开发的三要素及其核心，指出市场Agent（Market Agent）是未来的发展趋势，单个Agent的功能将逐渐被大模型覆盖。讨论中强调了拟人化设计的重要性，并解释了如何通过多用prompt框架，如RTF，来提升Agent的能力。此外，讨论还涉及了O One在大模型训练过程中的贡献，以及如何合理使用不同规模的大模型以适应特定场景。最后，针对如何优化小模型的提示词提出了建议，强调了Agent工程师不仅需要掌握提示词技巧，还需要熟悉工具使用和开发框架，以实现高效编排。

01:09:34 - 构建具有反思机制的智能体

本对话详细探讨了如何使用n graph框架构建具有反思机制的智能体，强调了这种智能体不仅仅是一个简单的应用程序（agent），而是在技术层面包含多个子agent的复杂结构。通过定义两个主要的agent——写作助手（writing assistance）和反思智能体（agent two），实现了一个迭代改进的机制。写作助手负责生成内容，而反思智能体则评估这些内容并提供具体、可量化的改进建议，促进内容质量的持续提升。讨论中还提到了如何精确地编写提示词以引导大模型执行特定任务，并通过具体实例展示了反思机制在多轮迭代中对文章质量的显著提升。

01:28:37 - 反思智能体提升写作助手内容创作效率

通过使用反思智能体，显著改进了写作助手的内容创作，展示了生产力的提升和内容工业化的制造能力。反思智能体提供了具体的意见和建议，如增加背景信息、使用不同的语气等，帮助内容生成更加丰富和有趣。经过多轮迭代，生成内容的质量不断提升，评分也相应提高，最终版本虽有微调，但整体结构已趋于稳定。同时，讨论了使用特定模型（如nama 3.1的8BIT版本）时需注意的限制和处理方法，以及如何在实际操作中进行更详细的体验和了解。此外，反思智能体的代码已提交至课程项目供学习者使用。

01:33:29 - Homework任务详解：扩展反射Agent以执行通用任务及代码生成

本次作业分为必做和可选两部分。首先，要求通过扩展课程中的reflection agent实例，使其不仅能撰写文章，还能执行更通用的任务，如编写代码和生成报告，例如GitHub snail的报告。对于有余力的同学，建议在完成基础任务后，进一步尝试使用扩展后的reflection agent生成代码，具体目标是实现一个新的client，新增信息渠道并配备相应的prompt，以实现信息的抓取、汇总和报告生成。

01:35:44 - 利用反思机制和私有化部署的写作助手智能体

本次课程重点讲解了一个结合反思机制和欧拉玛私有化部署的写作助手智能体。通过在课程项目中使用的Jupyter文件，详细介绍了如何安装和配置所需环境，包括南欧拉玛的包和环境变量的设定。特别强调了使用私有化部署的欧拉玛模型以减少token消耗的重要性，以及如何选择适合的模型版本，如lama 3.18B指令微调版本。此外，还探讨了如何通过chat欧拉玛接口调用本地部署的模型，以及在统一机器上使用默认端口的建议，以便更高效地运行智能体。

01:42:22 - 使用大模型进行创意写作与评估的实践

对话详细介绍了如何使用特定的大模型进行创意写作，包括设置模型参数如token最大值和temperature值，以增加生成内容的多样性。通过实例演示，展示了如何参考经典文学风格改写其他作品，并使用GPU资源监控生成过程中的资源消耗。此外，还介绍了如何定义智能体（agents）作为“老师”角色，用于评估生成的内容，以及如何通过异步方法优化长文本生成流程，避免阻塞和超时问题。最后，讨论了根据模型上下文限制设定最大轮次参数的重要性。

01:50:31 - 评估AI模型性能和Token消耗的方法

讨论了通过nice miss项目中的reflection agent运行次数和消耗的token数量来评估AI模型性能的方法。具体介绍了如何计算time to first token以及如何通过state message的数量控制循环次数，以确定模型运行的终止条件。

01:54:42 - 多智能体系统实战：高亮代码及GPU使用详解

讨论了在多智能体系统实战项目中的代码熟悉度和具体实现细节，包括使用高亮代码、加节点和条件点、以及使用memory server的方法。强调了使用nice miss进行编译和可视化的重要性，并介绍了如何通过Python装饰器实现计数器功能。同时，探讨了大模型如GPU的运行和使用情况，包括偶发的GPU清空和重新加载问题。还提到了如何通过调整提示词来优化智能体的表现，包括如何利用GPT4或GPT4O来改进writing assistant的prompt，以实现更通用的功能。最后，简要提及了martian agent的迭代和解决方案作业的评价。

02:06:38 - 使用Nine Graph实现多智能体协作的更新方法

讨论了通过更新Nine Graph代码来提高图表生成成功率的方法。重点介绍了如何通过给智能体添加特定的注意事项（customer notice）来控制其行为，避免自作主张生成代码或提前给出结论，从而优化多智能体间的协作流程。详细解释了研究智能体和图表生成器智能体在处理任务时的不同注意事项，以及这些更改如何影响整体流程。

02:11:42 - 多智能体系统作业讲解及优化

本次讲解重点讨论了在2000年至2020年间美国GDP数据查询和图表生成的多智能体系统作业。讲解中详细分析了系统设计的各个方面，包括如何通过定制的prompt来明确各智能体的职责分工，避免生成代码，以及如何优化工具的使用以减少风险和提高效率。此外，还讨论了在命名和工具调用过程中的注意事项，以及如何调整代码以确保输出的准确性和稳定性。最后，鼓励大家参考新版本的解决方案，进行讨论和提出更好的解决方法。

02:18:32 - 大模型微调与反射机制的讨论

本次对话围绕大模型的微调、反射机制以及模型精度等问题展开。讨论确认了generator和reflect使用的是同一个大模型，但通过replay机制可以提升性能，类比为“当局者迷，旁观者清”的逻辑。此外，还解释了为何没有一开始就使用满74的16GB显存，指出这是由于默认模型并非16位精度，而是采用8位量化以适应不同GPU显存大小的需求。最后，强调了实践的重要性，鼓励学员通过动手实践来深入理解模型和代码。
