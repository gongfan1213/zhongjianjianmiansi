	好，我们接下来了解从GPT1到GPT3这两三年的时间一路风云变幻是怎么回事？为什么叫风云变幻？其实回看历史，这两三年一路走来，OpenAI的GPT它并不是当时的这个语言模型这个领域的研究的主角，它不是舞台中央的这个角色。让我们一起来了解这段历史，探寻一下技术是如何迭代到今天的。
	首先我们知道预训练语言模型这种方法，在2018年的时候，由GPT和GPT1和bert发布出来之后，是非常受到大家认可的，并且迅速的成为了一个新的研究方向，它的这个方式我们其实现在应该都已经很熟悉了，对吧？它通过未标注的数据，大型的语料，未标注的数据，比如说微基百科这样的一些语料去构造出了一个语言模型。在这儿大语料构造出一个语言模型，这个语言模型本身我们叫预训练的语言模型。这个预训练的语言模型针对下游特定任务的数据集，比如说这个问答，我们的FAQ，我们的这个销售，它都有一些特定的话术。针对这种特定的任务的数据集，我进行模型的微调，会去把这个大语言模型的大的参数固定之后微调去稍微调一调它的小的模型参数的值，调整范围就比较小，这个叫微调，去微调这个模型，然后最终在测试集上面去验证我这个微调的效果怎么样。如果不错的话，它就作为我们最终的模型去使用。
	这个是一个典型的预训练语言模型的范式。在GPT e刚刚发布出来的2018年中的时候，这是非常流行。并且到今天为止也都是一个非常流行的范式。就是怎么把这个语言模型的预训练做好，让它的语言理解能力无限的强。这个要做到预训练语言模型，通常来看有三种网络架构。
	一种就是我们上节课讲的bert，它是一个ender为主的编码器为主的这么一个预训练的语言模型。它主要是用来处理理解这个输入的信息，像我们说完形填空，因为它从左到右，从右到左，它两边都在学。他对这个语言的理解，对整个句子的语义的提取能力非常强。所以他在这个理解任务上面，比如说文本分类命名实体的识别上面，在18年到2020年这三年这个大的区间里面做的非常好。
	我们熟知的这个GPT，它其实是一种典型的解码器为主的用于生成的这种模型。那它的特点是什么呢？第就是他在训练的时候，就是你给我上文，我生成下文，就是你你像我们这样鹦鹉学舌，就这个逻辑天天我的这个主人天天在那说你吃了吗？我吃了，你吃了吗？我吃了。然后等到有一天你朋友到家里来的时候，这个女朋友问你吃了吗？然后这个鹦鹉就回答他，我吃了。因为天天接受这样的一个训练，他他的他的从训练语料开始，它就是用来干这个事儿的。所以它非常适合用于这种深层性的任务。
	当然我们刚刚举的是一个简单的例子，我们讲到预训练模型核心就是大量的语料，然后我遮住下半句给你上半句，用这样的方式来训练。然后还有一种方式就是我结合了这个编码器和解码器的优点，这样的一些网络架构，我们就叫编解码的这种，或者说叫encoder decoder的这种结构。这样的一些模型其实也很典型，它的更好的能做这个对齐。因为他在训练的时候，他同时去训练了这个编码器和解码器，他把这两头的知识对齐的特别好，所以它适合做什么呢？做一些机器翻译，文本摘要之类的任务。然后这一类模型以T5和bark为代表。
	所以我们简单来看，预训练语言模型其实可以分成3种不同的技术路线，以verb为主的encoder，以GPT为主的decoder和以T5为主的encoder。Decoder这种结构，这三条线都有很多的人在不断的研究。目前看下来decoder这种结构GPT它在当下来看取得的成就是最高的，GPT4现在的能力也仍然是远远超过其他的大语言模型。但是不是decoder就是最好的方式，目前我们还无法下这个结论。GPT这个模型的迭代，包括OpenAI本身花了大量的精，不只是网络架构层面的。为什么现在讲大语言模型，你的成功不是一个单纯的数据加算力的成功，有大量AI工程的设计在里面，就是因为这个原因。
	好，我们再看一看2018年的语言模型，当时其实有一个很有意思的现象，就是大家要想象一下，那是五年前，那那就是五年五年之前。五年前其实我们还不知道大语言模型能不能做出来。甚至2020年的时候，GPT3发布的时候，大家还认为那个就昙花一现。GPT3的能力没有那么强，但他花了那么多钱，花了几千去训练一个模型，居然没有拿到结果。那在当下的这个经济环境里面是无法接受的对吧？
	但是在18年的时候，OpenAI继续笃定这个方向，然后从GPT e一路做到GPT3到GPT3.5。我们看看18年的时候，最早发发这个一篇文章，在18年非常有意思的这篇文章是由AI图发布的，它叫ELMO illam o这篇文章是18年春天发布的，接着几个月后夏天GPT1这篇文章发布了，然后在18年的十月份bert发布了。大家还记得我们上节课讲这个语言模型到大语言模型这个论文发布。当时左边那幅图就是18年10月份，bert发布的这个时间增长的一个曲线。
	那么在那个期间，其实我们能看得到有两种非常典型的去学习语言模型的方式。一种就是这种没有方向的，就是单向的。我们在上节课有讲过单向语言模型就是主流，包括这个EGPTE，还有其他的一些transformer等等，都是这样的方式。那么bert做了一个很有意思的尝试，就是双向的，从左到右的看，从右到左的看啊，它能够做到更好的上下文的理解能力，把语序什么这样的一些障碍都都相当于掌握了，我们具体来看这三个有代表性的模型。
	UMO其实它是一个什么模型？它是一个深度的基于上下文来做word embedding的一个模型，是华盛顿大学和AI two这家公司一起合作发布的文章，它的特点在于哪儿？我们学习bert之后，知道bert是两头一起学。但ERMO它很有意思，它首先它是一个词嵌入的模型，所以它对标的是什么？是word in word to vector global vector这样的模型是用来做嵌入的。所以你能看到右边这部分是它的一个应用架构，它自己是一个retrain的invading。它不是一个retrain的语言模型，不是一个预训练的语言模型，它是可以为其他的模型服务的一个pretend embedding。所以他会去对接一个已经存在的这个模型的网络。
	它前面是它的这个东西作为一个in bedding的一个效果，那embeds ging的核心就是把我们看到这些语言文本变成一个向量，这个向量里面包含了它的语义，这个语义能够去做一些相关的操作，去通过这些操作，比如说相加相减去表达出去，或者说去提取出这个语言当中的语义。就比如说word to wake的最经典的例子就是这个queen和女人woman，还有包括这个king和man之间去做差，能得出这样的一个结果。比如说这个king减去这个man和king减去queen等于men，或者说king减去queen加上man等于woman，大家想象一下那个公式。
	其实是把男性和女性，包括国王和皇后的信息，他们做差的时候，其实得到的这个本质差距就是男女之间的性别差异。这是一个非常经典的例子，包括这个国家和首都之间这样的一些例子。它是可以去证明in bedding的效果好的话，是能提取语义信息的。但是world to rect其实它本身不是一个基于深度学习的方法，它是一个基于统计机器学习的或者说它是一个深度学习方法，但它网络还不够深，没有用这么多上下文的信息，他用了这个gram或者说联合上下文的磁带模型，但是没有用深度神经网络。
	ELMO在18年的春天发布了这个模型，其实是很有意思。他从左到右学了一个LSTM这个网络，然后从右到左又学了一个，然后他把它们拼起来变成一个更大的，就直接拼起来变成了一个更大的结果。然后这个结果把这两个东西作为一个完整的这个词向量，相当于这个词向量其实包含了两个词，一个是从左到右正序来读，一个是倒背如流的倒序来读。但是都是同一个词，相当于你拿到的这个词向量是两个，一个是正序的，一个是逆序的。
	针对这个你给下游的模型去做处理，当时的效果是蛮不错的，并且还有人在基于这个做进一步的研究，但是他跟我们的学过的这个GP学的这个bert就相当于临门一脚。第一他干的不是语言模型，第二他没有把它直接一起学。是他当时做的一个成果，很有意思，抛在这里是给大家去理解。18年初的时候，在学术界大家去怎么研究这些成果的。然后其实这个研究方式，包括这个套路，其实学术界也没有那么多夸张的黑盒子那么难，都是不断的把一些已有的成果做叠加。
	为什么叫站在巨人的肩膀上？也这个意思。那GPT做了什么事情呢？GPT也是站在别人的肩膀上。我们上节课学了transformer，这边是一个encoding的一个六层的一个结构，这边是一个decoder的一个六层的结构。Encoder当中的这个末尾直接连接了每一个decoder。大家还记得这个网络的话，还有一个muti head attention，这边也是marty head attention。但前面多加了一个mask的market head attention，就这么一个结构。
	那GPT1干了什么事呢？GPT1把这个transformer的6层结构直接干到了12层。然后接着把这个transformer里面的这个自助机制进行了更大规模的训练。因为transformer本身是提了一个网络结构，然后这个网络结构在基准测试上超过了之前的encoder decoder的最好的实验结果。GPT e OpenAI他们就想是，那我就把你拿过来用。你既然这么好啊，google发布的很靠谱，干到12层，然后再去特定任务上去做环境。发布出来之后效果还不错，确实在当时的基准测试上，又做到了一些新的提升。这个就很吊诡，大家可能就觉得我靠这也算创新，你把人家的论文拿来这搞的更深一点，搞到12层就叫创新了吗？
	这个就是我们看到的这个T1的网络结构看这幅图的话就很清楚，第一他做了什么创新呢？他把左边这部分大家还有印象。看这个transformer结构的话，左边是有一个encoder的部分，右边是decoder的部分。我刚才有讲过对吧？他把这个结构左边这部分直接就丢掉了，然后直接使用这个mask的mart self attention。
	这个我们讲过，其实就是它的much attention，然后接着做了一个layer law，就是一个正则，简单理解就是一个正则化。最后在下游去做这个find ti，就是我特定任务去做find ti，所以这个范式我们讲过，bert去强化了这个范式，提出了这个范式，但是其实是GPT1那会儿没有那么多关注，因为open a是一家新公司新成立的公司，马斯克站台的。然后一个初创公司做了一个成果和google做了一个成果，它的关注度是不一样的。
	然后那会儿GPT也不火，因为GPT大家现在整明白了，到现在为止应该整明白了。GPT的意思就是一个通用的预训练的transformer，他都不好意思叫语言模型，这就是GPT的含义。Generative print transformer它也不叫pretend embedding，也不叫retrain的language model，它就是一个retrain的transformer。因为它很清楚，它就是借鉴了transformer。OK这就是GPT这篇第一个第一代的模型。然后再下游去做各种微调，然后得到了一些比较好的结果。这是18年夏天他们发布的这篇文章，很有意思，就这么一个文章。
	当时其实很多人是觉得没有什么新意的，就从学术的价值来说没有什么新意的。然后你做这个下游的任务的时候，这个下游任务这里有三类，包括这个分类蕴含相似这些任务其实都是一些基准测试，然后你也没有得到特别高的提升，所以大家关注不多。然后我们看得到它的这个提升，我们最下面的这个叫fine tune的transformer LLM，就最下面这行其实就是这个GPT1拿到的结果没有特别高的一个提升就还行。
	然后我们再看一看这里还有一个叫ELMO的，就是我们刚刚讲的这个这个embedding的方法。它跟别的一些语言模型，当时也拿到了很好的成果，其实跟transformer差不太多。大家看这个SNLI这个基准测试的话，他是挑了一些不错的基准测试。这几个基准测试简单介绍一下，就是基准测试就是相当于高考题一样，用来看这些模型好不好的。但随着模型本身的能力变强，那么可能我们的题目也会越来越难。所以大家要乐比较客观的去看待这个基准测试，它就是用来做区分度的。刚刚那个表格里面，GPT e的论文里面写的一些基准测试，在这边有写。
	其实简单来说就是在18年的时候，语言模型还不够强，还是一些简单的自然语言的任务，包括推理，推理就是用来判断这个两段话之间的一个关联关系，是蕴含关系，是有自相矛盾，还是完全无关。就像我们看bert的这个训练手这个方法的时候，我去打这个标记，下面这句话跟上面这句话有没有关联，有没有蕴含关系等等。类似的还有像特定的科学领域的一些教材，是一种开放的自然语言的推理任务，包括score的数据集做出来的基于问答的一个自然语言推理任务，这些都是用来检测你的语言理解能力的。
	因为GPT也好，party也好，在那个时间节点他们都做了一个很重要的点，就是提升语言的理解能力。所以更多的这些测试都挑了一些理解句子之间的逻辑关系，和其他的比较细节的比如说蕴含矛盾无关性这样的一些语言理解能力的测试，这个是GPT1做的一些基准测试的一个介绍，大家有兴趣可以再详细的去了解这背后的基准测试。GPT本身做了一些什么样的成就？第一，它是一个很成功的decoder。这条路线我们还记得三条路线，encoder，encoder和两个都用的encode decode。
	18年的GPT是一个在只用decoder这条思路上非常成功的一个做法。他用了12层的这个transformer的decoder的架构，然后用了1亿的模型参数，今天看来很小，GPT3是1700亿，它只用了1.1亿这么一个模型参数。用768维的一个隐藏层和3000维的一个fit forward的隐藏层。这是讲它的它用的12层的这个transformer decoder的内部结构，它的这个bad pair，就它的这个字节编码的长度，用了4万个encoding。这些其实是一些它的基准数据。
	这个是很早以前，就是在18年17年穿sumer出现的时候，没有人想过直接用transformer的decoder能达到这样的一个成果。所以在那个节点，OpenAI是做了一个很很有意思的尝试，然后这个尝试拿到了一个好的结果。然后他当时的训练集是用了7000本不同的书，来自于这个book cost，books cops就是来自于这个cops是语料训练语料的意思，来自于一个特定的训练集。然后这里面包含了一些比较长距离依赖的这些语句。相当于我给你在书里面去描述内容的时候，通常不是上下文高度关联的。有可能我会用一个代词去引用几个段落之前的内容，这个是它的一个训练集的一个特点。
	所以从这个视角来看，GPT1第一是一个初创公司，OpenAI刚刚成立不久的一家公司发布的一个论文。然后拿的结果不算特别好，但是还是在一些特定的测试集上取得了最好的结果。然后它的架构极其简单粗暴，就是把transformer的decoder捞出来，从6层加到12层，就取得了这么好的神奇的效果。为什么说transformer是变革的里程碑？是这种基础模型加find tuning下游任务find tuning的这个基石就来自于这里。GPT1到今天的GPT4，其实都是沿着这个思路在不断的去做。
	那GPT2做了什么事情？GPT2做了一个很有意思的尝试，他发现这个效果这么好，穿former挺好用的那我能不能赶得再离谱一点？之前我是一个1.1亿的参数，我直接干到15亿，干到它的12倍的这个模型参数的体量，把模型变大12倍，我把训练数据也给它加多一点，就是我模型变大了，我消化能力变强了，所以你能给我喂更多的数据。
	他就只干了这么一个事情，就是为什么那会儿大家看不上OpenAI的这些研究成果，就觉得你这个不能称之为论文，你有什么学术贡献，你就是按照我们现在有一些同学，其实在这个公司里面去看这些有些看不上的这个交付成果，就觉得你也没做啥贡献。你就把前人的成果复制粘贴了几遍，你你你就捞出来了。你你你你还说你做的这个贡献特别牛逼，那是不认的。但是这个过程当中大家要想象一下，当然我们不讨论工作当中的事情，他直接把模型变大，把这个数据为的更多这件事儿还是很有勇气的。并且他一条道走到黑对吧？然后去干这个事情，听下来好像是特别简单的，但其实不是的。就是你想象一下你的胃口要变成原来的12倍，什么都不用做吗？肯定不是的这是第一个误区就是GPT2有它的贡献，这个贡献是它的AI工程方面的一些设计，包括模型上面的一些小的一些技巧。
	然后第二他还提出了一个很重要的思想。就是之前我们都想说用pre train加下游的fine two，那无论如何你不同的任务还是得find two，对吧？而且在这个GPT1的架构里面，它的这个翻译two的部分是直接甩到模型后面来的。那他就在想这么多任务都要翻译成，有没有可能我把数据喂得足够多，我就不需要翻译成了。我能把这两个事儿一起学习，就是不要变成两个阶段的事儿，我把这个反应痛的事儿直接在我一次学习里面就一次性搞定了。这个是他当时很很重要的一个思想，就是GPT2的一个在思想方面带来的一个进步，也是后面GPT3沿着这个思路做出来的一个很重要的一个原因。因为他们那会儿就有这样的一个想法。
	我们看一看，其实这幅图其实是当年这个GPT3发布没多久的时候，2020年的时候，整个大语言模型研究的学术界和工业界的一个主要图谱。我们能看到bert是毫无疑问的核心，这个bert占据了它开枝散叶，它就是开源的，它占据了非常多的地位，很多的人学习他参考它。我们今天看到这个ELMO，它是做emb ign的，通过深度学习把embedding n的效果做好。然后中间有这个bert，bert的开枝散叶了很多，包括这个多语言的，然后我们的这个多任务的生成的，包括加知识图谱的多模态的，然后encoder decoder的就生成了T5这个方向，包括像这个MOE的，就混合专家系统的出现这个switch transformer。这些其实都是我们能看得到在大语言模型这个领域的研究，研究bert是非常主流。
	GPT其实是旁边的一个小兄弟，没有多少人关注他，大家对它的评价也不高。这个图是清华的NLP的实验室，就是这个质谱实验室出的这个图啊啊啊一个小分支做什么的呢？一个小模型，小模型怎么变成GPT2的更大的模型，更多的数据，GPT3是怎么来的？Larger更大一点，它没有什么大的好的标签。大家看这些标签生成知识图谱，跨模态编解码，网络结构larger，这是大家对当时GPT3 2020年的一个理解，就GPT这条路是走不通的，你们现在没有什么创意，你们江郎才尽定了OKI不行，就只会搞大模型。这个大模型结构都不怎么变，然后知道GPT3怎么来的，GPT3确实是为了更多的数据，当讲不讲他确实是这么干的。
	我们看到GPT2数据到了40GB了，GPT3进一步增加了数据，增加了什么呢？增加了互联网的数据common co这个爬虫项目，有4100亿的tokens用来做训练，他当然进行过一些筛选，这个占据了他GPT3占60%的训练语料。然后包括之前的这个微基百科，他把这个书的数量又变多了。然后还加了各种互联网的文本，包括像redit这种问答社区。然后这些数据为的更多了，这是GPT3的数据，语料变多了。然后同时它的这个学习过程当中，模型变得更大比GPT2又大了100倍。大家回想一下，GPT1是一个一亿的模型，GPT2是一个10亿的模型，GT3是一个1750亿的模型，将近2000亿了。相比GPT2到GPT1的这个变迁，从十倍又变成100倍了，又高了一个数量级，所以大家看不上就在于这。
	但是它的效果还是很好的，就GPT3的效果还是蛮不错的。当时在各种这个基准测试上拿到了一些很好的效果。但当时因为这个模型变得特别大了之后，效果也还很好，就引发了另一个问题。就是大家知道训练一个GPT3的模型很贵，是一个几千万的成本训练出来的模型。你说你还能随便去做模型微调吗？你要把它跑起来的，这个成本就很高。今天我们都知道要搞大模型的公司花很多钱的，因为这个GPU卡就需要不少一个1750亿的参数。
	你要多少GPU的显存才能把它加载进来？加载进来之后你要怎么样去运行和训练它？因为数据加起来才能消耗更多的显存。那那这个成本这么高怎么办？所以GPT3提出一个非常重要的观点叫in context learning。就是在上下文当中去学习。这个东西出现之后，使得我们现在去学习这个大语言模型和使用大语言模型进入了一个新的高度。
	从GPT3这个时刻开始我们就会发现我们以前的这个传统的方式去改变一个模型的成本很高。以前都用find，但是现在通过这个in context learning，其实这就是这个提示词prom prompt的一个前辈前身，他当时想了一个方法，就是怎么样能够不改变这个语言模型，预训练的语言模型，还能按我的要求去拿到结果，去生成一些我想要的内容。这个就是crop t的这个前身，它叫做从一个特定分布，它定义好的特定分布里面去抽出一些示例，然后把这个事例给到我们的大语言模型作为输入这样就不需要去用这个梯度下降的方式。我们学过深度学习同学都知道首先他说M仍然是一个深度神经网络，它的训练需要反馈的传播。然后去把我们的梯度下降的结果重新更新到所有的模型参数上，它成本很高。通过我们刚刚讲的这种方式，它就可以不用从分布中采样，然后给到这个模型作为输入。它能够给你打个样，那你就不用再去改模型了，那这样的成本就低得多，通过这样的方式，这个是GPT3的一个非常重要的贡献。
	举个例子是什么意思呢？就是比如说我想让GPT3去完成一个特定的任务，这个特定的任务是机器翻译。那我们回想一下刚刚的GPT e bert都需要针对机器翻译再去做find turning，然后才能做成一个机器翻译的下游任务的适配。现在GPT3学了这么多的东西了，模型又变大了100倍，一千多亿的一个参数了，我能不能不要去改模型就让你能有这个能力呢？可以，我给一些这样的输入。这里是一个英语到法语的翻译。我们学attention这一节课的时候，知道这个机器翻译是一个特定任务。腾讯最大的价值是把对齐和翻译这件事儿在一个网络里面去学了。
	GPT3已经走了非常远了，就是前进了非常多了。这就是从14年到2020年这六年的时间发展了非常多的技术。他不需要再去改模型，也不需要做训练了也不需要注意力机制了。在大规模语料里面，在这个大模型你都学会了。只是你要说清楚，你得让这个大模型理解你想让我干嘛，你得学会跟他沟通，从GPT3开始跟大模型学说学说话，沟通技巧就成为了一个重要的技能。
	为什么有提示是工程师？为什么有jasper AI这家公司？有这么多基于GPT3的AIGC的公司？就从那刻开始的。那么这个机器翻译我就直接给你这样的一些示例，thanks mercy, hello帮助。这样的一个事例让你理解。
	你看这里有三个参考案例，我其实是想让你干翻译。这个water这个词就会翻译成对应的法语，not这个词，我不太会念这个法语单词。然后那那通过这样一个方式，不用改变这个语言模型，模型不用变，运行起来给你一些示例，就给一个结果。是不是很像现在的ChatGPT了，GPT3时代2020年就做到了。
	那么income text learning具体是怎么定义的呢？我们在最开始这个课程里面有讲过meta语言学习的概念。其实在GT3这篇论文里面，你看他第一幅图就有讲语言模型的。Meta 2没他能力是一个非常关键的技能。像我们刚刚讲到的中间这个sequence to，这是一个语言翻译的例子。包括让他学会去做这个算术的例子，这是一个让他学会做这个加法，语言翻译等等。这些例子非常好的让大家理解，其实要跟大语言模型去交流，让他学会很多下游的任务。
	除了翻译以外，可以用in context learning，在上下文当中让大语言模型去学会这个事情。但是怎么学？这个income text具体有哪几类？在论文当中GPT3给了几种示例，一种叫做zero shot，就是没有参考示例。One shot就是一个参考示例，few shot就是给你一些参考实例，通常是不多于十个，这个是一个你可以认为是行规，或者说一个经验值不超过十个参考实例。
	那zero shot就很简单，我直接给你一个任务描述。比如说把英文翻译成法语。现在我们跟ChatGPT交流，ChatGPT交流的时候也会用这样的一个prompt。大家想一想，这个下面才是它称之为这个prompt，上面是这个任务描述。这个prom就是我们的这个cheese，它会给你一个法语的单词，那一个参考案例。One shot就是我给你一个参考案例，你这样看看，还能在参考案例里面学到一些格式性的内容。Few shot就是给多个案例。
	从这儿我们其实能发现，包括我们接下来OpenAI的这个实战的部分和南券的实战部分就会讲。为什么会有这样的一个in context learning，或者我们叫prom的learning的技术，很重要。因为我们光从这个事例，我们就能学会为什么OpenAI后面会做多个角色。包括最近我们看到OpenAI的GPT发布了这个customer的这个指令的手段，让你能够多个角色的去给他输入这个提示词。其实在GPT3这边的问题就已经有了，大语言模型的输入提示本身就是分段的，它各自的职责也不同。像这种任务描述task description，我们在OpenAI的GPT3.5或者GPT4这些模型里面都会给它设置为system系统这个角色的提示词。然后example可以作为它的一个参考，或者说在南京里面我们会把它做成一个memory里面的一个记忆里面的一个参考内容。
	Prompt的是这一次我要你干的事情，就像我们人去干活，我有上下文我就能干的更好。这就跟老师傅跟新手干活不一样一样。老师傅他有这些任务的描述，他曾经干过，他知道怎么干，那会干的更好。直观来说我们知道有参考实例通常来说比没有参考事例干的更好，这是一个直觉。那实际情况下是不是这样的？右边这个就是它的一个对比，就find你的一个情况，实际情况下就是这样。
	我们看啊这幅图里面有写，这是一个怎么看这个纵轴是准确率，横轴是给的参考的上下文。然后三个不同的颜色是指的不同级别的模型，基本上跟它的一二三代模型的规模差不多，就是一个亿、十个亿和1000多亿。然后这三根线就是不同的准确率。
	首先模型越大效果越好，这幅图非常明显。然后同时zero shot和这个one shot和这个few shot，one shot这一这个示例有一个明显的拉伸，就是我们在大规模的就首先这个income text learning在小模型上面效果不好，这是他要表达的一个意思。就是你要搞这个prompt learning，搞这个上下文的学习，给参考示例让模型的效果变好，一定得在大模型上面，小模型不行。第二one shot比这个zero shot要好很多，它有一个迅速的拉升，从10%不到到40%多，将近50%。
	然后few shot你给的这个参考示例，如果比较不错的话，它还能持续提升。但是你看他这儿就有一个上限，就你给太多的参考实例也不好。这个就是他在论文当中做的实验拿到的一个非常重要的结果。所以第一要用好这个提示词，工程要在大模型上用，最好给一些参考实例。
	然后我们再看看这幅图其实有一个很好的一个对比，是讲什么呢？第一它更多的去比较了，就是我们刚刚看到了有1.3B的，有13B的，有175B的，但是还有很小的模型，还有一亿多1亿左右的模型。从这幅图能够更直观的看出一个什么呢？第一位越大的模型是越好的。在2020年这个结论是成立的，因为那会儿还没有太多大语言模型上面的训练技巧，所以你看随着这个语言模型的参数增加效果会越来越好。
	然后我们的there a shot比起我们的fuel shot，是明显有一定的劣势的。就是你只描述任务，但你不给这个参考，那他可能是做的就没有有参考做的好。所以今天我们去使用ChatGPT的时候，也一定要用好这个技巧。我们下节课就会去讲这个提示学习。这个prom learning就是这样的一个意思意思，你一定要学好这个怎么样把我们的这个示例比较准确的给到大语言模型。所以我们最后总结一下来了解这个一路的风云变幻怎么来的。其实这三个模型大家都学完这节课应该理解了。
	为什么有人对open I有这样的一些风评，就是说大力出奇迹，没有什么技术水平。就是因为他一直在深挖transformer的潜力，把transformer decoder从12层到48层干到96层这GPT3，然后把这个模型规模从一个亿干到10个亿到将近2000亿。GPT4是48个2000亿，就是一万多亿的模型。这就是他的他的一个研究方向和他的一个思路。我们很难去评价这个有没有技术含量。其实懂行的人都知道很有技术含量。你自己做一个1000亿的模型试试，然后这一千亿的模型怎么能够训练的出来？在这么多的数据上拿到这么好的效果，这么稳定的生成结果，很考验水平。
	接着我们看它的主要贡献点，我们再回顾一下GPT1比bert其实发布的要早，bert提出了这个free training加find tuning的这个范式，但其实OpenAI更早，比它还要早三四个月提出了这样的一个范式。使得大家了解了预训练模型做得好，下游任务只需要很少的标注数据就能够去达到非常好的性能了。这在18年非常重要。因为以前是每一个下游任务都要整一堆的数据，那这堆数据就价值就不大了。
	GPT2提出了一个非常好的方法，他要用无监督的方法来把多任务学习做到一个语言模型，这就有一个雏形了。就是说我们能够把下游的任务直接融会贯通的在这个语言模型里一起去学了。我把多个任务都学在一个语言模型里，不然我搞十倍的这个模型干嘛呢？这个思想非常重要，直接就启发了GPT3。
	我把这个东西再相比于GPT1样，我扩展了1000倍1千多倍的一个大模型，然后训练语料也是增长了上千倍。然后我能不能就相当于我学通了，我已经是一个大学本科生了，之前只是一个中学生大学本科生了，我有非常多的通识教育的能力了。这个时候你只要问我问题，问的问题，你把任务描述清楚，你给我一些参考示例，我就知道你想要什么。这个时候其实就进一步去提升了这个语言理解的能力。这个GPT3的这个预训练的语言模型就能更多的去解决通用性的任务，然后它的解决范围也变大了，能解决文档级别的任务。
	他们的一年一个脚印，GPT31路走过来，非常不容易。这里我们这节课有很多的概念，我这儿再简单总结一下三个关键概念让大家能理解。首先in context learning，我们刚刚有讲就是给参考示例，让你带一个徒弟，你给一些你给他下发任务，你最好能给一些参考示例，他能学得好，这叫in contact earning，特指这种zero shot one shot short的这种给大模型的这种套路。那其中future learning就是一种in contact learning，对吧？
	那么什么叫proved engineering提示工程呢？这个其实就是我们最近几年在尤其是在ChatGPT出现之后，大家会发现，我只给参考任务描述参考示例是一种prompt的方式，是一种给大语言模型提示的方式。但是不是只有这种方式，当然不是，那proof的engineering就是指我能够设计很多个不同的方式。In context learning是一种方式，in context learning里面具体有几种吧？Zero one few shot 3种。是不是还有类似于像in context ling这种级别的手段来给很好的提示词设计，让大模型生成我们要的结果，这个叫proved engineering提示工程。
	那什么叫proved engineering？就是提示工程师，那他就是干这个事儿，就是好的。提示工程师是根据你的任务需求，我给你设计这个提示的这个模板，然后你基于这个模板能完成你的任务，这就是提示工程师要干的事儿。他们做的事情叫提示工程，目的就是能够不改变模型。我们不是不用模型的反应to，只是针对我的输入去做设计，然后把模型的输出质量提高。