	好，我们接下来讲transformer的崛起。为什么它崛起而且称之为里程碑式的变革呢？首先我们上一节课讲了腾讯讯mechanical就是这个注意力机制，他14年的时候发布的这篇文章，bandon和这个本就也是图灵奖的获得者本就然后他非常重要，对大语言模型来说其实本就做了很多的贡献。我们可以看看，在14年的时候，通过注意力机制打破了局面，让大家能够知道一个神经网络可以学两个任务，translation和alignment对吧？对齐和翻译两个事情。然后17年的时候，一篇现在更有名的这个文章出现了，叫attention is all you need，就叫你只需要注意力集中就够了。我为什么敢说出这样的大话，甚至未来所有人其实都这么干，然后当时这篇文章其实文章本身不叫transformer，文章提出来的这个网络结构叫transformer。这节课就让大家理解什么叫传输功能，价值到底在哪儿。
	上节课我们讲了很多关于注意力机制的一些基础性的概念知识，大家如果没有消化好的话，一定要去多听多看啊。它对于你理解整个大语言模型的发展脉络非常重要。然后我们再抽象一下注意力机制或者说注意力模型的技术有什么关键点，其实可以把它分成三个大的部分组成的。
	第一个部分我们叫做neural architecture，就是我们的神经网络结构。那上节课我们有讲encoder，decoder, 这是最典型的一种结构编解码。那编辑编码器、解码器这个结构，其实在机器翻译里面用的很多，其他的很多场景也都有用。这个编解码的这个网络结构是很多很常见的。然后在上节课我们还讲到这个编解码用在了机器翻译上，这个就是叫做我们最低机制的一个应用。它具体解决什么问题？那具体解决问题什么问题，就会涉及到我到底输入什么数据类型，输出什么什么数据类型。机器翻译这个场景里面输入的这是一个sequence，一个序列的数据，输出的也是一个序列的数据，对吧？
	然后这个是最重要的两大类，我们上节课已经涉及到了。但还其实还花了一些时间讲各种各样的注意力机制的类型。其实就是我们类似于我们的alignment function，我们的对齐函数，我看有很多种。那么对于transformer来说，transformer其实最核心的就是把我们的注意力机制的上面两部分做了调整。
	第一神经网络的结构没有用encode decode，用了自己自创的发明的一个结构叫transformer，transformer在这儿。第二个就是说注意力机制这个类型上，我们的align function上面用了一个叫做self attention，就是注意力的一个机制。那我们待会儿就来看看具体是怎么做的。所以核心来看网络结构做了一个调整，自创了一个结构叫transformer，这个transformer很有意思。第二就是在注意力机制上，我用了叫做self attention。
	先看一下这篇论文的摘要和名称。这是一个谷歌的团队发布的很重要的一篇奠基性的论文，也带来了整个大语言模型的加速了它的发展。这篇论文的摘要非常有意思，也很重要。第一个就是这篇摘要里面有提，大家可以看这句话叫做。The best performing models also connect the encoder and decoder through an attention mechanical. 
	它非常直接的也高高度的去认可了encoder。Decoder再加上注意力机制，是非常好的一种模型，并且也是当时17年最好的效果的模型。就是我们开始上节课讲的这个encode decode with attention这样的一个网络结构非常好用，在当时是最好模型。但是这样的一个模型还是在用RNN。大家如果注意到的话，attention在在刚刚那个网络结构里面解决了RN的很多问题。他让所有的这的笔记都记下来，传给后面的人了。
	但是RNN只要存在，RNN的问题就一直存在。它只是说相当于这个RNN的效率不高，就是效果差的问题他解决了，但是RNN本身的问题他没有解决。RN本身有哪些问题呢？我们待会儿会去讲。但是简单来说就是RN这个序列越来越长之后，这些RN本身带来的问题他希望解决它。
	因为encode code，这就是一个IN的结构。他想在网络结构上面有没有什么优化的方式，提了一个他自己说法叫做全新的简单的网络结构，叫做transformer。The new simple network articular the transformer. 
	然后这个transformer带来了什么好处？带来了效果的提升，就是很直接。这篇论文的摘要其实写的非常好，也值得大家学习。第一，承认了前辈的牛逼之处，确实好用。第二简单直接的指出了前辈的成果虽然好用，但是有的地方值得改进。就比如说网络结构，大家还记得刚刚三个重要组件组成了我们的注意力机制的注意力模型的核心。那么这三块里面有一块值得去修改，网络结构，我们把RNN的网络结构改成一个更简单的网络结构，transformer效果提升了两个点。在一个特定的基准测试上，叫BLEU，很重要的一个基准测试提升了两个点，用了in simple的方法，in simple的方法其实就是通俗来讲就是三个臭皮匠顶个诸葛亮，待会儿我们看网络结构就懂了。
	Transformer作为一个游戏的game changer，就是我们变局的改变游戏规则的人，这个变革者他做了一些什么样的不同，首先这个是一个我们刚上节课有看过的叫sequence align的一个IN，它就是一种续列对齐这种方式。我们刚才讲三个组件对吧？左边这个其实也变，我们把这个网络结构变了，从RN变成transformer对齐的这个函数方法也变了。从这个序列对齐，我们上节上节课讲了很多的知识，我们把它抽象出来，它叫做序列对齐的RNN，这种attention mechanical type，就这种注意力机制的类型，它的类型就叫做序列对齐的RN，基于这样的一个结构，变成了一个self attention的一个transformer的结。那什么叫self attention，吧？这是我们接下来要去讲的self attention一个最重要的区别。
	通过这个结果可视化的结果来看，左边是一个上节课讲过的机器翻译的场景，使用了这个sequence aligned RNN的一个可视化结果。它解决的问题是我一个特定的语言里面的单词，中文、法语跟英语当中的area。它的这个高亮就体现出他们的关系，就是相当于这两个词的意义是一样的。因为我既学了这个其又学习了这个翻译，其实就是这个含义了。这个应该是已经讲过了，大家不明白的可以看一下上节课。
	那么self attention它要解决的是什么呢？第一，它解决的不是翻译问题，self attention解决的不是翻译问题，它要解决的是什么？它想要提升语义理解能力，他想要理解这一句话里面内部的这个关联关系。比如说我们看右边有一个这段话里面的左边和右边是完全一样的词，不是两种语言，我们看the law will never be perfect，but its application should be just, this is what we are missing, in my opinion, 这段话跟右边是一模一样的，这是第一个点。第二，这段话里面有一些词，是人来看的时候也都需要去思考的，比如说代词，but its application should be just这个it's到底指的是什么东西？比如说现在大家想想它指的是什么东西。首先通过结果来看，从他通过学习，这里有两条线，这两条线的意思就是他的注意力机制学出来的结果，这个也可能指的是law，也可能是指的application。然后不同的颜色代表着它的不同层的这个呃呃待会我们讲它不同的注意力机制学出来结果，不同的颜色是代表不同的注意力机制学出来结果。
	我们再看右边，是一个更完整的，不只是IT，每个单词其实都可以学出这样的关系。就像左边，其实每个单词它都跟左边的所有单词都是有关联的。我们注意机制是有关联的，只不过它颜色很淡，说明它的注意力权重很低的，attention位置很小对吧？所以它就没啥关联关。所以你看下面这些都是有一些颜色的，但因为它关联度很低，所以就还好。那么在右边也是一样的，它的颜色很淡，是表示它们有关联关联关系，只不过这个权重很低。
	我们从这儿就能看出来，这个is是指向了law，明确指向了law，这个law也指向了law，the也指向了low，对吧？那么这个是指the law，就是the肯定指向law，然后its也指向law，就是通过transformer这个结构，它这个self attention最想要学的东西是什么？就是我希望通过transformer理解语言，理解语义。大家再回到上节课的这个概念里面，我去了几次咖啡店，最关键的事情是什么？就是我要理解语义，这个是大前提。就算我注意力机制抓出来的这些词我不理解，他没有对吧？我只是知道这有一堆词关联度很高，但我最终交付的这个结果不是我最终想要的。好，回到这儿来看的话，我们的这些词的这个代词的关联关系被self attention和transformer抓出来了。
	还有一些动词，比如说missing对着missing，just对just，这里的but对着这个but然后purpose对the purpose这些词是没有太多指代关系的那也能够很清。被我们给拎出来。通过这种关联关系的学习，我们接下来可以做很多的工作。因为理解了语义就相当于我们现在大语言模型一样。理解了语义你有很多工作都可以在这个基础上去做开展。因为这是人类做事情最关键的，也是先听懂人话。你如果不听懂人话怎么能做工作呢？
	我们再来看一下这个注意力模型，这个QKV，就上节课我们有讲到的那在这个transformer里面使用到的这个注意力机制，其实最核心的这个对齐函数使用的这样的一个方式。Softmax是外层套的这个P就我们的distribution，这个分布函数，V是我们的输入对吧？那中间这个是它使用的这个对齐函数alignment function。这个elegant function我们就逐步给它做一个拆解。
	上节课学的这个similarity其实很简单，类似于similarity其实没有指定特定的对齐函数，但我们把它这个跑点解决出来一个注意机制就这几大块，从组件的成分上有三大内容。从形式化定义的角度来说，分布函数、输入对接函数。对齐函数里面我们看一下这个scale的dot product attention，就是可伸缩的顶级的推选。在上一节课的综述，讲注意力机制的综述里面的表格。
	第三个就这样的一个，对，大家可以再看看，左边这个是一个典型的transformer的基础结构我们把它叫做scaled dot product attention。你去看它的网络结构，我们再逐步做裁剪，其实里面干了什么事情，就干了一个矩阵相乘，scale一下，再做一个掩码，输出一个softmax，再跟我们直接的输入做一个矩阵相乘，就干了这么一个事儿。这个其实就对应着这么一个结构，但这样的一个结构就对应着我们这里的一个结构，这里的这个公式就是下面这幅图。这样的一幅图就叫做一个scale的dot product attention，跟我们上节课看的这个sequence aligned n里面的那个函数其实是长得一样的。就是他把这个结构做成了这样的一个形式，更方便他去组织出更复杂的结构。
	在transformer的论文里面，我们会看到有一个词叫做marty head多头，多头的一个attention什么意思？很好理解。大家再看这幅图，QKV是输入，我们QKV仍然是输入。我们把这样的一个结果我们做成了多个，就这里的H它是并列的多个，然后最终把这个结果在contact连接在一起。
	换句话说就是我们上节课不是讲过吗？这个课程笔记我可以记下来，记在A4纸上面。我是不是也可以录音？我是不是也可以录像？这里的三个不同的attention你可以理解成我没来听课的同学，我可以先通过学习笔记做一个scale的dot product attention，我通过这个录音我再做一个attention，我通过录像再做一个attention。这三学出来的内容都是针对这个QQV来的，我都是在针对QKV做学习。这3个QKV的学习成果，我最终再把它拼起来拼起来再给到后面去学习，其实就是干这么一个事儿，这就是多头机制做的事情。
	这个多头机制整体在这右边，在现在这幅图的右边，就是完整的这个transformer的结构了，对吧？我们刚刚看到多头attention，其实就是对应的这里的黄色框框的一部分，muti head attention。这个muti head attention是一个我们刚才已经讲明白了，就我有多种学习手段，我把它做在一起，然后整个transformer的结构，其实它也分成了两大块。
	一大块是我们左边看到的这个有input in bedding输进去之后处理做的这个处理encoding的部分。右边是我们的decoding的部分，通过output evading进去。然后这里有一些细节我们再展开讲讲。虽然我们的transformer没有使用encoder decoder RNN这样的架构，但是它仍然使用了encoding decoding这样的你可以理解成编解码的形式。因为你最终其实是需要这样一个输出。
	那这样的一个形式有一些细微的区别。第一个区别在哪里？就是我们看到他这儿做了一个位置编码。因为他没有RN了，他没有去生成这个黑点state，它做了一个位置编码。这位置编码首先把这个embedding你可以理解成输入了一堆的数，或者说输入了一堆的自然语言。这对自然语言每个单词变成了一个in bedding，变成了一个向量。这向量是没有这个位置信息的。所以它单独做了一个position的一个encoding，就相当于把这些位置记录下来，输这个output embedding也是一样的。然后我在学的过程当中，我还是一对儿作为我的训练语料，包括我们刚刚上节课讲的这个机器翻译，也是一段作为训练语料。就是你的训练语料始终是一对input output这个对应起来的。
	好，在这个学习过程当中，这个Martin head腾讯我们刚才已经讲过了，就是把我们的QKV做了多种不同的attention，然后拼在一起，然后做了一个学拼接。然后拼接之后，这里加了一个叫做前馈网络fit forward，它取名叫前馈网络。其实就是一个典型的神经网络，是用来学习一些比较复杂的网络结构。这个需要一些简单的神经网络的知识，你可以理解神经网络学的是什么呢？神经网络其实就是在拟合一个函数，然后我们通过这个marty head的attention的输出给到他，让他去拟合一些函数，其实就是在学这个数据的一个分布。
	然后这里还有一些关键点是什么呢？就左边我们基本讲明白了，但这里还有个N在原文里面，他有提到这个N是可以去做调整的，只不过论文N取的是6。我把六个input in bedding这样串起来，这个结构其实是串起来的，就是每每个我们的左边这一侧的input embedding这个encoding的结果都串在一起。右边比起左边来说多了一个什么？我们抛开最下面这个mask，这里鼠标有一个mask marty head attention以外，上面有这个muti head和这个feed forward。所以我们抛开下面来看上面后面接的这两块跟我们的input部分是一模一样的。
	那么下面这个mask是想做什么事情呢？他要做的事情就是学习我们的这个掩码，是为了模拟我们人去理解这个语义的一个过程。简单来说掩码是个什么概念？就是我output，就是我输出的这个部分，其实我是能拿到完整的输出结果的。
	但是我学的时候是对齐着一个一个去学的。就比如说我们刚刚说的这个the law is the law is never perfect，我觉得这么讲的，然后这个是输入输出，我也可以是这样的一段话，但是我每一步学的这个内容，我不是把后面的全部给他看。比如说我现在学到第二个单词，那后面的第三个单词开始我都不敢看我遮住什么都没有。然后我学第四个单词的时候，前面三个单词就给他了。然后学第五个单词的时候，前面四个单词都给他，但后面的都不给他。就从左往右的把这个语序给到他，让他去理解这个语序的这个过程。
	这个mask Martin head attention就是干这个事儿，就相当于它的QKV就只到当前这个position，这个位置，从开头到这个位置后面的都没有，这个就叫做mask的muti head attention。相比于普通的market head attention就这个区别，只看得到当前这个位置到开头的所有信息，当前这个位置以后的不给他看啊，一直到最后的这个位置的时候，就能看到全部的内容了。这个是outputs的这个position encoding加上mask muti head attention的这个输入要干的事情。但是他也能拿到全部的信息，就输入车的全部的信息。就通过我们左边这个，我们能看到左边有一个input in bedding之后的结果给到了这个muti head attention。所以到中间这个部分的mart head attention就既拿到了输入的全量信息以及输出的当前位置的信息，然后逐步的去做这么一个过程。最终输出一个output的概率，就我们根据我们的特定任务来的。比如说翻译的话，那就给出一个翻译的概率，哪个词可能是他最终要的那个翻译过去的对应的词。
	这里这个前馈网络其实就是一个标准的一个神经网络的一个操作。输入权重，BIOS，乘上这个权重，然后再将第2个BIOS，这就不再展开了。我们刚刚其实有讲这个结构，我们把它再抽象一下这个encoder decoder的transformer这个结构没有RNN了，那么它会它最多加了一个前馈和神经网络。在encoder里面就是一个self attention加上这个fit over self attention，就刚刚讲到的这个marty head的attention，再加上后面的一些简单操作，那整体的这个网络结构就右边这个结构其实就长左边这样。就我们的encoder它它也算former，是可以拿来做翻译的。因为跟你具体的这一段输进去有什么语料是直接相关的。那么这个结构其实就会被抽象成左边这个结构encoder我们刚刚看到了，我们把整体左边这一个小方块，一个像电池一样的一个小方块称作一个encoder。右边的这个一整个称作一个decoder，对吧？Encoder内部我们刚刚看到了就是一个腾选加上一个feed forward，这个marty head的tention就是我们的self tension。然后整体这个网络结构就被抽象成这样的一个结构，就对应的原文。
	输入是我们的这个假设我们还是用英法翻译来做理解transformer整个网络架构的理解的话，输入是这个法语。通过了六个encoder，接上了对应的这个六个decoder。我们看这里这根线接上了对应的这六个decoder，然后输出的是这个目标语言。
	在这个架构里面，其实我们能细看到的是有一个很重要的点，就是我们的transformer其实在每一个encoder里面，其实就跟我们的那个trans就是讲transformer之前讲的这个attention机制上一节课是很像的。我们把这个图我们倒过来看，就是早晨上节课下面是encoder，上面是decoder的话，其结构是一样的。所以它虽然说我提了一个全新的网络结构叫transformer，但他仍然没有脱离出encoder decoder的这个价值。只不过是说这个encoder decoder里面没有用RNN。这个是一个非常需要去重点理解的点。就是我们知道RNN最重要的事情是它有一个顺序，它这个顺序就决定了我知道哪个位置这个单词哪个在前面，哪个单词在后面。但是对于transformer来说，因为他没有用INN，所以他自己造了一个position encoding，造了一个位置编码，这个是第一个点。第二点就是说它的结构仍然是一个encoder的结构，只不过里面没有再用RNN来生成那个H和那个S而是通过我们的self attention，用我们的直接用注意力机制和这个前馈神经网络，生成了对应的一个我们中间过程当中学到的这个变量，这个隐藏层的状态类似于那这个位置编码，它自己设定的有两种方式，这里我就不再展开，大家可以去了解一下。
	然后这个是就类似于我们学注意力机制的时候，transformer也定义了很多很多的变量，但是有大量的变量是逻辑定义，是跟我们学的通行是一致的。我们能看到输入是什么，输入就这些单词对吧？然后in bedding就相当于我们变成了一个的高维的向量。那这个高维的向量还需要有一个位置的编码。
	就刚刚也看到了，最重要的QQV其实是没有变化的。我们query，然后我们的这个key，包括我们最终的这个value输入其实是完全一样的。然后我们算出来了这个alignment score，就我们对齐的这个分数。然后对齐的分数我们除以了一个DK的根号。这个是什么意思？这个其实你可以理解成这个操作就是为了把它的这个包括到最后的这个softmax都是为了最终获取到一个完整的归一化的一个值。
	就比如说我们假设输入是就两个词，然后这两个词他们都会算出来一个最终的attention位置，注意力权重。那通过这个方式就是去算出这个注意力权重，这里有八个不同的ahead，所以就按照这个八来，除出来之后，这个softmax最终大家可以看到这两个注意力权重，一个是0.88，一个是0.12。那如果这里再增加一个input，那可能就是这个地方就变成0.8，这变成0.08，类似于这个意思。那整个纵向看下来，不同的输入就等于我们在注意力机制里面看到的那某一个X。然后这条线下来的这些关键概念跟注意力机制我们讲的这些概念都是完全一致的。我们的query key value，包括我们的score，然后我们的这个softmax，这个分布函数也是为了更好的把我们的这个注意力的权重变成一个规划的值，然后我们能更好的去做这个学习。
	然后类似的我们刚刚看到decoder里面学了各种各样的marty head attention对吧？那么这muti head attention也是可以被可视化出来的。并且你会发现越往后面的这个muti head，腾讯就越越深层次的，就它有六层。那么越往后走的这个market attention，学到的这个呃呃你可以认为这个注意力是越好的。举个简单例子，就是绿色的这个是更深层次的，左边这个是更浅层次的。这个much had attention学出来的内容其实也就是of attention的，就这些名字都一样的，他就造了一些概念，这个market head其实就等于它自己的这个self腾选。
	我们能看到在这个里面，其实我们的这个线条能看得到这个application在浅层次的时候，它其实只能看，那这个意思和这个application有关联。但是，其实到更深层次的时候，这个application学到了更多的关联关系。就比如说，它跟这个B有关系。就是因为我们看这个语义，我们人来分析这个but is application should the b就这个B跟这个application是有关联关系的。但这个关联关系在浅层次里没有被学出来，有很多种原因。一种是本身更深层次学到的这个概念会更丰富。第二就是说能在掩码层面上那个信息就比较少，因为看不见，这些都是有可能的，因为它在他后面，通过一直到后面的更深层次的最终输出，其实我们能看得到在transformer内部self attention到底学了一些什么东西。这也是一个非常有意义的去观测我们self attention的学习效果的手段。
	在右边这张图是不同的颜色表达了不同的多头attention，每一个头每一个head的attention整的一个学习效果。我们能看到虽然有不同的层次，但是在一些特定的词上面，大家的这个相当于投票。就是我们讲三个臭皮匠顶个诸葛亮一样。不同的颜色、不同的同学、不同的层次学出来的这个关联关系，居然都指向了同一个结果。那说明他们的结果是很可信的这就跟我们上节课讲简单的注意力机制的时候，我可以只看前两个同学的笔记，我也可以三个同笔记都看了，我也可以只看一个同学笔记。如果我看完三次的结果都指向了一个这个概念，那个概念可信度就很高。
	最后我们看看transformer的实际效果，相比于它的前辈们的这些sota就是当时最好的模型的效果，它也是有比较显著的进步的。我们看到这个transformer base model和big model，big model就是它它不是六层吗？它也可以做的更深层次一点。那么在两个语言翻译上，一个是英文到德语，一个英文到法语，都取得了更好的效果。
	然后他的训练所使用的消耗也更少，这个是为什么呢？这就讲为什么transformer很重要的。第一个就是说我们刚刚提到很多，就是他抛弃了IN那NN天然的一些这个问题就被它抛掉了，就不用再去解决了。
	然后第二个点就是它是一个面向GPU并行非常友好的计算。为什么？因为RNN之前是前后依赖的，你可以理解成我要先学完一年级才能学二年级才能学三年级。在RN的一个特点，它是严格保证这个顺序的。那么对于GPU这样的并行计算的硬件来说，我其实是希望你别告诉我依赖关系，我最好能一起学，你一起找我要结果。有RNN这件事情就不可能。但是transformer有一个好处，它它的依赖关系，大家能看到它的decoder部分，没有依赖关系的我可以并行着算。所以这样可以天然的让它的训练效率更高能训练更大的模型。
	后面的GPT其实就把transformer这个六层干到几十层甚至上百层，其实就干这么个事儿。他为什么能干成？也是因为他能并行的计算，不然他要等很长的时间，这个训练的时间成本也是很难的。还有就是这个sentence level representation。所以我们开始看到最低机制两个词之间的关联关系我能找出来了。但是我想能捕获一段话的这个含义语义的时候捕获不了。
	Transformer其实就尝试在做这个事儿。比如说我们看到他去学这个is的代词指代的是什么？这个application跟下面的这个动词be有没有关系。这些都是为了去捕获更长的语义信息。这些语义信息能为我们的下游任务做更多的储备。因为你理解了语义，自然就能做很多的任务了。
	所以说它的变革性体现在哪儿？因为它为我们现在这种基础模型，在对接下游任务，体现出了它的一个前瞻性。就比如说以前我要训练一个问答机器人，训练一个信息提取的模型，都要做很多不同的大量的训练，就训练成本是很高的那transformer为主的这种基础模型做到了一件事情是说的基础模型，你要解决的问题就是尽可能多的给你的这个数据尽可能多。
	然后你花大价钱大时间、大成本搞出一个很牛逼的基础模型，就跟GPT3.51样。Number two这样的大的基础模型，你学的东西足够多，你能听懂很多不同领域的人话。完了之后我再去做这个adaption，就是适配下游的任务，去做轻量的适配，就能够变成一个可用的一个机器人。就跟我们现在用TIGPT，你会发现你问他各种各样类型的任务他都能回答你。甚至你稍微用一点prom的这种技巧，他还能回答，挺好的。那这就是一个adoption adaption，那这个adaptation说这个说错了。
	用这种适配的方式让我们的这个以基础模型为主的这种，你可以认为这种新的一个时代，就开始有一个基础了。因为transformer的出现，后面这些基础模型都。由着他来去做这个发展。我们能看得到，技术侧这四个大的时代的变化其实也就是这样发生的。
	从我们这个数据的角度，从我们的这个模型的角度，包括我们这个应用的角度都能看得到。这四次的大的发展其实是各自有它各自的特点。然后我们的大语言模型其实是非常得益于注意力机制和transformer的发现。然后使得我们的基础模型能够变成一个非常大的模型，它能用大量的数据并行的去训练。并且我要学的就是语义理解本身我是在学语言了，我不是在学一个具体任务。以前的NLP就是针对下游的具体任务去做设计，去做训练。现在我们不这样做，我们让模型尽可能像人一样去理解语言，然后下游的任务就变得非常简单的适配了。