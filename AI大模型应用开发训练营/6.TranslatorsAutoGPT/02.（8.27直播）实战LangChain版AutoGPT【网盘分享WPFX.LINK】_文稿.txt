	开始，今天讲的是怎么用南线来实现奥德GPT，课程的后半段其实有很多是跟代码强相关的了。然后我们的这个前面的基础如果没有打牢的同学，在学习过程当中我们也会有一两页的用来做温故复习的这个课件。大家如果还通过这一两页还回想不起来之前学的这些东西，或者说进度没有赶上的话，希望咱们能够抽空把之前学的一些内容能够追上来，这样能跟着大家的这个进度一起往后走。
	今天我们这3个小时的时间主要做这个auto GPT的一个分享。To GPT本身是一个很有意思的开源项目，他首先跳脱于南线之外，它本身就是一个开源项目。对，开源项目有他自己的一个定位，然后也有它独特的价值。我们会做一个关于auto GPT本身这个项目的一个定位和分享。
	第二部分我们会深度的去解读，南茜到底是怎么去实现的。Auto GPT这部分的代码解读其实本身也是一个让我们之前学了很多关于南迁的模块。然后我们怎么样去做一个南迁的应用，上节课的实战我们把OpenAI的translator当中的关于模型提示词相关的部分，用南茜给重新实现了。南茜版本的这个OTGPT，其实更进一步能够让大家深入去理解，怎么样能够去做一个AIGC的应用。或者说基于蓝券的一个生成式人工智能，或者说AI智能代理的一个应用。
	第二部分我们会花比较多的时间来讲蓝券版本的AI这个auto GPT它到底是怎么样去实现的。在这个过程当中，我们也会去把之前南线的这个agents和vector store，这是我们的代理和向量数据库。什么意思？现在应该没有这个噪音了，对吧？那同学有的说再把之前讲的这个蓝雀里面的这个智能代理和我们的这个向量数据库再做一个深入的理解和分享。
	同时我们之前看这个南茜官方代码的时候，应该有了解到南茜在最近一个多月把他的代码做了有两部分的一个设定。一个是在lap下面的南茜本身的这个库，还有一块叫experimental，就是它的偏实验性的一些还在还没有完全稳定下来，还在做探索的一部分代码。那么auto GPT的这个版本的能线呢就是放在这个experimental下面。最后我们会实际来试验一下这个auto GPT在能线的实现下面，它能达到一个什么样的效果。然后如果这个时间允许我们追进度，把上节课的这个flask怎么样把我们的OpenAI的translator变成一个web server，用API的方式对外提服务，也给大家做一个分享。放在最后也是因为我们希望今天的auto GPT本身，它也只是一个学习的过程。通过这一节课和上一节课的内容，希望大家能做一做自己的一个家庭作业。把我们的out GPT今天的实现也变成一个API服务，或者说变成一个我们上节课讲过的radio这样的一个图形化界面。
	好，那我们就正式开始。这个应该是调错了。对，应该是这个auto GPT的项目定位和价值解读。首先从开源项目的角度来说，我们很熟悉的网站叫star history对吧？这个呃star history其实一直跟get up这个统计，这个新兴的统计做的非常好，现在也几乎成为为这个事情的一个实施标准。
	我们从这幅图里面能看到奥特GPT作为一个开源项目。首先它开源项目的这个时间是在差不多GPT4出现之后，他自己也是这么定位的，希望做一个GPT4的这样的一个实验。GPT4开源之后，使得我们发现大语言模型可以做更多的工作了。就比起GPT3.5，它有更强的推理能力，甚至他能去做多模态。虽然他还没有官方发布出来。他也能够通过现在GBT的plug in去对接各种各样的外部生态。我们学了年欠的这个基础概念之后，我们知道function in这个拆GPT这个plug in本身都是属于一种在大语言模型这个时代的AI代理智能代理的一种实现方式。那么auto GPT也是这样的一种实现方式，所以它依托于这个GPT4实现了一种智能代理的一种实现方式。
	但是南线其实是一个更早开源的框架，我们能够看到其实在2022年，南线就已经开源了，不过那会儿是放在一个个人项目下面，现在变成南京AI这家公司下面的一个开源项目。从这个增长的曲线视图来看，其实奥特GPT从它发布之后，它的这个斜率非常高，就是它快速的说吸引到了很多人的注意。并且到今天为止，其实南县的这个star数量比起WPPT还是有差距的那至少从这一点说明，奥特GPT是站在聚光灯下面受到万众瞩目的一个明星项目。至于这个明星项目他具体做了什么事情，他能做到什么样的程度，他是昙花一现？还是说他还有更值得深挖的潜力。今天我们这节课就逐步来分享。
	在看auto GPT之前，我们在横向对比一下其他的比较有名的领域。像我们之前最早看过一个生态的图谱，有大语言模型，有web应用的开发，有移动应用的开发，有AI的开发，有云原生的开发。那对于我们来说，其实在深度学习，在AI这一波这个浪潮里面，最有名的这个开源项目应该就是了。
	我们也可以看得到，其实就算奥特GPT有如此高的一个增长斜率，但它现在还是没有超过这个tens flow的四大数量。这个跟年线是有一个质量的有一个质的差距的那我们可以看得到，其实特色flow这个增长曲线是一个非常健康的一个增长曲线。就是我们如果在学一个新技术的时候，一个框架也好，一个底层技术也好。他作为一个开源项目，在开源社区里面一直处于一个比较稳定平滑增长的一个关注度斜率，就这个增长曲线，这个斜率如果是比较稳定的话，其实说明这个项目本身是比较健康的，并且是有稳定的用户群体的那对于auto GPT和能线来说，现在还为时尚早。这是flow已经是一个开源了将近八年的一个项目，剩下这两个框架，其实也就一年不到的时间。他们还有很多的时间和机会需要去验证。但毋庸置疑，在当下这个节，这两个项目内嵌和out GPT是最受瞩目的，是需要我们去学习和研究的那类似的我们可以看到更早一点，在这个1314年的时候，我们云原生有一个非常有名的项目，也是google发起的，叫做cobs。业界也叫做K8S，八个字母K8s corporates在这个云原生的领域，其实一直在深耕，大家能看到其实它的增长到18年之后，反而它的斜率还变大了，就它还增长变得比较快速了。
	因为其实在1718年的时候，那会儿首先tens flow，他们的在深度学习这个领域有很多的增长。然后云原生的这个生态通过CNCF这个基金会有各种各样的云原生的开源项目发布出来了。然后云原生已经变成了一个我们现在大家聊你用公有云，不管是用哪一家的公有云，可能你会去买虚拟机，买他的EC。但也有越来越多的用户开始使用像类似于这个开源的cover native，或者说这个云厂商自己定制化的这个cover这种容器管理平台来进行我们的资源管理。所以本身也是一个非常有生命力，并且已经稳扎稳打变成基础设施一部分的一个，巨型的事实标准。
	但是我们能看得到的是，即使影响了这么多的人，但是他的四大数量居然没有奥特GPT高，但是它比南京要高，这就是说明一个很有意思的现象。我相信有很多咱们的学员不是研发背景，或者说不是这个AI的研发背景，但也许或多或少都给这个奥特GPT打过这个star。这说明两个问题，第一就是说这一轮的这个大语言模型真的是有破圈的效应，有很多的非我们原来这个圈内的人员开始去关注这个AI圈子类发生的事情。最好的证据就是这个star的数量。第二个就是说因为这样的一个关注，所以使得更多的资源更聚焦了，就是明明一个relative是一个已经开源了十年的一个项目，并且还有这么大的影响力，有这么多的开发者、贡献者、使用者，但仍然没有超过澳洲GPT。就说明这个红利也好，或者说这个资源的聚拢也好，在当下这个时刻是非常夸张的一个状态。
	那我们再看一个更多的普通用户可能了解过的项目叫spring。Spring应该有很多的java研发写这个web框架。我们这儿其实已经把很多的很有名的项目摆在这儿，也是有一个很有意思的现象。就首先我们的技术是在不断的变迁的。然后我们的时代的发展，我们的这些技术的周期和做创业也好，产品也好，它的迭代也都有一定的周期。
	但我们能看得到spring作为一个更早的项目，这个横轴是它的时间，已经有十多年的一个开源项目。它的生根很不容易，它也在缓慢的增长。但是跟云原生比起来，它差了一大截。他就这个曲线，其实大家仔细看，越长的项目，他在他的领域已经做到了极致了，他已经做到最好了。但是它比起下一代的技术也好，或者说下一代的这个产品形态也好，它是有一个天花板的。这个天花板是很难再去突破的了。那就说明现在的这个资源也好，人员也好，我们的这个技术也好，越来越聚拢。
	并且我们大胆的把这个横轴拉到2024年的时候，我们能看得到年线跟o GPT甚至有可能是超过做cub native。当然这个OT GPT已经超过b native，甚至超过这个TensorFlow。从这个视角来看，这么多的人都在关注它，不管他现在做的怎么样，这个方向一定是正确的。
	这个方向是有这么多人在关注，一定是不一定它的实现方式现在是正确的，但是这条道路本身是值得大家花时间去探索的，花了一些时间，啰嗦了一下，但是通过这些数据，是想让大家用不同的视角来考虑问题。我们的开源项目都在这个公网上面，大家是可以去访问到的。而这些项目也都有足够大的影响力了。但为什么他们有这样的天花板？我们去学习一个新的技术的时候，就跟我们最早讲这个learning一样，我们去学习一个新的技术的时候，我们要怎么样去抓那个呃ROI最高的部分，那么star是一个很好的参考。
	好，那auto GPT是什么呢？在他自己的这个官方项目的定位里面，它叫一个自主的一个GPT4的一个实验，autonomy's的一个GPT four experiments，这他自己的一个定位。具体来看，其实可以分成两个方面来理解。首先第一，这个实验它是一个实验性的一个开源的一个APP开源的一个应用程序。它是一个它本身就是一个应用程序，是一个完整的可以给你交付结果的一个应用程序，这是它的一个定位。然后同时它这个应用程序是怎么去实现的，那要有GPT4作为一个最核心的引擎来作为它的驱动。
	为什么选择GPT4？因为GPT4现在确实是最强的大语言模型。那么GPT4怎么样去驱动它的？第一我们要理解GPT4的语言模型的能力本身现在已经是最强的了。它在auto GPT4里面担任的一个第一个角色就是我们上我们上上节课，在这个南线的这个框架的基础概念的下，这一篇讲到了agent，讲到了agent的概念。其实alt GPT本身是一个agent，并且他在内部也是通过这种链式的方式，就跟我们男性讲牵everything，通过链式的方式去连接了很多个大语言模型。在他自己的这个官方实现里面，他的定位就很清楚，他既使用了GPT4，也使用了GPT3.5。在他自己的这个实现版本里面，当然它也有它的原因，因为我们都知道GPT3.5的成本更低，GPT4的能力更强，但它比较贵。他就会担负不同的角色。
	但无论如何，他们的核心还是通过练的方式，把LLM，把大语言模型的，你可以叫sort source也好，就思维也好，或者是我们上节课学过的这个reasoning推理能力也好，或者是操作也好。这些产出输入最终通过一个链的方式连接起来。连接起来之后，去实现一个用户输入的目标。好，通过这两个层面我们再回过头来理解，这是一个应用程序输入的是一个用户的目标。这个目标怎么样被实现的？通过GPT4或者其他的大语言模型链接大语言模型的输出，包括我们之前学过的链接一些工具集，来实现我们的目标。比如说在官方的这个视频里，我不确定是不是每个同学都赶上了这个节奏，可以看一看。
	他其实这个事例要展示的一个demo场景比较简单，就是体现了两个重要能力。第一个能力就是连接网络的能力。因为GPT4本身它不是一个可以联网的应用程序，或者说这个语言模型。他的时间是有他的这个训练集的这个时间是有截止日期的。就是到了2021年的这个秋天，也就是两年之前。这两年之间发生的这些新的事情他是不知道的。所以他一定要通过一个外部的工具服务来进行信息的检索。
	在这里，他是访问了这个浏览器，通过了这个谷歌的搜索引擎。然后接着它还连接了一些其他的工具，就是我们的这个文件的读写工具。所以他最终把我们的这个搜索引擎上查询到的结果，通过这个爬虫类似的技术找到了他要的信息，并最终写到了一个文件里面。这些其实我们学了南茜的基础知识之后，应该有的同学能有一个感知，就是说我们要做这些事情，其实不就是我们之前学的react再加一些别的内容，对吧？就比如说我们能把这个文件写出来，我们能把文件读出来，这些其实都是一些tools能干的工作。确实在年轻人的实践里面，也是按这样的方式去做的，我们待会可以去细看一下。对于他的这个定位来说，他自己从这两个侧面我们能够理解这个奥特GPT有这样的一个定位和他的这个目标。
	从一个开源项目或做一个应用程序的角度来说，它有一些什么样的功能特性呢？他自己这边列举了一些。首先能联网，能搜索信息，做信息的收集和聚集。第二能支持这个memory的功能，并且有memory的管理功能。这个memory就有long term和short term，就是我们的长期记忆和短期记忆，分别对应的这个你可以理解成对应的持久化和我们的这个内存，或者说缓存里面的数据。然后同时他这里体现了两个不同的语言模型，一个是说这个GPT4这样的一个语言模型，他们更多的是做文本的生成，就用GPT4来做生成类的这个任务，然后用他的这个理解能力，相当于既然是生成类的任务，到学到这个时候大家应该也能理解。他既然是在做文本的生成，那大量的提示词是丢给了这个GP4让他来处理，并且让他来返回一个对应的生成结果。
	然后还有一块就是我们有看到他有一个使用GPT3.5的场景，用来做什么呢？用来做这个文件的存储和总结，因为我们知道，就算是这个持久化存下来了，但持久化也是有一定成本的。因为这个成本体现在存下来需要耗的这个空间，也体现在如果我什么都存，那么这些存下来的东西我存下来是为了用。
	当我用的时候，其实这个都会变成prom，都会变成token，都要去计费的那我能不能通过这个总结summarize，然后把本来不需要存的这种又长又臭又长的这种流水账式的这种内容，通过总结的方式用GPT3.5，然后把它总结下来之后，在下一次使用这个曾经记录的内容的时候，以一个更低的成本，更高的性价比去使用它。然后同时它还能够访问一些网站和一些平台，就比如说一些平台的这个API，然后它还扩展了一些插件的能力，这个是它最重要的能力。接下来好像基本上我们在之前学习南线的基础模块的时候都有一些覆盖。
	确实作为r GPT也好，作为这个男生也好，其实我们到现在我们再来回看react这篇论文，他提出来的这个思想非常的重要，把语言模型作为了一个最中心的位置。但是语言模型以前我们的对他的浅显理解，可能没有学这个课程之前我们知道聊AIGC就是这个纹身纹纹身图纹身视频纹身代码。但是现在最新新的这个大语言模型的研究方向是什么呢？其实就是以alt GPT为首的这一类智能代理。所以我们看这句话其实是比较有意思的一个总结。
	但是这是他自己的王婆卖瓜的一个说法。首先他讲到auto GPT是作为GPT4完全自主代理或自主运行的首批事例之一，就是在GPT4刚刚发布的时候，他们就把这个项目发布出来了。通过刚刚的那个开源项目的star history，大家应该也能看得出来。然后它既然是首批的实例之一，那它有什么样的价值和效果呢？它推动了我们现在的人工智能所能达到的边界。
	为什么能够讲这么大的一个大话呢？是因为绝大部分的人工智能现在都还是在特定领域里面去解决问题。不管是我们刚刚看到的TensorFlow，服务的这些深度学习的模型，还是强化学习的模型，他们大部分都是在特定领域解决问题。即使是像这个阿尔法go阿尔法狗，它也是在特定领域。
	但是out GPT满足了人类的一些幻想。就比如说我们大家都知道钢铁侠有一个jv这个家伙是真的像一个人一样在跟你做沟通，你跟他说什么，他是能理解你的意图，并且帮你拿到你要的结果，对吧？现在这个短视频领域很火，叫要拿结果，对吧？你大厂也要这么说，拿结果是拿结果的能力，其实是最大的一个区分度的能力。就是对于我们一个评价一个人或者评价一个应用程序来说。
	但拿结果的前提是什么？是语言模型的语言语义理解能力。我们在理论篇的时候有跟大家讲过，GPT和bird这两个最早的大语言模型。他们的论文标题我不知道大家还记不记得，都在讲要做这个language这个understanding，要做语言的理解。那么在这个react这幅图，他提出来的思想是非常值得大家去研究的，并且所有的agent其实也都是离不开这个范式。
	我们在讲agent的这个模块的时候，又跟他讲这个具体的agent里面有哪些重要内容，那核心抽象来说，我们的agent这样的一种智能代理的模式，它让我们的人工智能具有了两种最重要的能力。一种就是我们前端能够听懂人话，能听懂你要什么，理解你要什么。甚至如果你要的东西很复杂，我能够通过这个思维链，通过我们之前讲过这些知识，能够把一个复杂问题拆解成一个简单问题，多个简单问题，一步一步来解决。
	那么我就能听懂你要什么，但是你要什么和你的这个罗翔老师也经常讲想要和做到，对吧？就想要什么和我能做到又是两回事。这个中间的差距是什么呢？其实就是他的action，就是他能做什么事情。这儿的这个能力就是我们能接各种各样的工具，我们在用这个react这个方这个agent的时候应该也跟大家讲过，我们能用这个serve API去连接网络，也能用一些其他的tools，我们也都列出来了门圈已经内置的那些tools。
	那react这样的一个agent和order GPT他们差在哪？从模块的角度来说，其实我们之前讲的这个react这个agent，就我们在课程里面用过的这个demo，比起现在的TGPT的描述，直观上来说只差一个东西就是memory。我们在rap的这个事例里面没有给我们的这个agent去加上memory，但在的gdt里面一定是需要这个memory的。Memory很重要对吧？它使得我们能记忆这个上下文。当然除了memory以外，这个prom的设计非常的关键。我们待会儿会去详细的去看这个prom是怎么设计的那我们接下来就来看一看t GPT。
	我们已经理解了官方有它官方的实现。Alt GPT是一种思路，它是一个agent的一种尝试，它有很多种不同的具体落地的实现方法。那么南迁的实现方法是怎么样的？它的这个架构有怎么设计的？具体的技术实现是怎么做到的？
	首先我们再温故一下这个年前的agent怎么涉及到。在agent里面最重要的一个思路就是他想要实现一个类似于react，当然他还有别的一些agent react这样的一种能力。我们刚刚有讲前端能听懂人话，后端能具体的干活。怎么样去实现它？
	在我们最开始了解大语言模型的时候，大语言模型就是一个很死板的一种交流方式。你给他prompt，他给你生成的结果。但是在能券的设计下面，我们首先学会了把这个大语言模型和prompt整合在一起。它变成了一个叫做LLM券，就是大语言模型的列。它是一个最基础的抽象，这个最基础的抽象被南线广泛的在进行使用。然后我们在学这个LMT的过程当中，我们知道一个欠能做的事情有限，他无非是把这个prompt和model解耦了，然后你在使用它的过程当中更方便了。
	我们经过open I translator的锻炼，大家应该也有体会了。那么还有没有可能把语言模型的这个能力再放大，把它的能力再放大。我们当时设计了这个sequential chain和router，用来实现串行的这种任务和我们的这种带有条件判断的任务。但是这两种任务也是硬编码的，它没有运用这个大语言模型的判断能力，他只是用了大语言模型的生成能力，我们希望大语言模型能够自己判断什么时候应该用什么样的工具，什么时候应该结束这一次的中间结果。
	直接把我们建这个结果作为最终的交付任务，交付结果给到我们的用户。那这个时候我们就会看到中间出现了prompting的strategy。这其实就是我们去实现一个agent的最开始的动机和它的一个组成部分。通过简单的券，我们能够让它的生存能力得到一个体现。但是通过这个提示词prompting的这个strategy，我们能够把它的判断能力发挥到极致。
	让我们的大语言模型来判断什么时候应该做什么事情。从这个视角来看，代元模型也就逐步从一个生成器变成了一个解释，甚至一个代码的编译器，对吧？就我们能够让他去根据我们的自然语言，然后来执行这些对应的工具。它本身就像一个一个python的解释器，或者说一个加的JVME。那么它能够具体的根据我们的人的自然语言来判断最后要执行什么内容。而这个自然语言一开始的输入是一个go，对于我们的这个agent来说是一个目标。这个目标通过大语言模型自己的拆解，而逐步按照这个错误的要求就变成了一个一个的我们的tool的这个command tool的这个命令和这个command需要的参数。这就跟我们的函数调用非常像。
	整个agent其实不管是什么类型的agent基本都是在模拟这样的一个思路，所以通过agent这种设计思想，大语言模型把它的生成能力利用之后，我们还利用了它的判断能力。然后把把大元模型变成了一个最中心的解释器，或者说编译器。它能够把自然语言变成一个真正像我们现在用的编程语言的东西，它就能够去做更多的事情。在这个过程当中，我们还学到了刚刚是静态的一个设计思想。
	当这个agent真正运行起来的时候，它会有各种各样的运行时环境，就包括这个plan and execute，还有我们的年轻人自己默认的默认实现的这个方这个方法叫做agent excute，那也是一种运行时，然后包括baby AGI hot GPT，这些都是一个agent的运行时状态。它具体的这个运行时状态在真正执行任务的时候是怎么样去实现的呢？这里有一个你可以叫伪代码，也可以叫这种agent实现的一个通用的一个逻辑。
	因为整个agent的核心就是干两个事，听懂人话，然后去干活拿结果。但是听懂人话要把这个目标拆解成多个子任务。多个子任务要一个一个去干活。干完活之后有一个核心要核心的难点是我到底这个活我能不能干。如果我的超出我的能力范围，不在我的这个two case里面，那我就干不了。那我要知道我能干什么事情，不能干什么事情。所以我们在通常实现一个agent的时候，这一部分是最核心的内容，那这个run方法是最核心的内容。我们要知道能够判断能力范围边界在哪。
	第二就是说当前的这个结果是不是我最重要的结果，我是不是应该停下来了。所以大家能看到这里会有一个agent finish，作为一个停止服务。我要这个活得总得干个头，干到什么样的阶段，什么样的一个程度就算干到头了。这个是我们去设计agents的时候最重要的一个核心流程，就是我们的这个two case的边界判断有没有异常以及我们的停止条件，就是在它运行状态下最核心的设计部分。
	对于能欠来说，能欠的agent生态其实现在已经越来越丰富了。我们能够看到在人欠里面，首先agents我们现在已经有一个共识了，这种形态这种应用的形态是通往通用人工智能目前的一种有效探索的方式。但要实现一个agent需要很多的组件。我们刚刚那幅图是一个我梳理出来的一个抽象，对吧？把我们的学的知识概念都拢在一起了。但是从这个组件的层面上来说，其实有很多概念都被它封闭起来了。最重要的三个组件，我们只要实现原则，通常都需要去做的就是这三个部分。一个叫planning规划，他要做的事情就是我们刚刚提到的听懂人话把一个用户的需求分解成子目标，那这个是planning要干的事情。
	很明显plan里面就需要大语言模型。因为拆解的能力就是语义理解的能力，包括这个think step and step这样的一些黑魔法的这种prom的这些能力，它都需要这个大元模型。所以在plan下面大家能看到这里有一个LLM。然后这个大于60个instagram是指南迁已经有超过60个大语言模型的集成。然后接着就是我们的这个memory，我们需要有memory，这个memory是用来用来记东西的对吧？我们保留这个记忆能力，而memory通常又会分成这种两种memory，一种叫short，一种叫这个囊肿。就短期和长期的，分别是指我们可以简单理解成在内存里面，当我这个应用一旦重新启动的时候，可能这个short term的就没了，内存也就没了。还有一种是long term，就我们的这个期记忆，这个长期记忆是可以持久化的。
	我们在讲这个南拳基础模块的时候也列了一个列表，目前支持的这个向量数据库已经有超过40种了。那还有就是这个工具了，这个是最宽泛的。这个工具其实就是各种外部来源的API等等。他们的核心还是要从这些工具的结果手上拿到一些信息。这些信息其实最终就会变成我们下一次就下一步。因为他拆解了多个子目标，下一步的一个输入，如果这个输入也可以再做处理。所以我们再看这幅图左边、上边和右边三个组件是最重要的。
	那么这个action是什么呢？Action其实我们刚刚看到有一个long time在上演。那个run time就是我实际运行起来之后，我要采取的这个动作，对吧？就跟我们这个react里面的reasoning和action一样。最终to执行出来这个动作，我们叫action。Action会得到一些结果，结果可以拿去给我们下一步任务去做这个循环的使用。这个是一个典型的一个南迁的一个生态图谱，以及它现在的一个情况。
	那为什么需要agent？反过来说，我们之前有很多的应用，在这个网上大家能看到有各种各样的包，一个大元模型，再加上一个API。然后就结束了。他好像就能去工作了，至少能在一些特定的小任务上去解决问题。
	但是它相比于这种简单的应用智能代理有什么样的一些优势？第一就是说我们能看到agent本身，就是比如说我们以out GPT这样的一个agent，它本身其实一直在判断我现在做的事情对不对。但这个取决于各种他判断的好不好，有很多的限制条件，取决于很多的因素。现在他用GPT4在做判断，已经是目前我们能看到最好的大语言模型了。这种判断的过程当中，我们在做子任务，就是人也会犯错。我天天都在做做工作，但是我在做工作的过程当中，我人也会天天复盘，去去看看这个复盘结果里面有没有哪些我可以改正的过程。
	智能代理其实有一个这方面面的一个优势，是他会把我当前这个阶段这个子目标的生成结果去做一个判断，这个判断取决于我的prom的设计的好不好了。我去判断我现在这个结果是不是我要的，我需不需要去纠正。因为我我的这个结果的产生本来就是一步一步产生的，也许中间这一步产生结果方向错了。那那方向肯定是比努力重要的对吧？你方向错了，你生成10万个token，你也拿不到对的结果。所以在过程当中，第一他要学会自我纠正。
	这个自我纠正我们刚刚提到的取决于最重要的就两个东西。第一个是这个基础模型，你使用这个大元模型够不够强。因为我们能够实现的LGBT是可以用很多不同的单元模型的，这个是它的一个优势。如果你用的GPT4版本的GPT和这个GPT3.5的，或者说其他的一些版本，它肯定效果是不一样的。这个是第一个点，这个是基础语言模型。
	第二就是这个prompt设计的好不好，作为一个out GPT来说，这个prompt怎么设计，是写这种很通很泛化的这种problem，还是说作为一个足够精确的。因为其实大家仔细想一下，我们一直在讲prompt就是一个咱们现在要学会理解的from就是一个新的编程语言了。那你能想象你写一个编程语言的代码就只写十行，让它一直有效，这是可能的？这不太可能对吧？即使我们有了大语言模型，这十行的from的相当于可能以前几百行的代码，那它也就只有十行。你需要花更多的时间去设计这个prom，然后让他去适应各种各样的场景，才有可能把这个agent的能力做到足够强，尤其是在自我纠正上面。因为我们现在发现，其实南线版本的OGBT在这方面做的还不够好啊。我们在今天最后的这个时代里面也会给大家去看这部分。
	第二就是去处理一些多项任务。所谓多项任务就是他不是连续的，他可能要多个。就我们之前讲这个GPT理论的时候，应该大家还有印象，就是它会要多步来进行计算的，包括一些比如说它还会有分支，就是它不是一个串行的，不像一个sequences圈，刚才是都天也因为它本身能判断，所以它最终可能是一个链或者一个树状的一个结构，它一步一步去解决，这是一种智能代理能够解决的一个很好的一个场景。
	因为你普通的LLM加API你不太好去做这个事情。因为在普通的这个LM加API封装的应用里面，你没有去设计一个agent，就没有去设计我们刚刚看的那个run time里面最核心的去判断现在做的对不对，要把这个任务去做拆解。这个模块你没设计，那自然就没有处理这个的能力，即使你的prom可能设计了一些一些特定的trip，一些特定的技巧，当然可能适用范围比较窄，没有把语言模型能力放大。
	还有一种就是这个长期任务的能力。因为通上来说，API封装的这个单元模型，它解决很垂类的具体问题，它的memory用的相对比较少。但是如果我们用agent，它本身可以去根据当前的一些输入，然后再对接一个向量数据库。就我们这边看到这种long term的现在数据库来进行记忆的搜索也好，或者说我们相似的这个问题的一个查找也好。这个是智能代理相对我们的大元模型对接API的这种应用的一个很重要的一个优势。并且这个优势是长期的。就随着我们刚刚对prom的理解，对基础模型的迭代，它会这个优势会越发的明显。
	我们刚刚其实有覆盖到这一部分，就是我们讲规划的这里面就是我们的这个提示词，再加上我们的这个代理。提示词其实是对应的给我们的代源模型的输入的赋能。这里我们已经学过的怎么样做好这个提示词。
	我们刚刚提到的第一，我们在花了很多精力跟大家讲怎么样去做这个大语言模型的多个角色的赋能，用好这个基础模型的能力。因为多个角色的能力是基础模型提供出来的，不是所有的大元模型都能提供多角色的输入给大家。用过其他的非OpenAI的模型就知道，那么多角色的这个赋能能够让大元模型更好的去理解他要做什么事情，这个对于他的plan当然是非常重要的。在我们用system roll，用这个系统角色去做赋能的时候，应该大家有感知的。包括我们上节课给这个system roll，让他去做这个多语言对的翻译。这是一个很简单的一个输入，就能达到这样的效果。
	第二就是说在给提示词的时候，要给予充分的上下文。就是我们从memory当中大家能看到这里，从memory当中去获取一些能力，给到我们的这个plan这个模规划的模块，包括我们的在理论课也讲过的这种学习策略，我们的这个prompt learning。怎么样能够用类似于这个思维链或者一些其他的方式去提升我们的这个prom的设计技巧的水平，让我们的prompt做的更好。
	然后在记忆这部分，刚刚有讲有内存的，有向量数据库的。当然有一些别的形式的，比如说缓存reads，也可以作为我们的short term或者说non term的一些选择。这里就很多，大家可以自己去查看。然后工具也是一样的，各种各样的百花齐放的外部可调用的服务，给大家去做这个选择。
	好，最后再看看这个生态这幅图里面的右边这一部分，就是我们讲智能代理是一个AGI的一种有效的探索方式。那这个智能代理是不是还可以再做一个分类呢？就我们对智能代理这个词太宽泛了。
	智能代理本身在我们去做设计，在他的目标导向上有没有可能去做分类呢？是有的。首先我们今天要讲的奥特GPT，它是属于这种我们叫做autonation的agent就自主的智能体。他的这个目标设计目标通常就是说你他的终极设计目标，大家可以理解成就是这个价位。就是有一个很强大的人工智能，听懂你的需求，然后给你你想要的结果。所以他一定是在他不完美阶段下，你会让认为他很抓马，很抓狂。因为他一直在尝试给你一个好的结果，这个过程特别像。
	如果大家有带这个小朋友，有带这个初级研发，或者一些刚刚开始工作的小朋友会有一个感知，就是你交给他一个任务，他有两种情况，就当他做的不好的时候，他有两种情况。一种是他老是就你刚刚给他布置的任务，他马上就给你拿了一个结果出来，那这个结果通常不是你想要的，那你就告诉他，你要多想一想，你这样你你你这个任务十分钟就给我结果了，你觉得靠谱吗？肯定做的不对，对吧？然后这是一种实现方式。我们我们想象一下这样的小朋友肯定不受欢迎的。然后我们会跟他说你要多思考，要深度思考，要理解业务，对吧？这是我们常常常用的这种职场话术，想象一下这个自主智能体，像奥特GPT，它就是这样的一个小朋友。他老是很快的给你结果，你是不满意的那就会陷入第二种不好的状态。
	第二种不好状态是什么呢？你布置了一个任务，你说明天你把官网的这个CSS或者说官网的一些布局你做一个调整。他就改了一周、两周、三周、四周都没有给你结果，一直在那改，然后他还不会给你反馈，他就自己在那判断，因为这个就跟我们刚才讲到的planning做的事情很像，他在自己决策，他下一步应该来给你汇报，还是我继续去改，那怎么改呢？
	我们刚刚讲到了他有一个判断的能力，就是我我在判断这个action是不是应该finish，有没有到我的这个finish的这个状态，他可能脑海中模拟一下这个场景，可能那个小朋友就改了一版网页出来。然后去搜了一下竞争对手的网页，发现改的不太对，又去改又改了一版，发现还是不太对，一直在那改，一直改不对。甚至他连竞争对手都找错了，这是非常有可能出现的一个状况。大家想象人尚且如此，LGBT1样的，如果我们的问题目标设计的不够好，你交给这个小朋友任务太难了，他就是做不来。你可能把这个任务改成把官网的某一个具体页面的布局，从这个分栏改成分成两栏这种形式，改成平铺的形式。这样的一个任务他马上就给你做好了，并且可能效果还不错。所以我们在使用类似于auto GBT，包括像baby AGI这样的automata agent的过程当中，一定会遇到我刚才说的场景。
	因为这个奥特GPT本身就像一个这样的小朋友，他现在还没有强到足够让你很满意的拿到他的交付任务交付结果。大家想象一下，如果它足够强的话，确实很多人就会失业了。因为他能做的事情太多了，他把这么多图都串在一起了，这很夸张的对吧？所以最终我们能看到这个自主智能体是最难的一条路。它会因为他能做的事情是一个开放式的场景，所以他一定是要花很长的时间去达到这个长期目标的。但是思这个方向，这个思路是值得我们去学习的那除了自主智能体以外，其实还有两种，一种叫action agents，一个叫simulation agents。
	一个是做这个行动的这种智能代理，它是决定这个行动序列。比如说我们的OpenAI的function calling，我们的react，这俩我们都已经使用过了，大家应该是有体会的。我们再回想一下我们这门课里面用过的这个function in，我们用来做什么呢？我们当时用来做过这个天气预报，对吧？假设我们现在有一个场景，它是封闭式的场景。这个封闭式的场景agents一直在诱导你去，或者说我们一直在通过这个system的prompt去诱导告诉他你的主要任务是回答这个天气预报。一旦你识别到这个用户在跟你聊天的过程当中，他想要了解天气情况，你就诱导用户往那个方向去问。
	这种是封闭式的场景，它天然来说更垂类，它就会做的更精细，然后也更好能够把这个任务交付的更符合预期，这个是行动代理。还有一类也是最近非常火的mention的模拟代理。我记得刚刚GPT出来签GPT出来没多久，有一个类似于twitter的这个项目。他们是做了一个也是一个在线的一个社交平台，在这个平台上面全是AI的智能代理，就这些模拟代理。然后这些模拟代理天天发feature，还互相评论。
	类似的像这个stands最近的这个小镇25个agents，还有一些其他的像国内也有一些公司和研究机构在做类似的事情，就是让我们的AI的这个语言模型，把它的角色扮演能力做到极致。让他其实这个过程大家细想一下，不管是我们的自主智能体，还是我们的similia，还是这个action的代理，其实核心都没有逃脱上面这个范式。我们在做角色扮演的时候，是不是一定要把这个角色的他本身是谁这个东西深深的埋在他的上下文和他的这个角色赋能里面，然后在学习策略里面，他也要去有一个目标。比如说我是要活下来，我在这个生存环境里面我是要活下来，我需要挣更多的钱，我需要提升我的技能。这些其实都是他的prom的一些设计。所以不管是哪一类代理，其实我们现在在今天拔高一个高度来看，agent就是这样的一个设计模式。它有它的关键组件，它的关键组件各自有它自己的一个设计目标。然后agent本身通过这些关键组件，我们有三类比较有代表性的这种agent类型。
	我们为特定任务，特定的场景服务的这种行动待遇action agents，或者是我们为了去像my club，像各种各样的像西部世界，对吧？那大家现在都在开始畅想这样的一些做模拟的那也可以。这一类是角色扮演类的这种similia agents。还有就是更通用的，它能帮你解决绝大部分问题的这种auto GPT，叫做automation agent这种自主的这种智能体OK到这儿其实我们把auto GPT的这个理论部分和或者说他的这个项目本身的一个设想，和他自己是一个什么样的一个模块构成，基本上给大家做了一个分享。接下来可能我们会花差不多1个小时的时间给大家去讲他的代码。但在讲代码之前，我想看到这儿为止，大家有没有什么问题可以提五分钟的这个问题。
	有个同学问planning用大元模型做真的好吗？我们之前都是用专门的任务规划子模块做，我没有就首先用大语言模型做真的好吗？我觉得这个思路都可以探讨，但是用大语言模型刚刚讲了，就是它的好处是什么？就它能用语言模型来帮你去做判断，这个是非常重要的。
	至于咱们提到的专门的任务规划子模块，这个任务规划模块是怎么实现的呢？是硬编码吗？还是什么样的方式？用模板吗？这个同学可以再细细聊细聊一下。
	你直接去询问ChatGPT返回结果有什么区别吗？这个同学问的，我不知道是不是之前有几节课没有这个跟上。首先最大的区别就是我们现在GPT就只是一个聊天应用程序，它跟agent差的很远。你单看这个tools上面，ChatGPT就没有这个tools，对吧？但你可以说ChatGPT它有它的plug in，那这个时候就很对。因为ChatGPT的plug in加上ChatGPT本身也是一种agent。我不知道这么说能不能理解到位，就它的各种plug in加上ChatGPT，它内部其实就实现了一个一点。
	AbNormal agency这一块有什么论文依据吗？上节课的react就是非常好的论文依据。大家可以去再去好好看一下上节课的这篇文章，就是我们的刚刚还有一个朋友的跳到这一页。就我们在这。在这儿有一个react reasoning加action，这是一个非常有意思的文章。并且也应该也在这个课件里面有附上这个文章的链接。
	大家应该是能下载到的这篇文章是值得大家去读一读的，就是我说的这个agents作为通往这个通用人工智能人的一条实现路径，最重要的事情就是让语言模型听懂你的需求。然后让语言模型去判断现在的交付结果能不能给到这个用户，把他两个能力都用起来。所以你看他在这个中心位置他会去做推理。他有他的推理的这个test，有个推理的路径，他也会去观察我的这个环境。其实就是环境里面执行的这些结果，这些操作所返回的一个结果，它会有个观测值叫observation，就相当于有点类似我们强化学习里面的这个事情。只不过强化学习我去设计这个rewards和设计这个policy的时候，我是一个特定的套路。但是语言模型它不是一个特定套路，它它的这个判断有一定随机性在里面，那就需要我们的prove设计的足够好。
	在定义结束条件的时候，有什么要注意防止过度执行循环。这个同学问的很好。首先过度过度的去执行这个循环，通常来说不是结束条件没设计的到位，可能是或者也能叫别结束条件没涉及到，其实是一个边界条件，需要去做设计。举个简单例子，就是你在做这个推理，在做这个判断的过程当中，我们回到一个典型的范式，就是在判断我们能看到这个agents的模块去做设计的时候，在运行时最重要的就是这样一个循环，所有的agent基本都是按照这个来的。在做这个设计的过程当中，有一个observation对吧？这是你的观测值，你要通过你的观测值判断你现在是不是该结束了，那这儿有很多的技巧和套路，我觉得可能一个最直观的技巧和套路就是你可以设计一个循环的上限。我最多超过多少步，就跟你交给你的员工，你最多就三天，三天之后就是deadline，三天之后没有拿到结果，你就给我那天的结果。这个是一种方式，就是你有一个硬的一个指标。
	第二就是这个tokens也是一种设计方式。当然这个token s就跟你在过程当中的一些细节处理就更相关了，就跟你控总预算，你的总预算你就是10万个token。那这十万个token用完了，你任务还没解决，你也没得玩了。然后当然你能在过程当中去算消耗多少token，这也是一种，这两种是最硬的，可以去解决防止过度循环执行的这么一个操作。
	不知道有没有回答到这个同学的问题。有一个同学说排期做项目计划用auto GPT来做，是一个典型应用场景。是的，就它的应用场景非常的广泛。但是你会发现你要把我的GPT用好，你需要把你的go设计的足够好，并且你的prompt也得设计的足够好。甚至它是一个综合性的东西。就是你要实现一个通用人工智能，你想象一下你得做多少工作，包括怎么样把memory给用好啊，也很关键。我们在今天的这个实验里面，你会发现，他现在还没有那么强。但是我们有很多可改善的方向，针对我们的具体任务。
	Auto GPT是自己实现了一套特定的能签吗？不是的，这个事情这个同学问的很好，就是out GPT是不是实现了一套特定的蓝券？不是，就是到今天其实我们做这个OpenAI translator这个实战项目的意义就在于此。为什么我们现在基础篇没有学南线的时候，要给大家看一下，也是能做这个OpenAI translator这个任务的。
	那么用能去实现之后，它有哪些好处？换句话来说就是我们在实现一个AIGC的应用，实现一个大模型应用的时候，南欠不是让你产生内容的关键，但人却是五金店的那些电钻之类的这样的工具。它能让你更便利更方便的去造出你最重要的那个东西。但是你没有你拿个榔头一个一个敲钉子它也能弄进去。你拿个扳手一个一个拧螺丝它也能弄上去，是这样的一个区别。
	那么auto GPT它在自己的实现过程当中，它也有一些对应的抽象。因为大家都是在复现这些论文的一些想法，比如说react这个论文的想法。那就是一个很好的一个，因为核心还是大语言模型。但是怎么样复用大语言模型的成果，怎么样让prom的设计的更好用，怎么样对接周边的生态更简单，这个是人生的价值。还有同学问什么网上买的3.5的key超请求上线了，这个可能只能问问这个群里有经验的同学了。
	用agent的时候，因为内置的是英文的，prompt的输出的结果经常变成英文了。这个有什么方法解决吗？加一个output part，这个我们学过的，就是你希望最终的结果是一个中文，对吧？或者说一个其他的文章有两种方式去作答。第一种是在欠的内部去解决。首先你有一个agent，这个agent的实现其实是一个券对吧？那这个券其实我们知道券的这个实现，里面有一个最终最输出去做规范化的操作，在叫做output的part，然后这个output part能让你直接去处理。
	还有一种方式就是直接把你最终的输出结果过一遍。比如说过一遍这个open I的translator，对吧？那不就变成你特定的这个结果了吗？但是为什么你要你要你得理解为什么他内部要用英文。我自己的实践实际经验就是你要理解就是他为什么用英文。
	最最简单就是你看一看这部分的这个抽象这个抽象我们有一个observation是实际的执行结果。然后有个run方法，run next action对吧？那这个next action是让这个agent去去执行的那我们可以想象一下，这些要执行的东西其实就是一个一个的two。这些tl其实也是自然语言。那这个自然语言，你想象一下现在所有的编程语言，大家都是用英文在写。然后这些two让大语言模型来实际执行的时候，也是一个类似的实践。我们待会儿看能确实现的RGBT你就懂了。
	那你想象一下，你把一个你现在写的python的代码或者java c加加的代码换成中文写会多难受。你都很难去查出来他对没对错没错，然后也没法去复用他以前学过的这个github代码库当中的知识，你要知道他能执行这个to跟他学过github那么多代码也是有一定关系的。他能理解一些基本的语法。
	我看一下，现在大家没太多问题，我们就往下一趴走，我们看看它的这个具体的实现。好，首先这个代码一定要看，尤其是南茜的代码是一定得看的。因为你不看第一次迭代太快了。你看到的一些网上的资料也好，甚至包括我们的课件，我都一直有教大家。在课件里面也好，在notbe里面也好，给了很多的这个索引的链接，是能直接访问到它最新的版本的。就是因为他的迭代非常快。
	然后这些迭代非常快背后的原因也很简单，因为这个技术太新了。那那就是大家每天都在探索出一些新东西，那既然新东西出来了，我得追赶上他们，对吧？既然新的部分，今天我们讲的也是南茜这个很新的框架里面更新的部分。
	就是我们在南茜的这个代码库里面，我们我们能看到这个南倩人现在顶级目录下面是有这个left，下面这个left下面其实还有两个目录，一个叫experimental是我们今天要看的。还有就是我们之前一直在学习的这个南线。那我们每次去使用这个连线from能线巴拉import一大堆东西，就是在这个experimental同级的能上面。要使用这个experimental的模块，我们也需要额外的去安装这个experience mental的这个python的安装包，它俩是平行的。
	所以大家可以简单理解成在一个南线的仓库下面有两个python的安装包，就它的发行版的安装包，一个就是我们之前一直用的派in store的这个欠，一个我们今天要去学习的这个type install年限的experimental的安装包。那在这个安装包下面我们能看到它实现了很多的agents，这里有这个自主智能体对吧？Authority的这个agents，包括我们看到这个generated的agents，生成式的就这种角色模拟的simulation的这种agents。然后也有plan and execute这样的一些agent，包括其他的像这个smart LM这个我还没用过，上周他们还有更新，然后还有像这个circle之类的等等。这些agent其实都在这个模块下面，大家可以去课后去自己去阅读，去学习，他的学习的内容。就像我们今天这接下来1个小时要教大家的要怎么学这些代码，很重要。然后它的抽象模块也没那么多，核心就三个模块对吧？然后在这个里面我们看到auto Normal的agent下面还有三个不同的实现，一个叫auto GPT，就我们的今天要学的一个叫baby AGI，还有一个叫哈根GPT，另外两个也很有，也欢迎大家去学习了解。
	在auto GPT下面，其实我们看到最核心的就这么几个python文件不多的，这就是南迁版本的的GPT的代码了，真的很少。我们为什么讲它像一个五金店的这个电钻一样，对吧？就是因为它效率高它能让你更快速的批量化的高效的去解决问题。这个是他这个框架的意义。就我们之前看实现这个OpenAI translator的时候，写了很多的代码，包括一些工具类的代码，能不能复用？我们是不是每实现一个AIGC的应用的时候，都需要写这么多重复性的代码，显然是不要不必要的，因为人欠其实想做这个事情，我们就把框架层和应用层做一个切分就好了。
	那我们看一下能欠版本的auto GPT具体实现了什么，首先要看的最重要的就是auto GPT，对吧？我们在聊这个东西，那它是怎么定义的？大家还记得我们刚才讲一个agent最重要的三个模块，tools、memory和plan。我们看看OTGBC的定义，在RGBC里面，他的这个构造函数要求有一些必要的输入比如说这个AI的name，他给这个agent取了一个名字，这个是必要的。第二个就是这个memory，这个Victor store rever，我们待会儿会专门花时间讲，大家可以理解它就是这里的memory，我们用来存东西的，用来存这个聊天记录也好，我们叫这个schema下面的message对吧？存这个message或者是存一些别的东西，把它用来存东西的记忆的部分，然后有一个券，这个券其实大家应该现在看到他很熟悉了，这个券定义了一个LM券。AMG其实本身现在看到它应该能直观的有这个条件反射。LM chain就等于一个model加from，对吧？
	那这个在哪呢？其实就在我们的这个play里面，我们的AMG the output partner，刚刚有同学还在问，就是我输出的最终想要一个中文，但他可能他自己在这个agent的过程当中，执行着执行着就变成英文了。那怎么办？可以在最终的output partner这个阶段上面去做处理，这是可以的，还有一些took这个tools。我们用过react，用过这个serve API之后大家应该很熟了。
	现在最火的应该就是这个serve API，因为它让大语言模型联网的。那么今天我们也继续会用，GPT也用了这个API，用了这个two，它是一个list，我相当于给了他一个。大家还记得刚刚那个架构图里面有一个tools，tools 1234567，就这样的一个历史。然后还有这个feed back to，它可以它是一个可选的一个参数，就不是必须要实现的。包括这个chat test three的memory也是可选的，不需要必须实现，但你要用它的memory也可以。这个是一个auto CBT的主要的成员变量的定义。我们能看到我们去初始化它的时候，他会把刚刚上面写的这些必要的request参数做对应的赋值。
	然后同时这里有个计数器，不知道大家有没有注意这些细节，很重要，都在细节里面。刚刚有同学问怎么让他停止不要过度的去执行，对吧？有一个next action count我执行了多少次了，那这个就是一个硬的计数器对吧？那计数器当然可以作为你的一个跳出它的循环的一个刚性的一个条件。
	然后这里还会有一个chat history memory，这个chat history memory使用了这个chat message memory。大家如果有印象的话，chat message history对不起，念错了。那chat message history其实我们之前在聊这个怎么样去记这个聊天记录的memory的时候有涉及到，不知道大家有没有印象。如果是用的chat history memory的话，其实就是相当于我去在初始化这个order GPT的时候，我是有之前的聊天记录的。我不是一个纯小白，我不是一个没有对你这个进行过，你是个老客户了。简单来说你是个老客户了，我知道你历史有什么需求。这个洽谈experiment用这个。
	我们写过这个能券开发的一些应用之后，我们都知道他很喜欢用from方法来做这个构造。比如说我们的这个from time plate可以用来构造我们的提示词模板，对吧？然后还有这个from message可以用来这个上节课学过的，from message可以用来把这个提示词模板构造的这个message的这样的一个template造出来，就相当于你造了一个聊天模型的一个template。Template里面充满了不同角色的message的template，你在format他的时候，给他传入他真正需要的这些variable。那对于这个T来说也仍然复用了，包括很多的agent都得复用。
	这样的一个方法叫做from LLM and tools。这个方法很经典，大家要记住这个类方法。那这个类方法可以让我们去构造出一个auto GPT的一个实例，我们能看到这是一个返回一个out GPT的实例。然后在这个方法里面，相比于刚刚我们看到的这个构造方法，还有一些细微的差别。第一增加了这个AI row，增加了这个角色，刚刚只有这个AI name，我不知道大家有没有注意，把这个LIM给它暴露出来了，就是不是直接使用一个这个LM线，把这个LM暴露出来了，然后可以使用这个chat model，然后包括这个human in the loop，这个是待会我们讲的时候会涉及到，这里就不再细展开。只是一个用来做输入的，然后包括这个output partner check free memory，这里跟刚刚也是一样的。然后需要仔细看这个代码，能够注意到的一点是，第一我们要把这个agent的做出来，核心那个AM线是躲不掉的对吧？就是我们的构造函数是一类方式。
	这个from LLMM的tools其实是想用更灵活的方式让你能去复用以前的大语言模型和你的tools。它其实给你敞开了更灵活的一个口子，但是你最终还是要变成一个欠来执行的，对吧？因为你的agent最终执行的是这些欠。
	大家应该刚刚我们这节课都还在复习那部分的逻辑，那这个时候他最终还是会去构造一个LM线，并且他要去构造一个prompt，就构造我们整个年轻人都已经很熟悉了我们的这个prompt的templates，这个prom temple，真正需要去传入的其实是这些占位符对应的实际的值。那这里的input viable大家有印象的话，这就相当于我们定义了一个函数的里面一些参数的名字。所以我们通过这四个参数能比较明确的看到我们的auto GPT要执行一次action的时候，或者说一开始执行action的时候，它必须要输入什么东西。这就比较明确。第一memory对吧？我们这幅图还在这里，memory要作为输入，然后我们的message，那message就是它的这个历史的聊天记录，这个用了chat模型的应该很熟了。Goals这个goal就是我们的目标，就我们现在告诉这个auto GPT你要完成什么样的任务。这个叫ghost还有一个叫user input，我们待会可以看看这个user音谱的具体是干什么的，设计的很巧妙。
	最后还有一个叫做什么呢？叫做这个token的counter，这又回应到刚刚说的一个问题，怎么样让它退出对吧？我们刚刚看到有一个叫做去记录这个next action count这么一个计数器。同时在生成prom的过程当中，我们会去记他用了多少token，这个他也在记，这个也是一个很有用的一个计数器，用来记token的。这个也可以用为我们这个auto GPT的一个终止条件。
	对然后human feedback to，这个就是指我们要不要做一个相当于用户输入的一个额外的一个条件。待会儿大家看到对应代码的时候能够理解。其实给理解成就是他给我们的这个大语言模型的执行增加了一个额外收入，相当于人来介入他的这个判断，这个是你可以简单理解，human input是用来干这个事的。
	然后大家可以看到我们把这个out GPT的from，这个是一个他自己定义的一个OTGPT的from实例化之后，这个from其实是一个模板，然后把这个模板和这个大语言模型一起构造出了一个LM圈。这个操作也应该这个套路大家都很熟了，就是搞一个提示词模板，然后写清楚它需要哪些输入变量，就相当于函数的参数名，再给一个大语言模型。在大语言模型是用户传入的这是一个没有这个默认值的，是一个required的一个参数。所以你使用这个from LM tools的方法的时候，一定的传入构造出了一个LMT，然后return，大家看这个return这个return class这个方法，这是一个python的一个语法堂。就当我们用这个return方法的时候，它其实掉的就是我们刚刚前一页看到的这构造方法了。所以其实这个代码就这两页，把我的GPT基本上大的框架跟这个一样就定义清楚了。那他把刚刚这些东西构造清楚，因为他其实自己的构造方法是需要一个欠的，然后把它构造出来丢进去，那这样其实就完成了一个auto GPT实例化的一个构造。
	你可以比如说你是一个很干净的新的一个OTGPT，你用它的构造方法。那如果你是在你的研发过这个项目研发过程当中，你有很多的agent，然后你甚至这个agent还跟其他的一些应用程序有交互。那有可能你这会儿已经有一个two的这个列表了，这个to o列表还是从一个大的列表里面筛出来的。或者说你现在已经有一个语言模型实例化好了。那你通过他们能够用这个from方法把这个奥GBT的实例给构造出来。OK. 
	最核心的方法是这个run方法，就我们刚刚有提到的这个方法。时间也不长，就这么多，就把l GPT的这个怎么样去执行，循环执行给定义完了，我们来看这个代码应该怎么样去看啊。第一还是看这个run方法，它需要什么样的输入，返回什么对吧？那么输入是goes就是我们的目标，我们在输入的是这样的一个目标，就跟我们前面有看到这个input verb里面的那个go其实是一个东西，输入的是一个目标。那为什么加了个S是因为大家能看到ghost是一个字符串列表，因为l GPT支持输入多个目标。我就多个目标一个一个帮你做，就相当于你给你的下面的小兄弟交代了三件事，一件一件去做这样的。返回的是一个string，就是他给你的交付的结果。是这样的一个方法。
	这个方法里面，我们可以逐步的来看。第一个就是这个user input，就我们能看到这个ur input是它预定已好的，并且这个user input应该是没有开放出来的。那么他写了一个什么东西呢？就很像一个prompt对吧？其实它就是一个要传进去的prom。它还有印象的话，我们的out GPT的需要它作为一个实际输入。
	Determine which next command to use and respond using the format specified above。那这一个prom的设计的是干嘛的呢？其实你通过读这个prom，你就能知道垃圾是用来判断下一个command要用什么，然后返回的时候要用这个respond using the format。然后就是相当于它它上面还会有一些定义好的一些format的方法，其实就是干这么一个事儿。
	大家想象一下，我们刚刚在前面第1个小时的时候有讲过，我们要把这个agent当成一个什么？就是它既有生成的能力，他还有判断的能力。判断的能力就在于判断我要用哪个to来解决问题。这个user input现在就是干的这样的一个工作，他是在负责这部分的一个最重要的内容，通过这样的一个prom。
	好了，如果大家能想出更好的一些front，显然就能直接去修改，对吧？能修改这个有的input，它也许就能获得更好的效果。因为你要知道整个这个OTGBT它就是一个很小的代码块，它整个这几个派送文件你自己去实现对一个新的版本。但你可以在他的版本上面去做调整，然后去调用南线的这些基础模块是很方便的。这也是为什么他要把它从主库里面拎出来，不然的话你相当于再改他的主库的代码，就很难受。但现在是一个experimental的代码，相当于是另一个库的代码。那能线的主库里面的这些schema的定义，比如说我们的human message AI message，或者说我们的这个vector Victor store都不会变，主副是稳定的。但是这些实验性的代码，这些agent你是可以自定义的，就这样的一个改法。
	第二部分是什么呢？就是我们刚才讲到的这个循环就开始了，对吧？这个interaction loop就开始了。那我们的整个RAM方法最核心的就是有一个循环。这循环是不断的去执行拿结果，然后判断该不该结束。这个循环就是从这开始的，这个interaction loop他自己内部有一个look come去看看它循环了几遍。
	然后这里我们看到有一个很典型的用法，self chain点run。我们OKI translator也是这样执行的。不知道他有没有印象，我们在translation chain里面，self chain点red传了什么呢？传了一个带翻译的文本text，传了一个我们的要翻译的原语言source language和目标语言，他get language。所有的AM线的用法，通过这样一个接口很规整这传进去什么呢？传进去四个goals，message memory和这个user input。User input刚才讲了，go我们的输入message和memory，我们再逐步看。
	然后通过这样的一个方法，这个券的执行结果其实是会拿到一个我们的返回的assistant reply。然后我们有印象的话，我们在使用这个GPT的时候，我们一直在讲用的是GPT4对吧？就是用的这个chat API，所以它是返回这个message的，所以这个assistant reply应该返回的是一个AI message的一个对象。不知道大家还有没有印象，用过这个open a translator的话，应该是有的。这个AI message AI message里面的这个content，那就是我们的这个assistant reply。
	所以大家能看到，第一，他自己打印出来这个日志。第二，他开始使用这个chat history memory了，那这个聊天的历史记录的这个memory，他往里面加了不同的message，这个方法也很直观第一加了这个human message，就是把这个相当于human message的定位这个角色大家还记得相当于我们普通用户说的这个message，我们的prompt放在里面，放的是什么呢？放的是这一段用来决定要执行什么的。接着是放了AI生成的这个结果，就这个助手生成的这个结果，assistant reply. 
	大家想象一下在这个message的这个历史记录里它会是什么样的一个组成。它就是之前他肯定也有一些结果，或者他之前是空白的。然后现在他记了一些记录，这个记录第一行是第一块，第一块message是这一部分叫娱乐input的这一部分用来决策的。接着这一串就是他这一次的执行结果，他把这个放到了这个chat history memory里面。然后这样他在下一次循环的时候就能直接看到这部分的结果。就是我们每一次执行完都会有一个决定要执行什么，然后AI有一个返回，决定要执行什么，AI有一个返回，这个变成他的一个聊天的历史，放在memory里面。然后这个部分是生成了一个AI的结果，然后把它放在memory里面记下来。
	但是我们是不是还没有实际的去找出来执行，我们现在只是react，现在只是做了reasoning的部分，还没有action的部分。那么action怎么做呢？就下面这部分的代码也不复杂。当然为什么之前要做OpenAI translator，都是。很精巧的课程设计，大家要去理解。现在大家再去看这个，我们去用这个参数解析器应该就很很熟练了，对吧？我们上节课还专门做了一个单例的config，这个就是用来管这个配置的一个统一管理。还有从命令行来的，有从这个呃呃秧苗来的，就是想让大家熟悉这些配置。然后这些配置其实本身都是一些自然语言，对吧？
	对，自然语言能够被解析出来，那么这些自然语言最终在这个AI生成的结果里面又怎么被捞出来的呢？我们之前学过一个东西叫output part，对吧？我们看到这里有一个self点，这个puzzle的pass，这里有一个action获取action的方法，待会儿我们会去看它怎么取的。其实简单来说就是我们把AI生成的结果里面，通过这个自定义的output powder解析出我们接下来要执行的这些操作，action就是这么被解析出来的，通过这个output的pass方法，然后这是我们想要干的事，就是AI生成的一些它通过推理理解这个go其实要通过干这些action才能达到。
	那接着是我们能干什么事儿，那能干什么事呢？取决于我们这个auto GPT初始化的时候给的这个tools，对吧？所以你看到这取了一个tools，这个tools就很像我们去实现function call的时候function calling的时候的一个操作。就我们从self tools里面去循环取出所有的took。然后这个tool里面当然有two的这个name，这个是只要你符合tour定义就应该有这些。你拿出了一个一个的tool，然后组成了一个tools的一个字点。那相当于你就把一个就相当于把这个to你能做的这个能力的工具集，就变成了一个大的字典。然后你只要给他名字，他就能给你一个结果。
	好，现在我们就看这个after partner出来的这个action是不是一个特定的停止符。这个finish name大家如果去看源代码的，就finish name其实就是一个字符串。它虽然这定义成了一个全局变量，一个一个特定的值，那其实就是等于一个finish，这个跟他的output partner是配套实现的。然后如果这个action name就等于一个finish，那就直接停下来了，就直接给他结果就好。所以大家看这儿的实现就跟我们的参数解析器很像。把这个action的arguments里面的这个response拿出来，就是相当于把他的action的执行结果拿出来，作为我现在alt GPT的执行结果，它就返回了，就直接return了。那这个就是作为我现在的一个反馈结果，我判断我应该结束这个操作了。
	然后第二个，就是说如果它不是停止的状态，那我们其实就要把这个action一个一个去执行，那他就会去做一个判断，这就是为什么要做成一个字典，对吧？做成一个字典比较好，以这种硬的方式来做判断，能实现也简单。这个action name其实就是一个字符串，然后tools其实就是一个key value，对吧？那key就是相当于我们的这个two的一个，你可以理解成一个函数名，是一个字符串的变量。然后他的这个字典的这个key就是函数名。字典的value就是对应的这个函数可以被调用的这个函数方法，具体的拓。
	如果我们的这个action name是在我们的工具集里面，在我们能力范围内的，那我们就可以去实际的去获取这个可以去执行的这个函数。我们通过这个方法就能拿到对应的可以去执行的这个，那就到这儿来了，我们还有右边左边就消耗完了，其实也不多，就2 30行的一个代码。那么具体怎么执行？现在假设不是要停止，而是在我们能力范围内，我们确实要去执行这样的一个操作，用这样一个特定的工具怎么办？这里我们取出来了这个tool，那这个observation就怎么获取的，用tool的run方法。到这儿大家应该慢慢就品出这个味儿来了。
	就是很多同学在学data connection这个模块的时候，有一个最大的疑惑就是当时我们做了一个叫做transform的一个券。那个transform的券其实没多大用处，就是把一个常规操作变成了一个to。然后学这个过程当中就问为啥要多此一举呢？其实大家在看这个agent的实现就慢慢能有这个体会了。就是他为了很好的面向对象的设计，然后统一的接口，大家能统一的去继承，然后这套代码的实现就会变得相对来说比较简单。所有的都是to鸡类派生出来的具体的子类，然后这些子类都要执行一个run方法，用来做实际的执行。他这个run方法接受的这个参数，就是我的这个output partner解析出来的这个action这些参数。但这个outpower得写好啊，就这里的这个action的这个arguments，是不是有点像我们在上节课open translation，这时候去初始化这个PDF translator的时候传进去的这个argues对吧？
	从ads里面去各种各样我需要的东西，我们也可以用很多方式去实现它。并且这个地方就能以一个统一的形式去取到这个observation，取得这个结果。我们还记得刚刚看到这个react这种agent的实现方式，reasoning trace，然后变成action执行之后，在环境里面拿到了这个observation，拿到the vision之后，通过大元模型再去判断要不要继续的去执行。
	好，那我们看看他下一步怎么做的那拿到了这样的一个observation，我们先看正常结果，不看这些异常抛出。那正常结果它构造出了一个字符串，这个result这个字符串是怎么样构造的呢？是一个f spring，我们应该也用过了，大家的代码也都用过了，写成了一个这样的形式，这个形式就很直观，command就这个指令，command后面接的这个是to the name，就这个具体的to返回了什么结果，返回的是这个to实际执行的一个结果，在这儿。然后这个是构造的一个result，就是我们通过这个two执行完之后，大家就可以理解成它其实变成了一个接下来我们还会用的prom，你能想象得到对吧？Prompt里面写了一个，我现在有个命令，这个命令叫什么？返回了什么？返回的是这个具体的内容，就跟我们这个react那个圈右边这一圈，就在这个result里面就表答完了。
	好，那当然有一些异常，比如说他这个validation error in arguments，就我的这个不需要的参数验证没有通过，那这个很典型。对，那我们就不再不再赘述了。就是很典型两个错误，就是参数不对，或者是参数的这个名字类型不对，这里可以衍生很多，我们这里就不再展开了。因为你写function calling的时候已经讲过这部分了。你去定义一个to，然后用自然语言给它往里灌的时候，你可以定义名字，可以定义类型，你可以检查名字，检查类型，包括必要的这些参数等等。
	然后还有一些情况，比如说我们查出来这个action的name是等于error，就比如说这里是finish name，它是一个特定的设定。Error其实也是一个特定你的设定，这个是需要咱们在prompt里面也要去做一些设定的。然后如果你的prompt里面没有去做设计，那至少你的output partner里面也要去做一些设计。因为最终这个action是从这取的，对吧？那呃partner里面只要发现，因为最终它是一个上一段的大模型的一个输出结果。就是我这儿有一个assistant reply，然后这是我确认执行的结果。如果这里面也许它包含了error，你就能够通过一个after partner提出来。
	这就看我们的offer partner怎么去跟这个单元模型去做对接了，包括这个self chain的这个run要怎么样去写。And anyway, 就是这个地方的逻辑应该大家能理清楚了。就是通过自然语言，然后我们用after partner提取出大语言模型生成的自然语言里面有没有停止条件，然后有没有错误，如果都没有然后我们就能接下来判断，那他就是不该停止，就是不该异常停止或者正常停止，应该继续执行。
	但是继续执行的时候，就有两种情况，一种情况是我要执行的这个command，我要执行的这个操作，我是支持的，在我的这个tools里面也对吧？在这个tools列表里面，那我就执行。还有一种情况比较倒霉，就是我现在不该结束了，但是我就是不会做，对吧？那我知道我现在没做好，我也知道那样做不对，但是我现在就是拿着这个中间结果，我不知道怎么办了。那这是什么情况呢？就是最后这种情况就是我有一些unknown的一些command，就我我不支持我不支持当前这个action，我看不懂。就比如说你下面是个前端兄弟，你让他去写一个什么后端代码，或者你让他去写个能欠的二次开发的代码，他现在就是不会，这对于他来说是一个unknown的command，那他只能报这样的一个错误，并且给他他的提示词里面不仅报了这个是不支持的，还给了一些额外的一些条件。比如说他给了一个come comments的list，那相当于一个外部的一个输入，可以参考一下这些commends的历史。
	然后巴拉巴拉，后面包括他他的返回要满足一个这个Jason的一个former。这个Jason的former跟他的output partner的实现有一定关系，那这边也写了，这个其实就把我们的最核心的用来判断这个action怎么回事。然后这个过程当中怎么样去获取action的这个操作，怎么样去执行two，如果超出能力。范围，或者触发了特定错误，或者说到了停止条件或者不支持，这四个主要分支分别怎么样去实现？那到这儿为止，其实它最核心的这部分就搞完了。
	下面这部分这这部分代码是它的memory，memory其实是锦上添花的东西，对吧？我们假设现在这个agent就用一次，那他现在也就够了。但如果我们想要把它这个任务做的足够好，要把他的结果不断的记下来，然后甚至这个结果还能给他下一次获取这个assistant reply的时候给一些参考。
	那我们需要把memory也做好，那memory在怎么做呢？大家可以看到其实就是去构造各种各样的提示词，就是整个RGPT的核心，它是很抽象的，最最难的这个提示词应该怎么构造？全看各家手艺，这就是为什么越来越像炼金术了。大家想象一下炼金术是什么概念？就是我们都不知道怎么练的，然后就那个老师傅知道对吧？他对这个工艺最熟悉，现在其实是这样的一个状态。坦白来说现在的大语言模型到今天为止还是这样的一个状态。就是谁prom的玩的牛逼，他的生产效率就是高。
	那我们再来看到这儿，这个memory to at他他要把这个什么样的信息加到memory里面？第一assistant reply对吧？就我们的这个大家还记得这个sist reply怎么来的对吧？就这第一次用券认出来的那这个results什么呢？是这个action执行的一个结果，就把这个two执行的一个结果，这个拼接是什么？是一个更完整的一个环。我不知道大家在在脑海中再想象一下这个react这幅图，两个圈圈左边那个圈圈是推理，在家这个操作拿结果，然后就是走了一个环对吧？
	那这个memory to add其实就是把这个环记下来了，记到了这个memory add里面。那上面的这个result记得只是右版权右版权记下来了。所以你能看得到整个这个memory to end里面，其实这个result记得是极其完整的。它不是只记了一个执行结果，他还记了什么东西，执行拿到了这样的结果，对吧？
	然后这是一个memory to add，最后我们能看到什么呢？就是这里很重要的一个方这个方法就是把我们的这个chat history memory在高亮提一提。就是我们这有题，就chat has。他们其实是把我们的这个系统的执行结果system message又塞进去了。就把我们的刚刚执行完的这个结果又塞到了这个system message里面。那他这个聊天记录就三段式就比较完整了。有人类就是有用户输入的这个user inputs，去告诉我们应该决定什么。有AI第一次这个大模型生成的推理结果，也有我们这个to实际执行的一个结果，这三段是就放在这里了。这个memory其实是还有一个add documents方法。
	大家还有印象的话，memory里面我们这个ad documents其实就是把我们的这个向量数据库，或者说把我们的年轻人的memory的抽象，应该用这样的方式去添加它的内容的。他最终会抽象成一个document。我们在data connection那一节是有对应的notebook示例，大家可以再去翻看一下。待会我们讲face，这个数据库是也会有相关的一些代码。就document是一个基础抽象，这个是我们在Victor store南线的Victor store里面存储的一些基本单元。里面有这个page page content。这个page content里面存的刚刚写好的这这一这一个左边这个圈加右边这个圈一次一次alt GPT的完整迭代的结果，放在了这个memory里面，那下次可以继续去用这个memory。
	OK这个就是它的核心方法上没有那么复杂，对吧？其实你细看下来，这么牛逼的一个项目，用能线来实现它的核心方法也就这么多内容，然后思路也很清晰。那我们再看一看提示词，提示词是我们讲核心竞争力，对吧？
	那骑士词在aut GPT里怎么去做的，怎么样去实现呢？首先他也同样定义了这样的一个auto GPT的prompt，我刚才也有看到。然后这个prompt在这个拍摄文件这个OTGPT的这个from拍摄文件里面还引用了一个新的方法，我专门高亮出来。大家可以看到在这个at Normal的agent auto GPT下面，这个是一个prompt点PUI。这个alt GPC的这个prompt的点PUI文件在这个目录下。但是还有一个这个目录下的prompt generator的这么一个PY文件。
	顾名思义，其实我们之前在某一节课的时候就让大家感受到了什么叫原模板，就是模板的模板。Out GPT也当然会有这样的技术，对吧？因为这个已经是去实现agent的时候一些惯常套路了。我们去写这个prompt就是在写代码，但是这个prompt本身它里面的这些参数除了运行时可以丢进去以外，这个prompt也可以去被构造。这个其实就是一个最简单的一个思路，就这么来的那在这里这个get prompt会被待会我们看到会被广泛的去使用。
	第一就在这儿，我们用OS GPT prompt去构造给这个agent使用的这个提示词的时候，就是用这个TGPT的这个prot实例。然后它需要输入的是这里的这五个，很直观。一个是这个AI name AI road，这都之前有的，包括这个tools token counter，这些大家都已经刚才都看过了，不再赘述了。还有一个是新加的一个成员变量，就发送的token的限制。这个也很直观。
	我们在造这个prompt，我们知道不同的语言模型的token限制是不一样的。我在设计这个out GPT的prom的时候，这个时候大家就知道为什么需要原模板了。我不可能所有的大语言模型都发同一份prompt，是这个原因多方面的。第一个是说大元模型同样的prompt产生结果不一样，我们在3.5和4上面用同样的prom。大家都试过了，包括之前什么妹妹的年龄差类的，这些都有效果不一样。第二就是说它本身这个大元模型接收的token的上限也不一样。所以需要有一个这样的参数用来做控制。你现在在使用的哪个语言模型，作为我们auto GPT的这个chain的核心的语言模型，那自然这个token limit也需要去做设置。
	默认用的这个4196，这应该是GPT4的一个常用的一个限制，就普通版本的。然后我们看到它最终返回的就是这个construct附prompt这样的一个方法，就是构造一个完整的prom的方法，它的输入是这个goals，就我们的这个目标返回的是string，string就是我具体的这个prom对吧？所以你可以想象一下这个construct for from这个方法干什么呢？就是一个消化目标的一个方法，我输入的是要干的大目标。当然这个大目标在执行几次之后就变成小目标了。这个大目标被我接收之后，我需要把它变成一个可以给大语言模型拿去推理的具体的prompt，就是用来干这么一个事儿，输入目标，然后我去生成这个完整的prompt，这就很有意思了。
	我们之前看过这个，我忘了是哪一个哪节课的时候我们讲过这个原模板，当时是用了这个模板的模板来做生成，那个router chain的时候，大家有印象的话，这个条件判断的券，它的自定义实现的时候，root chain的那个模板也是用了这个原模板的一些思想。那么在这儿，其实我们能看到他首先会去做模板拼接。我们自己应该用过这个南线的同学都很熟了。第一个这个prom step start你能看到他这有一些描述跟我们用user input类似对吧？来描述这个must always be made independently，就是你需要单独的去做每一个决策，并且不需要去寻取这个用户的协助。这后面这些我就不跟着念了，和合规性的，你要用LIM的，如果你全部都完成了，最后这一句很关键。如果你completed all your task，make sure for your vanish comment. 
	这就是配套使用。就是我们刚刚有看到有一个停止符号，就是action name。如果等于这个finish的时候他就要停止了，那个循环run方法就停了。然后这儿其实就埋了这样的一个prompt进来，这个prompt就是我们assistant reply接受的这个prompt。
	我们再再回忆一下，有印象这里这个地方的action怎么来的？通过assistant reply的pass就相当于从AI生成的结果里面解析出来的。如果有finish的话，那么我就要停止。那AI生成的结果的输入怎么来的？这个输入就是我刚刚去构造出来的，就这个self chain点run方法，内部会去调用这个problem的方法，这个基础知识，这个概念应该基础要打牢，就能看懂这些代码了。就是我用欠点run的时候，它会去调用我这个欠初始化的时候的这个auto GPT的from这个模板，然后丢进去这四个参数。这四个参数其中goes会给到他，然后goes给到了他之后，他会去生成这样的东西。并且告诉我这一次要调这个欠对应的这个大模型的时候，如果我所有的任务都完成了，要给我一个finish的command，这个finish command就能被我解析出来，我就能去停止这个循环。
	然后这个full prom怎么去设置的呢？就这些。你是谁对吧？
	你有一个AI的名称，因为你有可能你的这个alt GPT，你有多个AI它的名字是不一样的，包括这个roll，然后这个prom star就这里下面写了一个goals，这个是非常好用的一个prom的小技巧，就是多用用这个冒号。因为在训练语料里面，这个大基础篇其实就这个理论课的时候就讲过。这个GPT是一个自回归的模型，他的训练语料里面大量的是充满了我给上文，然后pay就是训练的这个那语言。对，是一个下文。然后这个上文通常会有很多冒号的结尾，这个也符合人的习惯。所以大家会看见好的这个prom或者说值得借鉴的prompt，一定会把AI即将要生成什么内容，通过这个冒号标注出来。这样他就很明确goals是接下来这一部分的内容。
	OK那我们接着再看，目前这个four from的是这样的一个结构，然后我们接着要去取购对吧？因为这一段前面这一段prom想说的是我们有一个任务列表。这个条件判断是if you have completed all your task，那oil task哪来的task？我们看到这里有一个goals里面去取出来，然后每一个目标都会加在这。他还很贴心的做了目标一、目标二、目标三，还给了个顺序对吧？这个大家应该能看明白，我们把这个目标1234还剩什么任务给列在这个goals下面。这个for prompt就等于最终把我们的刚刚生成的这一堆，既有start from，有AI的名字角色，包括我还剩下什么样的一些目标。做完之后再去把这个self tools传进去，生成真正的prom。
	这个部分的逻辑很简单，其实就是我构造好了我现在还剩什么任务，然后这个AI是谁？然后还剩什么目标，然后这个AI是谁？如果没有任务需要做的时候就停止，接着把我能有什么样的一些工具的能力再传进去。然后你可以理解成就是一个套娃一样的叠加。其实是串行的，就是前面构造的是reasoning的部分，就是到这儿一部分construct full prompt，这一部分构造的是推理需要的reading的部分。下面这个self to传进去构造的是我们的这个右右边右边这个圈，就是我的这个action obligation有什么样的图，也给了一个圈圈，然后会丢进去。
	通过prom generator这样的一个方法，就能生成一个更完整的，既有我的推理也有我的操作所需要的这个完整的prompt，这我就不展开了。大家感兴趣可以自己去看一下这个get prompt这个方法。然后我们再看一下，这个地方其实是造出了一个提示词模板。大家到这儿为止其实都是提示词模板，还没有真正把参数传进去。大家应该熟悉这个套路了，就是这儿造出了一个集成模板，真正要变成我们的可以用的给语言模型用的这个实际的字符串都是用这个format方法来生成的对吧？
	我们的LLM这种基础的模型用former方法，然后我们这个聊天模型也要用format方法。聊天模型用的是这个format messages方法，然后传进去的是这是一个python的一个语法堂，就是他这会传一堆的居民的参数，然后类型是任意的，返回的是一堆message。那这个格式像不像我们调用一次聊天模型？Chat models的经典的这样的一个输入。如果他把这做扩展了，因为调这个chat models的时候，输入通常是这个prompt，输出的是一个返回结果，它其实把这样的一个接口做了扩展，但是返回的类型是大体的类型。
	我们可以看它具体是怎么去实际造出这个prom的字符串，对，这有个base的prompt，它其实是一个给系统用的，这个系统这个self construct full prompt就叫的我们刚刚讲了半天的这个方法，所以你能看到刚刚说的这一大段，就我们的这个决策你要独立去做，不需要用户介入。然后你是一个很牛逼的大模型，然后你需要自己去看看有没有目标要做。没有目标做的话，你就输出一个finish的这个指令，这都是给到system的，包括这些tools有什么都是给到他的。然后通过这样的一个方法去取这个大家还有印象的话，我们在open a translator里面本来也应该是用这样的方式去实现的。但是我们用了一个python的语法堂，就是用了这个内置的一个ATTR attributes这样的一个方法，就可以把这个key arguments取字典的方式变成取成员变量的方式。但其实这是一种很常见的去做这个闭包的方式。就就简简单来讲就是去构造这种我可以不断的把参数传进去，然后内部再去解开这个参数的一种手段。
	这个是两种实现方式都可以。一种是通过这种域名，然后你拿这个key。一种就是像上一节课我们那样把它变成这个成员变量。因为你只传一层，就比较简单。然后类似的它除了把刚刚提到这一堆变成它的prom以外，还把这个时间当前的时间也加进来，做了一个time的一个from。
	然后还算了一下现在用了多少，他把这个time from t也取了一下，当前的这个时间就是用的这个python自己的这个time的包，然后把这个use token，大家可以看到这里有个self token counter，然后算了一下。Base的这一部分和time的这一部分。当然它是一个message的schemer，所以他要用content的方法去取它实际的字符串，对吧？这些都应该很熟了。我们这个课程设计是让大家逐渐熟悉这个文件的库的。你要是严格按照我们的顺序来学习的话，这些使用方式应该是很熟的。
	然后算这个token的方式，就跟我们最早OpenAI的那个基础课的时候，我们讲过这个token或者是自己去计算方法。这个token counter其实就是这边有去实现的，是一个corner able的方法。这就是一个函数，把它丢进去可以去算一算，这儿我们就不再展开了，这个实现方式多种多样，然后到这儿为止，其实我们把这个prompt的这个构造基础的system的构造了很多，基本就已经可用了。
	那接着这是刚才说的finish这部分。那接着其实我们再看一看它的这个message它是怎么玩的，message其实在这个system构造完了之后，他还做了一些操作。第一个操作就是把这个memory给引入进来了。我们能往下看这部分代码看着挺乱的。这部分代码其实细猜一下没有这么复杂，一就是他去定义了一个memory，就是他的这个数据类型，就pyto 3的一些语法，从这取出来的这个memory就跟娶这个goes一样，把这个memory取出来了。
	Memory是一个在人群里面的later store recovered这么样一个结构，就是我们用来向向量从向量数据库里面去检索取出数据的这么一个实例化的结构，叫memory。传进来了，类似的message也传进来了，因为他取的名字叫previous message，就之前的聊天记录也取过来了。那这跟我们自己去调这个聊天模型的时候，维护这个message其实是一样的。如果他通过这个k arguments，居民的这个参数解析就传进来了。
	你相当于拿到了之前的这个聊天记录，也拿到了这个memory，这个memory可以用来检索数据据，所以你看他就用这个memory调了这个get relevant documents方法，这是一个什么方法？我们讲memory模块的时候讲过，简单来说就是一个检索的数据库，我需要去取数据，我把这个最常见的就是通过相似度搜索去取跟它相近的。我们当时是找了一篇应该是新冠的TST文档，然后用了这个方法，当时用的chroma。今天我们也会给大家讲一下这部分的具体实践，有一个note大家回忆一下。
	Anyway, 反正就是取出一堆dox。那这个相到其实就简单来说这句话要这行代码要干的核心就是之前的message可能很多，我不能全部都用，我就取一些跟他相关的。因为人聊天他可能这里聊一句那里聊一句，那去执行也是一样的，它不一定都是一个顺序的那他要取出跟现在这个目标最相近的那是最好的。所以他取出这个最后就相当于从这句话往前数10 10句话，这是一个取出来之后变成了最相关的dogs，就是我们刚刚看document，然后完了之后document需要通过page content取出来变成字符串对吧？
	变成字符串，然后再去算一算这个memory里面这一把用了多少的token，就这么个逻辑。这其实就是把memory又取出来用了用，又判断了一下我现在的之前构造的这些token，和我接下来memory这些token加起来是不是超过了一个值，这是一个够的，然后是不是超过了这个2500？如果超过的话，简单一点，我甚至我就只用一句话了，就是我只用之前的上一句话，前面十句我有九句都放弃了，就干这么一个事，然后直到一句一句去终局，可能我最后一句都不剩，对吧？大家能看懂那个while循环，我就不再赘述了，就是我一句一句去拎出来，从十句、九句、8句到最后。然后这里还有一个content form是什么呢？就是我的最终的这个message的content，我希望它有一个特定的一个格式。
	最后这里有一个这个格式是用来表征我从之前的聊天记录里面取了一些内容。所以他这有一个reminds you of this events，就是告诉这个大元模型这一次的推理我给了你一些之前的一些记忆，就from your past给了这个memory，就是我们实际最后通过这个硬编码，2500个token拎出来，还剩几句话就丢到这里面来。然后把这个memory message，就做成一个系统角色的这么一个message。然后丢到我们的这个最终要给AI，或者说给这个GPT4大元模型去作为输入的problem的一部分，use token一直在做记录，把这个memory的这个message也算进去了，而且他现在就是之前这里没有算。现在拎清楚之后，通过这个system message，就是这个南茜的这个system message的content就能去完整的去算出，用统一的方式去算出。到目前为止，就有我们的这个判断的一开始做判断的这个提示词，然后有我们的tools的这个提示词，然后还有我们的这个memory的提示词，一起算出来这个use token OK好，接着到这儿还会去做一个什么样的总量控制呢？就是我们看到他维护了这个historical的message。这个其实是一个很典型的一个数据结构这个数据结构就是我们最终会经常会常用的维护给聊天模型的这个数据结构。
	那这个数据结构里面我们能看到，它其实是从我们的previous message，就是我们刚刚取出来的之前的聊天信息里面，就我们之前会有这个聊天记录，这个来自于这里，用户传的，所以这个其实我可能得再给大家再梳理一下，可能大家听到都有点乱了。再简单一点，一个是memory，一个是message。这是不一样的message，我是可以通过一些message的手段去维护的。然后memory是可能更远期的在向量数据库里的，这是两块大家别搞混了。刚刚维护的是刚刚取出来是memory里面的一些内容，就跟它相关的一些历史问题。所以你看它实际上remind you of this events，它可能是好多天前，甚至好早以前问的一个问题，存在了向量数据库里。但previous message是指我正在我手动维护的，就我们一直在OpenAI到现在都会手动去维护的一个message。但你也可以用连线的一些方式去维护他，这都可以。但是这个是近期的一些聊天记录，最近的一些聊天记录，通过message传进来的，另一个是通过memory传进来的，这俩不一样，这里在维护的是这个message的部分。
	那我们history的message构造出来之后，我们从同样的思路，就是我们在这个memory这边做的这个总量控制，在这个message这边也是一样会去做这个总量控制。然后我们可以看到他就从这取，然后一样的就是如果思路就是完全一样的，我算上了前面的这个提示，算上了memory，再加上我现在的这个previous message。如果我超出了一个这个值，它这里的判断是指我现在用的这个加上我的这个message的大于我的限制。4196减去1000也就3196，对吧？如果我这俩加起来大于3196，那我就直接跳出了那3196，跟着2500大家去算这些硬编码的字，这些都是可以去改的，就这样的实现确实很很硬。你也没法说这两个值，这几个magic word为什么是2500跟这个3196，但是这些都是我们在实现具体任务的时候可以去调的，并且很轻易的能去改动。那么当他们大于这个值的时候，我就不再往里加了，这个反向过程就我现在先加一条，没有超过再加一条，没有超过加第三条，超过了好，第三条就不加了，这样的一个逻辑。然后最终构造出了一个四件套都有的。
	我有这个user inputs，大家还记得前面的部分有这个构思，然后有我的这个memory，有我的message，全部构造到一起，然后放到了这个message里面。所以我们在看这个message的时候，他的这个实践也很简单。一个list里面有我的base，有我的time，有我的memory，再加上我的historical，就构成了我的这个四个部分，这个base就是前面说的最重要的这一部分，go加上post的这一部分，然后最终构成了一个message，这个message会返回出去，对吧？那format message最终返回的是这样的一个message。
	你可以看到auto GPT的这个prompt设计是有一些借鉴之处，当然也有它的一些很硬的实现。就比如说我们刚刚提到这个2500和这对，这里还有一个框框告诉大家这个message的就是我们的整个format message这个方法，包括这个PT的prom方法，这个form message这个方法是aut GPT prom的一个成员方法。它的这个实现方式跟我们其他去构造聊天模型的这个message的方式本质上都是一样。就是我要构造一个好的提示词，这个提示词它是通过模板去构造的，然后这个模板本身还可以再去造各种各样的这个花样。但是它就有这几部分固定的内容，是通常你要去做一个A的去考虑的。比如说我们的memory，比如说我们历史的这个message，比如说我们的这个go这个任务目标是什么？包括我们的停止条件，他这里用了这个vanish，这些其实是构成了一个完整的我们要去做agent的时候比较好的一种实践。其实是模板的套路，这个套路是大家值得去学习的，至于这里面的2500跟这个3196，大家可以自己再去调整，这都没有关系。
	对对，然后我们接着就通过这个再引申出向量数据库，这个我看很多人都在问，但向量数据库其实是另一个很大的命题，它跟人是一样大的一个东西，所以我们会尽量讲跟课程强相关的。这里其实就这个memory就是在使用一个向量数据库对吧？然后这个memory其实大家看它的这里实现也很巧妙。他是用了一个vector store rever这样一个基础类型，就跟我们在文件里面随处可见各种就是这里传一个base model，那你传一个base chat model之类的，通过这个方式，你就可以使用各种各样的memory。因为它反正只需要你要求是一个鸡肋就好了。那那这个其实奥TGPC的实际实现，你就是可以根据你的数据存在的，你就给他传一个对应的memory就好了，就像我们之前用crema，今天可以用face，就是为了专门用一些不同的让大家理解。他不是只能用一种，他只要满足这个设定，他就可以去做对应的事情。
	我们再回忆一下memory，memory是干嘛的？我们刚刚看到有memory，message是一个聊天模型里面一直在维护的东西，这个prom里面有，那memory是我长期记忆，对吧？我先假设忘掉短期记忆，内存里有个长期记忆，他是十天半个月以前的，甚至更长时间的一些记忆放在里面，然后他可以读，可以写。然后读有两个场景，比如说我们这个往这个其就其实就是初始化一个应用程序的时候，我可以把memory加载进来，我也可以不断通过这个运行，然后把每一次生成的一些结果存进去。然后在下一次运行的时候，根据一些条件往里加。就比如说我们刚刚说的这个get relevant documents跟他相似的一些问题，历史上跟他相似的一些问题找出来，丢到这个prompt里面。那如果prompt这个token的上线的要求，我还可以择优录取对吧？我不把所有的历史相关的都丢丢进去。
	这个是一个memory模块的一个比较偏抽象的一个设定和作用。在刚刚看到的这个get relevant documents里面，我们这个方法具体干了什么？首先这个ctr store retrial是一个最基础的retirement的一个实现。大家看到它的鸡肋是base recover，这个通常不会直接用的，大家都会用这个vector store recover，因为它实现了一些具体的图像的方法。就比如说我实际我要去实现一个具体的比如说ma或者说其他的一些recover的时候，我可以复用这个方法。如果他子类没有实现的话，然后大家看这里具体的这个get release documents做了什么事儿，这是一个很典型的实践，它的他的这个获取的方式其实就是在找就是从一堆向量数据里面，就这么多不同高维度的向量数据，我要去找一些跟我相关的那怎么跟他相关？这个度量其实就各种各样都能选了，对吧？
	最常见的就是我们已经用过的这个相似度相似度的这个搜索，它叫这样的一个方法名，就这样的一个搜索类型，也我们也说过这个搜索类型如果你质量太差了，就我们之前讲这个vector store和讲怎么样去造这个prom prompting的时候有找有有讲过。如果你你搜出来太差了，你需要有一个阈值，就比如说你相似度都只有0.1，因为你整个库里面就没有什么跟他相似的，最高的也就0.1，你也返回过来了。这样其实对我的结果是有损害的，我的质量反而会下降。
	那这个时候你可以使用这种score fish后，我加一个阈值。比如说相似度要大于0.5或大于0.7，我再用，那就用这样的方法，类似的还有一些别的方法，我包括这个最大边际相关性，还有一些其他的你去使用的什么memory，它的这个recover的实现各有不同。这个是一个学术的一个重要的研究方向。Face在这一块做的还不错。大家如果了解这个库的话，他在这个相似搜索检索这一块做了很多的优化。
	我们再看一下这个vector store，就是在人气里面有很多的概念。我们再梳理一下，就刚刚刚刚里面实现的那个抽象叫Victor store rever，就是把这个Victor多再加上reveal对吧？但是我们知道这个向量数据库是向量数据库retriever retriever这个应该是两个东西，大家一定要理清楚。向量数据库里面是存这些向量的一个持久化的一个组件，或者说一个服务。就比如说chroma或者我们今天要讲的face，这个是一个就跟我们用mysql去存数据一样，它是存的这个东西，然后retrial是一种手段一种方法，retrial的手段也有很多种。你比如说我们刚刚看的那三种相似度，带阈值的相似度或者最大边际的相似。这个就是相当于一个是一个池子里面有这么多数据，一个是我怎么从池子里面去取数据，这是两个东西。
	所以vector store和这个vector store的recover是两个东西，大家一定要分开。他们的名字上有一些容易让人整晕的地方。我们看得到在南线里面已经支持的Victor很多，我们之前的no notebook demo里面展示过这个comma。
	今天我们讲一讲这个face FAISS base。这个时间紧任务重，只有1个小时。我先把这个部分快速讲完，我们再再给大家留一点时间提问，然后我们进入实战，这个face是一个meta就是facebook这家公司的AI研究小组，放在应该他们的这个fundamental AI research这个小组研发的一个销量数据库。然后这个线上数据库有一些优点，还挺还受到很多关注。但是现在数据库现在也是一个创业的热门赛道，很多人都在做，现在不去直接评价谁特别好，谁特别差，会有一些优劣。
	我们单纯看它的一些特性。第一就是它是一个比较高效的库，就两个大的优点。从他的自己这个自己的描述来看，第一就是性能好，很高效。第二就是说它针对不同类型的数据，就比如说我们现在处理的是tax evading。
	我们到目前为止OpenAI的embedding都是输入是文本，变成一个高位向量。但其实face还支持非结构化的，就不是文本。如果是一个图像，我也可以变成一个云白领。这个大家理解的，就是学过计算机世界应该知道图像也是可以invading的。然后in这个图像的invading，它也能搜，这个是它最大的两个特点。然后除了这些以外，它支持GPU。就是我们在使用下载数据库的时候，可能跟传统的关系型数据库不太一样。就我们很少见到mysql存在GPU上面，mysql可能都用的是这个内存。
	但是向量数据库，因为本身它需要去做各种并行的查。因为他他查找这个事情其实是并行的，它不像我们关键数据库这个表这样去建的。然后他但它的并且有很多种具体的实现，跟它的索引实现有关。但是一句话来说，GPU能够帮助向量数据库提升性能，所以说face就提供了两种版本，一种是CPU的版本，一种是GPU的版本。它同样这个GPU的版本的实现也需要依赖于英伟达的这个大。然后face的这个GPU的版本性能很好，然后它能支持CPU或者GPU输入，就跟这个test flow的GPU版本兼容了，CP就和GPU1样，这是比较常见的一种兼容方式。
	就是你你之前有一些存在CPU上的，可以直接掏过来，用它的平替的这个方法，他有一个建索引的方法，这是它的性能好的一个很重要的一个关键。然后如果CPU的版本使用这个index的flat 12，然后如果是CPU的版本前面加一个前缀，然后如果你之前已经有一些CPU上传的向量，可以通过替换这个CPU，应该把它从CPU传到这个CPU上去。它也支持单个或者多个GPU并行去使用。然后如果你全程都在GPU上，不是这种一会儿CPU1会儿GPU的话，那性能会更好。
	这个是他给的一个性能数据，没有去做最新的验证，但是看性能确实还是不错。首先第一他提了一个就是你你做这个检索，最重要的是召回。就是你别明明那个库里有这个答案，结果你没给我找出来，那这个是最蛋疼的。那么这个one recall是一个重要指标，他这边能看这幅图的话，就是我们看他的这个横纵轴，横就是这个one recall的成功率，就是这个召回率，就是找到一定找到一个，就别一个都找不到，无论如何我能找到一个答案。这个有一个比例，从0%到50%。
	然后纵轴是毫秒，就是每个Victor要用多少毫秒，一个Victor其实就相当于一个结果。因为向量数据库我查会查出来的结果就是然后这里有一个点是说，当它在小于2毫秒的情况下，有40%的召回汇率，这个还是很好的一个值。然后在一个单核心上面，它能做到500的QPS，就一秒钟能查500次。
	然后那我们要怎么看这个2毫秒呢？这里是一毫秒对吧？这边写一毫秒的时候，它是不到43% 18左右的一个very的一个比例。如果是2毫秒的话，其实应该是这个值就40%。
	所以。是这样的一个看看这个性能的一个方法，这个值还是不错的。至少我初步定了下来，还算是一个还不错的数据。但是跟商业的或者说一些最新的开源数据库谁更好？也欢迎同学讨论，给一些这个向量数据库的benchmark。
	那提到bench mark，那就得说是在什么样的一个数据集上面去测出来的。我印象当中应该是在叫deep one b这样的一个数据集上面，当时有一篇sota的论文，在2016今年的CVPR上面是20毫秒45%的一个one recall。那大家看这个图的话，20毫秒就这儿这个十上面再加一个double这个数字，那这个数字拉过去其实差不多就是47% 8的一个recall，其实是比这个CVPR2016的结果要好的。这个是face的一个初步介绍，它是一个开源的项目。Facebook发布的性能还不错，能支持文本和非结构化的一些向量存储。
	这个是一个简单的流程，时间关系我就不再赘述了。简单来说就是各种各样的输入，通过它的embedding n加indexing之后存下来，然后可以存在内存或者显存里。然后这个result是指它检索的过程，就是我们刚刚retried的过程。通过一个特定的向量相似度的一个方式，我去取出跟他最相似的，把那个度量函数我们可以自己选，然后得到一个结果。那这个跟他相似的他是什么呢？就是这个query，所以他故意用了一个图像的方式去表达。
	就是想告诉大家，其实向量数据库它不是一个很死板的，只能存文本的。因为向量数据库存的是那些高维的向量in bedding的结果。所以只要你的embedding做的够好，他就存下来就完了。因为对于向量数据库来说，他不care这个emb ign原来是个啥玩意儿，它只care它只知道的是你的embedding足够好。那么我的这个result的度量就是成立的那我新的query进来，我就能通过这个向量之间的度量算出跟它相似的东西。这个是这一页想要表达内容。向量数据库跟关系数据库最大的区别在这儿，存的是invalid。北京很重要，大家要理解用北京这个概念。
	我们最后再看一眼这个output poser的设计，output partner是什么呢？其实就是我们很多同学就一直在问的，但是又语的不是很清楚的一个模块。Output part其实第一我们知道这个output partner是从刚刚的这个AI的推理结果，AI assistant reply里面把它作为输入。我们要pass出一些action，就是接下来要给to我们去执行的一些东西。我们看这个类它的pass方法，输入是我们的这个text，直接text就是我们的AI大模型输出的一个结果这个就是我们要返回的一些action这么一个设定。这个action其实大家可以看到，这个是他一个name的turbo，就是一个python的一个新的pid 3的1种内置的一种数据类型。大家不用介意，这其实这个action就我们开始我页面看到的有一个名称，有一个argues名称是一个字符串argument，是一个字典，就这么一个玩意儿，它是封装成了一个auto GPT的一个action，返回是这么一个东西，然后他具体怎么pass呢？我们能看到就这就这那返回的就是一个pass这个command name，这个command August，他通过这样的一个方式来把我要的操作的名称和参数复制过去了。
	那这个pass是什么东西呢？其实就是通过这个js node来的，就把输入的这个内容通过Jason，变成了我们的一个序列化的一个字符串。然后从序列化的字符串里面去取这个名字和结果，跟function calling和我们的ChatGPT这个插件很像。所以他要求我们的tax相对来说还是比较稳定的。
	然后这里还定义了一个base out GPT的output，然后他们其实是去相当于层层的去去去做这个嵌套。大家可以看到这里其实是用了这个base out output partner，就是你自己要自定义一个outpower的话，一定要基于它。然后这里又做了一个叫做抽象，这个抽象是把它做了一层子类的一个实现。然后这里有一个pass方法，这个pass方法就是留给实际的out GBT的这个partner去实现的这个pass方法。但是他还有一个Jason的这个out input的处理，这里是做了一个简单的一个正则表达式的处理，就是怎么把一些这个字符串给它这个格式整顿，这儿我们就不再赘述了。其实这个是一个非常常见的套路，大家问很多问这个out partner怎么处理的，可以看一看这部分的一个实现是很典型和经典的。
	好，到这儿其实我们把整个PPT的实现就讲完了。大家回顾一下，我们的这个奥特GPT的这个代码，就这么几个PY文件。然后我们回到这一页。
	核心其实就是这个乱方法，它串起来了所有的抽象，我们有自己的OTGPT的这个class，他需要这个四件套的输入user input goals，然后我们的这个memory和我们的这个message。这四个输入直接使得我们的这个rand的主体能够不断的去执行。然后在这个执行过程当中，我们在构造我们的这个prompt，这个prompt的构造也分成了几部分，并且还在计算这个prompt有没有超过这个上限。这个prop里面有一些magic word一些硬编码的上限的值。比如说我们的这个2500，比如说我们的这个3196，这些都是大家可以去做修改和调整的。
	然后整个prom的设计其实是跟这个aut GPT的agent out the part是一起的。比如说他在prompt里面预埋了，你要判断是不是所有任务都结束了。是的话，把这个finish command写一写。然后如果不是的话，继续执行。
	他会把这个goals列出来，1234567对吧？然后会把我们的这个memory用起来。如果我们传了memory，这个memory里面过去历史上有一些记录我会去记。如果没有的话没关系，我就从这一次开始往这个memory里面去做添加。Message也是一样，在我没有超过我的这个token限制的情况下，我就把我们的这个message不断的去做往往里添加的一个动作。
	比如说我过去一条，我能记下来，过去两条、三条、四条一直加到我能加到上限，通过这样的一个方式去构造我们的这个message，最终不断的去做这个循环，使我们的这个agent得以实现。其实整个奥TGPT的这个版本的实现，也就是这些内容就能够做出来了，没有想象中那么复杂，对吧？我们看看大家谁有什么问题。
	有些同学问，如果有一个agents，有一个message特别长，超过限制怎么办？这个你得看看，如果4000个token都都没法满足你的一个生存要求，那那确实不太靠谱，就说明这个message的不太靠谱。但是如果实在是你觉得这个message就需要这么长，也是还有办法的。我们知道GPT4有32K的版本，你可以选择试一试，就是可能比较花钱。这个是一个理论上message太长不是一个很好的现象。因为你要知道大元模型它的处理上下文窗口能力是有限的，太长的message会让他拿不到精确结果。
	原先的agent execute有什么不支持吗？为啥不基于agent excute实现，而是要重新写一套？这个同学问了一个好问题，首先沿线的agent execute是一个抽象的运行时，它跟实现这样的一个应用程序是不一样的。这是两个两个层次的东西。就可以这么理解，就是原来的那个agent execute过于简单了。你会去你回想一下那个agent excute代码，你去看源代码就知道了。他没有这么多prompt的精巧设计。原来的这个agent export是需要你去设计这些prompt的。
	然后为什么要重新写一套？是因为我从我的个人判断，第一r GPT很火人线去实现和LGBT能体现LGBT能体现人性的能力，对吧？就你l GPT这么大一个代码库，我就这样就实现了。虽然可能质量没你高，但是这个架子搭起来了，你要怎么样去优化，你可以再自己优化。第二放在experimental里面，也是希望大家去群策群力做贡献。
	南茜的奥特GPT和TGPT是同一个团队开发的吗？不是。这个auto GPT只是用来学习它的思想源源码，还是说直接可以用？当然直接可以用，只是说没有那么好用。为什么没有那么好用？就是这1个小时要告诉大家的，这个prom的设计还可以再优化。包括这些神奇的token限制也都可以再优化，包括使用memory的方法也都可以再优化。
	这个都是根据你的具体场景来的，因为你要根据场景来决策memory怎么用，然后previous message怎么用，prompt应该怎么调。对这个代码丢到ChatGPT里，让他逐行详细解读也可以吧。这个同学问的问题可以自己试一试，他应该能解答一部分。但是有很多import的包它没有代码，所以它不是特别有可能不是特别准确，会有一些不是很准确的地方。对，GPT4也许还可以，因为它可能吸收了一些新数据。
	GPT4考虑多用户并发的话，memory要和session绑定，是一个很好的问题。这个看咱们的场景，就比如说如果我们的多用户是完全数据隔离的话，那可能是需要的。但如果我们的多用户问的是一个很泛的场景，并且他的历史聊天记录不会个性化的影响回答的话，那我觉得是没有必要的。因为大家共享了其他用户的提问，其实是对于咱们服务端来说是压力很小。就比如说你做了一个天气的应用，这个天气的应用问的是上海今天多少度。然后用户A问了一次，用户B直接去访问memory就好了。他不应该再来走一遍完整的的GPT流程。
	看大家还有什么问题吗？有没有听懵掉的？
	我们稍微休息两分钟，大家提提问，我去接杯水。
	把那个牛的alt GBT的prompt，那个牛的是demo特别牛，它也不是所有都可用的，他也是有这个特定场景的。
	有个同学问to是在哪里实现的？这个问题很多同学都问过。Toss是南线内部实现了很多。对，需要大家再回顾一下之前的课程，还有列出来所有的toss有哪些？这个大家再看一下，这里有写，这个tools是能欠自己有去实现的。但这个实现不是指他把google写了一遍，而是他对接了对类似的像这个向量存库，也不是说他自己维护了40个向量数据库服务，而他对接了相关的API单元模型也是同样的道理。
	有个同学问介绍一下GPU怎么限购，是什么概念？这个能稍微细一点。如果是基于私有文档的问答，使用上面的retrial al合适，还是包装成to更合适？我理解一下这个问题。
	和这个我不太清楚咱们是要做一个什么东西。如果是一个问答机器人的话，他甚至都不需要使用auto GPT这么复杂的实现。你想问答机器人更像什么？更像一个action agents，一个行动代理，它是更直接的，然后你就套recover就好了。然后我们下节课不是也要做这样的一个实战吗？
	Auto GPT的爬虫和年轻的爬虫能力一致吗？这是个好问题。第一他们俩都不解决爬虫的能力。我不知道我讲完这么多大家有没理解，这俩奥特GPT和南劝都不解决爬虫的事儿，然后都是他们对接的tos来解决爬虫的事。那就纯看怎么对接的，以及爬的时候给的pro好不好。
	我还有个同学问，如果能对照单独调用auto GPT本身和今晚能建一起用做对比可能更清晰。这同学没听懂，就是不存在auto GPT和能一起用。对，你可以理解成auto GPT是一个应用程序，跟ChatGPT是一模一样的，就跟OpenAI translator是一模一样的。南茜是一个造这种应用程序的框架，现在是用南茜的这些框架比较方便的实现了一种auto GPT。Auto GPT它就只是一种应用程序，它它的功能定位、目标都是有明确的定义的，就我们这一页写的。所以open I translator也是一样，我们可以不用能欠，也可以用能欠。它本身就是一个翻译工具。对，就像ChatGPT是一个翻译工具，你可以用GPT3.5，也可以用GPT4，当然你还可以用蓝线实现一个聊天机器人，就类似于ChatGPT1样。
	现在有做问答结果评估的服务吗？有时候GPT自己为是想让三方服务辅助他评估是否解决了问题。这个同学可以具体提一下，这个要举个例子，就是要怎么样结果评估。因为这个GB就是你相当于有一个鸡生蛋蛋生鸡的问题。所以你得举一下具体的介绍一下GPU怎么选购。GPU的这个选购，我们会在最后一周私有化部署的时候去讲。
	对但是我举个例子，就是这个GPU怎么选，就跟你怎么选房子是一样的。就是你自己首先得清楚你的需求是什么，对吧？就比如说图像生成和文本生成，这个维度不一定是那么大的。
	就比如说我们选房子你会怎么选？你会选面积，这是一个很刚的一个指数的面积。然后你会选什么？你会选三室一厅还是四室一厅，还是四室两厅？这是很刚的参数对吧？
	那我们在这个课里面的GPU的部分，也是想告诉大家，GPU的选购也有这样很刚的一些参数。就是你你讲应用怎么选没法聊的。就比如说你帮我老婆选一下房子，我怎么知道你老婆要什么样的房子，对吧？这没法聊的。但是你说我要一个三室一厅99平的房子朝南，然后最好日照时间是多长，那是可以聊的那GPU有类似的东西，比如说我有显存对吧？我有扩大的核心数，我有tensor的这个知识的核心数，我有它的算力。比如说它是多少flops的算力，在全精度下，在半精度下，这些参数是干是比较干的一些参数，那是可以聊的。所以咱们要把这个应用程序转换成业务语言，或者说转换成GPU的指标，我们再来选GPU才有的选。
	我看到有个同学居然问了一个错误日志，就是message超过一定的token大小，没有超过模型的限制，用能券实现翻译的时候一直报。Error in standard out call back handler on retire has no attribute on retry. 所以这个上下文缺失，同学你的上下文不够，我没法帮你解答这个问题。对。我不知道你是指open s state这个项目吗？还是指什么？对，如果是这个项目的话，我建议你提一宿，就提提github面的issue。大家都能看到toss有没有他人开发好的，直接用的，有没有集合类的文章或者社区，去看南线的官方文档，它上面的took是更新的最快的，也就跟着代码走的对。然后如果你单纯说你发现了一个特别好用的tss南线，这个生态还没接进来，那你可以去社区提issue，提这个request的这个issue让他去接，或者说咱们自己直接提pull request去把你的实现贡献到市区里去，那这个图就接到这个生态里了。好的，那等张涛同学回头提了一宿之后，我们大家一起看一看。那行，那我们就进到具体的实战的部分，让大家感受一下这个好的GPT和这个向量数据库。
	就是在这个南券auto Normal的这个agents GPT下面，就我们刚刚看那些代码，大家可以再去研究研究。
	好，那我们在这个目录下面有两个notebook，在我们的two patter我们可以看一下，在这个南茜的拍摄下面有这个应该是对这个目录应该是空的，把它删掉。
	在jupiter我们之前有很多的核心模块，我们把能线把这个能线版本的r GPT也放在这里了。这里有一些中间结果的文件，我到时候不会上传的，就是一些示例文件。对，就中间结果不重要。然后有两个最重要的，一个是这个FAISS这个向量数据库，就是meta发布的这个开源的项目。还有一个就是这个auto GPT的目录。这个大小大家能看清楚吗？
	这大小需要再放大吗？
	当然没回，那应该是OK的。好，我们这个ISS这里这个notebook是想让大家再温故回忆一下在南京里面怎么样去对接向量数据库。第一首先咱们需要安装一下这个face这个python的包，然后它有两个版本，我们刚才提一个CPU的，一个GPU的。我这台macbook我就直接装，我这台服务器，linux的服务器远端的我就直接装这个CPU的版本了，他没有GPU。然后如果是要装GPU的，可以使用这个杠GPU的这个版本来安装，它是兼容CPU的。好，我们重新启动一下。
	好，这里我们回忆一下之前讲这个向量数据库的时候，是怎么怎么教大家当时用的。然后用了这样的一个文件，state of the union这样的一个测试文件。然后几个核心要素，第一个就是重新我加载了一个。
	好，第一个就是需要import一些特定的我们的这些库，第一个就是我们的这个text node文档加载器。在data connection的这个章节有讲过，如我不记得的话，请跳转到这个data connection这一节，我们有专门讲四个重要环节，loader transformer embedding store好吧，然后这儿大家有不懂的可以回去再翻一翻，对比着看一看这两个向量数据库的使用就好了。这里的text loader其实就是加载一个测试文件，有这么一个TST加载进来之后，这是一个实例化的这个loader，然后我们还有很多loader对吧？当时讲过arve loader去加载这个论文，然后还有一些什么加载视频的字幕的，这个地方我们就加载这个文档，然后实际加载的这个文档就放在这个documents里面。
	好，然后这个是加载出来的一个文档，然后这个文档我们先把这个之前存的向量数据库的结果删掉。好，然后我们需要再把这个很长的文档给它分段，按这个character text litter。这个讲过了文本分割器一个大文本，按1000这个字符去做切割，并且overlap是0，就是没有重叠的，等会切得干净一点，没有重叠，方便我们做检索。然后实际切割出来之后，我们把它放到这个docs里面，split documents。然后到这儿为止，其实我们把这个文档就加载进来了，box是长这样的，跟我们刚刚在RGB t里看到的所有的用rever他们获取结果都是这样的一个格式。其实基础的这个单元是这个document这样的一个抽象，然后里面的具体内容放在了这个page content里面，我们输入这个把这个OpenAI的这个invade ence，这是text ADA002的这个invading模型，最早我们前面几周就已经学过了。实例化。
	然后这个地方是一个新的部分，我们要用这个向量数据库，这个向量数据库怎么样去实例化呢？这里还记得roma怎么用的吗？Roma有多种方式来做初始化，这是一个最简洁的方式，就有点类似于我们去定义一个LLM chain的时候，要传大语言模型和prom的这个模板。这也是一样，这个dogs是我们想要去evading的内容，就是这样的一个内容。这个in bedient是一个invading的模型对吧？然后通过这个from documents方法，我们是把这个dogs通过这个evening模型变成向量，并且存到这个向量数据库里。这个方式跟我们当时学这个chroma是一模一样的。
	不要有同学忘了之前学的内容，我们看一看这个地方的vector store，我们讲了这个。还记得吗？这里一模一样的，只是我们把这儿换成了face对吧？From documents因为他们都基于年线的基础，底层的积累去做的实现，所以这里的接口很统一，就把我们的这个documents和我们的这个invading的实例丢进去，就不再赘述了。
	然后我们把这个实例化一下，这个DB相当于这个TXT文档变成了切割之后的这个文本，文本再通过这个open I的evading模型变成了一个向量。这个时候我们就完成了从加载到这个切割，然后到evading到存到Victor store就结束了。接着我们才完成的是这个retried的过程，对吧？
	你有一个query，这个query要去vector store里面去查谁跟他最相似，那比如说我们构造的这个query就。What did the president say about kentish Brown Jackson? 然后这是一个query，然后我们还记得这个similar search，这些方法都是一致的接口，就是大家了解南天的这个接口的统一还是做的相对来说比较规范的。我们可以直接通过querrey来搜索，也可以通过query的evading来搜索，对吧？那我们就没有必要再做一次embedding了，他会默认用这个DB的。你这个GB初始化的时候，我就知道他要用什么嵌入模型，所以他在这儿直接给query的话，他会把这个query通过这个invidious变成对应的向量，再去这个向量数据库里去搜。这个在data connection那节讲过，这是我们搜出来的一个结果，就我们搜出来跟query相近的这个结果，我们可以打印一下看看。这个是跟这个query相关最相关的一个输出结果，这儿我就不再赘述了，这个操作都是一致的，我给大家让大家熟练一下。
	不过当时讲这个data connection的时候，没有讲的一点是什么呢？就是讲这个持久化存储。我记得当时有同学问，但是我们当时没去做，一个比较简单的一个方式就是这个save local方法，当然它还有其他的一些序列化的相关的一些save方法。但我们做开发测试的话，用这个save local是最简洁的。
	我们回到这个alt GPT的这个目录，我们可以看到，我们可以把现在滴滴里面存的这些结果存下来。Save local会新增加一个这样的目录，就是说我们刚刚把向量数据库里的结果存下来，可以生成这个pico的文件。然后。
	那现在假设我们的场景是我新启动了一个应用，这个应用需要去加载原来存存好的一个向量数据库。而不是说我去直接加载一个文档，然后文档变成向量，向量再用来初始化，而是加在一个已经有内容的一个向量数据库。那怎么加载呢？一样的使用这个load的这个local方法，但这个时候你需要用这个FISS是这个就是我们因为你还没有实例化，对吧？你是通过这个类方法来直接加载的，那么new DB就是新加载这个new DB，然后还是说这个quercy是没有变化的。我们打印一下，这个结果是完全一致的，跟我们之前在内存里面的这个结果是完全一致的那这几个接口是最常用的。然后大家如果想要换别的这个销量数据库，套路也是一样的如果它的这个接口有略微的调整，可以看看API文档，这个应该是很通顺的一个事情。
	接着我们再看一下这个auto PPT，这里需要安装几个库。第一个是提醒大家，如果我们从上课到现在也过了一个多月了，大家没有去更新蓝倩的话，可以去更新一下南倩，更agreed。我们重新启动一下这个路子。
	好，刚刚还有提到这个南茜的experimental是一个单独的包，所以大家一定需要装这个，这个是我们之前的课程里面没有安装的。
	然后从这其实大家能从路径依赖看得出来，南倩的experimental对于南倩的包的依赖并不是那么高，他只需要239这个版本就好了。但我们刚刚安装最新版本是已经到了274对吧？所以其实本身experimental对于底层的依赖迭代还好，所以而且它是完整的两个包。这个face CPU刚刚也提过了，就是我们这个demo里面用到的一个向量数据库，咱们可以去需要去做安装。然后接着就是这个tool，这个tour我们最重要的联网的这个tool是用的这个service API。这个在讲连线的agent那节课的时候已经专门讲过了，我再再去登录什么的，大家自己再看一看那一节的课程和demo。
	然后我们从这个南茜的utilities里面去导入了这个surf API的这个封装，然后接着我们从agents里面去获取了这个图，就相当于标准化的一个工具，它需要通过这个two来进行实例化，就这样的一个方式跟我们定义方形框很像。然后接着我们还会去取两个预定义的，在file management下面有一个写文件的图和一个读文件的图。然后我们能看到这里自定义了一个two，这跟我们之前用react是一样的。因为这个to需要三个重要的变量来三个重要的参数来进行构造。一个是这个to o的名字，这是我们最后用LGPT的时候去调用的这个action name。大家还记得的话就是个two name。
	然后它还会有一些参数，然后包括它会需要有一些具体的可执行的to，那就分为这三部分。然后这个参数其实对于这个surf API来说，其实就是他要的这个我要搜什么内容，然后这个东西在search点run里面已经被实现好了，直接传进去就好啊，通过它已经实现好了OK然后这两个是系统内置的突兀，所以可以直接去使用，因为它已经是一个突然的子类了。然后我们继续看看这个要怎么用，因为我们还需要使用这个open I的in bedding，我们导入这个open invading的模型，接着我们使用这个face的向量数据库。这比较需要注意的一个跟刚刚比起来没有介绍的新的功能，就是它的这个索引的功能，这里使用它的这个index flat l2，因为我们CPU的，如果你是GPU的话，可以使用它的GPU index let l2。然后这里做的视频我们可以看一下。
	第一大家还记得OpenAI的这个in bedding模型是1536维的。所以其实是为了给什么呢？给我们的这个，这里怎么讲，应该大家有一些这个数据库的使用经验会大概理解。我们可以类似的来理解，就是说在使用数据库的时候，我们可以一条一条的去查数据，也可以建一个索引，它你可以简单理解，建了索引之后我能查的更快。就跟你读书的时候，我会有一个书签，像这个便利贴贴在这个书里面，我就能快速的给它分了章节。那我可以按章节来搜，或者说他分了这个页码或者之类的，通过索引我们可以去提升检索效率。
	关系型数据库如此，向量数据库也是一样，像这个base他自己提供了很多种不同的所以方法。比较常用的是这个index的black l2索引，它需要输入的是这个向量的维度，那种对1536维的向量维度用来建这个索引，所以我们再去实例化。就刚刚这里是有一个DD from documents，然后传了一个documents的列表和一个向量的embedding的模型的实例。那也可以通过这个方式，这个方式就是它的类方法来构造，对吧？跟我们刚看到GPT的时候有这个from方法和构造函数一样。所有的这些类它的实例当然都会有多种方式去具体的实例化。
	这里这个方法略微不同在哪？第一就是我们可以看到这个in bedding model，是我们开始定义好这个in bedding model。然后这儿传入的是他的这个in back query，传这样的一个数据类型。然后接着传index，就是我们这儿实例画出来的这个索引。然后再传这个in memory的这个dog store，就是要传他具体要用什么样的这个方式去存这个，你可以理解就是怎么样去存这个数据。那之前我们是存成了一个文具体的文件可以存到这儿，也可以存到这个内存里面。如果你是GPU，它可以存在显存里面，然后空的，这里没有这个向量数据库是一个空的，这里是空，没有存任何东西。好，那我们执行一下之后，获取到了一个向量数据库，就我们刚刚看到这个完整的路径里面有一个向量数据库，然后有一个每次询问的query和一个具体的recovered，对吧？
	那我们再回忆一下刚刚讲奥特GPT的代码的时候，这里我们把奥特GPT从这个experimental然后Normal agents里面导入进来，然后使用的是一个OpenAI的聊天模型。这里我们知道如果默认用这个，他会用GPT3.5对吧？然后我们从这个OGBT的刚刚的源码解读里面，知道这个方法是需要一些特定的输入的，有些是躲不掉的。比如说这个name row，然后我们的这个tools，tools就我们刚刚定义的这个tools。那现在这个tools它就具备了联网读写文件的能力。然后如果我们要用别的tools，就是去修改这个tools的部分。如果我们要换这个语言模型，那就去换语言模型。
	然后这个memory是什么？我们刚刚有记得memory在它的这个实现里面是一个vector store的recover，对吧？然后我们这儿的这个vector store是一个向量数据库，所有的向量数据库只要符合能线的这个向量数据库的定义，都会有一个方法叫做as recover。你可以简单理解成我这个向量数据库本身它就实现了一个recover，那通过这个方式可以直接用，也是一样的。那就能够符合auto GPT的from方法实例化所需要的所有的内容了。所以这样的一个auto GPT就具备了三个tools，然后一个assistant的身份，然后使用了GPT3.5，因为GPT是稍微有点贵，给大家做demo，然后大家自己可以去试一试使用试一试。
	然后用这个GPT任务作为它的这个单元模型。然后memory使用的是就是它的这个向量数据库使用的是这个base，去定义出来这样的一个agent。然后这里我们知道要去看他内部的日志，有一个verbs对吧？那我们的这个agent这样实例化之后，我们刚刚看代码里面有写这个方法。内部会去把这个LLM和它的这个prompt整体做成一个嵌。所以它会有一个self chain，那我们自然就能访问到这个欠他把他的verbal设置为true，就能看到更多的内部日志。
	我也试了很多的不同的agent的样例，我的一个直观体验是什么呢？第一就是因为现在这个tools很弱，我们没有给他太多别的tools。就我们这里所以大家课后需要去尝试做的一些事情有哪些呢？第一就是说咱们要尽可能的去尝试一些不同的poss，给他增加一些能力，然后让他去选，这个是第一个。然后第二个就是说在用的过程当中，根据你的to不同，它能够解决的问题的范围规模也是不一样的。你现在直接只有读写文件的能力和搜索网络的能力去生成代码，是比较难的，这个可以直观的说，但是你去让他搜寻一些结果是很简单的。比如说我们之前的这个react去问什么大运会什么的，我们可以再试试当时的那个react的一个问题。
	甚至可以给他问多个问题，我可以先一个一个试吧。大运会举办地。
	大家可以看到因为我们把这个LM chain的这个table设置为竖，所以它能够正常的去把这个日志打印出来。但是这个比起瑞我们用那个react和agent excute的时候明显不同。就开始有个同学问有什么区别？区别就在于RGBT它自己这个类，它实现了这些prom的一些设计，我们可以在在这学习参考做了些什么。
	第一，大家还记得这一段话，在我们的auto GPT的prompt里面定义属于prompt的start，对吧？他会写你是谁，然后角色是什么，这一段就是他的prompt start，这个goals他自己拆解出来的，然后constant，这个是它的一些限制，比如说4000个词的这个限制。然后如果你不确定的话，往往有一些限制性。这个comments是他给的一个参考的列表，就是我们能有一些什么样的能力，我们这是值得我们去细看它内部的一个实现逻辑。
	第一，大家知道我们给了三个to，就对应的这三个to分别是search，就我们的search API他能做什么呢？他能去联网搜索问题。然后搜索问题的这个schemer是一个这是two input，这是一个type和string，跟我们写方形call很像有一个写文件的图，有一个读文件的图，写文件的图需要有文件路径，文件的名称描述。这个描述就是指这个文件，这个title是指文件的路径，description是指文件的名称，对吧？是不一样的对吧？不好意思，然后这个type里面还有这个文件的类型，就是这个TST还是mark down之类的。然后还有就是我们的这个文件具体要写什么内容，然后要怎么样去给它添加内容等等。这个是一个rest file to的内容。
	如果我们有一些其他的tour，大家不想去看源代码，他到底干了什么事？通过这个方式是一个比较简洁去看他最终给到我们的大源模型去干活的时候，他生成的command什么样。然后需要注意的是说，这里我们还有一个finish，对吧？这个也是我们在奥特GPT的from里面看到的，他通过这个vanish去做了这个控制。就是如果我们判断没有够，就输出一个vanish。然后还有这个resource，还有哪些可以用的资源，还能联网，还有这个长期的记忆管理。这是因为我们传入了一个FAISS这样的一个项目数据库，它是一个GPT3.5 power的agents。因为我们传的这个默认的开头NAI的模型是GP3.5，它还有这个文件输出的能力，他的这个performance evaluation数据，它的表现的一个预估等等。
	然后这是一个对它的输出的一个要求，就是我们的这个单元模型的输出的一个要求，做了一个格式的参考response format。然后我们能看到这个结构就是比较适合用来auto GPT的output part，直接接上node就能返回的一个结果。好，然后这个地方是insure巴拉巴拉，然后这个是他们的time format。大家如果还有印象的话，然后这个地方是它的这个memory。因为之前是空的，没有记忆，所以这个地方memory是空的。然后human是我们最后有一个user input，大家如果还有印象的话，然后finish change是他AI assistant的reply，这个AI的返回结果是满足他的format要求的。
	Response format, 然后这里有thoughts command，source是什么？Command是什么？这就其实就对应着我们的推理吧？和我们的这个comment，就是我们要做的操作这个格式它做的是蛮漂亮。
	然后大家想象一下，如果你要做一个prom的设计，能干到这程度吗？其实很难吧？所以为什么要去学这些好的agents的设计？一方面是因为它的分他的分块分角色。然后包括什么construction，什么是command，什么是resource，什么是response format，这些东西都能够让你更好的去做这些结果的获取，让你进一步能够把agent做漂亮。
	包括你看他为什么要买一个time的这个prompt，也是因为我们最终这些结果问了很多次之后，他们都会变成你的上下文，变成你的message。那你有这个time是不是对于大语言模型来说，它自己就带了时序了，对吧？但是比较有意思的事情是我们看到他都要去search对吧？search. 
	然后这个测试的是什么呢？是2023年的world university games location。我不知道这个算不算大运会的翻译，然后他就会实际去执行这个翻译的操作。因为整个这一段执行完，大家回想一下我们刚刚说的源代码的解读，他只做到了assistant的这个reply，然后还没有去进行这个action，没有去真实的去执行这个to。到这儿我们应该看到他会实际的去执行这个two了。
	到这儿为止大家可以看到这是刚刚上一段的assistant reply被放在这里了，然后还有他的这个结果也被放在这里了。这里search command这个就是它的result，我们还有印象的话，为什么花时间讲代码？就是让大家能看懂他的这个LMC的输出，我们最后造了一个输出的message，里面前半部分是我们的assistant to reply，后半部分是我们的这个results。大家如果有印象的话看一下，我记得我们上节课用过一个工具，看看它现在还好不好用or matter。
	但他也分不出来，那那肯定不行，他只能对嵌套的list比较好用这种list加字典的他就没法干活了得用这个节省format，但不重要。这个大家应该能看出来，这个就找一个formatter的工具就能看明白了。这个command再加上这个arguments，包括它的结果写的很清楚。然后这里的这个human就我们的这个using input，用来再去做判断需不需要结束。然后他把他这个结果最终写到了这样的一个文本里。然后这个。刚才还继续在finish，他认为他判断结束了，不过这个结果好像是不对。北美看一下他写到了2023年的这个，这个是他最终写到文件里的一个结果，为什么会发生写到文件里，并且是一个这样的文件命名。
	其实到这儿大家应该能理解了，就是我们怎样去用好agent和之前怎么样去用好这个t GPT1样。它其实需要很多的你说叫套路也好，叫技巧也好，其实是需要你去理解他这堆prom的到底背后是怎么构造的。就比如说我们现在其实是有一个预期，这个预期是他要写到这个文件里的，那么他自然就会去生成一个文件，然后你又没有去在目标里给清楚他写到什么文件里面，那么他他就不会把这个写清楚。
	我们现在再来看一个很有意思，就是我们重新把这个问题做成两个问题。一个是问这个大运会的举办地在哪？然后我们再看一下这个。
	放到下一个我把这个日志影响。
	首先我们能看到，当两个问题传进去的时候，在背面的问题。当两个问题输输进来的时候，这个prom的设计是按照我们的预期发生的对吧？他把go变成了两个，然后这两个go在处理过程当中，我们需要看看他有没有去复用之前的这个结果。是2023年的大运会举办地在哪？这个过程当中我们看到，他去提了一些新的prompt，这个是初次执行，但是这一段之前是空的，大家如果有印象的话就this reminds you of the this event from your past。就是这个是memory里面的结果，对吧？
	就我们看刚刚的这个代码实践的话，再给大家回忆一下。我们在auto GPT的这个from的定义里面。我们可以看到这个。Content format对吧？
	This reminds you of this elements from your past, 是来自于relevant memory。那relevant memory来自于哪呢？来自于这里，来自于relevant documents，来自于memory的get relevant documents？那么从这个视角来看，其实它完整的取出来了。在内存里面就我们还没有把现在的这个第一个问题的结果存下来，在内存里面存了一些结果，而这个结果是直接可以取出来的。然后那这会我们再看他下一步干了什么，然后。他在解读这些内容，然后写写了一个文件。直接就完成了所有的任务。然后我们看一下他的第二个问题，奖牌数是放在哪儿呢？
	Human command search command search AI的反馈结果是这个。
	这GPT3.5应该就是出现了问题了。我们从这个debug的方式也会跟以前有一些不同。首先大家能看得到，通过这个输出把我们的assistance的输出结果就是这一段。这一段其实是拼接了两次的结果，我们通过这个assistant reply应该是能区分出来的。这个是第一段的一个结果，然后这个是第二段的一个结果。然后第二段的这个结果，他是在这个决策他需要知道2023他应该是把这个world university game这个location举办地，然后他要去搜索短期记忆里没有然后拿到了这个举办地的一个结果。然后这个结果就直接使得这个大元模型造成了一个误导，是什么？就是他忘记了他有第二个go，这可能就是GPT3.5确实比较弱的一个地方。
	那我们可以同样的点，就是我们有讲到对于agent现在的实现确实是高度依赖于两个东西的。一个是我们的这个单元模型本身，然后还有就是我们的这个prom的设计。短期来看，其实我相信大家prom的设计是有各种技巧的，不能很快速的有一个跃升。那一个直接的一个能够改变他的一个思路和套路，就是去做一个大模型的切换。我们可以试一试。首先我们把这个agent做一个。新的处理。
	假设我们第一个。T4的一个agents。
	然后这里有一个细节需要注意的是什么呢？就是我们能看到整个新定义的agent里面，其实memory是不是一个新的，它它已经存下来了。刚刚的一些内容就是我们在在这儿定义的这个vector store，通过前面这两次执行，其实已经存下来了一些内容。
	所以一个比较稳妥的做法，目前也没有一些绝对的标准。就是我们再去实现比如说电层DB，再去实现一些特定的不同的agent的时候。目前我的经验是，如果这个基础模型是不一样的，那么可以用不同的这个DB是比较靠谱的。也有可能它的搜索逻辑会不同，就相当于这个基础模型变了，同样的query去得到的结果是不一样的。那这个时候往同样的一个DB，往同样的一个vector store里面传，是会出一些比较麻烦的问题的那我们再来试一下它来执行这个问题是什么样的一个效果。
	犯了什么错？
	还不能直接这样。看一下memory store。
	就是这个。
	应该这个初始化不能把这个。In memory这里直接这样做处理，需要把它清干净内存里面，我们现在只能重复用一下这个memory。在这里大家可以看到我们没有把这个verbs打开的话，它其实只会输出这个AI assistant reply，就是我们给AI的结果。这个AI message输出出来，其实是不太方便我们去做进一步的调试的这车可能我们待会还得把这个verb打开。但从这个地方其实已经能看出来，GPT4做了一个不同的输出，我们在在这个角度来看，第一它肯定是复用了这个向量数据库里面的结果。第二他没有忘记这个，第二个go就在这儿，其实已经能看到他在做这个第二个目标的查询了。
	就是在这个2023的这个世界大学生运动会上，中国对他的这个奖牌数是多少。他现在正在执行这一条这个command，他也拿到了一个结果，178，然后写到了一个文件里面。然后到这儿为止，他判断他完成了所有的工作，他把这个结果放到了，应该是在打开一下。Medal count, 这里是它的这个输出结果。然后我们可以看到在前面他有写这个是放在了2023。这为什么说他复用了之前这个结果呢？是因为这个明显是直接去取了这个文件的路径。那这个是我们去使用这个agent的一个比较常见的场景。那你包括像这个奥特GPT自己的demo里面有做一个事情，就是问alt GPT是什么，把它这个写到，我们可以看一下它的这个实例。
	这个是他的一个需求，然后我们可以尝试把这个。结果写到这个。
	应该要上一个list。
	这边他。
	我们把这个verbs打开。
	重复执行一下看看。
	他的构还是正确的，然后。现在这个执行在查找什么是GPT。
	这里应该再把这是他的历史的一些记录。然后最终写到了。看一下。还在持续的迭代，这边其实已经在写到第二步了。就我们刚开始看到他查出来的一些结果，在这一步里面。Search command search。然后search完之后，接下来他的command下一步动作是写到这个auto GPT到TXT这个文件里面。我们可以看到，他查到了这样的一个结果，并且写到了一个文件里面，那通过这个事例，其实想给大家展示的几个点，包括今天我们3个小时给大家讲了这么多内容，再回顾一下。
	第一就是说奥特GPT是一个应用程序，那既然是一个应用程序，它本身希望能够直接交付结果，那交付结果的内容形式由什么决定呢？第一，作为一个大语言模型的应用程序，它一定能交它一定能给你交付一堆文本。然后除了文本以外，我们其实希望他能给你更多的类型的产出，比如说对接了red file two之后，他能去对接这个生成文件，生成各种类型的文件。我们也看了red file他的这个prom是长什么样的那同时因为这个read file two的接入，它其实也能读一些文件，只是我们这儿没有去展示这个对应的功能。类似的还有好几十个two。
	在南线的这个实现里面，我们都可以去尝试，把它放到这个tools里面去做各种各样的尝试。大家在课后作为这个家庭作业，可以自己去试一试。然后最关键的一个拓能够联网的能力，其实是可以复用的。这个写法就是我们的这个serve API，它是能够让我们快速的去测试不同的联网的能力。因为这个是相对来说比较规范的一个，或者说比较常见的一个套路性的操作。然后在这个过程当中，我们了解了out GPT的源码。所以我们也就知道了out GPT的南线版本的实现其实并不是一个非常复杂的事情。
	还有几个核心的组件，它是定义了自己的auto GPT的类。然后这个out GPT的类里面自己实现了一个auto GPT的prompt。这个LGBT的prompt需要几个输入，我们的user input，我们的这个goals，我们的message，我们的memory。这四个四件套的输入使得我们能造出看起来非常规整的prompt。并且这个prompt能反复的复用，能对接上我们的这个向量数据库。这个memory也就形成了这个prom当中的一部分。
	然后如果我们要去做这个prom的总量的限制，包括这个循环的限制，他也提供了一些便利。比如说这个循环的计数器action的执行的次数，包括我们的这个token的上限等等。这些都可以使得我们更好的去控制这个alt GPT的执行的循环过程当中，rain控制条件。这些其实就是我们这个RGPT的实战部分的一些内容希望大家能够发挥自己的各种想象，根据自己的场景去扩展突破这个列表，使用auto GPT已经实现的部分。好，看大家有什么问题，我们最后再留五分钟的时间提问。
	是的，就是直接使用这个GPT。四是的，是在环境变量当中配置的APIP。
	这个同学问的挺好的，就前面的那些历史的message和现在新的问题都没关系，也一定要拼起来吗？不是会判断相关性吗？这个地方你说的很对，你你你问到了一个很关键的点，为什么它会被捞出来？我们之前讲这个release的时候有两个方法，一个是直接用similarity search，一个是seminary。这个search的这个score我们这没有去设定它，我们在这个地方很粗暴的直接and recover对吧？但是实际上这里recover之后，这可以去传一个要用什么similarity的方法，我们可以加一个预值，就用这个我看这个地方的代码。就在这个地方。
	看PPT找的还快一点，大家看一下这个地方的实现。这个地方我们有我们现在用的默认的这个方法是search。所以它只要有，它就会搜出来，它就会加上去。但如果我们在传这个relevant的时候，我们给它加一个方法，这个方法是with relevance score，然后给一个具体的score，那自然它就不会全都找出来了。这个是一个很这个是一个非常好的问题，这个是在去实例化这个奥特GPT的时候需要传入的。
	文本切割如何保证语义完整？好问题，文本切割本身不保证语义完整。应该这么说，就是咱们用这个文本切割这个character text leader这个东西。
	首先它只是一个工具，它自己本身没有这个语义分解能力，你可以这么理解。但是它好就好在第一他切的时候最终是给大语言模型去用的。所以你切的时候它有两个至关重要的参数。一个是切的那个块的大小，一个就是要不要有这个overlap，有没有那个重叠。如果你是一些问答类的场景，那建议是overlap设置为零，不要有重叠。然后那个块设置的这个稍微跟你的问答对的长度比较贴切一点。那个split er他自己有一个相对偏这个机制的一些设定，一些trips就是如果你的overlap设置为零，它会稍微上浮一点。那个那个块的大小会尽量保证，不会把你一句话给切断，那这样的话是有一定程度的保障的那如果你的这个场景不是这种问答或者什么的，就是一篇这个文章，一篇这个小说你去切，你可以设置一定的overlap，这个overlap可能是21百。
	这个时候，GPT或者说其他的语言模型，它天然会去弥补一些上下文。比如说这里断了，或者哪里少了几个字这样的一些缺失。它是在语言模型训练过程当中是有做这样的一些尝试的。大家还记得我们讲理论篇的时候，像bert去训练的时候，他会有一定几率把那个词直接掏空掉，mask对吧？
	对，这个同学说的很对我刚才就说了，因为没有换这个向量数据库，所以他直接就去取了这个。这也算是正好演示了一个错误的使用方式，就是他直接去取了之前的那个向量数据库里的结果，然后就直接打拿出来了也然后GPT4就没有去直接去跑一遍这个举办地在哪。这个问题没有在模型里面去跑，只有第二个够。第二个问题奖牌数他就走了一遍GPT4的模型。
	这个同学问还是没搞懂和react有什么区别。再说一遍，就react它是一个react跟这个没关系，你可以理解这一堆prom跟react一点关系都没有。如果你要写给一个能够保证拿到好结果的，如果你还有印象，我们之前用react经常会出现什么问题，他不给你输出这样的response format，大家还有印象吗？如果你自己用react，你需要去解决怎么样去把这些AI的返回结果变成你想要的结构，然后并且能够被正确的解析出来，再交给你的下一次action迭代。我这么说应该比较准确的。找到了一个巨大的差异，就react它不是一个应用程序，react是一个更底层的写agent的思路，但是auto GPT它给了一些更具体的实现组件要求，并且能线的这个实现也把它做到了，把这个架子搭起来。
	呃。
	我们不能讲GPT3.5的微调，这个不符合法律要求。对，不好意思，这个是把中国的数据交给了美国。但是我们会讲私有化模型的微调。然后还有同学问大运会的例子，这回答的结果的准确性不是很高。这没办法，因为GPT3.5，他可能处理这个数据它不是特别到位。对，然后GPT4就好很多。但是你要知道一个很残酷的事情是，大部分9%十九大99%的大语言模型都不如GPT3.5，那就是现在大语言模型的基础模型的差距。
	然后我们要想把A线的做好，其实逻辑很简单，你要做一个通用人工智能。如果这个通用人工智能现在的语言理解能力，拆分问题的能力都已经达到你理想的状态了，那真的大部分的人就是会失业了。你想象一下，因为大部分的人就是面对电脑处理的这些文本类的工作，也就跟我们现在问的这些问题的复杂度差不了太多的。所以说RGBT是一个思路，是一个正确的方向。但是他现在还没法做到那么通用，所以我们没有把它展示的好像特别牛逼。但是你针对你的特定场景去设计它。比如说你要生成一个好用的circle，针对你的这个代码库，那是不是LGBT是可以用起来的对吧？我觉得肯定是可以的。
	尤其是circle就非常适合用memory了。我这是提供了一个好的使用场景，大家可以去体会一下，circle CRUD的这些代码都是很适合用它的。GOM微调有推荐的运行环境吗？可以看到它的官方的这个文档，read me, 对，需要至少一个74的GPU，它最小的这个UB。我们微调会用6B对，就是60亿参数的这个版本。
	还有同学问prompt的这个原模板构造的这个prom太浪费token了，可以重构吗？当然可以。我们今天花1个小时时间讲它的代码，就是希望大家能自己去改它，能能去改一改这些prom的设计。对，然后太浪费这个事儿看你怎么去理解了。是第一他有些prom是很必要，并且我觉得是写的很好的。比如说这个system go constraint还有comment，这都是很好的。包括resource response format。
	你说唯一浪费的可能是什么呢？是这个memory和它的历史的message，这两个可能是相对来说比较浪费的。但这两个刚刚有提，第一个就是说这个memory，我们可以去调整这个度量方法，比如说加阈值，加其他的度量方法。Message我们也是可以一样的，根据你的场景，如果你的场景是问题，问的问题之间通常都没有连贯性，那你message压根就别传，message始终传个空，这都是可以实现的。真正需要去调整的，你要重写这个GPT，要改的就是他的prom的那个方法，就format message的方法，还有这个run里面一些细节的一些调整没了。好，我们就今天10点20了，我们就今天就到这儿，回头大家有什么问题我们在群里再沟通。好，感谢大家。