	已经整个课程进阶篇也到了最后一节课。这一周我们这节课讲完，其实进阶篇就收尾了。然后下一周我们会还有两节课是给大家讲生态篇的这个内容。那么作为这个进阶篇，其实作为进阶篇，其实我们最后回顾一下我们的进阶篇讲的内容。
	我们通过三周的内容讲了南券这个框架的基础概念，包括这个上中下三篇，我们了解了它的六个核心模块，包括这个model，prompt，这个data connection，以及我们的memory相关的这些内容。接着我们通过三个实战项目让大家逐渐的去理解这些模块。包括在这个模型里面，我们有LLM它的基础大语言模型和chat model它的聊天模型。这两类模型的使用场景也略有不同，包括他们对应的大语言模型的能力也不一样，使用的这个套路也不同。但是我们通过实战项目理解了跳出这两个语言模型的定义和范式，其实它核心还是在处理prompt处理我们的提示词。通过我们的prom的template提示词模板，可以去构造各种各样的提示词。然后让我们把大语言模型当成一个编译器，当成一个解释器，让我们把大语言模型整整体作为一个可以执行我们自然语言模型的一个底层的一个解释器的话，可以让我们真正的开始体验怎么使用自然语言来编程。
	然后这三个实战项目，我们把在这个基础篇里面的OpenAI的translator去做了进一步的扩展，用南茜重新实现了它的大语言模型的抽象和对应的提示值的部分，并且也使用了LM欠这个最基础的南茜的抽象来实现了多语言对的翻译，并且我们还使用了radio这样的很简洁的，像AI继续学习服务的这样的一个框架，使得我们的服务能够变成有一个图形化界面的一个产品。在open I translator，我们做了这样的一个，radio server这么一个入口，让大家能够把多语言对的翻译也有图形化界面的支持。然后同时在十三二我们讲介绍了auto GPT它的一个实现的一个原理，以及auto GPT的价值。并且它的实现原理我们通过源码的解读发现，南茜实现的这个auto GPT其实并不复杂。通过简单的四个拍摄文件，我们就完成了一个alt GPT的基础定义，这个框架的架子就搭出来了。
	第三个实战项目，我们是上节课讲到的，基于这个已有的知识库建设的这样的一个向量数据库。然后把向量数据库作为我们大语言模型的第二大，它能为我们的query提供比较偏向于我们实际用户场景的答案。并且结合大语言模型的优势，我们可以把已有的向量数据库里的知识和大语言模型对语义理解的能力结合在一起，去回答各种各样场景里的问题。这样的一个销售机器人，我们看到最后加上它的图形化界面以及蓝券的代码，也就4 50行的一个代码量，就可以做出来一个带有界面的聊天机器人。并且我们可以去进一步的做扩展。这些都会作为我们进阶篇的一个结题的实战作业，也会像基础篇一样，大家到时候会看到会有优秀的同学做的更好。
	那么作为最后一节课，进阶篇的最后一节课，我们会想要跟大家分享一下，大模型作为一个当前这个时代最热门的一个技术。从其他的两个视角，一个是从开源的这个视角去理解它，这个开源其实是我们讲了很多次，但没有正经去讲什么叫开源。第二个就是说从开源的视角以外，我们真正做做一个大语言模型。我们都希望它能产生价值，不管是业务的价值，还是它只是一个小工具，能提升我们自己的工作效率。最终如果我们想要把它变成一个应用或者对外提供的服务，它一定要满足各个地区的法律法规。那么如何把一个大语言模型应用的法规合规性这件事情讲明白，其实我看目前也没有太多的现成的资料去跟大家做分享。我们也希望在这个进阶篇的最后一节课，跟大家分享一下我的一些观点。也是当然有很多资料都是来自于互联网，大家也可以去进行探讨。尤其是这个企业在合规性上面有哪些应对的要点，规避的方法。
	好，那我们就正式开始这节课的这个主要内容。大模型时代的这个开源和数据协议有哪些呢？首先我们讲大模型时代的开源的前提，得跟大家讲一讲什么是开源。开源其实是一个非常被广泛使用的一个词，我相信很多的同学都听过这个词。然后开源的英文叫open source。但什么叫开源？其实大家脑子里可能有一个模糊的概念，但是不一定能够说得明白。开源是什么。其实开源这个词它最早来自于一个更长的词，就是开源软件，open source software. 
	开源软件其实是一个更早的概念。因为大家可以理解，开源。大家聊到开源的时候都会想起来开源其实是一个开源社区。比如说我们想到github，想到github上面有各种各样的社区，比如说南茜也是一个社区，tn sor flow也是一个社区。
	当我们聊到开源软件的时候，大家通常的直观理解就是开源软件是由社区开发的，它不是一个作者或者某一个公司来单独开发的。就像林茜最开始在她的作者的这个github托管的项目目录下，现在变成了南泉AI这个开源社区的项目，它通常会有一个比较明显的转变，不要让人家觉得这个项目或者这个软件是属于某一个个人或者公司。但是也是因为这些同时也是因为这些优点，所以它通常成本比较低。因为它这样的一个社区没有雇佣关系。不是说我开了一家公司，大家一起来写这个代码，对它有一些特点。比如说它的成本可能更低，也更灵活，寿命有可能也比专有软件更长。
	这个是开源的一个比较通俗，也是比较公认的一种来这个词的来源和它的一个表现形式。但是到今天，其实开源的这个定义有两个方向的延展。第一个就是开源本身，它其实是一种软件许可的模型。当然如果写代码，都知道我们写出来这个成果，这些代码通常在更大的尺度上把它都叫软件。
	这个软件许可模型许可的其实就是两个阶段的事儿。一个叫开发的阶段，一个叫分发的阶段。开发的阶段就相当于我是在生产，我正在写这些代码。那我写这些代码需要有一些需我们之前讲前面几节课的时候有跟大家讲过协议友好，开源友好这样的一些词，我们尝试理解一下，从软件许可模型这个定义延展来讲，其实在开发过程当中，我们选择什么样的开源协议其实非常关键。同时在分发过程当中，你已经选择的这个协议支持你以什么样的方式去分发。这个其实在它的开源的这个软件的license，就它的协议里面都写的非常清楚。所以从这个开源协议本身来说，它强调的是一种软件许可的模型。
	在这种模型当中，通常来说软件的源代码是公开的。这就意味着其实所有的人都可以来看来修改和分发这些代码，就像我们这个课程项目一样。这个课程项目大家都可以去查看它，也可以去修改它。当然你也可以去fork这个项目分发它，因为我们的课程项目使用的是阿帕奇的2.0的license。
	第二个就是说开源其实也是一种协作方式，这个其实就是大家经常听到的开源社区这个词。就开源其实它已经不再只是一个开发的方式，不是不再只是一个分发的方式。现在因为开源社区变成了一种，首先开源社区是一种协作方式，同时开源社区的成果这些项目，就比如说南京这个项目，它可以变成一家公司，它可以去融资。这家公司不直接拥有这个项目，但它可能是这个项目的发起人。这也就是为什么大家看到有很多的创业公司，他们就拿一个开源项目就去融资。这个方式其实是被资本和大部分的，包括这个代码的开发者和使用者其实是认同的一种方式。
	然后开源这个运动本身，其实他是希望能够通过这种协作方式，不拘泥于某一个公司的这个控制权，让其实简单来说就是我们能更多的吸收社区的意见，吸收用户的意见，然后大家一起来想办法解决这个问题。就比如说我们这个项目，我们会有一个课表，然后会有一些在这个文档或者一些小的细节有一些问题。那么咱们的课程学员就在提这个pull request。在解决这些问题，其实也是希望让大家能体会到这一个开源的过程。开源是一种非常友好的一种协作方式，那它的优势就自然就会跟我们刚刚提到的这个定义和这个发展有关。它透明，它很灵活，只要我们能够提一休这个一宿是满读社区的发展里程碑和方向的那可能这个软件就会被接受，去往这个方向去满足你的需求。
	以前大家如果在公司里面是这个采购的岗位，对，或者是跟乙方打过交道的岗位，你就会知道你去提需求通常都是有这个预算要付钱的。但是在开源社区通常不会，只要你能说明白你这个需求是有价值的，是符合这个项目的发展的路线就可以。然后通常开源软件也都是免费的，这个是大家应该能感受到的。我们使用南线没有花钱，对吧？直接把代码拉下来就能使用，然后很多的人去支持。所以它的文档，它的包括像南券，其实有很多的线上的社区。比如说当然这都不是国内很方便访问的一些线上的交流的社区他还有很多的开发者对他支持，比如说一千多人成为了能欠这个项目的贡献者。所以这个是开源本身它的一个定义的起源，包括它现在的延展和它的优势。
	然后我们回过头来看，其实我们一直在讲，开源这个词很早，有多早呢？其实开源的历史就是互联网的历史，这句话是没有任何争议的。我们其实大家有了解，我们最早讲人工智能，1956年的时候，也就是20世纪的50年代到60年代的时候，人工智能这个词才刚刚被提出来。但是我们的互联网要比人工智能这个词提出来更晚就如果大家了解互联网的历史都知道互联网最早它的这个原型其实叫r per net，是来自于darpa就是美国国防部五角大楼为美国的几所高校提供的一个研究经费的一个课题成果，这个课题的研究目标就是说在上个世纪记，就相当于19七八十年代这个时间点，大家其实是没有很多方式去共享信息的。就其实就50年前左右，其实全世界的信息除了电话以外，电报以外，没有太多，很高效的去共享信息的这么一个平台。那arpa net就是为了解决这个问题。当然后来他不断的去扩大，变成了现在的互联网。
	那在这个过程当中，其实随着互联网的发展，那就很明显会有一个需求，就是我们做了一个新的架构，或者说新的项目。它是全人类连接在一起。就是哪怕到今天为止，我举一个很简单的例子，就是最有名的这个创业者叫马斯克，对吧？Elon musk, 那他在做一个什么样的项目呢？叫星链，就是解决全世界还有几十亿人，他们都接入不了这个互联网。
	其实这个世界的变化非常之快，就到90年代的时候，早期互联网诞生了。然后到再过十年到千禧年2000年左右的时候，互联网泡沫发生了。就这十年的时间，从早期互联网的诞生，包括网景浏览器的出现，让我们能有一个方便的方式去接入互联网。然后十年之后互联网泡沫，然后这个三大门户网站，新浪、搜狐，然后开始逐渐外部1.0的创业。然后到今天为止，其实我们很多人都应该还听过一个词叫web 3.0，对吧？像这个词有各种各样的妖魔化，或者很丰富的含义在里面，我们都不去扩展。但其实互联网的发展非常快，甚至我们直接的感受就是中国的13亿人几乎都接入了互联网，这个是我作为中国的用户的一个感受。但其实还有几十亿人，比如说非洲的用户，还有一些很偏远地区的用户还没有接入这个互联网。
	那为了接入这个互联网，马斯克搞了一个项目叫星链，就发射很多的卫星，通过他的一家公司叫SpaceX。通过这家公司发射了很多的卫星，这个卫星的覆盖近地轨道，所有的人都能免费的连上一个wifi，免费的接入互联网。但是从这个视角来看，这也算是技术发展的一部分。并且我们能想得到未来肯定这一部分的就接入互联网这么大动作的一些相关的代码，有一部分也会开源出来。就像特斯拉，像这个自动驾驶的很多代码也都逐步开出来了。
	所以其实开源的历史跟互联网的历史是完全相关的。包括早期更早期可能大家不熟悉的，就怎么样去定制这些定义这些互联网基础的协议。比如说这个TP，包括这个TCP，然后这个IP到上面的UDP以及七成的HTTP这些协议其实它的定义是公开的，它的实现也是有一些公开的实现。所以整个互联网的发展，甚至到我们说车联网自动驾驶等等都是在开源。通过开源可以很直接的去促进一个行业的快速生长。大模型也是一样，大家现在能直观的感受到有很多的开源的大模型出现了，对吧？
	所以从我们总结一下，就是开源是一个比人工智能还要早的一个词，它来自于开源软件。并且开源本身其实是一个随着互联网发展的一个过程，开源已经深入到整个各行各业参与，不管是你是做这个电信网络的还。是做这个互联网应用的，还是做算法开发的。大家都在以开源这种方式去协作，去推进一个事情的发展。然后随着90年代互联网的开始，这个事情就在不断的加速。所以我们才能看到下面有很多著名的开源项目。
	比如说这个linux操作系统，这个是一个开源的项目，也就是在早期互联网诞生的时候开源的。然后我们移动互联网能够发展起来，有一个很重要的项目叫android安卓，对吧？Android, 谷歌开源的这个安卓，其实是直接推动了像中国的小米这个鲶鱼效应。打败了很多的早期的中国的手机用户，手机的厂商。然后吸引了一大批他的新的智能手机用户，一直到我们现在讲云原生，这个云计算能够火起来。
	这个openstack ice层的这种虚拟化技术，比如说cover native，在这个pass层容器云管理调度的这个技术，包括docker我们能不能像JVM，在java这个语言里面有一个JVM虚拟机。只要我把代码写好之后编译好，我把它部署到很多地方都能使用，就没有部署的问题了。Docker希望大家所有的事情都有一个虚拟机，把linux这个很好的特性，把它这个最重要的一部分的抽象出来，把它弄到一个docker里。然后这个docker就会以一个容器化的形式运行。这样我们通过docker这样的技术，使得我们很多的部署的问题都解决了。
	以前我们都知道写一个代码最难的就是怎么样先把它安装上来，那现在通过多我们能很方便的安装各种各样的应用，像深度学习有TENER flow py touch，数据层面有post Green circle，还有其他的一些数据库类型的开源项目。一直到我们现在在学的这个南茜。就怎么样能够通过一个开源项目，南茜去跟大语言模型去做很好的交互和沟通。其实整个世界的发展就是一个由开源去驱动公司闭源项目的这样的一个发展过程。如果大家感兴趣就可以看一看像这个人工智能简史，或者说这个浪潮之巅这样的一些科普读，很能够有更大的感触去了解开源和这个互联网和人工智能的历史。说回来开源的形式协作方式我们都了解它有很多好处了。
	那落到软件许可模型这个核心点上，开源有哪些协议呢？其实我们把这个开源的协议，从简单来说，从是否友好的角度去做了一个区分。我们看到这里，其实有很多同学都知道这个GPL这样的一个协议GPL这个协议的全称其实是叫做GNU的通用公共许可协议，叫GNU的general public license这样的一个缩写。这样的一个开源协议，其实是一个不算特别友好的开源协议。为什么？你看这里的描述也很简单，这是一种强制性的病毒式的一个许可证，这个就是license的意思。他要求任何对源代码的修改和再发布的人，必须也要将代码开源。
	这里就要提到一个关于开源很重要的点了。我们都知道开源作为软件许可这个模型，它有两个阶段，一个叫开发，一个叫分发。有的许可协议，它其实是说你可以用我的代码，那就是相当于我做了一部分代码。你把我的代码拿过去，拿过去之后，你可以基于这个代码，然后再去做一些改造，为你的自己的应用去服务。就比如说我们的课程项目，如果使用了GPL这个协议，那咱们基于我的这个实战项目，我们课程里的实验实战项目做了一个自己的应用。那你也如果我们用了GPL的协议，那你也需要把把你改的那部分的代码也都公开出来开源出来。但这个其实对于商用就特别不友好了。
	不知道大家理不理解这个概念，就是有一个很好的前置的成果，是一个项目开源的，然后你希望把它商业化，那这部分代码你可能不希望开源。但如果它是一个GPL的协议，可能你就不太好去做这样的处理了。那么GPL你可以认为是一个极端，还有一些就是在极端和很友好中间的这个协议，叫莫吉娜的这个public license MPL。它其实是介于GPL和BSDMI也是两个协议在下面有写之间的一个中间协议，他要求修改的代码必须开源，但不强制全部代码都必须开源。你可以简单理解成就是啊当然它有更详细的这个分类，大家有兴趣可以看右边这张图，它的点就是说你可以不用全部开源，但是有一部分的这个代码你需要去做开源，那具体需要开源什么呢？这个大家有兴趣可以再详细去钻研。
	然后我们项目当中使用的这个协议，叫做阿帕奇的这个license。那它有多个版本，我们使用的这个2.0的版本，这个版本其实它就比较友好了。我们能看到这个有一个明显的分割线，perms，这个阿帕奇，其实它是允许用户自由的去使用，就你把我的这个项目folk了一份，然后你可以自由的去修改，自由的去分发。然后还但是有一点就是所有的这些开源协议，如果咱们去使用它的话，你需要去附上这个协议本身。咱们别考完代码之后，把人家的这个license删掉了，这肯定是不行的。这个被发现是会严重的这个有问题的就不是你把这个原来的代码拿过来，你把人家的GPL协议删掉了，你好像就没有这个协议的约束了，这个是绝对不行的。所以即使咱们folk了，这个项目仍然是走的这个阿帕奇2.0的这个license。然后也允许在这个修改后的代码当中去运用一些专利。
	然后MAMMIT就是MIT的这个license，它就更加灵活，它几乎允许你做任何你想做的事情。只要你把原来的这个MIT的这个license带上就好了。就是原始的这个版权和可能，那它对你的开发和分发几乎没有什么限制，然后BSD就与MIT类似，但是它包括一个不能使用许可软件的名称进行推广的这样一个条款。就比如说大家都叫这个同样的一个软件名称，然后原来的这个项目叫GPT。
	然后你现在他使用了假设他使用了这个BSD的这个license，那我们尽可能不要就使用同样的这个软件名称的像不要把它的这个名称作为你的这个软件名称去直接进行推广，会有这样的一个简单的一个限制。当然还有很多的国内的一些项目，他甚至都或者说有一些个人的项目，他他做的比较早期，他甚至都没有去放他遵循什么样的license，这样也是有的。就比如说我们在github的这个ripple首页上都会能很明显的看到它使用了什么样的一个license。如果你什么都没写的话，那那就是没有一个license的状态。在这个阶段，其实相当于他没有做出任何的约束和说明，保留了这部分的权益。这个是对于代码来说，我们现在有这样的一些开源协议了。
	那从数据的角度来说，其实我们现在大家了解的话，其实不管你是看一些书，还是说我们在使用这个训练语料，我们在看到GPT3理论课的时候，使用了大量的训练语料。比如说其中有百分之GPT3有60%的数据来自于网络爬虫，common coral。然后还有一些是来自于维基百科来就一些已经发布的书籍，其实这些都大部分符合数据协议的约束范畴。
	数据协议有不同的级别的你可以简单理解，类比于我们开源协议，它也有不同的约束的要求，不同的级别。最宽松的其实是叫做PDDL public domain。Education and license它它就允许我们的数据所有者将数据放入公有的一个领域，就相当于直接放在公开的这个互联网上。几乎没有什么任何的限制，就看到我们这里有个public domain，然后我们也经常看见有这个，包括我们在hugin face上也会看到有一些数据类似的协议会采用不同的协议命名方式。比如说这个CC buy，就是一个具体的人，就允许一个他人分发修改、改编你的作品，但是要把署名权给到你，还有这个CCISA，就是署名相同方式的共享，他们以相同的许可进行发布，可以基于你的作品去进行改编，这里会有各种各样的在数据协议册的约束方式。
	除了我们列出来的这一些以外，其实现在越来越多的基于特定场景。比如说我们可以看到这里其实是不同的维度，基于不同的维度，我有支持和不支持，可以做出各种各样的协议。这里也没有列出这个全集，大家如果有兴趣的话，可以去再去做一些，尤其是咱们看到一些不同的协议，不管是开源的协议还是CC的协议。这里最直观的是要告诉大家，你得理解什么样的协议是服务于什么样的内容，然后如果有一些你没见过的这个协议，你去这个网上搜索都能够追根溯源，回到一个不同维度这个角度上去理解它。就比如说它的拷贝和发布，然后这个。比如说commercial的这个use，包括它的修改和这个应用的权限，包括它是否能够去修改这个协议本身等等。
	好，刚刚讲的其实是什么呢？是开源的历史对吧？然后开源的发展，然后同时开源本身，我们讲开源是一个从软件来的一个概念。但现在我们讲开源的时候，已经不约束于软件本身了。软件代码层面我们有刚刚讲的GPL的这些协议，阿帕奇BSD这样的一些协议。在数据层面我们有这个CC的协议creative common。
	那么大语言模型有什么样的协议？这个其实是今天很多人包括我也没有弄明白。因为其实他现在还没有成为一个更好的标准。我相信妈妈兔的开源当时应该是很多人都有刷到这样的一个新闻。但随着它开源没有过一两天，很多的媒体都开始讲这样的一个问题，就是lama就facebook的lama包括na ma two，是不是伪开源？
	这个是一个被广泛讨论的话题。那是不是首先我们讲开源，刚刚讲的那些都是一些业界，包括历史发展的一些内容。但开源这个事儿要运作起来，有这些开源社区，那一定有一些组织。那这里就有一个很重要的组织叫OSI，open source的这个就专门。他首先它不是一个官方的组织，他不像一个政府部门，他来管开源他管不了，因为开源太烦了。但是他有点类似于这个民间协会，大家可以这么理解，他会去给出一些行业或者说这种协会给的一些标准。
	这里其实OSI本身，它对于开源是给了一个所谓的他的建议的定义，或者说需要满足什么样的要求。这份文档其实是在2006年的时候，就已经发布出来了。在右下角这里有一个对应的网站，就open source的这个definition，就在这个open source的org这个OSI的这个官方网站上有这么样的一个定义。
	这份定义其实最重要的一点是什么呢？就是我们讲开源。首先这里的开源更多其实是聚焦于这个开源软件或者说这个代码这个层面上。他这里有提到开源其实更最重要的事情，不是说只是你能够免费的去访问它的源代码了，它的分发形式必须要满足很多的要求。它就列了十点不同的要求。
	从这个视角来看，其实大家想一想，是不是回到我们最开始的开源的定义，开源是由开源软件来的，开源当它的定义被延展之后，有两个维度的定义。当我们聊开源软件的时候，更多是在聊它的软件许可模型这回事儿，也是它的开发和分发。那他这其实在讲开源的核心，不是说只看它的开发过程是不是你能直接访问它的源代码。更重要的事情就是你的分发是不是受到了很多的限制，还是说它符合开源的精神，我们都只能讲精神，因为没有一个法律条款去告诉你怎么样就不是开源了，这个是一个很核心的点。为什么大家说它是伪开源呢？其实就来源于它违背了这里的一些精神，就是OSI这里的一些重要的所谓的精神。
	Number two，它这个大语言模型的这个github上面的项目是怎么写的呢？其实右下角是它对应的这个原文件，就是我们能看到facebook research下面的这个lama有这样的一个license。这个license其实就是在6月18号7月18号更新了这一版。然后这一版更新之后我们在这份协议里面我们去解读出来会发现确实如大家讨论的，他并没有很好的去回应OSI的这个开源精神。具体来看，其实怎么样？就有一些限制性条款，我们这边重点解读一下。
	就是第一在在我们刚刚看到的这个十个很重要的符合VSI的这个开源精神里，有两条非常之关键。就是我们的这个第五条和第六条，跟我们的这个纳妈兔的这个社区协议是有一些冲突的，简单来看就是不应该有这个第五条。我们看右边这个第五条，就第五条的核心就是说我们不能针对一些特定的个体群体，个体或者说群体有偏向性的意见或者说歧视。然后同样的，个体群体是一个维度，那么一些特定的领域也是如此。我们不应该保护一些领域或说歧视一些领域，这些领域是不能怎么样的那在OSI的这个定义里面，这个是一个很重要的一个点，就是我们做开源不要不要变成一些特定人的工去了，你就把一些特定的群体就拿走了。所以这个也很符合现在美国这个解放运动觉醒运动这样一个特点。
	左边其实是nama two这个社区协议里面的一部分，这里面其实我们看一个非常明显的点，也是被很多人吐槽的点。就是他这里有一个第二条叫做additional的commercial terms，其中有一点是什么呢？有提到就是如果我们基于妈妈兔这样的一个大语言模型做出来了一个应用。然后这个应用如果它的月度的活跃用户超过了七个亿，那么这个时候，你相当于前面的那些协议就可以忘掉了。你需要再额外的就you must request a license from meta对吧？就你必须要找meta这家公司，有facebook这家公司去申请一个协议，由他们来决定你通不通过。如果他们觉得你没有通过的话，你是不能用这个number 2的那这个事情其实是很违反开源精神。
	我不知道大家理解这个意思没有？就是本来你开源一个东西，核心是希望大家都来用。但是现在就变成了，如果我我基于你基于你的这个大语言模型做出来了一个很好的应用。然后它的用户也越来越多，到了一个比较重要的数量。比如说七一的时候我就不让用了，对吧？那这个其实是很很不友好的，然后也不太能够使用它去做一个非常广泛的应用了。
	简单来说，然后同样的在这个一点B的关于分发和使用的这个协议里面，其实也写了一些不是特别符合开源精神的。包括他提到了我们不能把它用到一些跟法律、法规各种相关的，这个就是相当于不是很合规，也违反公司公序良俗，投资类的领域你不能用。你也不可以把它用于一些它它这里提到的一些notice，就是它下面有一些附件提到一些领域。简单来说整个一点B其实就是写了一大堆，你不能在什么样的场景下去分发和使用。这个其实也跟第五和第六条是非常有违背的。所以整体来看，第五第六条冲撞了一点B这个是或者一点B违反了第五条和第六条的这个开源精神。
	然后下面这个一个月度活跃用户数的实现，一个不管什么样的要求，只要你月度活跃的用户数超过他，你都必须要向meta去申请。这个就更加的不符合开源的精神了。所以这个是为什么很多人质疑是一个伪开源的一个点，包括他还有一些更多的附件，在特定的领域去做这个细的限制，这里我们就不再展开了。大家如果有兴趣的话可以去，并且还想要用lama two来做应用的话，可以去深入研究。
	这个是lama ChatGLM这个项目也是我们下一周生态篇会去用的一个项目。这里提前给大家看一下这个项目，在右下角这个清华大学DM这个实验室的这个group下面，现在托管了这个项目chat GM two 6B这个项目其实我们去分析它的整个项目的介绍很有意思，就是为什么前面要跟大家讲开源，有代码的协议，也有数据的协议。那现在模型是不是也应该有模型的协议？我们能很明显的看到，在这个介绍里面，首先他讲了chat GM2的这个6B是一个中英双语，它不是多语言的，它是中英双语的一个对话模型，是之前ChatGLM6B的第二代的版本。在这个原来的基础之上引入了一些新的特性，这些我就截掉了。
	这个是这个项目的一个基本介绍，他的协议部分在最末尾，在他REDM的最末尾，非常清楚的写了这个项目的仓库当中的代码，依照阿帕奇2.0的license开源，跟我们课程项目一样。但是还有一部分就是chat GM的这个模型的权重，它的使用需要遵循一个叫做model license。你可以理解整个这个项目就是两部分了，一部分是这个源代码本身，一部分是使用这个源代码的时候需要额外拉取的一个大语言模型，这个大语言模型不遵循apache 2.0的license。因为它本身不是一个代，它是一个模型权重的文件，或者说它是所谓的模型权重。就是我们知道模型有很多的参数，那这些参数都有一些特定的值才能称之为一个模型。那这个模型的权重就是指它训练好了之后，这些值都变成了它训练出来的那个权重的值，然后就变成了一个模型的文件。这个模型的文件我们在使用它的时候，需要遵循这样的一个license。
	这个license是什么呢？大家可以看到它被放在了这个项目下面的model license。除了model license，还有一个阿奇的license。
	这个model license里面其实它的这个定义很有意思。首先就是。他明确了整个这个项目是属于这个质谱AI，就是通过这个质谱AI去联系他，他们关于软件关于这个模型许可和版权的任何的问题，需要去联系这个智谱AI这个团队。然后他的定义他说的很清楚。整个这个协议里面的许可方就是指分发其软件的这个模型团队。就是我们在这个开源项目里会看到它的模型权重，未来也许也会更新。那这样的更新这个模型的团队是他的许可方，软件是指根据本许可提供的模型参数。
	这个其实是一个在大模型时代的一种很新的license的方式，这个是之前都没有的。我们即使是在大家想象一下在深度学习这个时代，我们看到各种各样的开源的模型。比如说image net上面预训练出来了一个rez net 50等等。他其实也没有这么严格的去给resonate 50的这个预训练模型去做各种各样的license，或者说因为它的使用范围没有那么广大家还不够关注。
	但是今天我们看ChatGLM26B，质谱AI他们给出来的model license其实还是很严肃的。他们并且明确的把这个模型参数，这个模型文件本身称之为了一个软件。然后这里就写了这个许可授权。比如说根据这个model license，就我们现在看到这个model license，这个许可方模型团队授予了使用方。就我们使用这个模型的人有非排他性、全球性、不可转让、不可再许可、可撤销、免版税这样的一些版权许可，然后包含在本软件的所有副本和重要部分当中，也就是我们本软件就是指这个模型参数，当然它也可以基于它去翻痛，这个就是它的一个其他的副本，或者说你直接去fok它，把它变成你项目当中的一部分，这样都是属于，他的授予范畴。
	还有一些限制，比如说，任何军事非法目的，都是不能这这两个这两个目的是不行的，军事目的是不行的，非法的目的是不行的，在这个前提下，如果你不是这两个目的，你可以去使用复制、修改、合并、发布、分发，去使用他的这个作品本身和他的衍生作品。衍生作品就是典型翻译，当然也还会有一些法律法规的一些要求。我们其实回过头来看啊，大家都在讲lama two是不是一个很好的或者是伪开源，对吧？但是我们抛开那个7亿月度活跃用户的视角来看，其实chat GM26P跟他有很多限制性条款是类似的，但我们这里不展开讲。
	谁好谁坏或者什么样叫伪开源的模型。什么不是伪开源的模型？我们理解所有的协议核心是看它约束了你什么，他准许了你什么。而不是简单的二元化的理解，是开源不是开源。我们知道它有这样的一些限制，那在我们去使用它的时候，只要没有突破这些限制，其实我们就可以正常的去使用，包括它的免责声明、责任限制，争议解决等等。然后有一个很重要的点需要大家去关注，就是说整个model license的许可是受中华人民共和国的法律管辖并按其解释的。然后因为这个许可引起的或者与本许可有关的任何争议，要提交到北京市海淀区人民法院。
	我们都在感受开源好像是数字世界当中的一部分。尤其是中国这个知识产权开源协议没有受到这么多的保护，或者说执行的不是很到位。但其实我们今天还会讲gdpr，其实在海外的话这部分是很严苛的。
	我们在理解一个协议的时候，如果我们真的要去商业化，它很核心的是这个协议是会不会跟实际的这个法律有直接关联。那很显然这个model license是明确写到了，他是也要符合中国大陆的法律体系的，这个是需要大家去注意的那这里我们在讲它的这个大语言模型的开源，包括它的协议相关性，以及到最后合规的时候，我们还有一个很重要的点就是介于法律违法和这个开源中间，其实有一个很重要的点叫做可解释性。或者说就是怎么样让我们或者说让我们的用户也好，让我们的投资人，让我们的开发者能够理解你这个大语言模型。
	首先他不是个骗子，对吧？他不是一个模型背后其实站了很多个人，是人在给你服务。同时，如果它只是一个运行的软件程序，或者说一个有权重的模型。那这个有权重的模型你凭什么能够证明它很稳定，你怎么能够保证他能够给出你比较准确的结果？按照我们现在的一个俗俗语讲，就是怎么样能够避免大语言模型少一点幻觉的产生。这些其实都是跟它的可解释性息息相关的一个内容。
	那么大语言模型的可解释性，这里我们去有一个很好的图片去解答它。就是我们看到很多人都把大语言模型，包括深度学习模型、机器学习模型，所有的这种参数化的模型都当成一个黑盒子。因为这黑盒子比较形象，你其实不太能理解这种可以有很强的拟合能力的参数化模型到底是个什么东西，我们一句俗话去讲，神经网络就是一个函数映射，把输入和输出映射在一起，然后我们通过大量的数据训练，把符合这一堆数训练数据的分布的这个函数给拟合出来了。所以接下来你只要没有跳出这个分布，你给它丢一些内容，它都能够符合分布，给你一个输出。这个是比较形而上或者说抽象化的一个方式去解答。但是你把这个话告诉一个没有很深的深度学习理论或者说概率学背景的人来聊，他其实还是觉得你是一个黑盒子，他没整明白你，你没给他说清楚到底是怎么回事，尤其是我们大家如果在中学和大学阶段学过一些非参数化的模型的话就更有体会。
	因为非参数化的模型通常讲得清楚什么是什么，所以为了说清楚这个黑盒子里面发生了什么，其实我们在理论篇的时候也涉及到了这部分的领域，就有一个很热的研究方向就叫可解释性，或者说叫可解释性的机器学习。因为现在的机器学习模型被视为黑盒子的核心，就是我们刚刚讲到的决策过程不透明。首先训练过程你就很难理解，然后训练结束之后他的决策过程，就比如说我在用大语言模型生成一段话，我用这个深度学习模型去跑一个输入图片的识别，这个过程也不透明。然后这种不透明就是可能会导致一些错误的判断，而且你很难识别出这种错误的判断。尤其是现在在大语言模型，我说一段话，我生成一段文本，它不像这个深度学习阶段，我识别这个是猫，那个是狗，然后我打上标签，如果我识别错了，直接一比对它不是猫。这个label是很好判断的。但是大语言模型的生成结果都是一些自然语言，你很难去量化去评估这个单元模型到底好不好。所以大家能看到在理论篇的时候，我们的benchmark都是一些什么，数学题对吧？这个就又转换成了一个数学问题，包括常识的推理这种最后都能够直接去比较这个大语言模型生成结果怎么样。
	但是还有一些很多的细节的应用，一些垂类的应用，你很难造这种benchmark让你去判断这个模型好不好，那就很难翻译to。这个过程其实就包括你看ChatGPT最终是用一堆的人人基于人类的一个反馈来做的强化学习，来做最终这个训练。在这里会有很多的难以解释的点，让我们无法判断这个大语言模型好不好，也无法相信这个大语言模型是否真的能够可靠。这就是可解释性想要去解决的一个问题。
	在学术界和工业界，我们在GPT4的这个多模态分析的时候，其实讲过这样的一个图很有意思。就是统计学家和深度学习的计算机科学家，他们在解决问题的时候思路略有不同。那么这幅画通过GPT4能够解答出来，反正讲统计学习的这些科学家他们希望能够通过这个去判断，他很严苛的了解你是不是过拟合了，或者说这个欠拟合了。然后他通过过拟合欠拟合去了解你的这个数据量够不够。
	简单来说就是过拟合和欠拟合这个问题核心就是数据够数据太多了，还是模型太复杂了。其实就这么一回事儿。如果你的数据特别多，模型特别简单，拟合不出来。相当于你学你的这个要学习的内容太多，你的脑子不够用了学不过来。
	还有一种场景是说我要学的内容就这么点。然后你的脑子太强大了，你甚至没有把这个数据分布里面的这个分布提出来。而是你因为太强大了，你直接把每一个数据点都记下来了。那那其实你就没有学一个分布函数，而是你记得每一个数据每一项数据。这样就会变成过拟合的状态，脑子太强了，然后数据太少了。比较好的状态其实是大家是比较匹配对等的，所以这里会有很多政策化的技术，这个是统计学家的一个做事方式。通过这个方式相对来说它的可解释性比较好，因为他能有一些比较严肃的论证。
	但是深度学习的这些科学家他们就不太一样了，他们要做的事情就是。你可以简单理解，我的数据要做到无限多。我先忘记我的这个呃数据的标注，或者说应该怎么样去造数据，去做这个特征工程这件事儿。大家还记得我们理论篇的时候有学从这个GPT3开始，有一个很重要的变化是使使用这种未标注的大规模的数据来进行训练，他就不用标注了，我也不用去做大量的筛选了。可能我唯一要解决的问题就是咱们有很多同学都在问的，怎么样把这个数据能够分段存到向量数据库里。在训练过程当中也有类似的问题，我不可能把一整本书全部丢给你们，我也需要做一些预处理。
	在这个过程当中，其实最核心的问题是足够找到足够高质量的语料。然后先不管这边的大脑有多强，先把数据怼的越多越好。然后在这个过程当中，这个大脑怎么体现呢？其实就是按照深度学习这个阶段的做法，无非就是把我们的网我变深一点，在这个CNN的这个为主的这种识别类问题里面把网络变深一点。
	比如说这个read net可以搞100层甚至1000层，然后我们的这个RN的这个序列也可以搞得特别长。然后无非就是这个特别长的过程当中要训练需要反向传播，反向传播我们能用一些不管是这个短连接，还是说这个记忆门，通过一些方式能够让他这个训练的效果，最终能够回到前面的神经元去做模型迭代。这个就是很像大力出奇迹的一个做法。
	包括我们GPT模型的迭代，也是把我们的transformer从transformer这篇文章OU need 6层的一个encoder decoder的一个架构，变成从GPT1的12层到GPT3的这个一百将近100层。GPT4可能现在更深，也就是这样的一个过程去不断的去堆叠。我可以去学习这些数据的网络结构，相当于把我的大脑做强。这个过程当中也有一些政治化的技术，写这个Normalization的一些技术。这些技术去消化这个语料，这个是深度学习的一个做法。
	但是也是因为这样的一个做法就带来了一个坏处，就是你很难说清楚每一层网络他到底在学什么，学到了什么，对吧？这个其实是它的一个缺点。但是从结果视角来看，它就是能把一些特征工程专家系统的一些无法突破的这个规模效应给它拉出来，把这个优势就给它做出来了。这两个对比其实非常有意思，也直接体现了可解释性学习为什么现在又火起来了？
	因为效果特别好之后，大家开始去追求这个可靠性了。所以从这个视角来看，其实我们会这是这是这也是一个很经典的一个分布图。它其实有点像一个是跟效率与公平一样。这个可解释性和它的这个性能。所谓的性能你可以理解成在一个特定模型任务上面我们的一个指标。就比如说这个识别的准确率也好，或者说你的这个翻译的准确率也好，这就可以作为它的性能跟它的bench mark的这个指标是你可以直接对应起来。
	然后另一个点就是它的可解释性。从这幅图我们能看到，Y轴是这个可解释性，interpretative然后performance这个X轴是它的这个性能。越往这个Y轴的值越高，其实它的可解释性越强。
	这里我们看到一些什么经典的机器学习模型，统计机器学习模型、线性回归。这个甚至大家在高中可能都接触过了。线性回归，包括决策树、逻辑斯谛回归、耐用贝叶斯、朴素贝叶斯，还有这个KN、支持向量机，包括insider的measure。这个我们其实在讲GPT3的论文的时候也提过。
	就这个insistance这种集成方法大家可以去了解，很通用的一种方法。到这个神经网络，其实整个这个过程你能看到往右边走，它的可解释性其实是越来越低，然后往上面走，其实它的可解释性越来越高。但这个平衡的这个点，其实是很难去综合的，就是你很难去如果要给一个没有学过咱们这个课程的人去讲这个黑盒子到底怎么回事？其实现状就是没有特别好的方式去解释它怎么回事。并且如果你想把它解释清楚去退化，用一些解释性很强的方法，你就会牺牲性能，这就是现状。
	因为我们人没有，你可以说数学或者概率学，或者人的这个精巧的设计，就是还没有超过AI的这一部分，就是这个算力的这一部分。我们单纯的通过设计这种算力，就是能拟合出更好的模型。它没有形式化的定义，它不可能写成一个逻辑斯谛回归或者奈伊姆贝叶斯这样的一些很好的公式。它没有这样的一个形式化的公式，但是它就拟合出来了一个巨复杂的函数，这个函数它是有效的，这个就是现状，但是我们有很多的科学家在尝试，能不能把我们的这个，大家能看到这里有这个神经网络，把它的这个性能尽可能不是安检的情况下，我们还能把可解释性给它做高，这个是很有意思的一个方向。那具体来看怎么样能够把这个可解释性体现出来，有一个很直观的方式就是可视化。
	我们在讲这个注意力机制的时候，我不知道大家还有没有印象，注意力机制的时候就是我们的第一课，讲这个attention机制的时候，有提到attention。我们通过机器翻译这个经典任务，将bench的这篇论文，14年的论文有提到这个机器翻译里面，通过这样的一个激活这样的一个混淆矩阵的激活值。这个灰度图能看出来我们的这个注意力机制是怎么样。贝壳是画出来的，就相当于这个注意力机制当时也是一个神经网络。大家还回忆一下第一节课的内容，还有印象吗？就是一个encoder，decoder with attention, 就中间加了这个注意力网络，这里是他的这个注意力权重值。
	其实我们能通过这样的一个方式，就是把这个模型当中的一些中间结果可视化出来，是有一定程度上能达到这个可解释性效果的。在语言模型上，或者说在更早期的这个机器翻译这种自然语言处理的任务上，这种网络上，或者说在这个图像识别的这个领域里面，它的激活的这个热力图，我们其实都能发现。可视化是一个非常好的方式去用来展现这个网络神经网络到底学到了什么内容的一个方式。这是一个非常好的可解释性的手段。
	除了这两种以外，我们还在讲transformer这篇文章的时候，跟大家提transformer这个多头注意力机制。其实核心在他在包括在他自己的给这个注意力类型去命名的时候，也把它叫做self自注意力机制。他也没有说是两个语言之间的注意力关系，注意力权重，而是指这段话内部我的这个注意力，到底我的这个词是指向哪些词，有跟哪些词有关联，通过这个多层，它不同层，这里的红色、绿色，包括这里把所有的层叠在一起，不同的这个颜色代表它的不同的这个层。然后越到比较深的深的这个层里面，其实他学到的这个self attention的注意力机制越健全。这个也是一种很直观的方式去给大家展示中间结果。就我们的transformer对这篇论文的或者说穿梭这篇论文本身，就这个这个机制的这篇开山的论文是怎么样能够通过这样的一种形式去给大家展示中间结果。
	除了这个以外，其实今年也有一个很很有名的项目叫羊。我不知道是不是叫中文叫羊驼。斯坦福的一个团队做了一个7B的就70亿的一个大模型，其实也叫大模型。虽然大家先看这个规模，感觉像是一个小模型，70亿参数的一个模型，它的这个文章也发到了这个stanford blog，是一个中文翻译的版本，里面有一些词可能翻译的不是特别准确。那这么一篇blog其实有去尝试去解释这种10亿级别以上的参就10亿级别参数以上的这种大语言模型，到底他的这个模型本身学到了什么？
	就我们知道GPT这种decoder only的大语言模型里面充满了各种各样的transformer的结构。那么他到底学到了什么？这些attention的这个Martin ahead，Martin head这个attention到底学了什么？尝试在解答这个问题，但是我们要首先知道刚刚看到的早期的14年的那些文章，就是不管是机器翻译的这个注意力权重，还是17年的transformer这个self attention的关联关系。就他们在今天2023年的今天去回应这些大语言模型学到了什么？它没有一个所谓的很好的中间层了。
	大家想象一下我们的大语言模型，它不是为了机器翻译服务的。我们学过理论篇的同学都知道，现在这个大语言模型的核心已经不再是retrain加fine tuning这种范式了。它就是一个什么都学会的一个足够通用的模型。再加上指令微调，或者说加上in context learning的这个prompt这种手段去让他描述，然后让大语言模型去响应你的这个结果。
	那怎么样能够让我们理解大元模型到底学会了什么？它这个巨大的几十亿甚至几百亿、上千亿的这个模型参数到底有什么东西，怎么样能够把它可视化出来，其实是一个很新的研究课题。然后现在的这些可视化的方法，就我们刚刚前两页看到这些方法，不太能够去解释。
	或者说可视化我们现在的大语言模型，为什么呢？其实有三个比较重要的原因，一个就是说它的搜索空间太大了。大家想象一下我们讲attention和transformer这两篇论文的时候，其他的模型规模还是很小的，还是挺可控的。一直到我们出现了这个GPT1的时候，其实也就这个一亿多的参数，没有特别多。现在动辄就是几十亿的参数，这个搜索空间其实是好多个数量级的差异。这个神经元的搜索空间太大之后，你基本上启发式的搜索工具就已经失效了，因为这空间太大了。
	然后第二个就是说它的表达本身是分布式的。它的大语言模型当中的单个神经元的激活和概念之间的映射，它是多对多的，而不是一对一的。什么意思呢？我们回想一下刚刚这幅图，什么叫一对一？多对多对吧？这里的这个中间层，因为它是特定任务，所以我们能看到这个词跟这个词之间这样的一个激活是有感知的。然后在右边这种图像类的，因为它是一个位图，就我们的这个像照片一样的这种位图。这些位图beat map我们也能通过这个视觉感受到他到底学到了什么样的一些内容，包括像这个词跟词之间的关系。
	但是一个大语言模型，它其实已经不是在词这个级别上了。就跟大家要讲明白我的一个embedding的向量，到底这个向量它是什么，其实你也很难说的清楚。然后如果你你你把这个向量当中的这个有特定维度拿出来的话，那对于大元模型来说有几千亿个神经元。那么这几千亿个神经元的这些权重到底它是一个什么样的概念？就是首先不可能有这么多概念，那么这个概念跟神经元之间的这个映射关系你说不清楚，因为它太复杂的对对应关系了。比如说这个先工作是指stanford这个小组，他们之前做了一些工作，比如说当前以前的工作是可以在一些简单的模型上面去理解，有一组神经元表示一个简单的概念，比如说性别，然后这样的一些方式其实是在大语言模型当中是行不通的了。
	还有一个点就是它的鲁棒性比较低。鲁棒性就是指你做了一个工作，但这个工作可能换一个场景或者换一个模型就失效了。在以前的工作当中他们找到的这种因果机制，通常就是假设为一个特定任务微调的模型。这就很像GPT1那个时代，包括bert刚刚出现那个时代，需要有特定任务微调，下游任务去微调。那基于这个下游任务微调，我来去做一个因果机制。待会我就去讲这个所谓的因果机制，去做这样的一个方式去做可视化。但现在我们知道大语言模型到今天没有下游的微调，这个就失效了，所以你就没法针对同一个模型去搞一堆的因果机制的模型，这个很难受的这这个也不够有泛化性，因为你已经不存在下游任务了。
	以前每一个特定的下游任务都会微调出一个模型，那一个模型对应着一个因果机制的解释，来解释这个特定任务微调出来的模型好不好。但现在没有特定微调的模型，大概就一个模型。但是干这么多任务，那你怎么评价他在这些特定任务上有怎么样的效果呢？你也没法用一个很好的评价方式去评价所有的任务。这个就是现在的工具要去解释大语言模型存在的一些障碍。
	那他当时做了一个什么事呢？这篇文章首先他使用的是阿帕卡这个模型，这个模型当时刚出现的时候也挺挺火的。我印象中应该是一季度末还是二季度初的时候出现这个模型，并且托管在了stanford的这个网站上，很快就被挤爆了。他当时这篇文章，他为了去描述这个可解释，有一个很巧妙的设计，就是他让这个70亿的这个语言模型去做了一个游戏，叫定价标签的游戏，叫Price tagging game。
	简单来说就是你首先它是一个大语言模型，大家要抓住这个大语言模型的场景，它是一个大语言模型。那大语言模型我们要给它prompt，它要有一个输出对吧？然后我们通过这个过程去理解，或者说通过这个过程我们尝试去找到他的它内部的这个大元模型内部的决策过程，或者说这个神经元之间的响应的过程，是怎么跟我这个最终答案结合在一起的。
	包括如果我的这个最终答案，我自己能想清楚它里面是一个什么样能够被拆成一步一步的这个过程的话。那么它的一些神经元，因为它它内部也是一个推理过程，还能跟它映射起来，那这里的这个任务就是说呃呃简单来说就我下面翻译的这句话，我会输入的一个一个一个区间，就是数学当中的一个区间。就比如说二和3，比如说这里就是二和3，当然你也可以有这个小数，二和3。如果你算出来的这个成本Z是在二和3之间的话，就回答yes就yes。是啊，如果不在这个区间，那你就回答no，就否，这是一个比较简单的状态。然后input就是这个值，对吧？那就是相当于其实是一个非常简单的判断。并且我们如果用编程语言来写的话也很简单，就一个if else就可以写完了。
	但大语言模型是怎么完成的一个推理的，其实我们不知道。我们希望通过这个简单的定价标签游戏，去理解大语言模型内部到底发生了什么样的一个情况。然后这个因果机制的来说就是这个回答过程怎么跟大语言模型的神经元激活，或者说哪些神经元被激活了，然后响应了我的这个需求，通过这个因果机制去找到它。
	这个是论文摘要里面贴了一个很有意思的图可以简单看到，我们这儿有两个输入的示例，就比如说在这个X和Y是我们的两个区间，左区间和右区间。就是我我的要判断的这个区间是在二和3美金之间，然后我的成本是Z就是1.5，显然它是在这个区间之间的那这里他就会去判断X是不是小于Z，或者说Z是不是小于Y这个判断很简单，就是指我是不是在这两个区间中间，我不清楚这中间这一行大家能不能看明白，就是我比他的这个左区间要小，比它的这个我比他我大我的这个成本是大于它的这个左区间的，然后我是小于它的右区间的那如果这两个都是真的话，那么他们的这个and for操作也就是yes，这个是一个逻辑数。那这里其实是另一个逻辑数，比如说我的这个Z它大于了这个左区间，然后我的这个Z其实没有小于它的这个右区间，那这个时候他自然就是no，这个是他的内部逻辑。
	那他尝试想说明什么呢？就是如果我们去写代码的时候，就我们人来写代码，或者说我们人的脑子去想这个问题的时候，其实就是这样的一个过程，分成了多步，有点像我们之前讲的这个COT，就是思维链，其实我们是分成了多步来最回答最终这个判断的，就是yes和no其实可以拆成多步的。然后这个多步就是典型的这几个判断。然后这几个判断可以被演算成或演化成一些特定操作，这个操作是不变的。有点类似于我们的prom template，是不变的你只需要往里丢竖就好了。然后这里的这两种判断方式就对应着这里的这个神经元，就我们整个大语言模型神经网络当中的特定神经元。
	然后他希望通过说在解决这么一个非常简单的if else数字推理任务的时候，能够去解释我们的大元模型的这个中间变量。然后这样的用来解释它的这样的一套模型。因为它中还需要去找到哪个神经元被激活了，那整个去找到他的这个被激活的方法，他自己有一个叫DAS的方法。那整个这一套去寻找那些被激活的神经元的方法，它叫做在数字推理任务这个特定的press tagging game上面的这个因果模型。
	但我们抛开这些不需要深入了解的概念来说，就是通过这样的一个事例，我去判断这么一个的简单场景。我要去找到大语言模型当中哪些审计人员是完成了这样的一个逻辑推理。然后这些神经元响应了我的输入，响应了我的这个指令的变化，并且它还具有一定的鲁棒性，因为我在去调节这个过程当中，其实不是一个特定的下游任务，它其实是一个逻辑任务，它是具有一定的鲁棒性的。它也试了一些别的这个方式，那这个其实是在大语言模型当中，我们想要去逐步的去理解也好，去用可视化的方式去呈现也好。去给所有的想要了解大模型的人的一种呈现方法。
	这里我们再看一个特定的事例，就我们跳出刚刚那个抽象的，我们把整个多个步骤跟神经元对起来。这里其实还有一个更典型的例子，也是在这个文章当中，包括他提到了一个很重要的指标。首先简单来说刚刚的这个推理逻辑，比如说成本要大于左区间，小于右区间，然后是否大于这件事情要抽象成一个布尔变量，出和for。这两个布尔变量还能去做交运and运算或者or运算，就是简单的这个布尔运算，这个其实是很很符合，这个其实属于数学当中的一部分属于这个呃那但是这个概念其实我们认为要把这个概念学会大语言模型怎么样学会的？包括你说你脑子当中哪一部分的大脑细胞也好，神经元也好，是在记录这个功能。或者说你学会数学了，你学会游泳了，你学会骑自行车了，其实也是说不清楚的。所以刚刚那幅图核心是找到到底哪块神经元是在干这个事儿。
	更具体一点，比如说我们要理解什么是加号的。加号就比如说这里有一个更简单的算术任务，比刚才那个还简单，叫做A加B乘上C这样的一个非常简单的数学公式公式。它就是大家这里大家需要可能绕过一个弯去理解。就学会一个数学公式，学会一个加法和你能写一首诗，写一个文档是完全不同的两种能力。真正学会加法是一个很难的事儿，因为它是一个符号推理的事儿，跟你看了很多书，学会鹦鹉学舌一样去说话是不同的能力。我们尝试在通过这种比较方法论或者说推理的这个核心，就掌握这个符号逻辑符号推理的这个核心，去找到大语言模型当中哪块神经元是有一些固定的能力的。这个一定要整明白。
	我们回到这儿来看这个算术任务里面，其实有一个很很有意思的点。就是说在这个问题里面，比刚刚要简单的加法和乘法的这个问题里面，有四个神经元与代表这个A加B的中间变量完美对齐。我们知道它有很多神经元，可能这些神经元学会了一些特定的符号推理方法。并且这个符号推理方法我们把A加B乘上C看成一个prom template的话，那么他其实已经学会了A加ABC是可以换的词。这样我们可以在input variable里填的词。但是加法括号乘法这个东西是prompt的template里面的内容，并且他还准确的知道加法应该怎么运作，乘法应该怎么运作，这个是很大的一个核心的区别。
	而这里它把四个神经元和这个A加B的中间变量，也就是我们看到右边这幅图，AB加起来有一个中间结果，这个中间结果会跟C去相乘，有点类似于我们刚刚看的那个三层结构。只不过这个抽象的更简单一些，就两个数合起来有一个中间值，你需要存下来，那这个值和最终的这个C你输入的另一个值去做相乘。那么这四个神经元就代表了这个中间变量的结果。
	如果我们能整明白这件事儿，或者说我们能准确的锁定出这四个神经元的真正含义。比如它代表就是A加B的结果，那么那它就能够被提取出来去用。我不知道这个大家理没理解，就所谓的我刚刚提到脑机接口也是一样。脑机接口核心就是整明白你大脑里面到底怎么运作的，哪一块有问题你就把它修好就好了。那那这里也是一样，如果我们真的把这个A加B乘C这种典型范式，很基础的这个运算的范式里面的中间结果能够抽出来，那它同样也就能够插入到另一个输入里面去，那这样的话模型的结果也就会有变化。这样这里一加2乘3，如果把它插入到另一个2加3乘4当中，那么这个模型的输出就变成了1加2乘上四等于12。因为它本来你已经能提到这个神经元了？
	那如果能做到这个级别，这是很理想的情况。他如果能做到这种级别，他他他对这种理想情况的对齐他称之为所谓的完美对齐，他自己提了一个概念叫互换干预的准确率，interchange intervention accuracy IIA为百分之百。他也同他也可以用这个方式去相同的指标去评估一些子空间当中的一些对齐情况。所以通过这样的一种评估方式，如果我们真的能做到这样的一个程度，那对于这个对齐问题，align这个对齐这件事，那就能够做到非常的细致了。那这个大语言模型就能够被我们更精细化的去做微调也好，去做精细化的使用也好，也能够够更清楚的评估这些特定任务上，特定能力上他做的好不好。这个是目前比较前沿的关于大语言模型可解释性的一些进展。
	但是也有一些局限，就是他当然做的还不够好。就比如说他们的这个工作，是开始朝着理解大语言模型的内部的一些因果机制的。这个刚开始刚起步有局限性，比如说在更大的规模上，他们无法去用一些比较复杂的推理任务跟这个因果模型去对应起来了。就简单的推理任务，我们知道大家学计算机的这些基础课的时候，我们刚刚包括讲的这个布尔运算，都是一些很基础的逻辑。包括像一些复杂的位置逻辑，一些推理机上面的一些任务，可能就很难被很好的因果表达出来。
	这个是他们现在明显看到这个依赖关局限性。包括他之前的一些先验知识的依赖，在实际上当中也不一定很能满足实际的情况。包括他最终的可扩展性，还有他没有一个确凿的答案，就是无法给出一个确定性的判断。只能说我知道这几个神经元确实跟他有高度的因果关系了，或者说有有他响应了我的这个输入和特定任务的指令。但是是不是只有它响应了，或者说我换一种这个prompt是不是就是别的来响应了，这个事儿其实还没有定论，核心还是因为这个模型实在太大。我们就是没有一个很好的技术手段去找到一个切口，去让你理解它内部到底发生了什么。因为其实这样的一个模型参数的规模已经快接近于人的大脑的神经元的数量了。所以我也一直在讲，要把这个通用人工智能做出来，脑科学也肯定要迈大一步，往前迈一大步，我们才有可能去做到这样的一个地步。
	好，其实我们通过前面这1个小时出头的时间，跟大家分享了这个大语言模型有哪些。就是我们讲开源的时候在讲什么，大语言模型的开源有哪些协议，有源代码的协议，有模型的协议。然后当我们去聊合规之前，我们还是希望这个大语言模型它的这个可解释性有一定的让所有用户放心的这么一个说法。不只是说我合法了，因为本身这个法律也在制定过程当中。你能不能让你的用户有一个比较直观的感受，去知道你这个大语语言模型是靠谱的，它是稳定的。
	通过我们刚刚看到的这些最前沿的研究，其实也都才刚刚起步。就是机器学习的可解释性现在有一定的发展了。但因为大语言模型实在太新了，它的可解释性还在一个非常早期的阶段。如果大家有一些看到一些有意思的文章，也欢迎大家去做这个分享。好，我们先留十分钟的时间先来回答前面这部分的问题。
	我看一下大家之前有人提P等于X小于等于Z为什么是除？当然是true。这个同学是不是刚刚没看，就是X是左区间，Z是成本，Z要大于这个X这件事情是对的，他就是应该在区间之内，所以应该是出。
	我懂这个同学问题，大家忽略那个下面的字，就忽略那个数字，忽略填进去的那个input verb。他我听懂这个同学的问题了，就是有这么一页，大家忽略这里填的数字，因为这些数字其实是输入的这个input arrival。这里的核心是讲prompt template，大家可以这么理解，我去拿杯水。
	我搞。
	这个是美国的对，是的。
	有个同学问，如果一开始是MIT的协议，后面变成金U了该怎么办？这个没办法，这个完全是看这个开源团队他们的一个想法了。他们如果觉得这个事儿后面就是GNU了，那就只能按照金庸的协议来。
	刚才讲的这个游戏测试很认真，听也没听明白为什么能够理解大模型的因果链，这个同学还没有讲明白。最后再一句话讲一下，就是你可以理解成大语言模型本身是各种各样的能力都具备了。但是因为它各种各样的能力都具备了，所以大家不需要再微调了。我们没法针对每个微调的任务，或者说微调出来的这个基于特定任务微调出来的模型去做和解实性的研究。我们就要针对这个非常大的模型去做可解释的性的研究。
	现在我们希望说这个大语言的模型它有各种各样的能力。我们就找一些小的简单的任务。所以简单的任务要回答这个任务也需要具备一定的能力。就比如说刚刚在这个游戏里面，需要有判断一个数谁大谁小的能力。需要有判断出这个数字之后，他要理解布尔变量，就true false将二元的布尔变量基础逻辑课这样的能力。同时针对布尔变量，它还有具备基本的布尔运算的能力。比如说and或者or那这些能力，最终所谓的这些能力都是由神经元来学到的，它就是一些特定神经元的值。
	那哪些神经元是在干这个事儿呢？那他现在就要去找那些神经元，然后他怎么样找的呢？有一个DAS的方法，简单理解成就是它通过一个搜索的方式去找到底哪个神经元在响应它，但这个搜索空间很大，因为是几十亿的一个模型参数，我们有讲它的局限性，就是现在的搜索空间太大了，它的这个势力是70亿的一个模型参数。那那你要知道做做这个模型，每一次它生成结果的时候是一个推理，所以它其实会在内部运算一次。那就找一下哪些神经元参与了这次运算，然后通过GES的方法不断锁定到底哪些神经元在响应。响应的这个内容跟我的刚刚说的能力是有映射关系的。但是这也不是说一个神经元代表一个能力，而是一组神经元代表一个特定的能力。
	这里有一个更简单的例子来讲，就我不只是能判断刚刚说的这个布尔运算，我在表达A加B这个中间变量结果我也能存下来。我不只是能存这个操作服务中间值，我也能存下来。因为这个中间值就跟刚刚判断true or force的出活的是一样的，也是一个中间值。
	中间值也能存下来，也有一些神经元跟它响应。这个对其的学习这个因果关系找到之后，我三炮某种层面上其实就是再给大家展示我的神经元，或者说我的这个神经元其实是模型的一部分，我的模型到底学到了什么？就相当于你可以想象一下你的大脑，我们现在的脑科学研究是你有什么大脑小小脑什么小脑负责你的这个身体协调能力，巴拉巴拉的，其实就是这么个意思，这么大一个神经元是不是也能切出大脑小脑不同的脑不同的区域，海马区是负责记忆的之类的。就这个东西，你可以理解成脑科学的研究，可能比现在大语言模型的研究稍微近了一点点。因为我们的脑科学一直在做各种各样的电信号的采集。就我们的这个脑机接口也好，或者说我们现在脑科学的研究也好，就让你去想各种各样的事情，去探测你的这个脑电波信号有没有什么变化，这个过程其实是类似的，你可以这样去理解。
	数据协议约束的是什么？这个同学问的，我要切回去。数据协议一样，就是咱们这里有看到有拷贝，有发行。对，然后也有各种各样的，包括是不是能够在这个工作当中去怎么样去使用它。然后这个原始的工作能不能随便修改这个给大家提供的一个入口，是希望大家接下来能够在面对数据协议的时候有一个抓手，能够去了解数据协议其实也不是一个什么很难的东西，不要被一堆的CC给搞晕了，这些CC其实都是一些creative commons这个license下面的各种各样的分支而已。这个好像和寻找现实世界的解释没有什么区别。问题是如何判断找到的这个解释是个好的解释呢？同学你说的这个和这个解释是具体可以讲一讲是是是指什么？是指这个是指什么东西？对。
	我们最后再回答两个问题，看大家有什么这个问题没有的话，我们就9点25的时候开始后半段的内容。
	还有同学问模型权重是不是算数据的范畴？就今天才把这个事儿都拆开来讲的。很重要的一点就是让大家了解什么算什么样的范畴不重要，核心去看他到底限制了什么，约束了什么，就是那一个一个的维度。
	为什么一开始讲开源要讲开发和分发，为什么？这因为这最大的两个维度，开发能不能访问源代码，分发有没有什么样的限制？然后分发过程当中，如果你分发的是你在原有的基础上有有做过一些调整，那是不是这个分发就不符合要求？然后分发的对象是不是有限制。从这个维度去去看，就是所谓的源代码、数据模型，都是我们人在不断的总结抽象这一类东西。但是这一类东西现在还在野蛮生长，我们就不要强行去把它算到原来的范畴里。我们就看这一类东西到底限制了什么。就像我们刚刚讲chat GM two 6B它的model license里面也很清楚的去讲了限制了什么对。
	比如通过一个逻辑是这样，比如通过一个布尔代数运算，找到了一组神经元对应这个运算，认为这个映射是一个的解释。怎么认为这个映射比另外一个更好呢？这里很可能不只是唯一解。同学是这样的，就是他没有想要证明这个映射比另外一个更好，他没有在做这件事情。对。
	老师开源的项目商用会有限制，个人玩问题不大的对吧？首先这个问题，开源的项目我不知道是不是前面没听我上半节课这个开源的项目这种说法是不到位的对，以后大家正儿八经上过这门课，你应该准确的描述你的问题是符合什么样源代码，开源协议的什么项目。它要在什么样的使用场景下，有没有限制，就比如说阿帕奇2.0的源代码开源协议的项目，我要去把它变成一个商业化的项目是没有限制的，只要你附上他的license吧？然后个人玩那个人你要准备怎么玩，你要不要把它变成一个对外服提供的服务，为什么我的给大家演示这个radio的这个界面的时候，我课程完了我就要把它关掉，这就是我马上下节课要讲的内容，这个就不叫个人玩了。对，个人玩是一个未定义行为。
	不太理解数据协议限制的数据是指什么，这个还不理解。最简单的就是你写了一本书PDF，你的blog，你所有生产的这些文字内容都可以叫数据协议。同学想象一下，包括音视频文件，对你你唱了首歌，你自己创作了一首歌曲，原创歌曲对吧？你拍了个短视频都可以满足这个协议的。好，9点25了，这个我们就往下走了，来讲到这。