	好，大家既然能听见的话，我们就开始今天的这个实战课程。就基于知识库的这个房产销售顾问，就sales consult这么一个课程。实战课程其实我们更多的会不只是教大家技术，也是想说能够给大家分享一些。
	如果我们把这个实战课程当做一个最小的项目来做的话，我们会怎么样去看待一个项目？要做一个项目，技术是其中很重要的一个环节，也是它很重要的一个组成部分和价值点。但是除了技术以外，要做好一个项目，我们要理解业务，理解原有的业务流程。然后我们可能还得了解原有的业务流程里面什么部分的价值点最大。从这个视角来看我们其实作为一个技术人员，如果想要做的不只是一个我们所谓的螺丝钉，而是能成为一个项目经理，项目的负责人、owner, 那一定得能够理解业务，理解业务当中的价值。从这个视角切进去之后，我们就能知道技术怎么样在原有的业务流程当中去发挥价值，哪一块是最值得技术先去做改造的，不管是去做这种信息化、数字化还是智能化，都是这样的一个思路。
	所以我们第一部分会去给大家分享一下现在的这个销售顾问，或者说这种销售的这种对话机器人，这种技术形态，它的业务流程是什么？价值有哪些？市面上有没有一些现成的这个机器人的产品，定价是怎么样的那我们做这样的一个实战，有没有它的现实意义？有没有可能基于这个实战项目，大家能够去改造它，变成一个真的能够去卖卖钱也好，或者说能够再次扩展，成为一个帮助你自己提升生产效率的一个实际的项目和工具。
	第二部分我们会继续的以能源为中心用能欠的这个框架去告诉大家怎么样能够把这个实战项目落地，它的技术方案是什么样的。架构设计跟我们之前学的一些内容有一些呼应。但是又会我们其实整个课程安排，包括实战项目都是逐步的。每节课每一个实战都对之前的一些技术有呼应，但同时又会新教一些东西，让大家通过理论加上实战，加上这个基础概念，不断的去学会南线框架是怎么用的。在各种各样的这种典型用例上，我们有哪些实战的项目的代码是可以直接用的，还有哪些可以改造的内容，可以扩展的内容留给了大家。
	最后我们会来实战销售顾问的这个项目。首先我不清楚大家有多了了解销售的这个角色，或者说就每个公司应该都有销售，我不知道大家有多了解销售这个角色，以及销售它的主要工作是什么，这里我简单列了一个销售顾问他的一个的业务流程，那它的业务流程是什么样呢？很简单，我们首先看啊，这是一个非常典型的，不管是to c还是to b只要你是去卖东西，不管你卖的产品是什么，尤其是to b类型，就面向企业用户的，或者面向这种大型的C端用户的就比如说面向咱们这些听课的同学，我们想象一下咱们是在这个公司里面一个完整的一个产品，从生产出来到研发，然后到最终销售一个什么样的流程。我们从角色的角度来看，会有客户和销售这两种最典型的类型。因为整个销售他要解决的问题就是把一个生产好的东西卖给客户，这个是他要的工作核心。卖给了这个客户，客户本身他有很多的行为。我相信大家时不时都收到过广告，不管是电话销售给你打过来广告，还是你的短信收的垃圾邮件，这些都是广告。这些广告其实是触达用户的直接的行为。
	所以我们能看到，在决策方面我们可以分为客户和销售，这个是买方和卖方，在这个业务里面，其实有很多的系统，这是一个最抽象的一个概念，就是我们摆脱你具体卖什么的话，通常能抽象成这三层系统。第一层叫广告系统，第二层叫商机管理系统。例子是商机的意思，销售系统就是我们最终要把这个货卖给客户了。这个是一个销售顾问，他在整个卖货过程当中会接触的三个环节对应的三个系统。
	广告系统非常简单，我们刚刚讲到有各种各样的广告，包括个性化的广告。你去刷抖音会刷到广告等等。这些所有的广告其实都是为了干一件事情，就是找到那些愿意看广告的人，他们可能就是潜在客户。
	这些潜在客户通常会被导入到一个叫商机库的这个你可以认为是一个池子里，或者叫数据库都可以。这个商机库首先做的稍微好一点的这个商机管理的一个公司或者平台他对于这些商机，他是会去有一个自己的评价系统的，叫商机的质量计算。有的自己的这个评价系统，因为他历史上做过投放，他做过研究。比如说to b的销售，他他就能知道什么渠道上来的这个客户的质量比较高一点，这个渠道它就容易成交，都有可，这个质量计算，其实整体来说要做的事情就是过滤。通过我们的这个商机的评判的标准，把一些所谓质量不好的，他就不分发给销售了。他觉得这个商机可能是很很很不可能成立的，成立的这个概率比较小。接着如果通过这个商机管理系统判断下来，就是有可能成交的那他就会给到销售。在这儿开始，其实真正销售的工作才开始接触。
	在很久以前没有这个信息化的，我没有互联网的时候，可能广告系统这部分也都是销售干的。就像大家在大学的时候看到有人发传单，那发传单其实就是在发广告，在触达用户。现在因为大家都是线上去浏览信息了，所以广告系统这一部分已经有我们的。就我们在讲我们在这个技术人员要做产品，做系统广告系统推荐系统，这不就是我们做出来的一个非常好的产品形态。所以现在的销售通常不负责广告系统的行为了，他会负责什么呢？负责接过广告系统筛选出来的商机，再经过内部的商机的这个评判，系统发现这是一个潜在的很有价值的商机给到我们的销售。
	那销售会做什么事情呢？假设我们是一个to b的销售，通常会有一个环节叫陌拜，就陌生客户的拜访，你也可以简单理解成在线下就是我登门拜访，像刘备三顾茅庐一样，我去去看诸葛亮对吧？我觉得诸葛亮很厉害，我想请诸葛亮出山对吧，一次请不动，要请三回。这个就是陌拜，我陌生的这个客户拜访。在线上，其实就是大家可以简单理解成你刷了抖音，你刷了一些其他的小红书之类的平台，突然就会有人来加你微信或者来给你打电话，其实这个就是陌拜，只不过这个陌拜是线上的形式。这个是销售会做的一个非常重要的工作。
	然后销售会进一步去判断现在的这个商机是不是真正的意向客户。如果经过销售的人的判断，因为这个商机的判断很有可能是系统自动化的那如果是这个销售经过他的经验判断，这个客户可能不是我符合我的这个目意向的客户，我就直接结束掉了。我聚焦哪些是我有可能达成的这个客户，如果他判断剩下这些是我的意向客户，就会进入到一个销售的系统。那这个销售的系统里面就会使各种各样的招数，对吧？打折、套餐、分期，各种各样的销售策略。最终通过各种各样的销售策略，再筛选出来哪些是真正的客户，哪些是无法打动的客户。无法打动的客户可能会放在一个地方，也许未来某一天通过别的销售策略或者一些时机都会成功。
	整个业务流程，其实是一个非常通用的一个销售顾问参与卖货的这样的一个业务流程。那其中最大的价值点在哪儿？其实我们会发现价值点有两个。第一个其实是其实它整体是一个漏斗的模型。大家如果了解互联网的一些经典运营手段是一个漏斗模型，那漏斗越大当然价值越大。就是我全网有几亿的用户，如果这几亿的用户都能看到我的广告，那很牛逼对吧？然后你的成本还很低，每个用户看到的成本都很低，所以整体这个事情就是第一个厉害的点在于固定的预算。你能让看到的这个广告的用户越多，客户越多，那你这个技术就越好。
	所以这是推荐系统要干的事儿，那大家整整体理解为什么会有个性化推荐。其实个性化推荐就是把浏览广告，就是我这种像以前看电视看到的广告，它没有精准的个性化的推荐。他其实是把这种撒网式的广告加上这个例子的质量计算合二为一，变成了个性化的推荐。这就是个性化推荐系统的价值。
	因为它虽然总的人数没变，但是我们看一下这个公式，就是最终给到销售这里的其实是一开始的这个假设我们有100个用户，通过商机的判断，可能最后只有50个用户给到咱们的这个销售系统。那其实你是投了100个用户的钱的那个性化的这个推荐系统是说你有你有投放100个用户的这个预算。那现在我精准推了。80个用户最终都给到你，你可以用。所以到销售陌拜这个环节，个性化的这个推荐系统，虽然它的总人数没变，但它的高质量的商机变多了。这是个性化推荐系统在这个流程当中的价值。
	那么销售对话的机器人有什么价值呢？首先我们知道这个是否是意向客户，以前都是人来判断的。然后各种各样的销售策略，其实也都是人。销售这个人根据自己的经验，他对这个潜在的高价值的用户他有一个标签，他就用他的这个不同的标签，有不同的套路来做这个事情。但是这里还是有一个比较烦的事情，就是假设我们把销售也变成一个机器人，就这个销售陌拜的这个环节也是一个机器人来做的话。那么这个机器人要怎么样判断它是不是意向客户，或者说把客户的这个需求给挖掘出来。
	这件事情我们当然希望这个部分的，因为大家可以想象，其实100这个例子举的是比较小的。我们假设有100万然后个性化推荐给了你80万的潜在商机。那这80万的商机你不可能再找8万个销售去做这个消化。那你一定希望能够有一个自动化的手段来做消化。所以我们讲销售顾问也好，讲这种对话机器人也好，其实都是想聚焦在这个地方，就我们红框的这个部位，就是我们通过花钱花预算投放了广告，广告出来有很多的高质量的商机。那这些高质量的商机怎么样通过一个自动化的手段，去帮我挖掘出哪些是真正高意向的客户。这里就有很多种实现方式了。
	这里整体我们可以提一个概念叫意向率。意向力的意思就是说我们给你了很多的给销售的商机。然后最终这个意向客户数就是我愿意再往下走，真正去给他推销售策略的数字。这个比值叫做意向率。
	现在的问题就是如果我们不用自动化的手段，只用人来做，那人的精力有限，这个意向率就高不上去。因为每个人每天可以发的信息，可以沟通的时间是有上限的那如果用自动化的手段，我们其实同样的一个自动化的系统，不管你是什么样的实现方式，那这个意向率显然就成为了一个比较你的水平高低的一个很关键的值。就是同样给你这个聊天机器人，一万个客户你聊出来了5000个意向客户，他只聊出来1000个意向客户，那你这个5000的这个机器人肯定就很厉害。并且如果你还能够挖掘出客户的需求，去给出这个对应的销售策略，给到最终成交的这个环节，那就非常的厉害了，对吧？因为那就不只是意向率了，还直接到了最终的成交率了。所以这里每一个环节都有一个率。你不管是叫转换率也好，叫这个意向率也好，叫成交率也好，那几个率乘在一起才是最终你产生的价值。个性化的推荐系统在最前端产生的这个价值，把这个漏斗变宽了。
	接下来我们讲的这个销售顾问的这种自动化的系统，这种机器人是希望能够把中间这一环的一项也给做到一个比较高的数值。回到刚刚这个逻辑里面，我们以一个实际的体感让大家感受一下。每天我们可能都会接到这个垃圾的电话，或者说这种垃圾的邮件，他们是怎么样做的，在内部的实现里面，刚刚是一个很抽象的，我们卖什么东西都可以这么做。
	那现在我们想象一下，如果咱们自己要去做这个事儿，先跳出能欠跳出大语言模型。就想象一下我们接到的这个客服机器人，或者说现在有很多这种你去咨询类的业务都是用的机器人了。那这些机器人在内部通常会是一个什么样的流程再进行处理，主要就是怎么样去处理信息。然后在这个流程里面有哪些角色呢？刚刚我们讲到有两类，一类是客户，一类是销售。不过销售可能是一个人的角色。现在我们想象一下，这个销售就是变成了一个机器人了。那我们会怎么样去把这个机器人销售我埋到原来的业务流程里面，让它非常好用的那这幅图其实我们尝试从两个角度来讲。
	第一，我们明确一些这个概念。比如说我们现在的销售机器人，它就是一个电话销售机器人。当然电话销售及时跟我们接下来要做的这个事例的唯一区别就是你接一个API让他能念出这些字，对吧？然后你再接一个API能够把通话里面的这些音频信息识别出来，变成文字信息。其实就可以做一个电话机器人了，并不复杂。它的场景是一个电话机器人的销售。
	同时我们看到角色发生了扩展，有有客户有机器人的销售，但是还增加了一个角色叫运营。运营其实就是跟推荐系统也好，跟这个预算也好对接的一个角色。他更多的是把漏斗的前端给处理好啊，找到一些比较好的策略，比较好的渠道，给你尽可能高价值的商机。最后我们会发现仍然脱离不了人。就跟刚刚看到的这个销售阶段，最终成交可能还是由真人来成交的。这个也是比较常见的电话销售的一个流程。
	我们看到这里的技术点有哪些？第一就是说我们看到整个流程里面的角色我们讲清楚了。纵向的这个系统无外乎就是三种系统。这也是我们在做营销也好，做完整的项目也好，经常会看到的三类系统。一类叫做CRM系统，就是这个customer relationship management，就我们的客户关系管理系统，大家可以理解这个CRM系统里面接到的可能就都是商机了，这里就已经是商机了。过掉了出广告触发的这个筛出商机的这个阶段。
	然后第二个部分叫做智能外呼外呼系统。我们可以理解这个智能外呼系统其实就是我们机器人销售和客户进行切磋过招的一个系统，这个系统就是可以有很多种不同的玩法了，包括我们现在讲的这种很时髦的虚拟人，那无非就是在电话销售的机器人的系统上面，再给你套了一个虚拟人。这个虚拟人能根据这个音频，然后包括音频里面得到的一些语义，他有一些情绪在里面，再再套一个皮。那其实核心就是这样的一个系统逻辑和它的技术实现。这个是机器人销售和客户过招的系统，我们可以叫外呼系统。
	最后一部分是一些智能的系统。这些智能的系统其实在我们的今天这个案例里面来看，就有点类似于大语言模型该做的一些工作。整体来看会有三个不同的系统，分别去处理不同的信息和任务。
	我们看到这个流程里面比较直观的流程顺序是由商机给到机器人。那我们的这个机器人再根据我们的这种沟通渠道，不管是打电话，还是虚拟人，去跟客户建立了一个连接。就像我们建立了一个web socket的连接，或者说我们这样直播建立了一个连接，只不过这个直播是单向的，可能这个电话是双向的，实时的能拿到对方的信息。建立了这个连接之后，就会有一个通话的过程。那我们可以看到在通话过程里面，这个处理模式是非常典型的，到今天为止，这样的一个，流程仍然在广泛的被使用。
	就我们接到种电话销售就这样的一个流程。在这里面通话过程里面我们看到有两个箭头，一个是客户给机器人销售的，一个是机器人销售回给客户的那这两个箭头，第一所有的客户给到机器人的，其实机器人，因为机器人它不是一个真正的人类，他其实是在处理这种各各种各样类型的音频信号，我们看到会有一些音频的处理，包括收音，降噪等等。然后同时这些音频最终要变成NLP或者语言模型，或者大语言模型能够处理的内容需要从音频变成文本。这里可以套一些经典的语言识别的这个API或者算服务，变成了文本。然后这个文本通过我们的自然语言或者说通过大语言模型的推理，我们可以进行一些处理。
	处理完之后会变成什么？其实最简单的方式，按照原先的这个机器人销售电话这种销售渠道上面最简单的方式就是一个很典型的一个检索系统。就是我根据我识别出来的结果，我检索一下有没有对应的模板。如果有模板的话就直接套入一个模板。如果没有模板的话，就说一个固定的内容。就比如说你说的是什么我没有太听懂。
	那在今天的实战里面，我们还故意把代码留了一个这样的处理。就是如果我们没有大语言模型，我们就会退化成一个比如说我们的房产销售，我发现我的模板也好，我的这个向量数据库也好，里面没有存这个问题的答案。那我就会说我得去问问领导，你只要是超出超刚，不在我的这个模板，不在我的套路里，我就会说我得去问问领导。但这种体验很差，对吧？
	所以我们现在这个系统和我们有大语言模型的系统的区别在哪呢？就在于当我发现这个问题我不会的时候，超纲的时候，我可以让大语言模型来给你过不过招对吧？大语言模型跟你陪聊呗，就是你想聊什么我就跟你聊什么，这个是一个最大的区别，就我们大语言模型比起传统的电话机器人销售来说的话，最大的一个区别。市面上也有这样的一些现成的服务了，我们待会可以看看价格。从这个视角来看我们再把这个流程说完了。
	在经典的没有大语言模型的加持下，他就只能播放录音。就跟我刚刚说的按模板来回复一样。那这个录音就告诉你，用户就跟你交流。聊着聊着可能用户就很不满意了，就挂机了，通话结束了。但也有可能用户其实是通过跟你的聊天达成了意向。所以这里我们会看到挂机之后，一定会有一个二次的外呼，或者说二次的拜访。这个其实就比我们看到上一张图里面的陌生拜访要效率高很多。我们刚刚提到所有的销售陌生拜访会有一个上限，不管是线下的还是线上。
	这个二次外呼，通常我挂机之后，这个通话结束之后，我还会对它进行一个处理。大家可以简单理解成，我会把整个电话录音再去做一次NLP的处理。我会有一个最简单的一个模式，就是根据这个对话，我能判断出你是有意向的还是没意向的那有意向的我会推送给真正的销售。这个销售跟进的有意向的客户，甚至他还可以看到原版的这个录音，然后他就可以打电话，再去给客户去做这个沟通，就跟我们刚刚看到的销售系统的环节一样。这个是非常真实的。
	就现在我们每天都在发生的一个典型的机器人销售和客户，以及真实的人类销售之间协作的一种模式，包括我们今天讲的大元模型，也只是在智能化的这个环节，就在这个部分增加了大语言模型的能力。我们可以知道这个系统一定是有价值的。因为卖货是一个非常好算账的事情。就我用一个销售，然后这个销售只要能卖出超过他工资加上其他成本的这个价格，那这个销售就是值得雇佣的这是一个很简单的逻辑。我们看看现在的这些电话机器人销售，再加上大语言模型的这些竞品也好，这个市场上成熟的产品也好，都是怎么样在宣传他们的产品功能，又是怎么样定价的，这也是我们做这个实战项目的意义之一。这个是我在华为云上面找到的一个智能问答机器人的一个产品介绍，我主要给他看他的一个产品的核心优势和能力热点，其实这些核心优势会被大语言模型给消解掉，或者说这些核心优势本来就来源于大语言模型的技术积累。那你看到它这里有两个核心优势，后面这个训练部署就不用讲，那是私有化的部分。
	前面关于它产品本身来看，有第一部分叫智能的问答管理。比如说什么它能对热点的问题、趋势知识去进行自动的分析和统计。它也支持未知问题的自动聚类，匹配相似的问答，包括辅助人工不断的去扩充知识库。这个就是说在聊天过程当中，我们对历史的这个聊天记录去做分析整理。然后把这些整理出来的内容变成我们的智能化系统当中的一部分，不管是直接给到大元模型里面，去让他去做繁重也好，去做这个proof learning也好。还是说把这些问答比较好的问答，有高成交率高意向率的这种问答，变成我们向量数据库当中的一种更好的这种问答。或者这种模板都可以，同时还能支持这个问答的调测，点对点的监测，这个智能的应答过程。
	这个也是很好做的。因为它本身是一个机器人，所以每一个问答的结果我们其实都能够监测得到，并且根据它的应答，大家想象一下，如果我们用棉签来做的话，根据它的应答，我们甚至还能调整动态，再去调整它的prompt，或者说去调整一些阈值。就像我们上一节课讲的，我去找知识库里面问答的时候可以调整阈值。那今天我们就会把这个预值放出来让大家理解这个怎么用，同时也支持一些领域知识的挖掘，包括这个标注工具等等。这个就比较抽象了，聊的就比较饭。
	大部分的领域知识，其实大语言模型也都是有的，是能跟你闲聊的。这个是它的智能问答的部分，就是相比于这种传统的基于模板电话销售机器人它的优势。我们可以很直观的看到，这些优势大部分来源于大语言模型的能力。
	第二部分是它的所谓的全面的对话管理。因为问答管理可能是单轮的，或者说比较少的就两三轮的对话。但对话的管理通常强调的是啊可能我会有这个多轮的能力，就像他最后写的嵌入多轮对话的技能，复杂的任务性的对话场景，这个是多轮的能力。
	同时能外接知识库。我们到今天这节课的时候，我相信大家已经理解什么叫知识库了。其实知识库就是一个向量数据库，对吧？就可以存在向量数据库里。我只要接上不同的知识库，那它天然就会有各种各样的知识。
	这个知识是打引号的。因为我们在理论片的时候教过大家大模型基准测试有重点几类，比如说常识性的，比如说数学推理类的，这些都算是大语言模型自带的知识。但这些知识跟一个特定我要卖东西我要卖东西，我不了解这个产品。那那对于这个产品本身有什么样的一些特异性的或者个性化的一些产品介绍，产品详情这些内容，我认为更符合我刚刚说打引号这个知识。因为你最终是要卖东西。这些知识放在向量数据库里，对接到大语言模型，变成大语言模型可以去检索的一部分知识，会更有助于你去跟客户去聊这个产品本身，有助于转化，提升印象率，同时自然语言的多能力的融合，包括这个对话的中控。
	这个自不必说，肯定也是我们现在单元模型所具备的那所以我们要做到一个这样的产品，首先想告诉大家是说是有机会的。我们去对接一个GT3.5GPT4，或者说那马的这个第二代，或者XGIM的第二代的6B都可以，这些大语言模型能够直接为我们所用，去实现这里的大部分功能。那价格又是怎么样的呢？我们可以看一看，就刚刚我们讲的这个华为云的这个机器人的报价，它分成两种模式，一种是实例化去部署，就是相当于我买了一个机器，然后我把你这个问答机器人服务也不叫买。租了一个机器，在云上面租了一台机器，然后把我的这个对话机器人的服务部署到哪个机器上，会有一个价格。然后第二个，就是这个接口的调用，就跟我们一直讲的按token计费的这个OpenAI的这种服务就很像。那按照这个接口调用的费用，我们可以看到这个价格是0.012元，每次相当于一分二每次，那每次他也他他相当于就每一次问答有这样的一个价格，然后他肯定对每一次能问的这个上限也是有限的。
	因为实际的问答机器人这个场景，你想你跟一个机器人聊天或你跟一个客服聊天，你一次问的话很少的。除非你是售后，你售后可能会针对我之前承诺的一些产品，你直接复制粘贴过去会消耗比较长一点。大部分的调用可能都是在按照我们现在对token的了解，都在1000个token以内。那其实他这接口费用和GPT的这个GPGPT的费用已经差不多了，甚至更贵一点点，这个是我们直观的一个感受。然后第二个就是说如果要私有化的去部署，大家能看到这里有一个不同版本，基础高级专业旗舰的不同的版本。
	我们刚刚有看到在介绍产品优势的时候，有一个叫问答，有一个叫对话。实际上问答和对话本身就是两个特性，同时也是你可以理解这两个特性的背后的代价也不一样。为了实现对话，我其实要进行这个对话历史记录的管理。举个例子，就是我们在学习OpenAI的时候，我们有completion的API，也有chat completion的API。那大家有没有感受到chat completion的API会更贵一点，为什么？因为你要用更多的token，你每一次传的时候都要记录历史的聊天记录，这个是对话。问答可能就是我基于你的问题我来答，不一定有太多的上下文。所以很简单，一定对话比问答不管是技术实现还是成本测都会更高一些。
	所以实际上来看也是这样的，我们看到问答机器人的实力，1600包月，这个是它的一个价格。那么对话的机器人显然要贵得多我们看到这个基础版就要588，那么旗舰版刚刚那个是1600，这里的旗舰版是8万，非常的夸张对吧？那这个就是现在实际的价格。所以首先我们不管他卖不卖得出去，但是如果你能把这个销售真的做好，8万的销售人，我们单纯讲销售，如果是一个现实中的这个人的话，他他是能卖出去的，其实我们把这个50的路数减到10，他也是2万。我们可以再回看一下，这里是1600，这里是8万。因为它是按照这个路数来卖的。通常你买这种旗舰版的时候，它会有一个底线的路数的要求。那么这个50路相当于并发数，50路的这个并发数的要求相当于你这个人同时能接50个对话。
	针对这样的一个场景，8万块钱一个月的价格，我相信可能是超出大多数人的预估的。包括我自己我们公司在这个采购云服务的时候，很少会有单价达到这样一个规格的，包月的产品，并且它还只是最基础的配置，就50路数是一个最基础的配置。那那我们想一想，首先刚刚有算1600是这个单路的价格，那50路就是这个8万的价格。那我们如果能做出一个类似的服务，不说这个卖8万，卖一个比如说这个4000或者说八千，那有没有可能呢？我觉得是有可能的。因为本身现在的这个对话机器人服务，大家可以去试一试。我刚才也有贴链接，它是有十几天的试用的，就华云的这个对话集成服务。
	我们要去做出一个对话机器人服务，它的技术难点在哪里呢？刚刚我们有分享你要对你要卖的什么产品必须要非常了解。同时你要让客户愿意跟你聊，最好他都能不能感受到你是一个机器人，你把大语言模型的能力充分发挥出来。如果能把这些点做好，我相信做一个实际可用的产品是非常有场景的。并且销售是一个永恒的话题。就像我们上来的第一页的这个课件讲的，就是卖东西是一个永恒的场景，因为它能直接促使这个产品有继续生产的这样的一个动力和周期，那那它就会持续存在。
	那好，刚刚讲的其实是一些偏项目维度的概念。就是我们讲了做一个销售顾问，做一个销售机器人。它在原有的这个业务流程里面是处于什么样的一个位置。怎么样去衡量它的价值，同时现实生活中已经有这样的产品了，就在公有云上面，那又是怎么定价的那对于我们来说，我们学了能券，学了大元模型，我们也希望自己至少做出一个销售顾问，销售基层的demo。
	那怎么样去做呢？其实没有那么复杂，我们今天看完实战的代码也会知道很简单。第一我们先看一个典型的使用人权来做这种基于某一个知识库问答的典型用例是长什么样的。我们逐步把这个问题变得更难。稍等，我开个空调。
	好，我们看一看就是一个知识库问答的典型用例是什么样的。我们刚刚有讲所谓的知识库，就是把一堆个性化的知识，不在大语言模型学到的这个语料里面的知识，装进一个可以用来纯知识的库里面，然后让大语言模型来调用它。这是最简单最大白话的说法。
	好，个性化的知识本身它的类型来源就会很多。比如说非结构化的知识，比如说代码，比如说结构化的知识。这里的结构化和非结构化更多是面向数据库这个维度来讲的。它把这个关系型数据库，我们把它叫做circle，对吧？关系型数据库也有很多年的历史了，这里面的数据当然能够被大语言模型所用，我们去查它就好了，在这个OpenAI的在基础篇的时候，我们讲这个OpenAI去造出这个function calling的这个例子的时候，就造了一个去连接circle light。
	大家还有印象，那个实战的代码，用circled的这个数据库后端或者说这个数据库引擎很轻量。但是我们用大语言模型来生成去调用数据库的这些内容，这个是可以的，甚至都不用放到向量数据库里。第二种就代码，能不能让大元模型去基于代码回答问题，甚至基于代码去组装生成代码。还有一类就是最常见的文本类的，或者说图像等等都可以。我们上节课学的这个face，就是facebook这个AI研究小组做的这个向量数据库，是支持各种各样类型的数据转换成向量，转换成in不一定存下来的那我们现在简化问题，先关注一下这个文本，也是我们整个AI大模型训练营课程里面处理最多类型的数据就文本。我们把这些文本作为非结构化的数据给到大语言模型。
	那大语言模型是一个APP，我们再回忆一下我们在进阶篇里有跟大家讲过的，大语言模型的APP不等于GPT的这个API封装，对吧？那么这个意思在这个基于知识库问答的典型用例里能够得到一种很好的回应。就是我们当然还需要接各种各样的知识库，并且把知识库和大模型结合起来用，这是一个典型用例的一个场景，那那这幅图我们看懂了左边和中间了，我们要造一个大圆模型的APP应用。这个应用的用例其实就是问答或者说聊天两种场景。其实是问答就是更偏销售化的对吧？我问一个你产品的问题，你回答我一个产品相关的答案。然后这个时候，如果我还想跟你闲聊两句，因为你有大语言模型的能力，可能跟你闲聊，所以它是一起的一个问答。但是同时还有知识库的这么一个场景，那怎么样去实现它，回到我们之前学过的知识点，同样有非结构化的数据，还有这个数据库，我们还记得这个data connection这个模块。
	在南茜的基础概念的时候，我们有讲上中下三节，其中中间这一节应该就讲了data connection这个模块。大家还有印象的话，里面有四个不同的，都不可能教大家处理各个环节。我们的文档的加载器，document loader，我们的分割器split，包括我们的用来存这些文档向量化之后的这个向量数据库，以及我们能够从向量的数据库里面去检索数据的recover，这四个标准的操作，这个是一个典型的从原始数据到向量数据库里面的可以用的向量，以及到。最终我基于一个query，然后又基于这个query去找出一些相关的结果，然后把这个结果去做处理，这一个标准化的流程，在上节课里面我们讲了auto GPT也有讲了这个auto GPT的实现里面怎么样通过从向量数据库，从各个地方去拿结果。这个实现方式，包括今天我们也会继续用。
	前面这四个部分，就是一个典型的data connection模块的一个标准化的流程操作的一个机制，一个标准操作。这些东西最终结合到我们刚刚看的这个基于知识库问答的这个典型用例里面，会变成什么样的事情，其实就变成了第一，我们会把这些结果再跟我们的给大语言模型交流的这个prom提示词去做一个整合，这个也很好理解，首先如果我只有大语言模型，我会跟你闲聊，甚至聊着聊着我们都不知道自己在聊什么了。所以我一定要跟你聊的过程当中给你一些上下文，这个上下文就是问题的答案。所以我们看到用户问了一个问题，用户在这儿问了一个问题，我会把这个问题从向量数据库里去查出一些答案来。如果我没有答案，那我给到大语言模型的这个prompt里面就没有什么有用的输入。换句话说就是用户的这个问题，我是没有相关的知识储备的那我可能就陪你闲聊呗。
	第二种情况是用户向我提了一个问题，因为我们始终是一个聊天对话的一个应用场景。用户向我提了一个问题，一个query，我有相关的答案在知识库里，然后我会给到用户，然后怎么给呢？首先是通过这些查出来的结果，跟我的prom的模板组装成一个新的可以用的提示词给到大元模型，最好大元模型再来判断我应该怎么回答你，对吧？是直接原封不动的把这次会议的结果给你，还是我再包装一下，润色一下，这些都是可以处理的，关键就在这个prompt要怎么样去设计好。最终给到用户的就是这个结果。这个是一个典型的data connection模块，和我们要做的问答机器人结合起来的一个流程。
	那落到年前的实现上面，我们要调用哪些类呢？其实就是这些，我们在这个过程当中会用到包括这些代码里面会用到一些结果，不同的颜色代表了不同的阶段，然后不同的阶段会有不同的一些类用来做处理。这里我们用了一个用这里我们今天的实战不会用这个类，就建索引的这个类，因为我们的数据比较少，没有必要。但是这个类的使用方式也很简单，在这个文档里面，对应的这个AI文档里面都有，我这边就不再赘述了。
	简单来说就是我们如果数据量非常大的时候，大家知道我们在向量数据库里存的都是向量。那向量就是embedding。那这embedding每一个embedding是什么呢？就是我们分割出来的一个个文本块，也就是那一个一个的document里面你的page content，对吧？
	我们先把这些一个一个的向量存到向量数据库里，那怎么存呢？在存的时候可以加一个索引。在上节课介绍face的时候，我们也用过索引，那个face的flat l二大家有印象的话，所以但今天我们没有用。在上一节课已经教过大家怎么用了。如果大家有兴趣可以把那段代码粘到今天的示例里面。
	然后这个vector index creator就是一个在能里面去创建向量数据库索引的一个操作，一个对应的实例抽象。但我们今天会用下面这两个，一个叫retrial l的QA，你可以理解成能券已经自己实现了一种专门用来面向基于知识库的问答的这么一个recovered这个recover，他自己实现好了这么一个类的实力，这个类的实力可以用来干我们上面说的这个事儿。就是我刚刚描述的闲聊，或者说我有这个相关的知识储备，这个产品的详情我结合着跟你聊。
	那在这个实例里面，还有一个叫low的QA chain。我们待会儿看代码的时候也能看到这个node QAK就是具体的这一部分。就怎么样在load QAT里面去组织了这个prompt以及去调用的这个大语言模型。然后这一部分的查出来向量知识库查出来的这个结果，是通过这个QA查出来，然后在它的内部再丢给这个券，从它的这个抽象程度和它的简洁程度做了一个倒排。大家可以理解最下面这个欠是其实就是一个LM chain，再包了一层，它叫做我印象中叫什么staff chain。大家可以看到，然后再把它包在了这个QA里面，代表在然后再包在了这个上面。
	我们其实看了这么多实战项目和代码，包括auto GPT，上节课花了很多时间解读这个源码，大家应该逐步熟悉了，做一个大语言模型的套路或者说方法论了，我们也不能叫套娃，但是它有一些标准的抽象方式，大语言模型prompt一起变成一个欠，就像这儿这有个output是它的输出，对吧？这也是最终这个应用的输出，就是一个提示词加上大元模型套在一起变成一个chain，最简单的嵌就是LM chain。基于业务场景，你还可以去设置不同的，就变成各种各样的券。就比如说这里的QQA券。然后这个券也可以被封装起来，包起来。比如说用agent把它包起来，用the travel这种面向向量数据库的抽象类把它包起来。相当于就是一个欠加上一个面向向量数据库查询的一个工具包在一起变成了这样的一个抽象。当然你还可以再往上包，给他一些加索引的能力，这个是标准的一个像在这个冷却里面处理数据的一个流程，以及应用的抽象。这个就是我们今天会实现的一个比较整体性的一个技术架构，我们具体可以看看怎么做。
	我们具体来做，第一步就是解决最左边的问题，怎么造数据？为了能够授人以渔，我想了一个小的trick，就是网上肯定大家也都也许能找到一些数据比如说找到某个产品的这个详情页，你把它抠下来，然后变成这个。假设你要去卖卖一些特定的产品，标准化的产品，卖空调，卖手机，那你可以找到这些页面。比如说我们不说哪个网站了，反正总会有一些网站有这些产品的介绍，对吧？搂下来。然后搂下来之后，我们再把它变成可以用来放到向量数据库里的数据。这个是很典型的，就跟我们之前的这个事例里面去处理这个TXT文本一样。
	我们今天想说处理因为QA问答给大家另一个方式来造这个数据，就是用GPT4来造这个数据，并且要去做这个数据的生成，其实并不复杂。我希望大家能通过这个方式自己去造各种各样的数据。然后造出来的数据，咱们还能够通过调整prompt去感受一下。
	我们怎么样能够把我们的最终问题，就是我们最终问题，其实我们知道最终要卖什么，这个销售最终要卖什么，在生产销售话术这个阶段就能跟他对接起来，就端到端的把这个事儿给吃透。简单来说，你的prompt写的越好，你就越清楚你最终要卖什么，以什么样的方式去卖。那这里的知识库里存的这个问答就应该越精准。
	那么你的给真正的客户去用你这个销售机器人的时候，自然也就能够他感觉更舒服。因为你在在用户视角造了很多问答。那我们可以看到在这里，其实首先我直接用的ChatGPT，因为这个比较省token，大家都懂的。那直接然后这个ChatGPT的这个分享链接我也贴在notebook里面，今天会提交到github面，非常简单。
	这个prompt第一就是给他一个身份，对吧？然后现在要培训一些职场新人，这是他的任务描述。具体的这个任务就是给出使用的销售话术，给了一个格式上的要求。大家还记得我们上节课学到的GPT，response format，那其实就是类似的，就我们用的中文，让他以一个定的格式给出来，它输出的当然都是markdown的格式。首先他给出来了类似的这些问题，然后他也说的很明白，精心准备的销售话术可以极大的提高成交率。咱们这个就跟我们刚才讲的最后一个率，不就成交率。
	这里是他写的适用一些中国房地产销售的适用话术因为这个我相信所有人应该都会遇到的销售就有这么一个场景。我们看到他的客户问题和销售问答，其实写的还蛮好的。就比如说有很多买房的人都会关心我去我买这个小区或者说我租这个房子便不便利，交通便不便利。我现在一般都是坐地铁或者坐公交车打车的不考虑，那么坐地铁或者坐公交车当然是一个很好的回答，包括吵不吵，我买房房价会不会涨，附近有没有学校，有没有医院，小区的绿化怎么样？有没有公园停车位吧？包括像这个精装毛坯，旁边的配套有没有商业区，这个电梯的配套，然后这个大阳台，包括这个什么时候交房，是不是期房，有一些特定的楼层，包括这个优惠，这个是不是提供按揭税，税费怎么样？这个问题其实是挺实用的。
	就是现在的GPT4去帮大家造这个知识库也好，招这个特定的销售话术也好，是一个非常实用的场景。我期待大家在这个家庭作业也好，在自己的实践也好，去想一想一些特定的场景，去造一些数据去试试。然后这个prompt具体怎么做的，我们待会儿可以看看实例。
	第二部分就是把刚刚照的那一堆东西存下来，存到向量数据库里。这个应该很熟悉了，我这儿就不再赘述了。但也在这儿放下这一页，通过我们还是用上节课讲的这个face，然后把它存到一个本地的持久化的目录里面，index的这个PO存到这样一个目录，然后我们可以实际的去做一个提问，比如说小区吵不吵，这个问题在原来的数据里面是没有一模一样的答案的，就这个query，当我们存下来之后大家可以看到很有意思的点，上节课有人在课后问的点，我们通过这个query。我们先不说大语言模型，就像刚刚讲的这个比较早期的，包括现在大部分的电话销售机器人的这个场景，其实就是这一页的一个场景。这一页就是几乎代表了所有电话机器人的常见场景。
	就是我把我的问答存到一个库里，然后我基于我的问题去检索我的库里面有没有类似的问题。如果有的话，我就把这个问题的答案给到我的这个用户，但是这里有两个点是需要注意的。第一个点就是说我们怎么样去存这个一每一条问题。就比如说我们看到它是一个QA问答队，对吧？我是只把问题存进去，还是说把问题和对应的答案都存进去？如果我只把问题存进去，那么问题和答案的这个对应关系我需要单独处理，这个是一个点。第二个点就是说如果我把这两个都存进去，会不会存在一个现象是说我的这个query会去跟问加上答案一起去做这个向量的相似度比较。那这个时候有可能如果我的这个问答很长，那它的效果就不会很好，对吧？
	那么这是两种处理手段各有优劣，像我在这个事例里面选择了一个比较取巧。因为我们这个场景不会问特别复杂长的问题，我们直接把问答放在了一起。但如果咱们要把问答分开也很好处理。最简单的方式就是我们把把这个问题的这个key，把这个东西作为一个key，把这个问答的答案作为一个value。哪怕我用一个python的字典，我都能存下来，对吧？也就是一个专门做这个匹配关系而已。然后这样做的话，我的问题就能跟用户提的这个问题更直观了。
	但这些东西都是要根据你的实际场景去做设计的。也有可能在你的场景里面，它的问答是高度相关的那你把它放在一起去做query，说不定更好。就比如说他问小区吵不吵的时候，他可能问的是你们小区是否隔音你们小区有没有降低噪音所以这个没有标准答案，我只能说给大家提供两种方式。但是回过头来我们忘掉这两种方式，就单纯从这个相似度搜索这个实践上，会不会发现这一页的答案其实是有问题的。大家会看到我们问的是吵不吵，对吧？前三个答案都挺不错的，但是第四个这个答案是担心小区会很拥挤，小区的总体规划合理，保证了每个单元之间有足够的空间。显然这个就跟我们问的问题不怎么相关了，对吧？
	因为我们用相似度搜索这个方式去去从向量数据库里去检索的时候它默认的有一些参数，其中一个就是说返回最高相似度的四个答案所以你看我在这儿遍历了这个答案，同时这四个答案它是没有阈值的。就像上节课我们用alt GPT的时候，大家会说这个memory怎么一直在往里传递，那是因为没有设置阈值，它就会至少保留四条，像这个答案，然后作为alt GPT里面的那个memory往里塞那有没有别的方法来做呢？当然有，第一就是你刚刚说top 4是它的默认值，对吧？那我们能不能自己去设置要top几？比如说我们刚刚看到了要top 3，那可以，那就top 3好了。但是这样的方式是不是太硬了，对吧？就是我们如果只设置这个top k这样的一个参数，大部分的场景或者说它适用的场景是说我的向量知识数据库里面存的知识非常多非常非常多。我大概率每一个问题都能问到一些答案，不会存在说相似度非常低的情况。
	那我用top k是合理的，因为我就是固定想要那么几个答案，它的结果是非常稳定的，不会存在说一会儿三个答案，一会儿五个答案，一会儿十个答案，这种是它的使用场景。但是我们知道我们刚刚照了几十条数据，那么这几十条数据里面就会存在top k，比如说top三个都不相关，那怎么办呢？所以我们还提到可以通过浴池的设计，对吧？
	那我们可以用另一种方式叫做similarity后，那它的是它的搜索方式。检索方式就是设置一个阈值，就比如说我们把这个相关性要设置在高于0.8，我才能给你结果，那这样的话就能保证一个点就是给我的结果一定是相关性非常高，高于我设置的阈值。至于这个阈值的经验值设置成多少，看场景了，看你的数据质量了。但是这种方式它的坏处就是有可能当我数据非常少的时候，那我一个超过0.8的都没有，那怎么办，大家想想怎么办，那就应该用大语言模型来回招了，对吧？就是我们开始有提过的。如果超过这个阈值的答案一个都没有，那就由大语言模型来扩招。由他来想想办法，他来闲聊也好，他他克制一点，他什么都不聊也好，甚至我就写一个特定的模板，像我说的这个问题我不知道，我得回去问我的领导，这些都是一些处理的套路。
	跟我们去回应这个具体问题和场景是直接相关的那最后我们把这个都做完了，其实至少面向数面向线上数据库这一部分做好了，这个大元模型怎么弄，待会儿可以再讲。接着就是说最终我们当然不希望它只是一个notebook，我们希望它是一个聊天机器人，对吧？那之前我们在OpenAI translator有教过大家用radio，今天我们也依然会用radio，用他的这个聊天框来实现一个图形化的界面。在这个图形化的界面里面我们就可以跟这个大语言模型加上向量数据库这样的一个销售机器人去聊天。
	这里就是我实际问的一些问题。比如说我在小区方便吗？他打我这个很方便，这个就能看到，这个处理是几乎把他的这个标准答案就拼起来了。然后小区吵不吵，很注重这个居住体验。我只回答了这个答案的部分，没有把他的问题反馈出来。我看到旁边有这个建筑工地，对吧？他这里就会回这个建筑工地，但是这个隔音很好啊，咱们是精装房吗？好的，还有回答。
	这个就是一个我们今天最终会去给大家看的一个实例。在实战之前，我最后再简单的用这样的一幅图跟大家捋一捋这个逻辑和知识。我们用五分钟的时间来回答一下大家的问题。接着我们就实际上代码，就是我们大家再回想一下，如果我们要用南倩来去做一个基于知识库的对话机器人，它的最佳实践要用到的冷却里面的概念。
	第一就是我们的大语言模型，对吧？因为要做聊天机器人，首先想如果没有知识库，大语言模型也是一个对话机器人，只不过跟你瞎聊。如果我们要用知识库，那一定就要设置好这个prompt，我们把这个提示词要设置好。这个其实是就是属于一个当我有知识的时候用知识，没知识的时候大约模型你就靠你自己了。
	所以它的prompt一定有一个知识的来源，这个知识的来源就来自于向量数据库。这个向量数据库里面会检索出不同的结果。根据他的搜索的规则和方式，比如说相似度，比如说这个MMR会得到一些答案。这些答案会给到我们的prom去做组装，这里就会有各种各样的设置了。所以你能看到这里两条路，一条是完全没有这个答案的直接question给到from大约模型就回答了。
	第二条线呢就是大语言模型。他不仅自己很聪明，他还有一个外部的知识库，告诉他你其实是有标准话术和套路的。你结合着你的这个聪明才智给一个答案。
	然后这里还有一个很经典的memory这个设计，就是我们在讲memory模块，包括讲auto GPT的时候，上节课都有去强化它。这节课我们就不强化它了，比较费这个token。我看有同学在讲这个memory怎么用，上节课的代码大家也可以直接摘来用。简单来说就是在问答机器人的时候，我们把答案丢到memory里面。这个memory怎么样做到prompt，也有很多手段。上节课我们其实就是用的类似于从库里面去获取memory的手段，对吧？那上节课我们用了这个similarity search，这节课我们会教怎么用这个带阈值的similarity search相似度搜索。从memory里面去取答案一样可以套用这个similarity search。
	可以作为大家的家庭作业，自己去扩展。好，看大家到这儿有没有什么问题，我们可以回答五分钟的问题。然后接着就开始做实战的。
	这个部分了。
	正好我接杯水。
	有个同学说这种是问答式的，比较局限。有没有推荐式的？其实推荐和问答没有本质区别。咱们仔细想一想，为什么我刚刚把这个GPT4生成销售话术专门讲了讲就是推荐房子是不是也可以让GPT4来生成对应的问答呢？然后如果我们推荐房子的时候，真实场景，就是人跟一个真实销售去聊的时候，他是在不断采集你的需求。首先我们没有说大语言模型或者能嵌天然把所有业务场景都做完了，这不是它的定位。业务场景一定是咱们应用层要干的事儿。
	我就跟大家讲一下怎么样去做一个推荐房子的销售机器人的逻辑那就很适合现在这幅图。首先推荐房子就一定需要用memory了，因为用户跟你聊的时候，一定是不断的去把需求挖掘出来。比如说我想要一个三居室，我想要阳台大一点，我想要客餐厅的进深和面宽是多少，我想要两个卫生间，还要有衣帽间。那这些信息是不是都在memory？然后我们把这些memory里面的这些东西，通过from的是不是可以组合在一起，变成一个新的query。这个新的query是不是可以去我们的知识库里面去做问答。并且这个知识库里甚至可以去不只是对接一个向量数据库，还可以对接什么呢？还可以对接我们真实的后台还剩多少套房子，比如说我现在后台就是还剩这几个小区有什么样的房子，这些房子是可以打上标签的，这个标签就跟我们刚刚那个问答一样，就是你的prom会怎么组合一样。
	你可以让GT4生成什么样的东西呢？生成刚刚说的那些关键很刚性的参数，几房几室、几厅、什么面积。然后后面对应的就是什么样的小区还有什么样的房子，甚至什么样的小区还有什么样的房子做的更牛逼一点，做成一个function calling，对吧？去调某一个房产销售的API，他那库里面实时查出来。就跟我刚刚讲的circle light这个场景一样。其实你最终想象一下，它就变成了一个什么大语言模型，帮你再从客户那挖需求，挖出来的需求会变成很多干的这个指标。这干的指标可以直接去对应的一个数据库里。我们刚才有讲，这个QA，这个机器人不仅是能对接非结构化数据，也可以对接结构化的数据库，把这些干的指标直接去查数据库就可以告诉你了，甚至连价格都可以告诉你，这是一个很典型的一个框框，一个范式。
	我看还有什么问题，刚才还有一个同学在问多轮对话，多轮对话一定要用memory就是我们在用ChatGPT的时候，它是有记忆的对吧？然后我们在讲基础篇OpenAI的时候，也讲这个记忆是怎么来的，就是通过维护这个memory来的那维护memory是有成本的，因为你的memory不做处理，直接硬记下来就给大元模型会消耗头疼。所以这儿是一个关键，就是怎么样处理memory本身就是一个很拿出核心竞争力的一个水平。这就跟举个例子，这就跟好的深度学习或者说强化学习的算法工程师和一般的工程师的区别。一般的工程师拉出来一个开源库跑一跑训练数据就结束了。那好的这个工程师他就是会去做数据增强，他会把这个比如说强化学习，他就是会把这个评价函数做的好啊，这个环境仿真做的好啊，reward做的好。
	我们现在大约模型开发proved和怎么样去用这个memory就是一个很核心的差距。就做大语言模型应用的时候，你不是一个孤立的技术角色。你要想一想，就大元模型一定不是一个孤立的技术点，它是端到端的。因为你直接面对用户，所以你一定要去理解业务，理解场景，你才能做得好，prom才能设置的好。怎么用memory？
	问答库里如果有答案，为什么还要用大语言模型过一遍再给到用户呢？直接把标准答案给用户不好吗？有一个同学问，第一问答库里没有标准答案，这个是大多数的场景。就是你想象一下销售话术是什么概念？销售话术不是说每一个用问题都有答案，它不是1001问。他更多的是理解用户的意图，然后知道怎么样去基于这个意图，有哪些比较好的引导这个用户去转换的这些答案，一定是从这个角度去思考问题。所以你看到我们刚刚的答案里面是答案吗？不是，他更多的是积极响应用户的问题，比如说我们这个我们就直接跳到这个销售聊天机器人的这个示例里，大家应该能看到这里有一个ChatGPT的分享链接，是我用来造这个数据的一个链接，那我们能看得到有没有回应。
	首先像这里的答案其实都说的很模糊，比如说吵不吵，隔音设计，包括未来有大量的商业和基础设施建设，长期来看投资回报有保证，对吧？就是真正的销售是一门技术，这我们不讲销售技术是什么，但我单纯的是想跟大家讲，就是基于知识库的问答，从来就不是把标准答案存下来，而是说找到跟标准答案高度相关的问题。然后我们用这套模板也好，回答也好，话术也好，去回复用户。
	甚至我们可以找到多个问题，就比如说我们看到这幅图里面有多个相关的，多个相关的要怎么用，就全看咱们的prompt怎么写了。你是可以直接把它拼起来的，你也可以选择去重，对吧？就他们如果有表达相似的部分就揉在一起，这个都是大语言模型的能力，用了大语言模型的语言理解能力和他的推理能。
	还有个同学问，这个不仅可以做电话销售，也可以做主播吧？对，这个我刚刚有讲，不知道是不是开始没听到。就是讲电话销售的时候我就有提，这个智能化的系统，包括这个外呼的系统都可以在做扩展外呼的系统。套一个虚拟人不就是主播了吗？对吧？
	还有同学问怎么对大语言输出的内容进行质检，请回到基础篇。我们讲OPAI的时候有说过，OPI还提供了一个API叫做moderation，就是用来做检测的，就是敏感词过滤。当然这些敏感词是不能直接回复给客户的，并且大家如果要对外服务，还需要去进行这个生成式人工智能的公司备案。还有同学问怎么样存向量数据库，是一篇文章还是一个问答，还是什么，跟你的应用场景高度相关。然后还有同学问这个基于知识库问答的时候，怎么避免生成式的幻觉，比如添油加醋什么的，这个可以通过prompt来设置，比如说待会儿我们就可以看看这个retry QA它是怎么设置的。
	还有同学问，第一天问了，过了好多天又来问怎么样查询。查询memory的话，历史对话的from太多了。当然不是，查询memory我们刚刚讲过，就这种我为什么我说对话和问答机器人是两个水平的事儿，因为对话机器人就要考虑memory对吧？那问答机器人可以说简单一点就是一轮问答。那有这么多对话，你也可以把这些对话存在向量数据库里，就是我们造出来的这个销售问答的这个问答对啊和你跟用户真实发生的这个问答，真实发生的问他也不是二等公民，他也可以存在向量数据库里。那你是不是也一样可以去检索出你现在这个客户，现在来问的这个问题，在历史上有没有跟他相似的？如果有相似的，是不是就可以按照我们上节课学auto GPT1样，把高度相似的按一个阈值找出来，然后再设置一个上限几个，然后再给到大语言模型的problem。
	当然可以的。
	机器人可以做量化交易吗？这是这不搭嘎的两个事儿，就量化交易是量化交易，机器人是机器人，或者说机器人就是一个自动化的工具。那量化交易是量化交易的这个完全两个东西对。
	假设知识库有向量数据库的、关系数据库的、文本类的那要从这些不同的答案里面找到最佳的完全依赖prompt。好问题。首先这些不同的用来存数据的知识库，各有各的检索方法。比如说ES比如说最近很火的新的一个替代ES的开源的扩。包括这个面向文本的这种基于向量，或者说主题查询之类的经典方法，这些东西都是用来查我的这个query相关的一些知识，查出来之后要怎么用。确实我认为目前来说最好的方法还是基于我们的大模型，是最简单最省事的。但是怎么样基于大模型来找最佳，这个真的是靠prom，就prom设置的好，它就是能找到好的。GPT4比较厉害，换其他的大元模型估计就不太灵光了，这个同学说的还挺对的，是的。
	这个同学问的就更什么过了几天来问的这个同学，那你现在问的就完全不是大语言模型的问题了。前几天问了哪些问题，如何知道？对这个如果你是说不能识别出哪些问题是你问的，哪些问题是其他用户问的那这个简单，每个用户有自己的ID和历史记录。如果你问的是前几天问的那些问题，我们刚刚已经提过了，就是机器人不知道你脑子里怎么想的。你现在比如说你现在关注哪些房子问题，一定是你当天又问了一次。就是你你想清楚一下你的这个场景。对，就是你是一个聊天的人，你正在跟一个人聊天，就算对面那个人记得住你前几天说了什么，但是你现在不发问，他怎么知道你现在要跟他聊什么呢？这个就很不合理。
	对吧？
	QA系统的准确率需要不断提高，然后这个迭代提高准确率的机制是怎么样的？首先不存在准确率，就是这个同学不存在准确率。我们刚刚一直在讲销售，至少我们今天讲的这个场景不存在准确率，最终都是业务指标，就是成交。
	一个向量数据库只能存一种in bedding算法的结果吗？那你可以用，首先这个答案的结果是的，就是因为你如果in bedding的方式不一样，那向量之间就没法比较，所以是只能存一种embedding的方法。但我们没有说你只能借一个向量数据库，然后目前比较常用的就是OpenAI的这个invading，效果很好。
	文档中有表格怎么处理？是转成文字描述吗？想输出的答案也是表格怎么处理？是使用吗？当然，我们的OpenAI translator就已经解决过这个问题了。
	请同学翻看一下对应的代码，文档中有表格怎么解析，怎么输出markdown都有。好，我们就来实际操作一下这个代码。首先我们看看我是怎么做这个项目的，一步一步的来。第一我们要干的事情是造数据。所以我们能看到选了这样的一个方法去造数据。毕竟很便宜，为GPT4已经付过月订阅费用了，所以不会再花钱，也不用消耗token了。那么让它来生成这个对应的格式。当然这个prompt不是写死的，是希望大家能够理解这个prom的结构，给他一个系统的角色，然后给他一个场景，给他一个具体的任务，然后给他一个返回的格式要求，这种三段式的结构大家是可以去参考的，所以它会给出对应的这个结果。
	我们刚才在课件你也看到了，它前后都还有一些不必要的。比如说由于字数限制，只能列举一部分这样之类的，你点继续，然后他会继续去给你生成不一样的这个问答。对，就是通过这个方式，其实你是可以造很多数据的。但是如果大家嫌这个比较麻烦，并且你是要生产去使用的话，你也可以选择把刚刚那个prompt使用南来调用我们的这个模型。然后把调用的这个结果直接存下来也是可以的。好，那我们现在手动来操作一下，就能让你理解如果你要自动来做会怎么做，继续，你会得到这些结果。
	好，假设我们现在要去把这个东西变成一个我们可以直接处理的文本文件，我们会怎么做呢？大家可以看一看实际怎么操作的。其实我们要做的是一些简单的字符串处理。比如说这里我们有一段结果，这个结果我们希望能够把它拷贝到一个我们对应的文档里面去，我们可以新建一个文档。好像。
	这个分享链接不能用，我得切到这个实际。
	编辑的链接里面。
	大家都知道这个GPT4每一个回答和每一个提问提问都是可以在编辑的回答都是可以拷贝，包括给他反馈。我们这样拷贝下来，其实它是一个mark down的一个渲染的格式。我们可以看到是这样的。所以即使这里写的都是一样的，生成的都是一些数字，那这些数字也后面也是可以去处理的那这个前后也是一样，这个前后我们写过python的这个字符串处理的同学都知道怎么样快速去处理，所以我就不再赘述了。
	对，最简单粗暴的方式就是你通过GPT4生成的这些数据，然后你可以直接拷贝一下，像这里我们直接拷贝可以得到这些结果。然后基本上是每一次回答生成了十几条到24条的这么一个数据量，这样我们可以把它存成一个对应的TXT文件，那这个TXT文件，就是最终我们在这儿看到的这个TXT文件OK。这个是我们的一个结果。
	那好，我们把这个结果存下来之后，我们希望大家再回忆一下这个是怎么样去处理我们的这个数据的。第一，我们希望把这个数据存到向量数据库里。然后存之前，这个大小应该大家能看见吧，需要再放大一些吗？还再放大一点。好，这样应该差不多。那我们可以看到刚刚打开了这个文件，就是这里的这个文件，我们捞了这个70条，这七十条数据我们从这个TST文件里面打开，加载还是重启一下。
	你再点进来，然后我们要把它存到向量数据库里。刚刚有讲，把它存到向量数据库里，我们一定要先给它进行切割，对吧？那怎么切？之前已经用过很多次的这个文本分割器，今天再给大家深入讲一讲。这个文本分割器是这个data connection模块里面的很重要的一环，甚至你要建索引，也是直接把这个拆分之后的这个内容imaging建索引。
	好，那么文本分割里面用的比较多的。比如说我们的这个character text bleeder，之前都用过，默认有一些参数。比如说这个用什么来做分割，以及每一个块儿大小，有没有重叠，就不同的分出来的文本的这个块有没有重叠，以及我们重叠之后，具体重叠多少，是overlap，包括去算它这个大小，用什么样的方法，以及我们给它的分割的这个分割符是不是一个正则的分割。那今天我们重点来跟大家讲讲这个场景下我们要怎么分割，故意把这个标号留在这里，就是想给大家讲一下这个文本分割的用法第一我们最重要的要把这个数字给拿掉，对吧？没必要这个数字存在，这就是通过这个数字我们能跟大家讲一讲分割它的这个分割符，怎么用separator，以及最后这个参数是不是使用正则来做分割。
	常见的分割就是我用换行符来做分割，就比如说有两行，这个两行什么概念呢？大家可以想象一下两行是什么样的一个情况。就是我这儿有一行，他这个后面本来就有个换行，对吧？那我其实只要相当于我正常的书，或者说正常的这个文本文件，通常就是会换行，并且段落之间会空一行。这样其实通过两个换行符就能把一段一段的文本给摘出来。大家想象一下前面我们讲这个叫什么united of什么state这个文件的时候，就这么分的，我们在就拍的tests里面有这个state of the union，对吧？这个典型的这有一个换行符这有一个换行符，那它就改成了一段一段的，那就能很好的把每一个段落，每一个paragraph都能分成一段，这个是比较常见的separator or的用法。
	那现在我们是希望每一个这个相当于每一个数字，比如说一点下面的都可以被分割出来，那怎么分呢？但是怎么用的？仍然是引入这个character text，用了一个正则表达式，这个正则表达式这个D加就是指这个D其实是number的意思，digital d加就是指这个digital可以是多位，比如说11 12 13对吧？15、16，然后这个点儿是用来表达这个点儿的，不会做这个分这个分隔符，不知道怎么写，这个分隔符也不重要，用我们这个上面的TIGPT的分享链接，也教了大家怎么样去做，比如说给大家看这个proms怎么写。比如说这儿我们这就在这个分享链接里，我们使用正则表达式提取下面的数字加标点。比如说一和2，直接把我们的这个生成结果切到这来。
	那我们的GPT是怎么回复的呢？使用了python的这个政策表达式的这个库，把这个作为输入，生成了这样的一个标点，并且这段代码你可以直接拿去试。如果你换不同的这个政策表达式和这个，他都能看出这个结果，都提取出来了。那这就是分隔符提取到位了，对吧？到这儿大家应该能看明白，我们可以通过GPT4来帮我们去生成这个分隔符。当然如果你的场景更简单，你的分隔符不是动态变化的那你甚至都不用正则表达式，就跟我们刚刚说的那个换行符一样，对吧？
	那么通过这个是想教大家怎么样去用其次生成数据以及去构造这个分隔符。但实际情况肯定不是像现在这么干净的，可能还会有各种各样的那你都可以通过跟GP4T4的交流，去造出这个splendor的实际场景。我们现在因为是问答的场景，我们不希望有overlap，所以overland设置的是0，然后我们也把乔克赛设计的这个块的大小设置的稍微小一点，如果设置稍微大一点，它会一次分出多个问答。对，好，我们可以实际执行一下，我们把这个已经生成好的，之前存下来的向量数据库，先给它干掉。删掉。
	好。
	那我们可以实际来看看它分出来的这个结果是长什么样的。得出了这个答案，这是其中的第一个问答，我们可以看一共有多少个问答，70个，大家还记得吗？这里是70个，非常好。这是为什么我要造这个number，比较简单，很巧妙的造了这样的一个数据集，里面埋了很多小心思。是想让大家第一能通过这个方式去验证一下，是不是真的都分割到位了，是不是每个问答都被分割成了一个筷儿，这样就可以去很好的看出来。第二能够通过这个方式让大家去学会怎么用separator。并且这里我们把使用separator的这个正则表达式打开了，用正则表达式来表达这个separator OK。
	这个是我们把这个文本就分割到位了，问答都分出来了。接着我们把这个face作为线上数据库的引擎，把刚刚分割出来这个document，使用OpenAI的embedding模型变成向量之后存进去。那么这个是这个DB就是我们的这个向量数据库，它已经存好了在内存里了。其实这个时候就已经有答案了比如说这个时候我们先不存，我们可以看一下在内存里面了，已经小区吵不吵看答案。这跟我们刚刚那个课件里面的截图是一模一样的。现在我们再把它存下来，把它弄到这样子。把它存下来，存到。
	这个目录里。
	这个使用应该跟上节课一模一样大家来可以自己试一试，存到这里来了OK那现在我们想一想，就是跟刚刚课里面讲的一样，这里默认使用这个similarity search的时候，它直接输入一个query就好了。但这个query这些参数如果你不去做一些调整，使用默认值有时候会不满足咱们的需求。比如说这个问题就不相关，那怎么办？可以使用这个search key arguments，这个是一个很重要的D参数的方法，然后传进去是key value。他也支持很多其他的search的key arguments，那这儿我就不这个方法大家应该上节课听讲的同学有印象。我们还记得offer GPT里面怎么去获取这个memory的时候，用到了这个s retrial al的方法。包括上节课我们去讲face怎么用的时候，就是把这个向量数据库本身都会实现这个方法简单迁移，相当于就是直接就构造出了这个recover。
	我们因为这个是每次都返回top 3的这么一个retirer top k的那我们现在设置为三，那我就给它命名为这个top k的一个retrial l设置好，我们能看到retriever top k的recover是个什么样的实力抽象呢？这个能看到vector store recover，alt GPT里面专门讲过这个源码分析师讲过这个玩意儿，然后它有一个tag表征了它是用的什么向量数据库。那它的vector store里面是具体的这个向量数据库实力，就是那个DD。然后使用的这个search的类型叫，然后使用的这个搜索向量，检索向量的类，这个类型叫similar相似度。
	然后在搜索的检索的时候有什么样的额外的参数呢？就是这个K是top 3，那我们可以试一试。我们看到这里我加了一个换行符，让它输出的更简单直接一点，这里都有啊。然后我们可以看得到，检索出来的结果就是最相近的三个了。但这样的方式也有缺点，缺点就是我刚刚讲到的，通过这个方式，我们有可能跟他完全不相关的答案也会被强行给搜出来。你可以试试，假设我们把问题换成。呃。
	我印象当中，比如说这个。
	问个这个问题，你看看他会有什么答案。首先他肯定会顺利执行，我们打印一下看有什么结果。大家发现没有使用top k的问题在哪呢？当你的向量数据库里面的结果不多的时候，你强行返回top k相似度还是很差的。我们看到这三个提供家具吗？哪些户型不想要一楼的房子，这是top k的缺点，优点就是他一定会给你三个答案的适用的场景更多是在于你的向量数据库里面存的比较多的时候，能给你一个稳定的结果，这个是使用参数K来返回top k的一种检索方法。当然我们也可以设置一个比较干的阈值，来提升它的结果的相关性的质量。
	相当于只要反馈给你的结果就一定得是足够高的那比如说这里我们有一个similarities。Core stage hold, 大家看这个这个应该很直观了。Search type和这个search key arguments是它最重要的两个参数，决定了它的检索的方法和里面的超参数。当然你不同的search type就会有支持不同的key arguments。比如说对于这个带阈值的相似度搜索，最重要的就是这个阈值了。
	那我们在实例化一个recover，同一个DB你可以实例化很多个不同的recover。相当于有一个池子，你生成一个检索这个池子的一个retriever。它当然可以多种多样的方式去retrial，对吧？
	那好。
	我们可以看到，针对刚刚这个楼下太吵的这个query，其实0.8真正超过0.8相似度的就这么一个。其他都很其他其实这个相似度都都很低，有没有跟他高度相关的？这是一个比较典型的手段和方法，那到这儿为止，其实我们基本上把向量数据库，包括首先是生成这个向量数据库里要存的这些问答，然后问答对去做处理，做分割。分割完了之后存到向量数据库里，并且先变成向量，先行bin再存到向量数据库里。针对这个向量数据库里，我们可以有多种多样的方式去检索，相似度top k，加阈值，这是到目前为止的这个逻辑，我们都整明白了。
	接着就是我们看看这个回答还是不够友好，对吧？结果没有进行处理，我们希望其实只需要回答销售，回答这后面的问题就好了。这里再给大家展示一下，如果我们要对QA的这个结果进行处理，其实没有大家想象中那么难。就是在简单再做一些字符串处理就好了，甚至这些东西你都可以交给ChatGPT去生成，就跟我们刚刚去提取出这个separator分割符一样。你就告诉他我今天存的是这个，我就想要这个，让他生成一些python的代码都行。
	这里我再给大家展示一下怎么做，其实很简单，还是通过这个方法，这个方法大家有一定影响的，就是去获取最相关的这个documents，默认用的是similarity。然后我们去取出什么呢？我先给大家看一下，逐步看一下其实。其实就是这个玩意儿对吧？就这一行，然后我们要的是什么？我们要的是最后面的结果，所以使用一些python的字符串的方法就好了。比如说这个split方法，那其实就会把这个玩意儿做成一个分隔符，就跟我们那个character的这个tex bleeder做的事情一样，sped对吧？Python自己带的字符串处理的方法，把这个玩意儿作为分隔符，并且split的方法也支持正则表达式的，所以从这个地方来看，我们都在对字符串进行处理。和这个地方没有什么本质区别的是他做了一些更多的功能。
	那我们使用python的这个splay的对结果进行处理非常简单，通过它就拆成了两部分了。大家就想象一下，就这么个玩意儿作为分隔符，那就相当于上面是一段，下面是一段，对吧？那就像这个一样，上面是一段，这个换行符也是一个字符串的下面是一段，然后我们要的是下面这段对吧？那就使用这个python的这个列表，这是一个python的list，是一个列表。负一就是倒着取，负一就是把最后这个拿出来。这样我们其实就拿到了真正我们想要的结果。其实真正的从向量数据库里取出来的结果，这document的内容就是通过这样的一些手段去处理的。你可以通过python的手段去处理，也可以通过大语言模型的方式去处理，这些都是没有问题的。
	包括我们待会儿实现的那个真正的版本，就通过代表模型去处理的那我们还想问各种各样的问题，不能每次都改这个barry对吧？那那好恶心。对，当然我们会去进行一些适当的封装，这些都是给大家打个样，让大家去理解。比如说我们封装一个sales的方法，输入的是一个query，并且还可以带上阈值，在这里面定义一个recover，拿到一个检索出来的结果。好，我们把这个检索出来结果，按照刚刚那个方法，获取到真正的销售回答的结果，然后当然这是一个python的这个应该大家都会用吧。这个list competition就是它的这个拉姆达表达式的一个用法，就是把拿到的结果for loop一个for循环，for循环里面每每一个都这样处理，就这么简单，得到一个s list，最终把相当于把你找到的这个回答里面的所有的这一部分都拎出来，组成了一个新的一个列表。比如说这里我的query是我想离医院近一点，这里就可以得到一个我想离医院近一点的答案。没有，这就是一个很重要的点，想给大家展示。
	第一个首先当我们去用这种方式的时候，就设置0.8的时候，它的缺点是什么呢？就是有可能当你的库比较少的时候，所以所有的问题都是你的向量数据库一定得做多一点，才能覆盖尽可能多的场景，对吧？当你没有接大语言模型的时候，你又问了一个超纲的问题。然后用这个freehold的方法，那就是没有答案，就是没有一个库里的答案是满足要求的，这是很常见的，他也报了一个窝里，不是报错，给你一个warning，就是说我们没有找到使用这个税code等于0.8的时候没有找到。
	那我们降降一降这个税后的是什么？比如说我们降到0.75，我们会发现就有了，并且还有两个对吧？这就是我们刚刚组装的list。当我们把它降到0.75的时候，查出了两条超过0.75的答案。然后我们通过这个split的方法，针对每一个查出来的结果都获取出来了它的销售回答。
	然后类似的我们也可以看看不同的阈值针对同一个问题会有什么样的一些反应，就是问这个价格高度敏感的。我们看到0.5他回答是不同的户型和付款方案符合你的预算，问的是价格200万以内，这个问题问的就不够好啊，故意的。这里其实他回答的这些问题，是跟钱有一定关系的。包括什么升值的潜力，付款方案还有付款方式等等，是跟他有一定关系的。就是因为他至少超过了0.5的score。
	但是通过这个事例，也是想让大家了解一下相似度这个玩意儿。大家是可以去通过各种方式去测它的。在你的这个业务场景里，合适的一个阈值的。包括如果你的这个知识库不变了，你很难再增长了，你这不就长这样了。比如说产品描述对吧？那你应该怎么样去调整你的意志，或者说怎么样去重新切割你的知识，通过这种方式是有办法去做横向对比的，尤其是一些高频问题。好，这个其实就是给了大家一些手段用来做调试测试，那我们其实就可以直接把query带进去各种试了，对吧？
	然后我们接下来就讲讲，如果知识库就是很小，我们能启动的时候怎么办？那用大语言模型的能力来帮你去做这个答案还是这样的一个点，这里引入了这个retry val QA，大家还有印象吗？我们刚才课件里又讲这个事儿，他在chance这个模块下，所以从这个导入模块的点，大家如果跟上课程节奏的话就会懂它在这个模块下，它就是一种已经预先使好的chain，对吧？
	这个chain是什么？我们就是一个prompt加这个大语言模型，就能组成一个最简单的欠。我们还可以用别的欠给它做组装。Sequential chain吧？Rota chain等等，这都是预制的chain，它是一个chain里面的玉石线。这个chain想要用一个什么模型呢？我们用的这个chat models聊天模型所以这里把这个GPT3.5作为了这个聊天模型具体的实例。Temperature设置为零，因为我们希望它不要开乱打幻觉对吧？销售不会的就不会，安分点。
	然后我们这个racheal QHA有很多种方式来实例化，一种叫from chain tag，一种叫from l一LM，这样我们就使用from PN type。简单一点，大家也可以去看看它另一个实例化方法，就传一个LLM。然后传用from chain type的时候，它就需要传一个大语言模型和一个chain。这是一个欠，大家要记住。传说错了也要传一个recover，然后最终还给你的这个是一个欠QAQ。然后传的这个recover就是我们刚刚类似上面定义的这个一模一样的rever。
	首先这个D就是我们的FASS对吧？As travel we travel, 然后用这两个方法就一定要阈值高一点，给我的结果是可信一点的。然后如果我这个答案没有，那么就用我们的GPT3.5来糊弄，就这么一个逻辑造一个QA券。好，那这个QA券券的输入是什么样？大家应该熟了，就是跟我们的prompt有关。就prompt里面的input variable的key加上它实际的值。这可以通过读这个的API文档能查得到，这我就不再讲无数遍怎么看API文档。
	我们现在同样这个query，这个query就是价格200万以内，对吧？然后0.8的时候它是没有答案的，0.75也没有答案，但是我们现在设置的就是0.8，看他怎么办。你看这是他的回答，这个是我们的QA券的一个劝的回复他给了这个query c的答案，这儿他没有什么都不会，他就通过大约模型再跟你两个聊了。请问你是在询问什么产品或服务的价格，那么我问小区吵不吵，我问一个他会的，他会怎么答呢？这个答案大家还有印象吗？对，这个答案是我们上面问过的，小区吵不吵。
	在哪儿问的。
	我问一下就好了。看看对比一下这儿问一个这个问题。
	大家看一下。
	这里它有一些。
	简单的润色。我不知道大家感受一下，这个小区特别注重居住体验，巴拉巴拉说掉了。对，有效降低噪音，是不是直接对应的这一段。但是你要知道用户问的是小区吵不吵，你直接这么答是不是有点干，就有点太僵硬了是吧？因为这个问题的回答，其实它本身的问不是这么问的，就相当于他的这个答案对应着这个对应的不是这个小区吵不吵，就他标准的提问在库里不是这么问的。所以你为了弥补出这个差距，因为简单来说就是如果你的搜索出来这个结果的相似度是百分之百，那你就直接回答就好了。但你现在也就只有80%多，对吧？那是不是这差的这10%几可以通过大语言模型去帮你润色呢？
	圆环让人感觉不是模板这就是大约模型的魅力和好处，所以你看他会给你补一句，所以一般情况下小区内部的噪音会比较低，这个就是大语言模型和只能用模板来检索的这种聊天机器人的优势，不知道大家体会到这个优势没有？好，这里给大家展示的就是我们其实也可以直接加载这个向量数据库里的结果。然后加载完了之后可以去用同样的方法。这个其实就我们刚刚上面定义的这个方法，然后我这儿我就不再加载和运行它了，直接从这儿开始，我再问一些比如说别的这个问题，这里就是想给大家看的一个反例，我尝试了半天，比如说这个问题就暴露出了他自己实现的这个券，we travel QA这个券触发了他的边界，他的prom写的还没有那么牛逼。
	当他当你问出这个问题的时候，他露馅儿了，对吧？露馅了。这儿其实是不是我们的预期的？因为我们的预期是我们做了一个应用，这个应用它就是一个房产中介，他不应该暴露自己是一个AI助手。但是我相信所有用过国内的国外的大模型的同学，包括ChatGPT，你跟他聊着聊着他就会说很抱歉，我是一个AI助手。这个大家一定遇到过，那其实你就是触碰到他的这个应用的边界了。
	就是大家理解大语言模型和ChatGPT，和这个bar和这个number a two它是有差距的。裸的大语言模型就是一个大语言模型，聊天机器人ChatGPT这样的东西它都是有预知的proved的。当你聊着聊着他告诉你这句话的时候，那就是它的prompt做的还没有那么牛逼，还不够通用。当然也可以是他by design就是想告诉你，他的能力边界到了，你别死命问了，这个就要通过我们去改造了。
	如果你不希望你的应用场景里出现这样的情况，有两种思路来解决。一种就是你自己去捕捉到，捕捉到他查不到答案了，然后他还会说出这样的话，那你就给他替换掉。像我们刚之前讲过的rota chain也好，用agent也好，都能去实现。当他发现有这个倾向的时候，你可以用比较强硬的一些prom，都告诉他永远别说你是一个AI助手，你就是一个谁谁谁。当你没有答案的时候，就跟我们上节课aut GPT这个finish command一样。当你没有答案的时候，那你最后就说我要问领导都行，这样都行。然后我们的这个QA券，我们现在运行都是直接给一个很干的结果，对吧？
	那其实我们也可以输出它的日志，它的内部实现是用了一个叫combine documents change。大家还记得这个里面这幅图combine documentation change是什么逻辑呢？就它大家可以看到它的实现源码，我就不再做一次源码解读了，就能签的源码没有那么难读好的GPT都很简单对吧？那么combine documents chain的内部实现，其实就是把不它如果有多个找出来多个相关文档，它会做一些拼接，并且跟大元模型的输出再去做一些拼接。简单来说就这样的，它的from的写的也很简单。在这儿我们可以看到，我们可以设置成有两个比较重要的参数，是大家可以去关注的。一个就是它内部的chain可以用这个word bos这应该熟的不行了，就输出它内部的日志。
	就输出它内部的日志，然后这里能看到它内部的一个结果，然后还有什么呢？就是。我们可以让他返回，他到底检索到什么东西了，就是我们这儿是直接已经处理好的结果了，对吧？
	然后还有一种情况是我把它检索了什么，打印出来给大家看啊。比如说这里它仍然进入了这个staff document的钱，在它内部的实现的这个细节的名字，这个大家到时候看看代码就懂了。然后在这儿我们可以把result打印出来。这就是他把这个return source document设置为true之后，可以额外返回一个这样的结果，就是指我到底有没有检索到。
	如果大家想要去做这个逻辑上的处理，做业务上的一些处理的时候，通过这个也是一个很好的判断。最简单粗暴的就是只要我判断这里没有检索到内容，我就走入一条逻辑链条。还有一种就是它作为你的一个判断依据，而如果你没有查到，他又答的不好，那么你可以走入一个逻辑分叉。
	好，这个是可以让大家充分去玩的一个notebook，大家可以在好好好研究，把整个流程都覆盖完了也也讲了中间应该怎么变，怎么玩。接下来我们看怎么给他做图形化的界面。也巨简单。其实我相信大家认真上过课学了这个OpenAI translator的同学应该会的。有点弄大一点，在这个蓝券的跟主Peter和OpenAI translator同级有一个sales report，就我们刚刚看的就拍ter的这个notebook，也就是这个玩意儿。跟他同级的有一个PY文件，待会儿课后把它推到github上，我们这就不打开了。
	然后整个这个代码真的很短，大家看到了吗？一共57行，实现这个聊天机器人加上图形化界面。然后如果现在大家还有人来问南茜有什么好的这个代码量你就懂了，这就是它的好的地方，最少的代码实现你觉得很复杂的功能，那那这是不是它的优势呢？对吧？
	好，我们看看这个代码首先这个代码跟我故意做成跟OpenAI translator的这个video这个图形化界面一样的。很像两部分。一个是一个全局的销售机器人，一个是radio的这个图形化界面的服务。先看这个销售机器人的初始化，跟我们刚刚的took里面看到的一样。我需要加载一个向量数据库的内容，这儿就我们刚才一模一样的加载这个向量数据库DB然后定义一个聊天模型，比如说GPT3.5，那我们可以在这试一下用GP4，然后一个全局变量sale spot，然后retry QA，传进去一个GPT4，这个阈值0.8，然后我们把这个source document设置为true。让大家自己在第bug或者看中间结果的时候可以看得到，那这个是初始化一个机器人儿就结束了，返回的就这个全局的机器人。然后我们还要启动一个gradual的服务，对吧？一个图形化界面，这里引入一个新的模块，大家可以去研究这个文档，挺简单的，跟我们找这个聊天，做做这个OPI translator翻译的时候是一样的，都是通过这个模块。这个china interface套路一样。
	首先它需要有一个函数来响应它的输入输出，我们叫sales check，然后有个title，就是这个图形化界面的这个title，然后它默认的其实还会有两个按钮是他给chat专门做的，一个叫retry。就是我现在我们先把这两个打开，大家看它的标准操作的样式，然后它的标准的这个宽度，就是聊天框的宽度是比较小的，注意感拉长一点，可以多看一些对话。我先把这个也给关掉，这最简单的形式，甚至你可以把这个都给它注释掉，但这个意思大家应该很明确，我就不注释了。然后在这里这个sales chat就是用来响应图形化界面里的输入输出的那具体怎么响应的呢？第一有一个输入，就输入叫message，我们把message录出来，然后这个message就是我待会儿打印出来大家就知道了，这就是用户传进来的信息。然后这个地方有一个to do是留的小家庭作业，就是这有一个参数是用来开关我是否要用大语言模型的。就比如说如果我把它设置为触网默认，那我如果没有检索结果，还记得这个吧？我把它打开了，如果他最后一个相关的答案都没有，那他本来应该会走下面这条，一个很硬的回答。
	我要问领导，我们可以把这个时间设置为force，大家感受一下，我要问领导，但如果我们把这个打设置为true的时候，其实他就会走这条逻辑，对吧？他就走这条逻辑的意思就是说我没有答案。但是大语言模型它还是有一些套路可以给你回复的。我们把这个打印出来，为了显示的比较清晰，我这里把它改成这样。message. 
	message. 
	这里是这个。
	这里有一个小细节，f string这里不能用两个双引号做全套，就单引号了。好，这个就是result。这都是一些python的简单语法，大家用的多了就会了。我们进到这个目录里。年轻的sales chatbot。启动一下。这两个应该大家都懂的啊，这就不再说了，都学过的。跳到这儿来还在这台服务器上。
	7860。这个是他默认的chat interface的样式，我们家的一个title，默认的高度，然后这个是我们要输的内容，默认的三个按钮。Retry就是我再发一次，undo就是我回到上一句，clear就是我清掉，然后假设我们要问刚刚这个问题，就是我们都知道这个问题的答案是什么了，对吧？就是查不出来？Source document查不出来，我们看看他会怎么回答。
	来，我们把拖过来。
	这样大家都看到。这个问题我要问问领导，对吧？这是典型套路。我记得刚才还有一个问题，他是问不出来的对吧？关于价格的200万。
	这儿大家能看到message，就是我们发给他的这个就叫message，然后他们都没有走到这个result里面来，都是走的这个套话，这个问题我要问问领导。这个就是大部分大家在线上用这个客服售后客服经常会去讨论问题。所以大家一般进去之后，现在都习惯了走起来就先输四个字，人工或者人工客服对吧？默认往那跳，这个输入人工客服，它的这个机器人其实也是跳转到另一个逻辑链条里了。
	好，我们把大语言模型的能力打开，这里有两种方式留给大家做家庭作业。一个是这里可以用命令行参数去启动初始化，还有就这里可以加一个按钮，大家可以稍微读点gradual的按钮，但是加按钮这个场景的开发玩一玩就好了，它不太符合实际的销售场景。因为你不能在这儿有一个按钮是开不开启大约模型，对吧？应该是埋在这边的。那我们把这改成去，然后为了这个聊天记录多一点，我们把这儿打开。
	好，我们刷新一下。这个就比较长了，然后我这个放大之后更大量，那现在我们还是问这个老问题，你们有吗？对。
	看他怎么回答。
	他没查到对吧？没查到任何的答案，但是大模型回答了，对GPT4还是触碰到它的这个边界了。这个为什么会触碰到它的边界？其实得看看这个玩意儿的实现，大家稍微搂一，大家可以看到这个里面的实现，就这个req a我们使用的方法，怎么去实例化它的呢？给大家找一找这个方法。
	这个方法内部我们传了一个大语言模型，传了一个欠对吧？然后这个chain其实就是我们传的那个S就DBS we travel，然后它里面默认使用的这个叫load QA券。还记得我们的课件吗？课件里面有这个，请大家回忆一下。整个这个node QA chain就符合这么样的一个设计。Reviver QA是一种特殊的欠，它里面有一个load QA的chain，这个load QA的chain就是一个from加大语言模型，这个抽象关系，大家把握住了就不难了。
	我们再回到这个代码。在这个load QA圈里面有一个chain type对吧？我们看这个load QA券怎么设计的那到这一层其实就是一个很经典的实现了，就是里面有一些这个loader的mapping，就对应着不同的。大家还记得有千太对吧？它实现了4种，不同的就是这个问答的这个链，内置的问答的这个链有4种，我们默认的用的叫staff，还有map reduced refind map recharge，大家都可以去看一看。
	然后我们退到这一层，那他这里有做一些对应的实现，这我们就不再赘述了。这个chain type就是我们传进来的那个参数。比如说我们用similarity，这个有阈值的similarity，包括这个阈值是0.8，都可以通过这个方式传进来，再逐步透传进去，这些都上节课教过的。然后最终重命名了一下。所以大家会感觉到有点奇怪，就是为什么这个东西的verbs我们设置为true？是因为它这儿最后它重命名成这样的一个名字了，仅此而已，没有什么神奇的。那我们看一看这里我们把它设置为true之后，这里也给它设置为600了，那这个整体就能运行了，那我们可以问一些别的问题，就比如说这个。
	这里就收到了一个新的message，非常便利，距离地铁站只有几分钟的步行距离，非常近大家如果想看看日志的话，也可以把刚刚我教你们的这个地方，不只是说输出这个result，也可以输出这个source documents，这都有有的，我们这就不再赘述了。时间关系。然后这里还有一个点是什么呢？就是大家可以看到这里有个history，the history是radio维护的，the history就是相当于这个聊天记录，我给大家打印一下，大家有个直观感受。当然这些debug什么的手段，咱们都可以自己下来实操一下，应该更有体会。你把这个也输出一下，叫source documents。
	复制一个。
	大家可以看到history是空的，对吧？这个没有聊天记录，还有第一次提问。这个是小区的交通非常便利，距离地铁只有几分钟，非常近。但是大家可以看到，虽然他回答这么简洁，但如果我们不用没有用内置的这个retrial al QA，包括它内置的这个staff的这个change，你就得自己处理这一堆结果。你看这里有当然了距离只有几分钟的距离，而且附近有多条公交线路，非常方便。
	然后巴拉巴拉这里说了一大堆，那这些东西其实都是他查出来的结果，所以他查出来了高于0.8的非常多，如果我们不用大语言模型，刚刚有同学就说为什么还要过一遍大语言模型，这就是它的价值。它可以去做语义的提取，它可以去做文本的摘要，这都是大语言模型的典型使用场景。对他不会很啰嗦，对吧？比如说你问这个再问一个旁边。
	我先不触发另一个想要教大家的知识点，先这样问。
	这个时间其实主要花在GPT大家看到了吗？这个history很有意思，是首先这个history不是南茜的那个history，不是因为南倩那个叫message，对吧？这个是radio帮咱们维护的那这个就可以用来干嘛呢？第一，这个东西可以直接拿来用，这是chat，就是我们的这个radio的chat interface实现的这个功能这history我在这个函数里面没有用，大家可以拿来怎么用呢？第一，这个history我们刚才讲过，就对应着我们这幅图里面的最佳实践的memory的部分。大家如果还有印象，对应的这个memory的部分，这个memory就是首先在history我们是可以存下来的，那它就是一个对话的形式大家再看一看。
	History就是对应的咱们上面的这个对话，然后我们再持续提问，他还会持续有这个history。但是因为我们没有用，所以就会出现他不记得你前面聊过什么。对于这个大语言模型来说，就我们在这儿sell sport去调的时候，他不知道你前面问过什么。所以比较好的方式是什么呢？就是一定要把这个history给用起来。如果我们要做什么房产推荐，要做多轮的对话的时候，但是这个怎么用，就像我刚刚讲的，你需要把它变成memory也可以，变成message也可以，就跟我们讲alt GPT的这个prom的使用一样。
	比如说我们问一个，他可能就会露馅儿。比如说我们旁边有学校吗？也许他就不知道这个旁边是跟房产销售有关的了。但是当然他还是会去查，那刚好这里有这个问答，所以他可以直接去问。应该是我刚刚打了两个回撤，所以第二个回撤就出现了，这个我看看。然后我们再问。
	这个问。
	的更更简洁一点，有这个有个什么呢？有有幼儿园吗？
	这是他之前记录。
	的。
	有幼儿园吗？答案是没有，没查出来。这个就是我们还可以再去优化的点。就是简单来说做了这样一个房产销售的聊天机器人的图形化界面，只用了五十几行的代码，已经非常牛逼了。从好的方面来讲，但是如果要做一个真正商业化的东西，五十多行的代码做出来也不太现实，对吧？所以还有很多可以扩展的点。第一个就是这个history，咱们是可以去做扩展的，要把它用起来。第二个就是这个retrial QA，里面还有很多可以玩味的东西，最重要的就是这个prompt，我们可以再去做一些设计，不用它默认的这个prot。
	好，那么刚好2个小时，这个设计的非常到位这个时间我们总结一下今天的这个实战最终的这个结果是一个带图形化界面的销售聊天机器人。不仅教大家怎么做出这个页面来，当然这五十多行代码里面还有很多是打印日志和一些备注，其实很短这个代码但核心是如果我们没有学前面的这些基础，这些东西都不知道什么意思，对吧？什么叫invading，什么叫Victor store，什么是change，什么是chat model，什么叫recovered，什么是radio？这个概念通过我们课程一步一步的学习，到今天为止应该很多同学都逐步掌握了。并且我们也教了大家这个知识库，不用天天想着怎么去从哪儿捞一点，有数据问题让GPT4来帮你生成不就好了吗？你就可以启动了。
	并且你可以通过这样的方式去做各种各样的销售，聊天机器人都是可以去落地的。那么好，这就是我们的实战这个销售顾问的基于知识库的QA的这个项目。看大家有什么问题我们再回答这个十分钟。
	看大家有什么问题。这个同学问用req a如果某个问题的相似度0.8DB返回三条结果他选择第一条显示，还是一定会去大模型生摘要返回。这个大家推荐大家去看看他的prompt，他prompt写的挺简单的。对你你这个谜底就在谜面上，就刚刚其实我没有说那么透。大家看这个代码实现为什么叫combine documents chain？大家想一想这名字取的对吧？把这个documents连在一起的一个签，为什么这里有一些很有意思的点对，其实就是把这个连在一起，但是不是硬拼，而是把语义连在一起了。所以这个交通便利的这个点大家才能看得到。
	他虽然有多个答案，但是他他做了摘要。对，但是你也可以不做摘要，你可以只选一个，但是这样就失去了向量数据库的意义。本来这个相似度就没那么准的，因为你你切出来，然后你存进去，相似度就是最终在一个合理的区间内取出都跟它相似的，然后针对这个结果去做处理。
	存一本书存到向量数据库里应该怎么存？同学这个我专门讲过的，separator的时候，存一本书，首先一定得切对。怎么切？刚刚花了时间讲这个separator的换行符，正则表达式都可以输。最典型的就画横幅，都是一段一段中间有空格的。
	销售顾问如果要有实用性，是不是要有很多语料或者素材，看你实用性怎么定义了。今天大家想象一下，我这个语料花几分钟，一分钟不到，GPT4就生成了这么多。那如果你真真你都跟我谈真的要使用了，你是不是有预算？假设你有1000块钱的预算，哪怕你100块钱的预算，你就直接让GPT4给你造1000条呗，对不对？然后你是不是就能建一个还不错的知识库了，或者你去往上爬一些。但爬虫现在比较敏感，爬的这个数据如果不对的话，是有比较敏感的问题的对。
	少量数据存入向量数据库中，检索效果还可以。增大数据量的时候就会出现知识混淆的情况。同学定义一下知识混淆。对，就你需要定义一下这个知识混淆。觉得你说这个情况更多的是分割没做好，就是。
	分割没。
	做好对。
	答案存在关系型数据库还是no circle都可以看你看你的这个东西更适合存什么。对，如果你是像关系数据库里面就存我刚刚跟你说的房价通过几个关键参数能查出来的，就跟filter一样，no circle里面存的也是字符串，向量数据库里面存的是字符串的向量是不一样的。No cco不知道你存下来就没怎么用。
	又有同学问这个敏感对话场景，怎么保证安全第一去做备案。生成式人工智能你要对公众开放使用，要去备案。第二用moderation API过滤。
	语料要根据真实的，谁说咱们这个不真实呢？你想一想，对吧？如果你是这个场景，就是销售这个场景，这些话术是可用的。如果你是要特地卖一个东西，那你还不只是说你要了解这个产品本身，还得了解还有多少货，在哪儿发货。这个是就是咱们今天整个讲的东西，是为了教会大家怎么去造数据。然后当然你有你有现成的数据更好，我们肯定不会用一个有法律风险的数据来教大家。
	对吧？
	我们用大元模型先对用户的问题加工，让用户的问题更准确。这里我没有特别看懂，这个同学可以再再解释一下。我大概理解你的想法是说想要提升质量，但是为什么是这个对用户问题，怎么加工呢？是通过大语言模型引导用户提的更好吗？这也许可以实际场景下知识库会不断更新。
	这个怎么处理？不对，同学这个向量数据库是可以往里加数据的，它没有说只能查数据，看看API文档一秒钟就知道了。这些怎么往向量数据库里加数据这个。对API文档好好看一看好吧，我们不可能去遍历所有的API对。
	这个同学问的很好啊，知识有落后的问题，产品功能升级了，我们是不是每一个版本的产品都可以放一个知识库，有没有可能？如果你的知识跟时间高度相关，可不可以每年都建一个向量数据库？大家多想想，用法很灵活，不要被限制死了。整个课程都在教大家mea learning，mean knowledge，这个开课的时候就讲过的概念，大家一定要抓住本质。没看懂哪里让大模型去做了摘要的，回头看看录像，问交通便利的这个例子。然后包括具体是哪一行代码，大模型做了摘要。前面也回答了，去看看南倩的那个retrial. 
	al QA的创。
	这个同学还在问如何过滤内容安全，请看基础篇的这个OpenAI的模型，讲过moderation。
	有的同学还在问这个具体问题答案不一样。聊天窗口问题的什么购房问题准确匹配答案。你这个问题的前提是你的答案足够多，才能准确匹配答案。还有个同学问什么，这个问题太生硬了，这个问题就写这条逻辑就是为了体现生硬。这个同学就是没听讲吗？这个else留在这儿就是为了体现生意，就是用来对比。如果没有大语言模型的时候，很容易被识别出来是机器人。然后正常这个路径就是让大语言模型来回答，你的理解是对的，这个地方就是为了体现出很生硬。
	好，我们今天这个时间也比较晚了，快11点了，十分钟的时间也很快就回答了一些问题。大家如果还有问题，就群里面再来提问，好吧？包括关于这个题目当中的各种问题都可以再问好，那么今天就先这样。