	我们就开始咱们整个AI大模型应用实战营的第二个课程，大模型理论基础。今天我们可能主要分为两部分，3个小时的时间。我们希望能通过今天这3个小时的时间跟大家一起去学习和分享。就是我们的GPT最流行的这个模型，它的架构发展是怎么一步一步到GPT4的。然后同时还有一个很重要的部分，相信也是很多人都关心的，就是我们的这个prompt，可以称之为现在这个大模型时代的一个黑魔法。那这个prompt又是怎么一回事儿？他又是怎么样一步一步的从最开始一个名不见经传的，大家都在很野蛮的在去使用prompt，到后来大家发现这个东西它也有一些学术上的一些人在研究，并且它也是一个解读和打开大模型黑盒子的一个手段。主要这两部分，至于之前我们可能在那个课表里面还有一个关于OPEAI的未来发展，包括南券，我们会在后续的章节里面再融入进去，今天我们会把整个大模型和prom pad放在一起。
	对ok首先还是回应一下我们同学的热点问题，我们在几个学员群里面有看到大家都在提问，这里我选了一些热点问题来回答。第一个就是说我们的课程当中是不是必须要使用GPU？实际上在课程里面除了最后生态篇，我们会有这个私有化的大模型去部署以外。其实我们的OpenAI的API的开发以及我们的南线的开发，其实都不需要使用GPU。因为它更多的是通过我们的框架也好，APA也好，去调用GPT或者说类似的这种大模型的服务。所以是这样的一个结论，不是必须要使用GPU，只有最后的那一部分我们需要使用。
	然后第二点就是说我们的GPU资源如果我们要用的话，怎么样获取比较方便。目前在国内有一些公有云的服务商，比如说华为、阿里、腾讯。如果大家是学生的话，通常还会有一些折扣可以去申请。那这个GPU的这种服务器价格也不会很贵。大家如果是按需使用的话，可能每一次的开启也就是在小几十元这样的一个规模可以使用几天。对，然后还有一些消费级的显卡。比如说我们之前有一些同学买了这个2080、3080等等这样的一些显卡，其实也是可以去直接使用的。然后还有一些像这个，如果大家能够去访问像google collab，它其实是可以提供免费的GPU或者GPU的资源。
	第三个就是今天有同学在这个提议，就是我们的回看的视频能不能添加字幕？这个已经安排了我们的班主任和助教，还有浩哥他们都已经把这个字幕应该在今天这个视频之后就会有字幕了。对。
	然后第四个问题就是说有很多同学担心学不学得懂的问题，尤其是之前没有深度学习和算法的基础，能不能听得懂？其实是这样，首先答案是肯定的，就是可以。然后第二个就是说学这个大模型的开发。其实我们一开始讲理论的章节，更多的是为了提升大家的上限，也是为了在后续的动手实践的环节里有很多的概念，我们提前把它梳理清楚。然后到后面的这个就下一周开始，我们其实就会有这个embedding相关的一些内容，就可以开始动手实践了。通过理论章节，是为了提升大家的一个上限，因为大家的这个背景可能不太一样，然后之前的工作经历也不太一样。那通过理论章节，每个人能吸收到的养分也不同，它不影响后续的学习。但是他会为大家未来去不断的学习这个大模型，是一个很好的一个提升上限的一个环节。
	然后最后一个就是说课程中讲到的一些相关的论文去哪里找？应该是在即刻时间的那个APP，就大家回看视频的那个AP上面是有的。然后我今天的这个课件里面也增加了这个推荐阅读，我们具体有哪几篇论文是很重要大家应该去读的，然后我们把它放在这里。好，这个热点问题我们用五分钟的时间回应大家。
	接着接下来我们就开始正式的这个课程，GPT的模型家族。首先GPT是一个目前最火热的大模型，它其实是一个从18年开始就有的这个大模型系列了。我们这里放的这张图片是一个什么概念呢？我其实在上一次我们有讲这个archive上面的论文已经突破了两三百万篇了。所以archive本身是一个非常好去呈现目前各个领域研究热点的一个论文发布网站。从这个论文发布网站里面能够看到有两个词的关键词的表达，就是有很多论文是否是以这个研究领域的，其中一个叫做语言模型，一个叫做大语言模型。
	我们现在大家都在讲大语言模型大模型。其实在CHAGPT火之前，其实语言模型是NLP这个领域里面更习惯性被大家聊到的一个词。我们待会儿会去讲这个大到底是多大规模较大。Ok那么从这个研究方向来看，其实语言模型是从18年开始一直都持续的在有人去做研究的，只不过我们看到右边这个大语言模型，它的上升曲线更加明显。他的一个研究热点也是从我们的这个OpenAI发布instruct GPT到CHAGPT开始，有一大堆的人都开始研究我们的这个大语言模型了。
	不好意思，我这里有一个是数字。我们具体来看一下这个语言模型是怎么发展的那语言模型其实是一脉相承的，就从上个世纪50年代开始，其实就已经有人在研究语言模型了。只不过大家的研究手段有一个发展过程。
	其实从1950年代到上个世纪90年代，这将近40年的时间，其实我们的很多的人工智能的学者以及计算机科学家都在研究怎么样把我们人的语言表达和我们人的阅读的能力，包括翻译的能力，用计算机去进行解读。那个时候更多的是什么手段呢？那个时候还没有这种learning，就我们现在都听到一个词叫machine learning，deep learning, 包括现在的这个还有各种learning prompt learning。那会儿其实还不会用学习的手段，所以更多的是一些人工规则。可以简单理解成就是我们的很多的专家就基于我们之前的知识，去一条一条的手写这个规则。这个规则会被我们的一个计算机的系统给拿去做执行，就有点类似于今天我教你要做这个，苹果是apple，然后男孩是boy，我就记下来了。记下来之后他就按这个去执行，是非常死板的。
	到了第二个阶段，我们就要统计机器学习阶段。就从差不多1990年代到20一二年左右。这个时间节点也很巧妙，我们其实之前有讲到13年14年的时候，有bengel NNLM，有world to vt这样的大量成果出现了。但是在那之前和人工规则之间，其实是有大量的统机器学习的算法，包括我们的这个标注数据在产生的。包括我自己最早期第一次创业的时候，做这个NLP给人看病，做这个辅助诊疗。所以当时就用了类似于这个CRF，这里有一个拼写错误，应该是CRF条件随机场包括我们的这个混合高斯，然后我们的支持向量机都是在这个阶段去在百万级的标注数据上面去做学习的。只不过那个时候没有用神经网络去学习，而是更多的是学习它的统计分布。
	这里已经有一个进步了，我们从人一条一条的手写规则变成了我们开始去学习它的统计分布了。只不过那个时候的这个学习方式还没有引入embedding这样的一些方法。到了13年到18年这个阶段，其实深度学习开始火热了。那个时候大家听到的都是关于计算机视觉的多学习，包括我们之前有提到image net这样的一些数据集。然后我们的从alex net到inception night，到这个VGG resign t，到后面我们发现在这个识别问题上，就是识别是猫还是狗这样的识别问题上，机器已经做的比人好的。
	在深度学习里面。但是在同样的这段时间里面，我们的自然语言处理也在发展。那它的发展，在我们上一节课里面有讲到我们的encoder decoder这样的网络结构，包括我们的world to react这样的一些embedding的方法。我们的注意力机制attention，其实都是在这个阶段开始产生的那这个阶段使我们可以用embedding的方法把单个词或者说一个短语用我们可以叫词嵌入，就是中文叫词嵌入的方法，把这一堆的语言，比如说我们同样都是中文，同都是英文，那同样的词可以用同样的一个高维向量空间来表达。这个就是一个早期的深度学习阶段我们能做的事情。然后差不多它的数据规模是在10亿级的这样的一个标注数据。
	而同期因为我们的神经网络的框架也在发展，比如说同期的TECFFF还有touch的出现，使得我们的有有算法to t attention，encoder，decoder这样的序列到序列的方法。要有框架tensor ffo pt ork，那我们就可以开始去做很多的语言模型，就是我们刚刚看到的这个语言模。是在深度学习阶段就已经有很多人在做了。
	那么到预训练的语言模型，其实有一些重要的变化。第一个变化就是说我们以前的这个数据标到10亿这个规模就很难再往上走了。因为标注数据是一个相对来说成本还是比较高的事情。
	那么到深度学习和预训练语言模型之间的一个卡点就在于数据实在标不动了。因为这个世界上的数据太多了，而且种类是很难穷举的那以前我们看这个image net，它其实标的这个万就世界上万物的种类，也就是千这个级别。只不过可能同样一个猫，它会有上千张照片而已。但是作为一个语言来说，它的组排列组合是很难想象的一个没有上限的一的内容。我尤其是中华文化对吧？我们这个几千个字能表达很多无数的内容，那这个时候你是标不完的那怎么办？这个时候我们就发现，其实有一个在机器学习领域就一直有的词叫做无监督，或者说要利用未标注的数据去学学习无监督的方法。
	那怎么样把无监督的方法引入到我们的语言模型里面呢？这个其实就是在18年，就是从GPT1开始，我们待会儿会去讲，逐步我们发现我们可以用未接未标注的这种数据，用这种无监督的方法，或者叫自监督学习的方法去把我们的数据用起来。然后它的这个技术栈的范式，其实就是一个print training加fine tony这样的一个范式。Ok然后到后面其实大家会发现，我们又把这个预训练的语言模型和大语言模型再做了一个区分。这也是GPT3包括GPT3.5。
	GPT3.5之后的一个巨大的变化，就是我们可以用更大规模的用户数据。这个用户数据是可能比较复杂的。逻辑推理，它甚至还有问答，有各种各样的形式。然后这些形式它的训练手段有了一个不同，就它不再是使用一个print training加fine tuning e的方法。因为fine tuning有一个比较大的变化时，它会去调整模型。
	但是当你的模型变到非常大的时候，比如说我们的大语言模型，我们的1750亿参数对吧？然后我们的这个GPT4可能是上万亿参数，因为它有多个两千多亿参数的模型ensample在一起的那它有这么多参数怎么样再去fine tuning？你很难去对模型进行精调了。因为fine tuning这个词的含义就是精调。我们在微调这个模型，但是这么多参数你怎么微调呢？你调不动，那这个时候可能更多的是说能不能不去调整模型，就是模型的参数不变。但是我通过一些prompt的手段去更改我们的模型输出结果。
	这个时候就是大语言模型和预训练语言模型在训练范式也好，在技术站上面的一个区别。我们把NLP的语言模型的整个技术发展可以画成这五个大的阶段。今天我们会重点去学习一下预训练和大语言模型这两个阶段，我们到底技术上有一个怎么样的变化。然后又是怎么样逐渐的我们能做到越来越强的语言理解能力。
	Ok其实为什么这个GPT1到GPT3取了一个词叫风云变幻？因为其实我们把时间拨回到18年到2020年这三年来看的话，整个语言模型的这个领域里面，其实GPT不是主角。那个年代GPT是属于一个默默无闻的小弟，然后一步一步耕耘。包括GPT3在2020年发布之后，也没有引起非常大的轰动，它比较大的影响还是CHAGPT出现之后，才让所有的人耳目一新。发现其实OpenAI做的这个CHAGPT是很不错的。
	Ok我们首先看一看这个预训练的语言模型，它有一个什么样的不同。就整个预训练的语言模型，其实它可以遵循这样的一个pipeline或者架构。首先我们用大量的未标注的数据去做自监督学习。然后把这个学出来的语言模型针对一些特定的任务，就它有一些下游的任务，各种各样的任务。比如说我用QA问答机器翻译总结之类的特定任务。在这种特定的任务上面再去对模型进行微调，然后得到一个最终的模型。
	这个事儿就很像是我本来做了一份主菜是牛排，然后这份牛排要给不同的客人吃。这个客人可能是想说我要牛排配土豆，那个客人是说我要牛排配这个意大利面。然后那个人说我的意大利面不要那种细条细长条的，往那种螺旋的意大利面等等，举一个不恰当的例子，你可以这么理解，就是大的那块牛排就是我们的这个预训练的语言模型，它已经不会怎么变了。然后一些特定领域的任务，就下游的这些任务可能会去做微调，或者说你要加不同的酱，这些都是可以的那这些都是在一些小，就是跟我们大的这个语料比起来是一些比较小的测试集上面，一些特定任务的测试集上面去做这个模型的微调。这个时候我们的模型还是会做调整的，所以我们的整个这盘菜端出去还是会有变化的，跟我们之后的大约模型不同。
	在预训练语言模型里面，有3种比较典型的网络架构，我们在之前的transformer，我们上一节课里面也有讲到，可能我们上一节讲到了这个transformer，讲到了bird。那bert是一个比较典型的，偏重于编码器阶段的一种典型的预训练的这种编码器。那它有什么样的特点呢？
	首先我们在学这个transformer的模型架构的时候，我们知道就是一个encoder加decoder的架构。然后它的encoder的部分，其实是一个处理输入里面所有信息的一个网络结构。然后它的decoder部分，其实是做了一个掩码。大家回想一下那个transformers架构的话，它内部展开应该是一个mask marketing head，就是我只看得到前面部分的这个内容的一个多头的一个注意力机制。然后再接了一个encode decode the attention，最后接了一个前馈网络。Feed forward neural network. 
	这个是一个典型的transformer的架构。在我们的预训练语言模型其实都是基于transformer的，这个大家应该都知道了，它也会有这个不同的侧重。所以从这个角度来看，编码器天然是能看到所有的输入信息的那对于编码以编码器为主的这一类模型架构，它因为可以得到所有的上下文，所以它比较适合处理什么样的内容呢？它比较适合处理文本分类，包括命名实体识别这样的一些比较好的内容。所以当时其实bert的这个生态也好，或者说基于bert这样能看到全部内容，而不是像未来GPT基于这个解码器为主的这种模型，会更受到大家的关注。因为换句话说，他理解能力更强，他对下游的任务更有帮助，他好像学到了更多，大家可以简单这么理解。
	像GPT1这样的一个典型的预训练，我们叫预训练解码器，我们先给它安一个这样的名字，因为它可能以解码器为主。解码器大家知道，因为它一开始是有一个掩码，用mask的这个markey head，其实他是看不到后面的内容的。所以他在训练他的过程当中，其他的训练方法就使得他更多的是偏向于去生成信息。但因为他无法看到完整的信息，也无法双向的看到信息，所以他的理解能力相对来说要弱一点。他们就比较适合各种生成类的人物，所以比较适合什么呢？适合文本生成QA这样的对话系统。
	但是其实还有一类当时叫又用解码器，又用编码器的这个架构，它的典型就是像T5和but这样的一些语言模型。它其实是当时也是非常重要的一个分支，包括现在有一些学者在沿着这条思路去做研究，这里我们就不再展开了。所以大体来看，其实我们的预训练的这个语言模型可以分成三条路。三条路分别是不同的研究结果。比如说我们的bird偏重于这个编码器的那它还有后续的研究。比如说这个Robert a这个Albert是偏轻量化的一个bert。我们的这个decoder，就解码器，像GPT就是它的典型代表。从它的第一代、第二、二代、第三代，然后我们刚刚提到的既有这个编码又有解码的这个典型的架构就是T5 part。这些编解码的这一块我们就展示到这儿。大家如果有兴趣可以自己再去深入去看这方面的论文。
	整体来看，我们的预训练语言模型就是这三个大的架构。Ok我们刚刚提到了2018年到2020年是预训练语言模型的主要发展阶段。2018年作为这个开启之年，发生了很重要的三件事情。就是这三个大的模型，也比较大的模型，三个模型被发布出来了。第一个模型是AI2，这个公司和我印象当中和华盛顿大学一起发布了一个模型叫ELMO，是在18年的春天发布的。然后在18年的夏天就发布了这个GPTE OpenAI。然后在这个十月份的时候，谷歌又发布了这个bert。
	我们上一节课其实已经讲过，bert是一个就跟我们右下角这里很像的，bert是一个。什么样的网络呢？它非常好，它主要以编码器为主。然后它的这个内容是可以做双向的训练的。我既做了从左到右的，又做了从右到左的，并且我是同时训练的。所以它有一个很很有趣的描述，就叫world can see themselves。
	就是我我们上一节课结束之后，也有做一个简单的分享。就是一句话来说，它是既能向右看齐又能向左看齐的。它这个序列当中的每一个词，其实都在同时能看到它的上下文。但是其实在bert之前，我们按照这个时间往回倒的话，他之前发布的这两个模型分别是ERMO和GPT one。其实它都是一个单向的一个序列，即使他们在学习这个语言的过程当中，他也是单向的。他并没有学那个往回没看这么一个操作。那那你就能看到其实就跟左边这幅图一样的，其实他学的是一个单向的序列，即使它是有多层的，那我们具体来看一下ELMO是一个什么样的模型，为什么它很重要？因为它的思路其实很有意思，它跟这个bert其实就差一步。
	可以简单来说，就18年春天发布的这个模型，它其实首先它是基于这个长短期基于网络的，就是我们的LSTM。大家能看到这个图当中每一个雷尔其实是用的这个LSTM。这是一个RNN的改进版，就是我们循环神经网络的一个改进版。它能使得我们去记住更长的这个上下文，然后怎么样去记住，有很多的方法，包括我们上节课讲到的attention，就是一个去更加关注与长句子里面哪句话对我更重要的这么一个手段，注意力机制。
	然后在这个过程当中，他其实是训练了一个什么东西呢？他同时训练了一个从左到右，又训练了一个从右到左的曲线入的一个向量。他但是他没有像bert一样是直接训练的，他是分开训练的。训练之后他把这两个向量就是你你可以理解成你有一个A网络，有一个B网络，然后他同时在训练两个方向，然后把这两个学到的这个向量直接拼在一起，拼在一起之后，变成了一个预训练的一个embedding，使用了这样一个单向模型，但是是两个方向拼在一起的单向模型做成。那这样的一个网络，是不是感觉就临门一脚跟bird就差一步，其实是这么样的一个训练方式。这样的一个训练方式，确实它的embedding效果更好了。
	大家理解embedding这个概念，下节课我们会重点讲这个词。我们现在尽可能把各个概念让大家每一节课有重点。Embedding的一个重要的功就是如何把一个我们现实生活当中的物体，让让我们的计算机能非常清楚简单明了的理解。就embedding就干这么一个事儿。就是我们人很多学习一些抽象概念的之后，我们人好像也会有一些通过图像、视频，包括关联关系去理解。那计算机怎么样理解呢？计算机理解其实都是这些向量，embedding就是去造这个向量，并且以一个统一的模型去表达这个向量。其实就是把人脑中怎么学这些抽象概念的过程，给他计算机的方式去学出来。这些模型其实都是在干这个事，所以大家都在把这个东西在学术界叫做表示学习。就是怎么把自然界的东西表示成一个计算机能理解的内容。
	Embedding是一个具体一个抽象的概念，我们也学过一些具体的方法。比如说这个world to vector，我们的global vector。这个EMO其实也是一种方式，让让我们的这个计算机去理解这个自然语言。然后他用了这么一个手段，两头都学学完之后拼起来，拼起来之后给到计算机。那计算机去用的时候，就是你自选可以看左边这一侧，它是左边这一部分它是一个正向的。你也可以看右边拼接的这一部分，就我们蓝色的这一部分，它是一个反向的。然后计算机在用的时候，他也就知道这是两个方向，但是跟bert差一点对吧？
	那我们的GPT是怎么样干的呢？他其实也在干一件事情，大家可以看GPT1这篇文章，其实并没有提GPT这个概念。这篇文章的完整的标题其实叫做improving language understanding，就我要提升语言的理解能力。因为那会儿其实大家都在搞这个预训练加这个下游微调的一个架构。预训练很重要，因为他要让大家都学会这个语言本身，那么它要提升这个语言的理解能力，所以他就要improving这个language understanding。用什么样的一个方式来提升呢？用一个generative的一个pretrail ing的方式，就一个比较泛化的通用的一种预训练的方法来提升。
	大家可以看到其实这幅图是它的一个架构，一个典型的一个GPT one的一个架构。大家如果还有印象的话，我们讲这个论文attention is all you need to。Transformer这篇论文的时候，transformer是一个encoder decoder架构，然后各自是六层。那GPT one把它搞到了12层，然后是一个transformer的一个语言模型的架构。然后下游再去调不同的具体的类型的任务。但它也只是一个单向的自注意力机制，把这个层数加深了，我们具体来看一下它是怎么样的。
	首先这幅图是论文当中的一幅原图，就我们的这个GPT one这篇论文的一个原图，去讲解了我们GPT one的这个模型的一个网络架构。大家如果看得到的话，其实我们这边边左边这部分是我们的预训练的一个语言模型。就我们的BT1这个架构跟我们之前看到的transformer架构比起来，大家可以看到这里有一个mask的这个martis self attention。这就是一个典型的transformer decoder的输入这一侧的一个内容。然后接了一个layer loan，大家可以理解就是做一些规范化、政治化的一些层，然后再接着接这个全会网络，他没有去接这个encoder decoder的multi head的attention，其实中间是看不到后面内容的。
	就我们标准的这个transformer，其实接了这个masks，这个muti self attention是会再去接一个marti self attention。那这个multi self attention是来自于encode和它自身，所以这里会有一个略微的不同，是它跟这个原始的transformer的一个区别。然后他把这个层加到了这个12层，然后同样输入是有这个文本和位置的这个编码，这个向量，最终会输出到什么地方呢？输出到我们下游的任务里面。所以我们下游的任务会接各种各样的fine tuning的任务。比如说我们的文本的预测任务的分类器，巴拉巴拉就这些东西其实是更下游的人物了。
	整体来看，其实整个预训练语言模型几乎都是这样的一个架构。就前面我们通过无监督的手段，自监督学习的方法，去学出一个不用大量标注数据就能学出来的一个语言模型。这个语言模型核心就是学会这个语言是什么意思。然后接着我们再会在特定的任务上去微调我们的fine tuning。然后这个时候就是根据特定任务再去调整。所以我们能看到这里会有不同类型的下游任务，他们会去接这个具体的测试集，然后再去微调我们的这个模型，使得它能够在下游任务上面的性能有所提升。这个方法有用吗？实际来看，在18年的时候，这个方法是有一定效果的，GPT当时在各种自然语言推理的数据集上取得了比较好的效果。
	大家能看到在论文里面，其实它都没有叫GPT，这个是来自于OpenAI的论文，它叫fine tuned transformer LM。这就是我们现在看到的最下面这一行，他也很直白，就是他他没有什么，他没有说我做了大量的创新。他的创新就是把transformer的decoder的部分拿出来，然后把这个层数从6层加到12层。然后忽略了编码器的输入，就把我们的中间那一层的attention干掉。然后同时在这个基础上再对下游的任务，不同的下游任务去做这个find you，然后获得了比较好的效果。就比如说之前的这个可能在这个MNLIM这么一个测试集上，最好的结果是80.6，它增加了1.5个点。然后类似的这个都有一些增加，但是没有显著的增加。像这个QNLI它有一些增长，但是在RTE这个任务上，它还仍然不是最好。
	在RTE这个任务上，其实是一个multitask by LSTM加attention这么一个网络结构是更好。大家知道这个by LSTM其实上次有讲过，LSTM是一个RNN的进化版本，by LSTM就是双向的LSTM。然后再加attention这样一个也是很直接的一个思路。就我们为什么要讲理论部分？
	通过上一节课，我相信大家已经逐渐能理解。其实翻来覆去在这十年的进展里面，我们的预训练语言模型、大预言模型都是在这几个大的概念里面去玩。RNN到LSTM，单向的到双向的，双向是先分开学，拼在一起的一个向量到同时学，然后我们的encoder decoder，我们可以只用encoder，只用decoder，那也可以一起用。在用的里面，其实这个decoder我们还可以把这个encoder拿掉，就变成了自己的GPT。所以其实概念的总数不多，但它就是在里面排列组合着玩儿，对吧？
	刚刚看到的这几个测试结果，其实我这边补了一个基准测试的介绍，大家可以也在下来之后再去详细看一看。这里其实主要都是一些自然语言推理的任务。然后其中包括了有的是说我是口语小说的文本，有的是去测试泛化能力的，还有一些是用来判断这个语义的。比如说我这个两句话之间是蕴含的关系，是矛盾的关系还是无关的关系。在GPTE的这个训练里面，就是这个SNLI斯坦福的自然语言推理的这个数据集，在GPTE的训练里面也有去做类似的标注。然后像这个QALI也是去做这个语义理解的这个内容。
	其实整个我们会发现，在18年的时候，我们对于语义理解还是比较粗糙的。就是因为那个时候大语言模型没出现。大家不知道原来语言模型可以提升到一个更高的维度上去的时候，大家大部分的这个基准测试我们都能看到，更多的还是测我的几句话之间的一个关系到底是什么样的。这个关系主要就是这三类，就我是一个蕴含的关系，我表达的是一个矛盾的关系，或者我是无关的关系。他就有点类似于像我们在做计算机视觉当中，把很多问题变成了一个分类问题。我们在语言这个层面上，自然语言推理上也大体分成了这三类问题。
	那那是18年的一个状态，我们总结一下看这个GPT1，其实它有一些比较大的成就。第一个就是说它是一个在预训练解码器这个方面一个非常大的一个成功，也是这条分支上最重要的一个开始。就我们看这个预训练语言模型三条线对吧？Encode decode和encode decode。
	然后在decoder这一条线，GPTE是有开创性的价值的。然后它使用了一个12层深度的一个decoder，用了将近1亿2000万的一个模型参数量。然后一个768位的一个隐藏层和一个三千多维的一个前馈网络，然后在字节字节对这个层面上做了大量的encoding到了4万条，并且他训练的这个语调数，也有一个在当时看来比较大的一个规模，就有七千本独立的书，然后也包含了一些长长链接的词语。所以这里其实是在18年的时候，GBT1在decoder这个预训练源模型上的一个里程碑的一个事件。只不过它的效果可能没有像我们最近看这个2022年到二三年这个CHIGPT这么夸张，但是是迈出了一个坚实的一个基础。
	那么到了2019年的时候，GBPT two就我们的第二代的GPT带来了一个什么样的成果呢？其实一直有一个声音，就是叫做GPT模型。其实没有太多技术上的创新，它就是一个死命叠加transformer，然后去以力破巧的一个产物。
	从GPT1到GPT2这句话是ok的。因为GPT2其实本质上并没有跟GPT有什么大的区别，他只是把这个参数变得更多了，然后训练集变得更大了，这个是ok的。并且它增加了一些之前都是在书上面去训练。现在在这个reddit，在这个在线的一个社区网站，大家可以认为这个支几乎就是模仿的海外的redis，在这样的一个网站上去学了更多内容，然后获得了一个相对来说更好的一个表现。
	大家能看到我们的17M这个其实是我们GPT1的这个参数规模。然后我们的这个GPT2其实是直接就干到了它的十倍的这个规模，十倍多的规模。然后它的表现确实也变得更好了，这个是一个从数据层面上看到的就是GPT2跟GPT1的差距。但是其实它也有一些在刚刚说的以利破晓之外的一些贡献。就是整个这篇文章就是我们的GPT2这篇文章。
	大家如果看右下角的话，它提出了一个叫做language model，是一个无监督的多任务的学习。提出了这么一个概念，就是无监督多任务学习的这这么一个概念。这个概念其实跟我们GBT1比起来是更进一步。
	因为GBT1是说我核心是一个语言模型，我要提升这个语言模型的理简历，然后我这个语言模型做好了，我这个主菜做好，然后我下游可以接各种各样的任务。但是GPT2希望把这两件事儿合成一件事儿，就是我直接就去为了下游的多种任务，我搞一个语言模型，它天然就能为下游的多任务去服务。这个就已经有1点GPT3的影子出现了，我把这两件事合二为一了。大家知道后面的模型就是我都不用去调整模型了，我可以直接就干很多事情。GPTR其实是为后面这个prompt learning埋下了一点影子，他在提这个概念就是一个书，unsurprised的mark task learning。
	然后在19年的时候，大家看右下角，这是清华的这个NLP实验室当时做的一幅图这幅图里面其实表达了当年的就2020年左右的时候，在整个这个semi super se，大家可以理解这个半监督领域的这个序列学习里面，我们的这些预训练，那会儿还不叫这个pre train的LM还没有那么火，都叫这个pre train的sequence to sequence。就是我们的encode decode这种架构，序列到序列的架构，这种预训练的语言模型的生态，中心其实是我们的这个bert对吧？然后我们的这个ELMO这个AI two公司和华盛顿大学一起做的这个语言模型在这里。然后GPT其实是这条线，这幅图其实跟我们看这个开始横过来的那个是一样的。然后这幅图里面还比较有意思的一点是，包括现在也还有人去做，就是我们能不能把语言模型和知识图谱去做结合，然后包括跟这个视频去做结合。
	然后大家看到这里有一条线远远的指过来有T5，这个就是同时有encoder decoder的这个架，包括这个switch transformer后面的。然后这个GPT其实是在右边这条线。GBT它是一个pre train的LM它是一个预训练的语言模型。然后分支过来之后，GPT1、GPT2非常直接。大家给的评论学术圈就是更大的模型，更多的数据。
	确实然后到了GPT3，其实大家给了一个larger，是因为GPT3其实大家知道的话1750亿的参数，对吧？比起GPT2又大了两个数量级。第一代和第二代之间是十倍的关系，第三代跟第二代是100倍的关系。大家当时都感觉这个OpenAI有点叫什么江南才尽了，不知道怎么样去搞大模型，就只能堆出数据对模型规模。对这个参数规模，实际上这么多其实是为未来的我们所谓的涌现能力。就是我们好像大模型突然就一下就学会了，就通了，就悟到了一样，包括我们资源后面也有这个悟道模型，就为这个事儿是打下了一定基础的，至于他是一个有意而为之，还是说碰巧就历史的机遇选择了OAI呢？这个事情我们不做评价。
	我们具体来看一下，GPT3比起我们的这个GPT2又大了两个数量级的规模。首先从数据从训练数据上来说，它就有了不一样的变化，我们知道这个GPT1是在书上面去学的对吧？就我们这里的books one，就这里的这一条线books one，所以这是GPT1的一个训练语料。然后我们的GPT2其实加入了一些reddit这些在线的社区的QA问答。
	GPT3引入了一个很重要的数据集，就这个common crew，就我们的这个网络爬虫的数据集。这个数据集其实已经有八年的一个建设历史了。大家简单理解就是我们有一个机构，然后他一直在网上去做爬虫，然后爬了八年的时间收集了大量的数据。那这个数据有多大呢？4100亿的这个tokens，这个pair，是还是过滤之后的那这个其实是非常夸张的一个规模。然后同时还加入了一些互联网的数据，包括我们的维基百科的数据。整个数据其实构成了我们GPT3的训练语料。
	在2020年的这个时候发布的这个GPT3模型，并且其实左下角我大概有列出一个我们的最大的，就在他训练语料里面占60%比例的这个common co这个网络爬虫的数据集的一个格式，或者说它的这个数据的分层格式。大家回头可以再去检索了解，分成这个meta data，including the data和这个excluded data，大概分了层。它的数据规模其实非常大的那在这个过程当中，我们就知道GPT3比起这个GPT2，是不是就真的像外界的评价一样，我就是没有什么思路和技巧，我就是怼数据怼模型这么简单呢？其实不是，其实可以简单来说就不是。我们现在再回过头来看，它是有一些什么样的思考，我们可以一起学习和探索。
	第一个就是说首先到了2020年这个节点的时候，我们预训练语言模型也搞了两三年了，对吧？大家都知道可以怼transformer，可以怼深度、怼数据，怼这个模型参数。但是我们我们跟预训练语言模型进行交互，就是我们怎么样去用这个预训练语言模型？其实就只有两个手段。第一个手段是从他们的定义的分布当中去进行采样。这个就有点类似于我们现在提供一个prompt，这是一种手段。第二种就是我们去微调，就是去改这个模型，然后这个时候微调完之后，再去用他们的这个生成的结果，或者叫这个prediction。因为大部分是生成结果，就这两种方式。
	但是GPT3当时想要探索的一个能力，就是说有没有可能我们不去再用梯度下降这样的方式去修改模型。就学过深度学习的同学应该知道这个深度学习的训练方式就是一个循环，对吧？我们正向在做inference，在做推理，然后得到了一个预测值，这个预测值和我们的这个标注数据去做一个比对，比对之后相当于这个度量函数，这个loss function会告诉你差多少。那差多少之后，通过这个反馈网络这个background的这个propagation反向的过程，然后去做这个模型参数的修改。那这个过程其实要怎么样去知道我应该怎么改呢？就需要用到梯度下降。但是这种超级大规模，我们已经到1751个参数了，对吧？
	怎么样去做梯度下降，做一次的成本有多高？这个其实是非常大的一个成本。所以当时在那个节点上，我可能也就在想，有没有一种可能就是我不要去做梯度下降，然后我还能够去让我的模型的输出达到我想要的效果。这个是一个动机和思考。这个动机和思考也直接变成了后来的一个很重要的词，也是我们这里显示的这个income text learning，就是基于上下文的学习。
	那基于上下文的学习具体是怎么样的？其实我们简单来举个例子就能看到，就是当我们现在可能很多人用过其他GPT，已经实际试验过了。这里其实是一个机器翻译的例子。假设我们的输入，我们给到这个预训练语言模型的输入是长这样的，就告诉他有这个英语到法语的一个翻译。然后前面三个其实是有样学样，就跟我们讲这个鹦鹉学舌一样，对吧？就是thanks对应的这个法语我不会读，那这个hello帮助。
	这个mint最后你给他留了一个，因为它是一个decoder对吧？大家都知道decoder为了下面的这个生成任务，这里你留了一个让他填空的内容，那它其实会自动的把它这个法语的对应单词给生成出来。这个是一个很有意思的现象。并且这个现象也直接导致我们后面的GPT3.5和ChatGPT其实都在沿着这个思路去做。这里其实就是通过一个叫做income text的example。就是我在上下文当中给你提供一些样例，通过这个方式去指定你要做什么样的任务。
	大家还记得之前在GPT1的时候，我是训练一个模型，然后我要做什么任务？我要去做模型的微调，我是要去改这个模型的。然后到了这个GPT2的时候，他是希望做一个unsupervised的multitask learner。就是我把这个下游的多种任务一开始就都学会了，然后我就后面就不用怎么改了。到了这个GT3的时候，他就在说我都花了这么大的成本去训练一个这么大的模型了，比之前还要大100倍的模型了。我难道针对于每一个特定任务都还要再去调模型行吗？那那我能不能不调？这个思路就来自于这里，我给他一些例子，因为他都已经学了这么多了，理论上他应该啥都会了，我就只是说要说清楚我想让你干什么。
	这个时候跟模型的交互就逐渐通过这种in context example或者说in context learning的方法跟模型去做交互了。这里就是一个很重要的词，大家在之前的这个学习里面应该都听过一个词叫make a learning，对吧？就是我们的语言学习，其实在这个GPT3的论文里面，它的第一幅图这个图1.1就提到了一个很重要的概念，叫语言模型的原型。
	语言学习就在上下文当中学习，就是指像GBD3这种千亿级别参数的大语言模型的一种能力。就是说我们不再需要去通过这个SGD就是这个梯度下降的方式，去改变微调这个大模型。而是尽可能说能不能不改变模型参数的情况下，给他一些上下文的信息，让他去学会我们要做什么事情。刚刚说的这个英法翻译就是一个典型的例子。然后如果我们不用英法翻译，我们用一个比如说中英翻译或者中法翻译给他做一些上下文的提示的例子。他也能够学会我们是要干什么事情。
	这个是GPT3带来的一个巨大的一个变化。通过这幅图，其实我们能看到，就是通过使用上下文的信息这种大语言模型，我们这儿已经开始出现大语言模型了。这种大语言模型是能够明显有效果的提升的。这里这里是1.3B和13B一直到175B大家能看到100倍的模型参数的规模，在准确率上有巨大的变化。
	然后我们使用的这里有三个概念，待会我们会讲叫做zero shot，one shot和这个fuel shot。这个具体是指什么呢？就是指我们刚刚说要给他例子，对吧？英法翻译给了三个例子，三个单词，然后你学会了，我是要做英法的翻译。那有没有可能只给你一个例子，就我只给了一个单词，你能不能学会我是要干这个事儿，甚至说我不给你。这个示例叫zero shoot，那这个取得的这个效果是不一样的。然后同时我们使用这个自然语言的这个prom pact和不给他这个prompt得到的结果也是不一样的。
	我们具体来看一下刚刚说的这个三个shop learning是什么意思。首先看右边这个例子，右边就是在没有在GPT3上使用的，就是更早以前的例子，就我们这个传统的fine tuning这个传统手艺。就是说我们要训练一个模型，要用梯度下降来做这个模型参数的迭代。它是根据我们的一个一个的带标注的数据去迭代我们的模型。所以它就会有一个gradient update会去迭代我们的模型，然后再不断的去学会我们要做什么样的任务。在GPT3开始之后，其实我们就不再需要去更新这个模型本身了，而是让模型理解你想让我干嘛。这里就分成三部分。
	首先我们看这个few shot。Few shot通常是说我给你几个示例，跟刚刚一样，我的任务描述，这个是我们后续发现，就我们给了人类自然语言的prompt。之前我们给的那个例子是没有人类自然语言的prompt，对吧？我们没有说我们要做英法翻译的例子，而是直接甩了三个事例给你，你自己去猜我要干什么。后来我们发现其实加上这个任务描述这种natural language的这种prompt之后，效果会更好。这幅图应该也看到了，对吧？我们加上了自然语言的这个指令提示词之后，其实它的效果会变得更好的模型。其实更能理解你要干什么事情，你再给几个参考示例就更好了。
	这个是full shot，通常我们把这个full shot定义成给的这个示例，在三个到十这之间。但这个不是一个现实的数字，是一个经验值。然后我们的one shot就是说这个意思就很好理解。我告诉你这个任务是做英语到法语的翻译。然后我给了你一个任务的示例，就是一个一example。然后接下来我给你我要干什么任务，这个单词要翻译过去，那zero shot就更直接了，就是我一个参考事例都不告诉你，但是我告诉你我要干什么，我要做的事情是英语到法语的翻译。然后我直接甩了一个英语单词过来，你能不能给我翻译出来？
	这个就是三个不同的手段。这三个手段其实都叫in context learning，都是基于上下文去学习，它有几个核心点，不改变模型的参数，然后说清楚我要做的任务，然后告诉我们的大模型，让大模型去理解你现在想让我干什么样的生成任务，然后我再去给你你想要的答案。对然后在这个性能方面，其实我们能看到是好于one shot，是好于zero shot的。在GPT3上面这个也比较好理解，就在在这个不同的benchmark上差不多都有这样的一个结论，并且模型越大它的效果越好。
	主要还是因为那会儿我们的prompt的技术也还不够强，大家都才刚刚整明白怎么样跟语言模型去做交互，对吧？大家可以想象，在2020年我们没有CHTGPT，大家也不知道让语言模型的这个水平，就花了这么多精力训练了这大几百万美金砸下去，训练了一个GBT3模型出来怎么用他不知道。突然发现这个income text learning是一种手段，给他几个few shot，他就能理解我要做什么事情。当时其实是也是一个非常大的进步了，因为不再需要调整模型了，对吧？在那么大的规模上调整模型是非常耗时、耗成本、耗资源的。当时去研究这个训练大模型的成本，也是一个热点的话题。包括现在为止大家也都觉得大模型的推理和训练成本非常高，对吧？那么我们就尽可能不要再去调模型了，直接去用它。
	在简单横向对比一下，就是三个模型其实是有各自的特点。从模型规模的角度是一个十倍、100倍，然后第三代是第一代的1000倍的这么一个规模。然后在transformer的层数上面越来越深，预训练的数据集越来越大对吧？
	然后主要贡献点就这三代模型主要贡献了什么。第一个就是说GPT1我们展示了用这种pre train的这种预训练的语言模型，加上繁重的这种范式是能干很多事情的，他能在各种自然语言任务上面去得到一些性能的提升。GPT two是希望把这两个架构能够合二为一，既把预训练的无监督的预训练语言模型给做了，又把下游的无监督的多任务的事情也在这个过程当中学了。这个是GPT2的一个贡献，同时也扩展了它的规模。
	第三个点就是GPT3引入了pu shelf learning，也就是我们的其中一种叫income tax learning，对吧？就基于上下文去学习，有少样本，有一个样本、有零样本，去引入了这样的一个能力，让我们能够不修改模型的前提下，让模型去为下任任务务知道我下游要做什么。同时开始提出这个prompt的概念。当然那会儿还不叫prom pad engineering，现在我们知道叫这个了。然后同时把这个模型规模和数据集进一步放大，又放大了100倍，然后甚至在文档级别上面我们能开始去做一些工作了。这三年的时间，其实OpenAI是一步一个脚印的在往前去做推进。把我们的预训练语言模型逐步走到了这个大语言模型。GPD3其实就是处于这个预训练语言模型和大语言模型之间的一个状态。
	Ok讲了这三代模型，我们再回顾一下这个重要概就是有很多learning。就是在在这个深度学习和大语言模型的时候，我相信大家都被这个learning搞疯了，对吧？Martian learning, deep learning, reinforcement learning, in context learning, future learning, their social learning, 这个就全是这个learning。
	刚刚其实讲过，首先这个income text learning是GPT3提出来的一个重要概念，我们再明确一下，他是说不它的核心点不改变模型，通过上下文的示例告诉或者说通过上下文的这个任务描述告诉我们的模型要干什么事情，那就相当于你不用再去变了这个牛排就是牛排，所以牛排不用变对吧？但是你告诉我你想怎么吃，我告诉我可以切，然后可以切成这个横条的竖条的都可以。对按照这个类似的例子大家可以去解释，就是不会再去变这个模型本身了。
	然后这个fusion learning就是说它其实是一种income text learning。它的方式是说我给几个参考视力，最好再能描述清楚我要干什么事情。然后让我们的大语言模型能够学习，你现在要让我干嘛，然后我就能去给你提供一些正确的生成内容。然后这个prompt and engineering后面我们还会有大量的时间去讲提示工程。提示工程其实更多的是说在这个大语言模型的设计或者说训练过程当中，能不能通过一些好的prompt，让我们的语言模型能够理解你想让我干嘛。说句简单来说，按照我们现在人跟人来聊天的话，就是prompt engineering就是一个提升大语言模型和人之间沟通技巧的一个工程学科？就怎么样让大语言模型听懂人话，怎么样让人能够理解大语言模型的话，这个其实就是prompt engineering的一个很重要的工作。Ok好我。我们现在从GP7的一二三开始讲到了CATGPT讲的很火热，我开个空调。
	我们讲这个CHTGPT，ChatGPT跟刚刚说的几代GPT有什么不同，他怎么牛逼了，他赢在哪儿？因为其实坦白来说，我们这一轮的对AGI的向往，对通用人工智能的向往，对于大语言模型的未来的期待，都是从他这儿来的，都是通过HGP来来的那他牛逼在哪儿？对吧？
	然后我们又反复在提，我们再看一下这个图，就是一个经典的架构。我们的这个pre train的LM加fine tuning的这个范式，就是我们从GPT1开始到GPT2想要和唯一的这个范式是一个很经典的范式。它是通过我们首先有这个红框，这个是一个基础的一个模型，用无监督的手段去训练。训练完了之后，它能提供一个统一的embedding的方法。然后我们再针对下游的任务去做这个fine tony，然后这个下游的任务就是一个一个的这个词汇，对吧？到最后的抽象，有这么一个经典的架构。
	但是整个的OpenAI的发展路径，从这儿开始到后面的CAAGPT，其实是逐渐在变化和演变。刚刚我们也在尝试说明这个过程，那具体是怎么样在变呢？我们把从GPTE到CHABT的这个过程，最终尤其是到GPT3到GPT3.5的这个过程，我们用一个词叫做预训练和微调的一个共舞，就刚刚那个范式左边第一步预训练，第二步是微调对吧？但是预训练和微调，其实这个微调本身也是一个很有意思的概念，对吧？我们有fine tuning，我们现在也有instruction tuning，都是微调。
	这个微调的跟微调的区别又在哪儿？其实我们通过CATGPT能看出它的变化。首先在GBT模型的这个演进过程当中，我们知道OpenAI一直在调整他的训练策略。从最开始的这个两阶段就分开训练，分开学无监督学模型，然后模型微调去调这个下游任务，到后面想要一统，再到后面我们能够用income text learning不调模型，指条指令，到这个过程当中，其实一步一步来的那在GPT2到GPT3之间，其实他们也一直在研究，能不能通过这个预训练模型，就在这个已经有的基础上，针对下游的特定任务，就是这个标注数据。我们这里有看到这个标注数据来进行微调，然后能使这个模型在一些特定任务上面的表现得到提升。GPT就是典型的这个模式对吧？然后包括这个GPT2。
	但是这个方式它也有它的一定的缺点，就是它一定是下游的任务，需要有监督的学习。有监督的学习就意味着需要人工标注，人工标注的这个数据是有限的。所以这里就开始从有标注的下游任务的学习逐步就开始，我们演进到我就可以能不能想一下，就不要再去让他下游任务去用人工标注了，而是让模型尽可能在一堆无监督的内容里面去使劲学学学出来之后好像就学通了，我也不需要下游的各种任务了。
	在GPT3的时候，我们发现这个事儿好像有一点可能了，只不过还没有那么通用。GPT3我们刚刚看的所有事例，其实都还是在一些什么翻译这种问题上，翻译的数据集太多了。那一些通用的，比如说我们现在的这个你帮我写一份周报，你帮我写一份日报，那这样的任务他可能还学不了。因为他的无监督的预训练里面这种内容太少了，所以经过了很多的研究，这个过程也比较曲折。
	那怎么样一步一步过来的呢？这里其实是有一个从GPT3到我们的GPT3.5，到ChatGPT的一个模型演变过程。我们简单看一看，首先刚刚上一个小篇章，我们看到的这个GPT3的这个论文就是我们的达芬奇的初代，就GPT3的这个initial叫达芬奇取的这个名字是在2020年的七月份的时候发布的。从此他就开始各种魔改，大家玩游戏都知道魔改是什么概念，对吧？就是这玩意儿成本太高了。然后再训练一个GPT3也没太大可能了，因为我能用的数据都用的差不多了，就是我只能想一些别的办法了。
	然后大家就看到这里，其实GPT3是有两条分岔路的对吧？第一条分叉路就是说在之后的第二年，2021年的七月份发布了一篇论文叫codex。就是我们左边这条线叫codex initial。后面有陆续的这个code divulge 001，code kashmir 001到后面的code dim 7002。那这条线呢是一个什么样的变化？首先它从一百多亿的GPT3进行微调，微调之后变成了首先我们在代码上面去做训练，有这个达芬奇001，然后再去做微调，变成了这个ccc ma 001。然后一直在做研究，就是使劲在微调做这个instruction tuning对吧？就是我们刚刚有提到的，我用这个有监督的小数据，现在这个是代码，他把github的这个代码库拉下来了，去在代码上面去做各种训练。
	就是我大家可以看到GPT3把人类的语言，什么爬虫、common co，我们的危机百科、互联网的数据，书都学完了。孩子能学什么东西？代码对吧？学代码，然后这个是非常有意思的一个点，也是GBD3开启了学代码这个一条思路。并且也有些学者在研究，就是为什么这个后面的GPT能够去做一些简单的推理，包括代码的生成都跟这条线路是有关的，开始在代码上面去做这个训练。
	然后同时还有另一条路，就是我们的这个instruction的instruct这个GPT，然后它后面迭代出了这个instruct达芬奇beta和这个text w7001。然后这个模型其实也是在做指令微调，只不过这个指令微调，它是学的一些不是学的大语言模型的刚刚说的那些训练语料，也没有去学这个代码，而是基于一些特定的指令。这里我就不再展开了。大家可以简单理解，左边学了代码，右边学了一些特定指令，然后这个指令也没有完全公开到底怎么弄的。但是，这里它们交汇在一起，这交汇在一起之后，这个语言模型相当于就能够先在代码上面去做训练。
	这里其实是有个先后顺序的。我先去学习了很多代码，在GPT3学了大量语料的基础上，然后再去做了指令微调。针对我的一些有监督的这个任务，我的一些标注数据学完之后生成出来了一个模型，叫做code diverge 002，这个code dewin 7002就已经很接近了，并且他又做了有监督的一个instruction tuning。这里有一些细节，因为GPT也没有公开，我们这里就不做过多的赘述。但他的整个思路大家可以理解成在所有的自然语言大语料上面。学完之后在代码上面再去做训练。训练完之后，在它的标注数据上面去做一些指令微调，就变成一个有监督的一个学习。
	要有监督的学习之后，最后在这儿又做了一些最终的版本发布，叫什么呢？叫text的win 7003和这个CAAGPT。这个就已经离我们现在很近了，就是去年下半年的事了。那么这俩模型有什么区别呢？首先这两个模型都是在2022年的11月发布的，就我们左下角和右下角这两个模型。并且现在大家在OpenAI的这个模型列表里面也能看到这两个模型，就是这个text w win 7002和这个ChatGPT。但这两个模型又各自有这个侧重。首先这个CHAGPT大家都知道，它最后一环使用了叫做基于人类反馈的一个强化学习来做指令微调。
	这个RLHF最重要的一件事情是做什么呢？就是你们可以理解这个text，达芬奇002，他的回答是最让人满意的。他其实是他的大家可以理解他的能力是最强的，相对来说，但是他答的不是很好，可以的。举一个简单的例子是什么呢？就是你有一个员工或者你有一个同事，一个朋友，他能力挺强的，但是他不太合群。所以你问他问题的时候，他说的答案可能都是对的，但是听起来就是不太舒服，或者说听起来就是不是你想要的那个答案，但其实他是对的。
	对，那么CHTGPT干了个什么事呢？他是找了一堆的标注人员，然后让这些标注人员去给这个text达芬奇002再去做标注训练，就基于人类反馈，这个人类反馈做个什么事儿呢？就是好现在text达达芬奇002这个模型。我问他问题，然后你给我好几个回答，给我好几个回答之后，我再去打分，我去给他打分，打完分之后就是人来打分。说这几个正确答案里面，我觉得哪种答案听起来我最舒服？干这么一个事儿。
	所以ChatGPT当时很多人都会感觉他跟像微软小冰，还有之前好多包括像siri像小爱同学等等这些国内的人比起来低。他很聪明很智能。第二个他的回答还挺挺让人觉得像是一个人的。他的回复挺舒服的，并且如果超出了他的能力边界，他也能给你。你说他乱编也好，你说他巧妙的回答也好，他能给你去做一些这样的事儿。这个其实就是church PPT非常重要，有成功的一个点。后面我们也会去讲这个过程具体怎么开展的。
	类似的这个text达芬奇003也是做了这样的人类反馈的微调，但他们调的这个重点不太一样。对呃，ok这个是一个点。但是这里有一个小插曲是说，其实我们现在用到的拆GPT这个网页页面的应用，我们的普通用户没有付费的用户用的都是GPT3.5，付费的用户可以用这个GPT4。然后我发现今天我在做这个课件的时候，我发现其实线上的这个GPT3.5已经没有在用这个text达芬奇0033这样的一个模型了。
	好，退回到这个002，然后在002上面继续去做一个微调，就这个有监督的指令微调。我记得好像后面有一页这个截图里面也有看到。所以其实大家可以认为从这儿开始就已经有一些黑魔法了。就是这个指令微调这事儿其实没有一个完整的正确的答案。他是冲着一个方向去走的，包括我们说合规，就是为什么CAAGPT1开始有些人去说他会什么给出一些生成内容，是要毁灭人类，需要什么的，后来又没了，这都是通过指令微调，不断的再去给他做调整，让他把一些生成的内容。但有的是通过逻辑上的，就我接了一些前后处理，还有一些是直接去做微调，在调整这个模型。但无论如何，它的整个发展路径是从三从3代到3点5代中间这个代差。这个0.5代的代差就是在于code training和这个instruction tuning。
	Ok我们关于这个从3代到3点5代就到这儿，我们具体再再来总结一下，就是我们的3.5GPT3.5还没到这个最后的ChatGPT它其实跟我们的GPT3到底有什么优点。第一就是说最初的这个GPT3.5，它都还没有接受过太多代码的训练。然后它首先在人类的这个指令响应上面，能生成一些更恰当的回应。这个事儿就跟什么就跟我们现在在讲，就是我问你一个问题，你尽可能回答我是一个跟我相关的一个回应。你别你其实不懂，但是你这个牛头不对马嘴的答非所问的回了我一个问题，然后你好像还挺自信的，就是关于这件事情上。GPD3.5比GPD3做的好。
	然后第二个就是它的泛化能力做的更好。这个泛化能力我们通过刚刚的论文已经知道了。就是从GPT3开始，我们都尽可能再通过不要去修改模型，尽可能通过这个income text learning的方式去做这个任务的传达，就是去告诉这个大模型我要干什么。但是在实际工作当中，其实我们还是会对这个大模型进行简单的微调的，就跟我们刚刚看到的，包括这个指令微调，都是通过这样的手段来做的。然后通过GPT这个3.5的迭代，它把这个泛化能力通过开始的学习这个代码和他做这个指令微调，变得泛化能力变得更强了。然后从这个code达芬奇002到我们刚刚了解到他后面又学了代码，又做了这个指令微调所以这个初代这里应该是写到这个下面，不应该在上面有。就到后面他开始学习代码了。学习代码之后，他开始能够去理解代码生成代码，然后他在编程方面的能力也就逐渐体现出来了。
	然后还有一点就是说在这个我们后面其实会讲所谓的思维链，就我们的chain of thoughts，包括一些复杂推理。在GPT3.5通过这个学习代码开始有一定的思维链的推理能力了，他能去做一些多个步骤的推理了。这个也是很有意思的一个点。就是在没有接受过代码训练的这个GPT3上面，是几乎没有这个能力的。就是它是没有思维链的能力的。
	但是因为学了代码，他有这个能力的。所以这个事儿有的人是怎么解读的呢？是说我们人他因为学的代码都是人写的。然后人其实在写这些代码的过程当中，大家知道最最典型的两类编程风格。一类叫面向过程的编程，一类叫面向对象的编程。其实面向过程的编程是一个逐步解决任务的过程，就我第一步做什么，第二做什么，第三步做什么。然后过这个代码本身的含义让有些人去理解，成就是其实这个逻辑的表达能力，通过代码的逻辑的表达能力被GPT3.5学到了。所以他开始能够逐渐去做这个复杂的多步的推理。
	对这个是但是思维链到底是怎么学出来的，仍然是一个待研究的一个开放性的问题。也有一些专家学者在研究它，这个就是我们的大语言模型的一个可解释的一个研究方向。但是还有一帮人就是跳过这个步骤，就是我不管他怎么写出来的，我尽可能的去研究。我还能够通过一些什么样的prompt engineering的方法，让我大语言模型的潜力再被挖掘出来。这个就是另一个方向，也是我们下一章要讲的这个prom pad learning相关的一些方向。Ok然后我们最后再看看这个CHAGBT的一个三段训练法，这里简单讲一讲，大家还记得刚刚那幅图里面我们的这个ChatGPT。最后这个CATGPT这里有一个supervised instruction的tony，对吧？
	那这个有监督的这个指令微调，有监督的指令微调是我们CHAGBT训练当中的第一步。对它其实就是让很多的人去写一些数据，然后去反映to m这个大家可以简单理解成就是我我在为一些特定的任务去写标注数据，写完这个标注数据之后，我就直接去调整这个模型本身。这个SFT是现在做这个不管是CIDCIGPT也好，还是其他的大语言模型也好，几乎都可以认为是它的第一步，就是他的第一步的训练过程。所以这个阶段其实他们通过训练这个SFT的模型，能够让它生成的这个输入，生成的输出，去跟第二步的这个奖励机制，奖励模型去做对接。简单来说就是我通过第一步，因为本身是一个生成模型对吧？所以我第一步训练完了之后，我就能生成一些数据了。
	生成完这些数据，大家了解这个强化学习其实是一个一个非常经典的一个架构。这个架构是说我要对我这个模型也好，我的网络也好，输出的结果去做打分。然后我尽可能设计一个机制去客观的打分，然后通过这个机制来找这个，我看举个什么例子，跟学围棋很像。对，就这个阿尔法狗，其实大家了解的话，其实它最开始是一个下围棋的程序。那阿尔法狗一开始学的是什么呢？学的是人类的棋谱。然后一直到阿尔法这个rayo，就是他没有在学棋谱了，他觉得人类的棋手的这个上限已经到了。
	他开始学的是这个，我不看任何棋谱，我只把这个围棋的规则给尽可能描述清楚。那什么叫描述清楚呢？就是我这里下了一步棋，然后我不会去跟历史上的某一些棋直接去做比较，而是我想办法给他打做一个评分系统，就跟这里的奖励机制一样。就这步棋下去，我得分比下那个位置的得分更高。这个其实就是一个奖励机制。这是一个通过类似于强化学习的方法来实现的那这里也是一样。
	在第二步，我们已经有了一个有监督微调的语言模型，它能生成内容了。然后我们设置一个奖励函数，一个奖励模型。这个奖励模型是为了跟刚刚第一阶段输出的内容去做打分的，它会对我们的大语言模型的打这个结果去做打分。打分完了之后，他会去对这个结果去给一个排序，就是我们大元模型可以输出多个结果。
	大家去用过OpenAI或者其他的大模型的话，会发现它有一个参数。就在我们的这个不管是chat模式还是说这个文本生成类的模式，都会有一个参数叫做top k就是我的模型其实不是只会输出一个结果的，我的模型可以输出好多个结果。比如说我设置成top 10，然后可能就会给你前十的结果，然后你可以自己在这十个结果里面再去选，对吧？那训练过程也是一样的，模型一开始输出的那一个top 1的结果不一定是好的，那通过奖励函数奖励模型我能选出来好的，那这里就要设置比较好的这个奖励模型了。
	第三步是什么呢？第三步是通过一个叫做PPO的一个奖励模型，来最后进行强化学习。然后这个强化学习其实是我会去算。最后我的这个我刚刚不是得到了几个分数，它会有好有坏。然后我会有一个策略网络去生成一个输出。这个生成的这个输出会去算出一个我们刚刚讲的这个分数。这个分数最终会给这个大模型输出的结果去做打分。
	然后这个打分还会给到这个人，就是我们的这个标注人员，再给他们去做一个评分。然后把相当于有奖励函数打的分和这个标注人员打的分共同去去选出一个结果。然后这个PPO其实是一个叫做近端策略优化的一个方法。关于整个CIGBT的训练，其实是在这样一个大的框架下面去做训练的。
	好，我们最后回过头来看，其实这个ChatGPT是一个我们讲的是一个技术和商业的成功结合。首先CHIGPT和他一起出现的这个达芬奇003，达芬奇003其实是同时发布的。但是CIGBT在造这个模型，或者说照在最后去做最后训练，在做这个instruction find instruction tuning ing的这个过程当中，其实他的目标就很清楚，就是它叫CHAT的GPT对吧？所以它更多的是现了对话的能力，语言的能力，语言沟通的能力，尽可能让我模型输出的结果是让人满意的。所以在商业的利益上和这个产品的设定上，这一点是非常好的一个设计，就是让我们的人更愿意跟他聊天。
	其实我们一开始发现他的结果不一定是最好的，甚至他的他在专门去做基于人类反馈的强化学习优化。之前的达芬奇002，可能是比11月份，去年11月刚刚放出来的CIGPT能力更强的。但是他舍弃了一些能力，这个是非常重要的。第二个就是说他在输出的生成上，我们刚刚提到更贴近人类的输出。然后包括它对这个上下文的生成，也能做更长的一个响应。然后对于我们一些因为人聊天最大的一个问题就是词不达意。就是我们的用户，我们的这个CHAGPT的使用者，有可能是说不清楚我要一个什么东西的，甚至是闲聊的那针对这样一些模糊的不太确定的指令也好，我们叫这个上下文也好，他也能尽可能给你一些输出。
	然后在最后一个部分，他做了安全性和道德规范的一些图和预处理和后处理。这样使得它生成的结果是尽可能符合道德要求和一些法律规范的，并且这件事情还在不断的去做调整。所以整个现在GBT是一个技术和商业的一个成功结合，它的商业运作的节奏也非常巧妙，使得这个ChatGPT能够快速出圈，并且持续的去制造热点。就比如说我们能看到从2022年的11月份到我们的2023年的三月份，就四个月前发布的这个GPT4。
	然后包括像我们前段时间刚刚发布的这个被所谓称之为GPT4.5的这个code interpreter，or就这个代码解释器，其实它整个节奏是非常好的，而且我们能感受到这是一个有意而为之的行为。因为整个GPT4，其实它不是说今年才训练好的，而是在发布ChatGPT之前，其实GPT4的这个大语言模型就已经训练好了。但他一直在做这个微调，在做调整，就跟我们刚刚说的做这个魔改做标注一样。整个节奏我们能看得到，其实是他一个很好的一个节奏的铺排。这个铺排最终带来的效果就是燃起了新的一轮的AI的热潮。他们获得了更多的资源，像这个CEO赛罗奥特曼也在全球范围内得到了很多的关注。现在开始在全世界的政治家首脑范围内去做交流。然后开始去设立相关的AI管理的政策和法案。
	所以其实整个从这个角度来看，OpenAI是一家很成功的公司。就是它不仅在技术上一直坚持着自己的道路，去做做模型大规模的训练，包括去加这个代码的code的预训练。我们看这个code x这也是他们第一个做的。一直到后来的这个CHAGPT这个方向，这个产品的定位，然后又看到我们在做这个ChatGPT这个第四代就GBT4的时候，做了一些新的尝试。这些其实都是值得我们每一个人去学习的。好，我们到激动人心的这个GPT4了，你讲了一个多小时了，所以GPT4首先给大家看一个官方介绍的短片，我看一下这个能不能切过来。
	Cheaply, for it takes what you come to with and just runs with it. From one perspective is a tool, that thing you can use to get useful tasks done in language. From another perspective is a system that can make dreams, thoughts, ideas flourish in text and gravity. 
	Depity four is incredibly advanced and sophisticated. It can take in and generate up to twenty five thousand words of text around eight times more than chat G. P. 
	T. It understands images and can express logical ideas about them. For example, it can tell us that if the strings in this image were cut, the balloons would fly away. 
	This is the place where you just get turbo charged by these eyes and not perfect. They make mistakes. And that you really need to make sure that, you know, the work is being done to your level expectation. But I think that it is fundamentally about amplifying what every person is able to do. 
	G, P, T four trading finished last August, and everything that has been happening in the past month up until we released has been a chinese print main secret or more aligned and also all use, though we have put in or already a lot of internal al guard eras around things like at the serial usage, unwanted quantity, privacy concerns. And when we release some model, we know pings are not. We know we have to learn and we know we have to update. We know we have to keep improving all the systems around it to make it to to work for society. 
	To me, the most compelling use cases of these technologies will come from starting with a real humanity. The obvious one where assistants have really incredible . 
	is an education. You beautiful, can teach a huge range of subjects. Imagine giving a fifth greater, a personal math tutor with unlimited time. 
	And patience is a great tool to bring learning to everyone in a way that is personalized with their skill level. G pt four brings the dream of having the most useful, hopeful system to like it. Really, about adding as much value to everyday life is possible. The partnership that opening eye has, what microsoft is to shape this technology. 
	And as something is going to be useful for the world, the power of A, I hopefully is that it can help us be more, more production, which ultimately leads to Better call in your life the development of the transfer of the computer, of the intervening semi conduct industry, all the programming ing language, everything came together to produce AI technology. And while it is very limited, is already easy to imagine what the impact of the successor many generations down the line will look like. We think that GPD four will be the world's first experience with a highly capable and advanced AI system. So we really care about this model being useful to everyone, not just the earlier adopters or people very close to technology. So it is really important to us that as many people as possible participate so that we can earn more about how it can be helpful to. 
	好的，我们看到了这个GPT4的官方的一个宣传视频的，配了中文字幕的一个版本。其实整个GPT4在今年3 4月份的时候发布出来，应该是引起了非常大的轰动的。他的轰动我觉得有几个方面。第一个就是说大家发现我靠第一件事情就是你现在发布的这个玩意儿是一年前就已经搞完的了，那现在你又是什么样的一个水平，对吧？大家对这个未来充满了无限的遐想。并且我跟微软的很多朋友沟通，其实大家一直在用一个戏谑的词在讲究这个GPT5其实是用GPT4在训练。这个呃可以用多个方面多个层面去解读，这里不再展开。
	但回过头来一句话，就是说整个OpenAI对于节奏的把握非常好，并且也成功的做出了很多的开创性的成果。但在这样的前提下，又保持着很谦卑很克制的一个心态，在做这个OpenAI后续的一些动作。这个其实是非常很有意思的，并且也是值得大家去去多方面去学习和参考的那从技术和应用生态的层面上，包括我们为什么会有这门训练营的课程的角度来说，都跟GPT4有非常大的关系。就当GPT4发布之后，尤其是刚刚那个短片，它很多能力展现出来了，各种各样的任务他都做得非常好，并且是大幅度的提升，跟GBTE那会儿大家刚刚还记得1个小时前我们讲GBT1对吧？叫做那个时候论文它的这个hours就是我们自己的工作成果，叫fine tuned transformer。这个LM就是只是一个在穿former的语言模型上微调的一个成果，非常的低调，然后也不好怎么讲到GPT。
	四大家都在想，希望服务于全人类，这个利益就很高。包括这一周马斯克刚刚成立的这有1点AI这家公司，想要去探索宇宙奥秘，知道这个宇宙的真谛。其实我们会发现今天真的是一个AI站在舞台中央的一个时代。但是这个时代我们刚刚通过分享OpenAI一路过来也很不容易。从18年到20年几乎是无人看好，就没有人看好这条路，都在研究bert或者说T5这样的一些方向，就觉得只靠生成这事儿是不靠谱的，包括计不计时出来之后，像这个乐坤，我们的图灵奖也说这个模型有很多的缺陷，它的缺陷也好，它的这个局限也好，我们先暂且不表。就他现有的成果，我们这些普通人，我们这些开发者能够有多少能够为我所用。并且在这个基础上，我们能够去把他的能力变成我们的杠杆，去做更多的事情。这个其实是我想通过这门课和不断的交流，跟大家一起去探索的一个事情。
	我们具体来看，GPT是有什么样的一个大的一个进步呢？首先多模态一定是GPT是绕不开的一个词。多模态是什么概念？首先我们知道GPT3.5也好，GPT3也好，都是文字进入文字输出对吧？我人跟大模型是通过文字，那大模型还给我的也是文字，我们都是这个文本。
	那么GPT4刚刚那个短片里面就首先介绍了，它是支持图像输入的，它有出色的视觉的信息理解能力。就是我开始能够去理解这个图像了。如果能够理解图像，这个事儿就很夸张了，对吧？
	大家想象一下，把GPT4当成一个大脑，但是他可能没有人那么强。他这个大脑现在有眼睛了，他能看见世界上很多的图像信息，然后这些图像信息他还能读懂。这个事情很夸张，就是我不我不知道大家有多少人用过这个纹身图或者纹身视频类的这个应用。就比如说这个stable diffusion mid journey runway之类的产品。它是说我输入一个文本，生成这个图像或者视频，再把这个一接上，包括现在的GPT这个四开放的插件code integrator不就能接上了吗？那我不就变成了我既有大脑，然后我还能有眼睛看懂输入，我还能对接下游各种各样的第三方插件。就比如说mid journey，我就相当于有手了，然后这个手还不是我的手，我是一个远程遥控，对吧？
	像这个老板一样的，这里今天新来了一家初创公司，是做纹身图的。那里来了一个纹身视频的，那里又来了一个纹身商业文案的。比如说notion，比如说copy点AI jasper对吧？那这些工具类的这些AI公司反而变成了我的下游了，我成了一个中心，我存的一个入口。
	这也是为什么第三点在讲，这个是CHADPT的一个野心，就是TBT加生态的动作和目的已经呼之欲出了。就是通过GPT4这个强大能力变成了一个入口。大家都想来用我这个能力作为入口跟我交流。然后我在这个上面去搭建一个plug in插件的生态。通过这个插件生态去搭建所谓的AIGC的应用。或者说我们叫这个大语言native，就l am native，就跟这个云原生，我们叫大语言原生这样的一个应用的一个生态商店。
	就有点类似于我们之前在移动互联网时代，就我们十年前刚刚开始有apple store，有安卓的应用商店一样。那就是因为大家想为什么会有apple store，为什么会有安卓的商店？不就是因为安卓手机好用吗？诺基亚不好用，对吧？Iphone好用，摩托罗拉不好用。那现在也是一样的，大家觉得CHIGVT4好用。Google或者research或者百度的search在解决一些问题的时候，没他别的答案好。这个就是一个巨大的流量入口的迁移，这个迁移就会会有很多的想象力，所以GBT加生态是OpenAI一定会去推的一个战略，并且正在执行。
	然后那回过头来就是多模态很强，然后他自己也在做这个AIGC的应用商店以外，还有一点就是它的上下文的窗口变长了，大家可以理解成这个大模型，大语言模型。现在跟大家去做交流的时候都会有一个叫做context。或者大家能看到我们调模型的时候，它会有一个最大的token数。这个最大的token数就是我们GPT3的时候就开始讲的，叫做text learning对吧？它有一个在上下文里面去学习的能力，就是这里的上下文它再怎么学，他也有一个上限。就我的这个上下文的窗口是有限的那这个有限的窗口跟很多原都有关，就有很多东西去限制它。为什么是这个窗口？
	但也有一些学者再把这个东西扩展到无限长。比如说我看上个月微软亚洲研究院还是微软公司有一篇文章叫non net，就是这个长网，就是这中文直译叫长网non net，就是把这个token数无限扩张，扩展到10万甚至100万，这个也是一个研究方向。但是大家通过我们这两三次的上课已经理解了，任何事情它都不是就是有一句很有名的计算机这个行业的名言叫no free lunch，就是没有免费的午餐。
	就是任何你看起来好像可以把它能力无限扩展的东西，都是会有一些另一方面的折损它会对另一方面造成一些影响，这里就展开就不展开了。这个上下文的窗口在不影响效果的基础上，GPT4比起GPT3.5有一个将近十倍的扩展。最终最大到了32768，就三万多个token的一个上下文窗口。而且因为这个上下文的窗口变大之后，它为后面的这个思维链，包括我们的思维数，思维素，trail thoughts这样的工作提供了一些可能。就使我们的这个大模型能够做更复杂的逻辑推理。逻辑推理是目前大语言模型非常弱的一个板块，后面我们也会有实际的一些例子。Ok这个是前三个部分。
	还有一个部分就是还有很多的原来的应用。就比如说我们看到的微软的office，然后国内的像WPS，然后像思维导图等等，有一大堆原来的移动互联网的应用。现在开始都在去增加GPT，我们把它叫做应用加GPT对吧？就跟以前互联网加加互联网AI加加AI这个逻辑是一样的。就是我的应用还是入口主入口，我的原来的应用的使用习惯，用户都不变，但是我给原来的应用提供了更多的能力，提供了更多AIGC的能力，大语言模型的能力。这个其实也是GBT4这个时代我们能看到的所谓的l am native这个应用时代的一个典型特征。因为现在我们就可以首先这句话就叫做所有的应用都可以被重做一遍，对吧？那重做的点是什么？就是更符合LLM native的特点，这跟云原生当年的说法是一样的。
	对，然后我们具体来看一下这个GPT4它有哪些提升。第一个就是在这个基准测试上，我们之前已经讲过很多基准测试了。首先GPT3.5当时是很牛逼的，就是这个5 shot是指它的learning的次数，然后这里是。Flame palm其实是另一种contact scenery方法，我们就不展开。能看到的是之前的sofa，就是指之前最好的这个实验结果跟GPT4比起来都是十个点以上的上升，这个是非常夸张的，就是75分到86分，85分到95分。大家还有这一点点高考或者说这个大学考试记忆的话就会知道这个都七十多分，八十多分了，再涨十分是什么概念，对吧？
	我们在计算机视觉领域看到这样的上涨是当年alex s net就是alex第一个深度神经网络，也不是深度十几层神经网络开始去做视觉识别任务的时候带来的提升。因为在那之前的最好的模型是一个基于统计机器学习的方法。但是深度学习开始搞视觉识别之后，带来了十几个点的提升。
	在这里我们也发现GPT4在以前的这种NLP的基准测试上面有大幅的提升。这也直接导致后来发现试卷不够难了。大家会发现现在有很多人在做各种各样的benchmark的测试集，这就是我们的基准测试。现在要重新去追赶我们的模型进步了。
	就是大家发现GPT4出现之后，我很多人都在学GPT4的这个套路方法。虽然它没有完全公开，那么在学的过程当中，基准测试慢慢就不行了。所以在有这样的一个变化，然后多语言能力也提升了。我们看到绿色的这个部分是GPT4的一个成绩。然后GPT3.5它的这个是蓝颜色的。然后之前也会有一些像palm google的第一代的大圆模型的一个成绩。那能看到都是十几个点的一个提升，这个是非常夸张的。
	然后我们再看看多模态，GPT4的多模态是什么概念？首先在OpenAI的这个官方文档，官方这个网站上，它有给出这些示例。第一个示例其实是什么意思呢？就是我们去看这个左边这幅图，就是有什么好笑的，我相信大家应该也第一时间能看出来有什么好笑的对吧？就是这幅图有什么好笑的那他他讲到了一个很有意思的点，然后就是说我们其实通过这个GPT4看明白这幅图了。
	第一这个VGA的接口可能很多人现在都不一定用过。这VGA的接口是非常老的一个接这个视频流的一个接口。现在大家都用的是HDMI或者type c了，那么VGA这个非常老的接口里面插了一个我们叫lighting campo，就是苹果的这个充电头，这个有点杀鸡焉用牛刀的感觉，对吧？它来源于reddit也是它的训面积之一，所以这个是他完全get到了，这个东西为什么搞笑？我当然还有一些别的点，我就不再做阐述了。
	第二个点就是很有意思，这个就更深层次一点了。就是说这个图为什么搞笑？这个图里面有一个重点。第一个就是说上面是统计学习，下面是深度神经网络，或者叫神经网络，这是两个学派或者说两种研究这个事情的思路。这两个里面的有一幅小的图片是很不一样的，对吧？这里是在逐渐的去做下降。而这个神经网络我们能看得到它的这个神经网络的层是越来越深，他这个小人也说了，stack more layers. 
	就是你你就简单来说，你啥也别管，像这个小组一样，你就把这个层往深了搞就完了。它其实是解读出来了，因为对于统计这这对于学统计的人来说，他其实是非常很在意这个可解释性的。他是他不太能错，他错不得的。因为统计一般跟什么有关呢？跟人口有关，跟经济有关，跟金融有关。你错一个数字，错一个百分比，错一个标点符号、错一个这个小数点的位数带来的影响都非常大，所以一定得可解释，出了问题我能说清楚，我的公式没问题，我的这个概率分布也没问题。也许是采样方法错了，也许是巴拉巴拉错了。
	但是对于深度学习来说，包括我们现在对于GPT4的理解也是没没完全理解到位，也不知道它内部原理是怎么样的。但大家有一个共识，就是你把这个神经网络往深了搞，然后把这个注意力这件事儿整明白。就是他其实大家能看见注意力一开始挺浅的对吧？就是我们的注意力机制上节课有讲，然后后面有了。Transformer搞到6层，GPT1搞到了12层，GPT2搞到了48层，GPT3搞到96层，现在都不知道这个transformer搞了多少层了。那其实都说好了，这个attention就是OU need的，google说的对吧？他他真的是他真的这么干了，然后这个attention叠加了几十层甚至上百层，结果效果还真好。
	这个其实是很有意思的一个事情。但是他们都在自己的领域里面取得了自己的成果，并且也实际的帮助人类不断的在做技术的进步，所以本身并没有谁谁高谁低，谁谁好谁坏的一个点，更多的是一个特点，GPT4也看懂了，其实刚刚这个逻辑还是挺深的。如果咱们没有这个统计学和深度学习的背景的话，不一定get的到。然后还有就是说他能开始做一些复杂的物理题了，就比如说我们这里看到有一些关于物理的题目，以前的GPT3.5是完全做不出来的那这里他能够给出一步一步的步骤，怎么做的，然后通过并且他要得读懂这幅图，他才能做这个题，都能做出来。Ok这个都是GPT4的一些能力。
	那我们实际去测一下这个GPT4和GPT3.5有什么区别？我相信有可能跟大家想的很不一样。第一个是大家能看到这个左边是现在我用的这个GPT3.5，我今天应该昨天晚上测试的一个结果。然后我让他干什么呢？我给的这个输入prompt是一个生成一个AI大模型应用实战营的网页，就我们这门课的一个网页。然后这个GPT305回复速度非常快，计算量也小。他说可以，直接就给了我一个网页示例。然后这是一个HTML的一个代码，我把它存下来之后存到本地，然后把它打开了。
	打开之后你还有模有样的对吧？就这个右边是有这个内容，包括欢迎来到这个巴拉巴拉。然后帮你深入了解和应用大模型技术，提升你的人工智能应用的开发能力。然后还会有这个课程信息，甚至他帮你写了这个课程时间线上的形式，然后内容帮我YY了一下，然后有报名的方式，还可以提交报名。但这个按钮没有做javascript的，不能真的提交，包括联系我们，就这个模板的这个感觉就出来了，就是整个GPT3.5，就是说给你一个东西，然后你能接着改给是一个这样的感觉。
	GPT4GPT4其实很有意思，我相信这个是他做了指令微调之后的一个点，大家能看得到的是我们在用CIGPT的时候，它的整个页面就这个网页最下面会去写当前是什么版本。然后我们能看得到GPT4并没有直接给我HTML的代码。它首先是抱歉对吧？它是一个基于文本的AI不能直接生成和展示网页。但是它可以提供一个概念上的大纲或者模板，描述如何设计一个网页。然后可以用这些信息来指导你或者你的团队创建实际的网页，然后给出了一些建议。
	这里我不知道大家的直接感觉是什么，我的一个直接感受是，首先GPT4在刚刚发布的时候，它会给出比那个GPT3.5更激进的一些内容。但明显感觉最近几个月的迭代，包括有的人说最近几个月能力回退了，他其实是在往回收。他的能力往回收，第一他会更强调跟人的协作，他不会直接就去替代人给你生成很多东西。第二他会把他的下面的内部的这个思考的路径，就是他的他怎么样去给你这个答案的这个路径，告诉你人家一步一步怎么来的。所以你看他他会告诉你，一开始我是文本技术的AI我干不了这事儿，但是我可以干什么？我干的这个大纲和模板是描述这个网页的，然后我也不会直接去把这个网页的模板给你写死。就不会写一些假的纸，一些mock data，一些虚假的纸，而是更多的呈现的是一些纲要性的内容。再进一步告诉你，你可以用这个去指导你的团队去做实际的这个网页。
	然后以下是我的建议，很克制。这个描述方式已经很接近于我们人跟他沟通的这种思维链的方式了。所以大家可以很明显的想得到，其实整个GPT44思维链也好，在这个更复杂的这种逻辑推理也好，一直在做迭代和改进。然后我就强行让他生成这个网页代码。
	比如说我说这个是我接着问的一个问题，我说很好，那你就生成一个网页代码，包含以上的内容，就包含上面这些。描述的内容，然后它生成了，并且它也是按照刚刚那个逻辑去逐步的解释这个过程。他有提到以下是一个简单的HTML的模板，它是一个模板，不是真实的内容。基于之前提供的大纲，这里其实就已经能看到有这个income text learning了，对吧？我说包含以上内容，但是我什么都没写。但他其实是把之前就他自己写的这个大纲的内容，叫做你之前提供大纲。因为他把之前的所有的上下文都当做可以学习的样例，这其实就是一个典型的income text learning的一个实现。
	他有提到这个大纲包含基本的HCML，但是没有CSS和javascript，就没有样式表和动态执行的指令脚本。需要再找专业的前端开发者帮助你改善设计和添加互动的功能。这里也很有意思，就是他明确的在不断的大家也能感受到我想表达的意思，就是我没有要替代你的意思，我求生欲很强，我很我我有能力，但是我是配合你的。最终还是要靠你去找你的团队，你要去找前端，去帮你实际创建网页，帮你改善和设计互动功能等等。
	大家可以看到左边这个是GPT4的生成的这个HTML的模板真的是非常粗糙，就只有这个大纲里面的五个内容。然后它不会像这个GPT3.5给你一些mock data。单从这个来看，大家就感觉好像是不是GPT4就不行了，对吧？就怎么给这样的内容。但其实反过来大家会去想的话，GPT4的这个操作是给了更多的可能。就是比如说我们人要来做这个工作的话，你在右边这个上面银行可改的东西没有那么多了。你就是去改一改名称、时间、地点、内容，这个报名方式要不要可能都删掉了。
	但是左边这个是为了干什么呢？其实如果GPT4现在这种模式你用的好的话，它更像是一个有点像我们之前讲meta non及meta learning这个逻辑。他把这个框架性的东西给你呈现出来了，然后把它的多部的逻辑推理的过程给你展现出来了。如果咱们能很好的去利用这个框架性和多步逻辑推理的这种prom pet的描述方式的话。其实现在这种GPT4的这个手段能帮助我们去生成更深度的内容。然后整个这个界面其实我这边就展现出来了。第三步我还有写，就是如果你是一个前端开发者，能不能帮我把你刚刚说的这个样式表CSS和javascript也写出来。然后他也给了一些内容，但是没有，因为我们描这其实很粗糙，就是他没有给非常多具体的内容为什么粗糙？
	也是跟我们接下来要讲这个prom pact有关。其实我们能看到左边他给了很多让你进一步去深入的内容，就是我们的网页标题顶部的这个导航栏应该长什么样？然后主页课程介绍应该有些什么样内容。其实我们针对这里的每一点都可以再跟他深入的去交互，这里我们就不再去深入展开了。
	整个GP4的变化其实我们能看到这几个月他在逐渐的把跟人交互这件事儿做的越来越强。这个其实就跟我们开始看那张魔改的图有关，对吧？他他为了更增加用户粘性，为了让你更加多轮对话，其实是有这样的一个考量，这个是新增加的一个环节，就是我们大家都在想我要去读读论文能更深入的理解。那我们就把现在刚刚讲到的GPT整个模新家族相关的论文放在这里是有助于大家。如果想要深入学习的话，可以去看啊左下角下面的这个部分其实是三篇论文的哈佛这种引用格式，上面是具体的这个论文。然后我们的论文在热点问题里面有提，在极客时间的APP里是可以直接下载的，然后这里是分别对应着三个版本，GPT123的这个论文，然后包括GPT4，GPT4它本身其实是没有公开这个细节的，只写了一个技术白皮书，那个我相信很多人都知道了。
	然后这里再额外推荐3篇文章。第一篇是来自于微软研究院的。因为微软其实在非常早在在三月份官方发布GPT4之前，其实就拿到了一个没有被限制的。我们知道最后都会去给他加上镣铐，免得他输出一些有违大家期待的内容。微软拿到的是一个没有受限制的GPT4的版本。这篇论文非常标题非常大叫Sparks of AGI，就是通用人工智能的这个火花，就是星星之火已经开始点亮了。这个点亮是怎么样来的？这个动机或者灵感就是在于他们在这个GPT4上面做到的做的一些早期的一些实验结果。
	然后中间这一篇是一个OpenAI和这个open research，包括这个滨州大学一起合作发布的一篇论文。这篇论文是说GBT对于人力资源市场的一个潜在影响，这个大家也可以去看一看，就是很多人关心是不是失业，其实他们也有很客观的一个表达，其实没有那么大影响。然后最右边的这篇文章，其实严格意义上也不算是一篇论文，更像是一篇技术博客的披露。讲的是从各种信息渠道来到的，就是GPT4它的一个架构基础设施，它的训练集，它的开销，包括它各种相关的信息，通过这样一篇博客抛出来了，大家可以了解。
	对，好，我们休息两分钟。然后大家有问题可以打到评论区。不好意思，我刚看见评论区好像是的，我今天一直在工作，这个词是读的不太对，应该是prompt。我刚刚难道读成prompt了吗？不好意思，对，是prompt。是的。
	那我们现在就再回到这个prompt的本身上来。这个prompt prompt其实是提示词的意思。这个prompt这个词在这两三年来应该是非常多的，出现在很多人的视野里面。然后prompt其实本身叫做提示词，但是我们通常很少会去讲prompt learning，但有一些中文媒体在提这个词，我就先把它铺在这儿。但其实prompt learning这个词在论文也好，在学术圈也好，讲的比较少，可以有一个类似的词叫prompt best learning，就是基于prompt的这个learning是有的。
	然后我们知道刚刚讲到这个GPT的模型家族的迭代，从GPT3开始，大家就会发现，可以用一些prompt的手段去不改变模型行的前提下，告诉大模型我们要做什么样的工作。这个其实是从GPT3开始的一个词。然后也应该说从他开始逐渐的进入到大部分学术研究，或者说这个科学家，或者说这个领域里面的人的一个起点。
	那么prompt我们刚刚其实是有看到在in context learning，就是在我们的基于上下文的这个学习里面首先被引入了这个词，也是在论文里面出现的。我们看有这个zero shot，有one shot，有这个few shot，然后在这个里面，我们把最后这一部分在论文里面叫做prompt，然后这个prompt其实具体是个什么东西，有很多概念。我们先来一个概念的解惑。首先prompt learning和这个income text learning是一个什么关系，对吧？这个结论来自于GPT4，然后我进行了review，然后做了一些微调。
	首先prompt learning是一种使用异性恋练语言模型的方法，不会修改模型的权重。在这种方法当中，模型被给予一个提示。比如说我们的这个prompt，然后它是模型输入的一部分，但它不是完整的模型输入。刚刚大家有看到它分成这个任务描述，参考示例和我们的这个prompt，指导模型产生特定类型的输出。所以在GPT3至少在GPT3这篇论文里面，这个prompt是模型输入的一部分。
	然后这个prompt learning就是说能不能让这个预训练的这个模型在不调整它的前提下，我们能够去学习到知识和能力。这个in context learning就是我们基于上下文的学习，刚刚已经讲了很多了，在GPT3里面是一个基本特性。In context learning基于这个上下文有多种方式，可以直接用这个zero shot就不给参考示例，也可以基于我们的这个one shot或者so full shot。整个上下文就是我们包括在ChatGPT里面我的多轮对话，我前面几轮的对话都可以成为我的context。然后我的这个上下文的窗口刚刚有讲到GPT4最多拿到了三万多32K这个是in context ery。所以这两个概念是有很多关联关系的，但是又稍微有一些不同，prompt更多的是引导模型的输出。然后我们的income test learning是怎么样利用这个输入序列当中的上下文来影响模型的输出，是有重叠，有overlap。
	然后大家如果去调用过OpenAI的API的话，就是你去调过这个OpenAI的这个大模型的接口。你就会发现其实ChatGPT它的使用，它一直是把你之前的很多轮的对话作为你下一次模型的任务的输入一部分。就你前面聊了很多内容，他每次去生成。一个新的回复给你的时候，都把那些之前的聊天内容丢给了这个模型的。所以这个窗口越长，他越能去找到更远端你曾经给他说的一个事情，所以这个还是有不同同。
	然后我们再看另一个点，就是说我们知道有learning有tuning，这俩概念又是什么样的区别？我们有这个from prompt learning，有这个prompt tuning，他们其实都是自然语言处理当中的一个概念，并且也都跟优化这个模型有关，然后呃这个prompt learning刚刚有讲过它是什么了，对吧？它是为了响应特定的输出，引导输出的。就比如说我们这里的这个这里的这个举例，你像模型提供了一个什么呢？就是把英文翻译成法文，然后这里放了一个text，其实这个地方是个占位符对吧？然后这个画括号是相当于为了表达这里面的内容，是需让模型能填进去的。
	那么prompt tuning是什么呢？其实更常见的这个叫法会被叫成这个engineering，它是一种优化技术。就我刚刚其实有提到说人话来说，就是说提升你跟大模型沟通的技巧。那这个沟通技巧的提升，这里就会有很多种方法了，对吧？就我们人类的沟通技巧的提升都可以写很多本书，对吧？那么我们跟大模型怎么样沟通，就会有很多的启示和方法，也是我们接下来要讲的很多种方法，包括启发式的方法，微信就是我们基于这个a star这种搜索算法，然后人工的这些选择优化的提示。这些都是我们在优化我们的跟大模型沟通技巧的一种手段，所以更像是一个方法论的东西。而这个prot本身它其实是指的一个具体的事儿。
	好，我们接着就来看看这个prompt它到底有一些什么样的学术上的研究。第一个其实就是一个叫做chain of thought，就是我们思维链，它其实是我们正儿八经开始研究跟大模型沟通技巧的所谓的开山之作，它非常有名，虽然它引用量不大，只有几百不到1000。然后这篇文章又来自于google，就非常吊诡的是整个这一轮大模型，大家如果往回看，transformer，google的人发布的，然后transformer的八个作者，我前几天在里面有法最后一个作者，就是base在日本东京的一个老哥也离职了。连google的八个算是former的作者都已经离开google了，然后都出去创业了，都不再工作了。
	这篇文章c erl soft其实是在ChatGPT发布之前，在2022年初，就是我们去年初发布的一篇论文。这篇论文也是这个谷歌团队，就这个谷歌大脑这个团队发布的。然后这个一座叫做Jason we，这个作者后来去了OpenAI，并且是去了之后还深度参与了ChatGPT的研究，所以你能想到为什么CAAGPT游戏GPT4这个CHAV sort的感觉越来越浓了，就是因为这作者都跑那儿去研究这事儿了。而且这篇文章是发表在我没记错的话，应该是发表在这个lips，就是很有名的自然语言处理的AI的顶会上。然后这篇文章第一次向人们表达了我们跟大模型的沟通也是需要技巧的，怎么样有什么样的技巧呢？第一就是这篇文章我们把这个c hl foot叫思维链的这种跟大模型沟通的方式，它有几个很有意思的点。
	第一个点就是说整个COT他开始允许我们这个大模型，这大模型其实就像你的一个队友一样，他其实思考问题他也很难一次性就想到位，对吧？那你能不能给人家一些机会引导一下别人。然后因为整个我们有讲到这个prompt learning，就是去引导模型的输出，对吧？那这个COT这个shell thought它其实就是引导我们的模型。你能不能把一个复杂问题，一个需要很多不明白的问问题给它分解一下。分解之后我们就可以去进行一些相对来说需要推理的一些工作了。所以这个是第一个就是我们能把多个问题拆解了。
	第二个就是他甚至能把之前我们知道这个income text learning里面有这个给样例对，就给他一个样例或者几个样例。这件事儿我们复杂问题其实也可以参考这个逻辑。就比如说我有一个复杂的逻辑，复杂的问题，然后后面我们会去举上节课讲的这个咖啡馆喝咖啡的问题。怎么样让我们的大语言模型理解你是怎么样解决这个复杂问题的？给一个参考样例或者给几个参考样例。这个也是我们刚刚提到有few short learning，在income context learning里面。
	后面出现了这个chain of salt prom，后面也还出现了zero shot或者one shot few shot chair of salt prompt。这个其实很套娃对吧？所以其实你会发现AI的这个研究没有那么多，这个就是非常尖深刻。
	我的这个很难理解的套路，你整明白之后，它就是这么几件套翻来覆去的用，把网络做深，把数据规模做大，把模型搞大。然后训练自然语言，然后先训练书，再训练网上的reddit这样的答社区，再去训练互联网上的数据，再去训练代码。然后又把搞不动了之后，又去把以前监督学习里面的东西拿过来，但是是做指令微调，然后又搞不动了，把强化学习里面的这个奖励机制弄过来，然后把人工标注跟强化学习再去去做结合。然后搞完之后发现可以了。然后你又开始发现这个模型的输出总是达不到我想要的效果。以前可以给他参考示例，现在复杂的逻辑也可以给他参考示例。其实是这样一个逐步演变的过程，既然能给参考示例，那我们在一些复杂逻辑里面，第一个要解决的就是一些数学题，就是一个一步一步逻辑来的对吧？包括我们的一些常识知识或者叫世界知识。
	现在这个乐坤叫世界模型，就我们能不能让大模型有常识，有这个是可以有的，然后包括一些符号推理，符号操作，都可以通过这个叫做COT raining，就是用思思维链来进行推理的手段，来解决我们的一些自然语言的一些任务了。最后还有一个点，就是说china for这件事儿很很厉害的点在于，首先它是在CATGPT之前出现的。所以那会儿他在做实验的时候，都是基于什么nama或者palm这样的一些大模型。在足够规模的这个大模型上面就是非常容易引发这个现象。然后这个是一个目前来看我们也很难去解释，但是我们实测下来是有效的一个结论。然后思维链，我们刚刚有提这个是来自于这个lips 2022年的一篇文章，他在论文里面举了一个很有意思的例子，就我们之前的这个prompt，就是我们没有这个chef sort之前，我们给的这个prompt通常是说我给你一个明确的任务帮我翻译，或者说我给你一些参考的示例。但是我们知道在做这个大语言模型的时候，我有一个很重要的能力。
	GPT3在2020年提出来的叫in contact learning。所以后面的大模型的研究都是这样干的。就把前面的输入的这个聊天内容，你跟模型的这个交互聊天的内容作为下一轮的输入。但是这个时候就会有一个很麻烦的事情是什么呢？你如果上下文出现了一些不相关的信息，甚至是误导的信息怎么办？就是我记得有一个俗语叫什么？我跟你聊这个城门楼子，你跟我聊跨过猴子是吧？这一个民间俗语就这意思就是明明我跟你聊的是这个事儿，但是你给我的上下文是另一个事儿，你反而在误导我。
	或者说你想象一下你正在听课，你听睡着了，然后老师突然叫你起来回答一个问题，你脑子里可能停留的还是另一个时间片的内容，那你肯定就回答的是牛头不对马嘴。在这篇文章里面，他首先把原来的这种prop的方式叫做标准化的standard的方式。这个方式大家看到这个例子就出错了，就是他一开始说的是这个网球的事儿，上面这个答案下面又问的是这个苹果的事儿，那这个语言模型就答错了。现在你去GPT3.5上面去试，这个也是能答对的。但它有一些答不对的，我实际试了几个例子，我们待会可以看看。
	那他给的结论是什么呢？就是他把这件事儿给他分解一下，就是之前我们能知道这个answer，就是第一个问问题的答案是十一，为什么是11呢？他他告诉了这个语言模型，就是为什么是十一？因为它是要去算的，就是每个里面有一开始有五个网球，然后这个网球桶里面每个桶能装三个球，它又有两个桶，然后就是2乘3就是6 5加61，所以答案是11。然后接着就问这个苹果的事儿，他也就会按照大模型，就开始按照这个逻辑去看我的这一个问题。这个问题是说我一开始有23个苹果，这个巴拉巴拉他就算出来了。答案对了。
	这个是当时在2022年非常有影响力，让大家第一次理解。我靠原来这个大模型。真的好像听得懂人话，而且你去给他做一些逻辑上的拆解之后，他也能理解。我们前面有讲过，可能是跟他学了这个代码有关，但有可能跟别的原因有关。
	但至少从一个一个实验来看，如果没有学习这个代码，可能它就不能产生思维链。第二个就是说如果你的模型不够大，它也无法产生思维链，这很有意思。Ok那么我们去实测一下，就这个在现在的GPT3.5就今天我们来看它能不能做到这个答案？你会发现可以显然？都一年半了，GPT3.5把这个cheese sw这个能力一定是已经埋在我们GPT3.5里面去了。所以我们不管是用英文来问，还是用中文来问，他都能够回答的出来。而且你看这个答案巨标准，跟他那个论文里面几乎一致，他开始一步一步拆解，initially任therefore？初始情况下，然后因此也是按照步骤一点一点来的。
	Ok这个属于什么呢？属于测试样例对。通过那么我们看看通过的这个测试样例ok了。
	我们回答一下上节课这个问题。我们当时说过，在讲这个注意力机制的时候，高频不一定是重点，那么就是为了这里埋一下这个伏笔，我们看看现在的GPT3.5。今天的我相信这个示例大家拿去试应该也是类似的。但可能问的足够多，他也许会学到一些什么。
	那么就这里这道题我们问什么呢？就是还是昨天上次那个课的场景，我在一个繁忙的一天结束后，去我最喜欢的咖啡店放松一下，然后我就开始折腾他了对吧？我去了咖啡店点了5杯拿铁7杯美式，三杯拿铁是热的，有四杯的冰美式。这个时候有些模型理解能力不强的话，他就直接把这个拿铁认为有8杯了，美式有11杯了，对吧？但其实这里有蕴含关系。大家还记得GPT1，我们讲GPT1的训练的时候，那个时候的自然语言理解能力里面最重要的就是理解化跟化之间的一些相关关系，是蕴含、是矛盾、是无关，这是一个蕴含关系。
	然后我找了一个靠窗的位置坐下来，跟我的答案没关系，对吧？我不知道大家看过一个小品没有，就是宋小宝吃面。然后最后考别人问题就问了一大堆，上下上了几个人，下了几个人，上了几个人，下来几个人就问我过了几站，对吧？那其实这个一样的逻辑就是跟你问题强相关的是什么？这里如果你的这个上下文太长的话，他说不定都过了那个窗口了。那我们这里的窗口还好，因为它内容很少。现在我们回过头来再看，他跳过了这个靠窗的位置。巴拉巴拉这个不重要。
	然后喝了一杯拿铁咖啡，对吧？然后送给了朋友五杯美式，然后我又喝了两杯热拿铁。Sorry，我这个地方应该是打错了，就是给了朋友五杯美式和并且给了朋友5杯美式和两杯热拿铁。看着窗外的人匆匆忙忙很惬意。然后我从咖啡店出来了，回到了家中，到家的时候还有几杯咖啡。
	大家觉得GPT3.5能打对吗？显然答不对。对他怎么做的，他仍然在用这个chain of source。大家可以看到他的这个理解，第一初始订单理解对了，就是五杯拿铁七杯美式咖啡的剩余情况。三杯减去两杯热拿铁等于一杯热拿铁。冰的美式是四杯，冰的拿铁零杯。到这儿就已经整不对了，他就把那个三杯是热的，然后四杯是冰美式，这事儿就有有点整的有点整不明白了。
	其实你会看到整个什么咖啡剩余情况这一段是有点迷糊的，就不知道他为什么突然说这个，他又说这个送给朋友后的剩余情况，就送给朋友这个5杯美式和两杯热拿铁对吧？他这儿还能知道热拿铁是拿铁的包含关系，就是我可以用五杯拿铁减去两杯热拿铁等于三杯。美式是7杯减5杯等于两杯。
	回到家的时候，两杯美式，三杯拿铁，还居然多了一杯热拿铁，对吧？很奇怪为什么还会多一杯热拿铁？他把这个地方整错了，就我们刚刚说的点了五杯，然后其中巴拉巴拉这个事儿他没有整的特别明白。其中里面他把这个两杯三杯热拿铁和送的两杯热拿铁也又去做了擦纸。所以其实整个咖啡剩余情况和送给朋友后的剩余情况可以看得出，对，是两条思维逻辑的结果。然后最后又去做了合并。
	我们后面讲这个更复杂的思维链的时候去讲，就待会儿但是这里就搞错了对吧？就这个明显答案不对。这里其实我们会会发现就是说它有两个分叉的逻辑，然后又合并之后导致了错误。但这个我们先暂时不去深究，它就是3.5在这个问题上失败了对吧？
	首先这个问题难不难？对于一个正常人来说肯定是不难的对吧？你问一个小朋友，小朋友上一二年级，然后你告诉他拿铁咖啡都是热的和冰的，然后拿铁是一种咖啡，美式是一种咖啡。然后你把这个问题描述给他他肯定是懂的对吧？但是这个GPT不懂，而且我相信刚刚我说的那个前置的知识，就是咖啡是有拿铁和美式，有热的和冰的，一定学过。但是整错了。
	那么GPT4能不能搞对了？GPT4很聪明，我们看看GPT4，它的逻辑链条没有那么复杂，它就是把注意力机制整的特别好。我们看看它是怎么整的，首先他最关注的是问题，他对我们的这个prompt到家时我还有几杯咖啡，理解问题理解的更深刻。我还有几杯咖啡，我问你我还有几杯美式和拿铁了吗？没有，吧？那美式和拿铁，首先冰的和热的这事儿好像我就不会去关心了，我还有几杯而已。然后完了之后我还有几杯美式和几杯拿铁也不重要了。所以他首先把问题理解的非常深刻，所以他因为问题明确了，那你中间过程也就简单了。
	好，你看他写的最初购买了5杯拿铁和7杯美式，十二杯咖啡喝了一杯送给朋友。5杯美式喝了一杯拿铁，然后还喝了两杯热拿铁。这个地方他以为我又喝了两杯热拿铁，不是送给朋友，不过这不重要，最终结果是一样的。所以总共消费了什么，他是这样算的。
	他把这个问题变成了一个简单的数学公式，对吧？就是一开始有多少，用掉了多少，最后还剩多少，变成一个数学公式了。这个数学公式就变成了一个12减去八还有四的一个过程，对吧？那这个你会发现它对于这个最终的prompt，因为我还有几杯咖啡，其实是那个prompt上面那一段话，算是他的in context对吧？是他的这个上下文的一部分。他对于prom的理解是非常到位的，所以他能够去去除掉一些不重要的信息，把问题变得更简单。
	GPT4做到了，刚刚大家还会觉得这个生成网页那个例子好像GPT4不行，对吧？这是紧接着问的一个问题，GPT4在逻辑推理上到位了，对吧？所以他并不是变弱了，他只是变得可能你得去学会跟他沟通。你看我这边有在继续去问，剩下的具体是什么咖啡？然后他这边有说一个更严谨的计算，他并不是整不明白咖啡。他告诉我最初购买了五杯咖啡，其中有三杯杯是热的，然后七杯美式里面其中有四杯是冰的。这个包含关系他拿捏的很到位。
	然后他说我又喝了一杯拿铁和两杯热拿铁，这个是我故意使了个坏，对吧？大家有注意的话，我这边有写我喝了一杯拿铁咖啡，我可没说我喝的是热的还是冰的对吧？但他理解热和冰这件事儿。他首先说我消耗了三杯拿铁，剩下两杯。然后我给朋友送了5杯美式，剩下两杯美式。那这个时候他就会说我回家的时候，剩下的四杯咖啡当中，首先他能分金属，有两杯拿铁，两杯美式。但是他没法确定这些剩余的咖啡中多少是热的，多少是冰的。这个就很有意思对吧？
	与我们一开始描述买了5杯和7杯的时候，是说清楚有几杯热的，几杯冰的。但我喝的时候和我给朋友送的时候我没说。所以这个时候他没法判断，那这个就很很到位了，因为他没有乱说，他是明确的知道他知道什么，他不知道什么，并且他没有上圈套，这是GPT是很强的一点。
	Ok我们回到这个过程当中，思维链其实是很重要的一件事情。思维链让我们的GPT不再是一个鹦鹉学舌。就是我训练集里有什么我就能说什么，然后我只能去按照我的训练集里面来回答内容的这么一个模型。而是说他好像具备了人的逻辑思维能力，他开始能够去解读我们人体想要去让他回答的一些问题。这里就是在这篇论文思维链当中给出的在九种不同类型的基准测试里面的内容，我们待会会细看一下。
	第一个就是说在数学问题上，其实刚刚我们人去理解刚刚那个问题，就是咖啡的问题是可以把它抽象成一个数学问题。当我们问他有几杯咖啡的时候，它是一个数学问题。当我们问剩下的咖啡是热的还是冰的的时候，它其实是一个数学问题，加上语义理解的问题。甚至如果我们往细了讲，它还是包含一个常识问题。
	我们看到右上角这边有一个CSQA，它是一个常识类的问题。因为我们人其实都懂这些东西，好像我们天生就会了一样。但其实不是，对吧？你问一个刚刚生出来的孩子，他不懂刚刚说的这些常识，他不知道什么是咖啡，也不知道美式和拿铁、冰和热是什么关系。但是这个大模型会然后他也能把它转成数学问题，包括一些策略的QA以及一些对于日期时间的理解，这其实也是一个符合问题。包括对于一些运动项目的理解，包括我们能不能通过我们的大语言模型去操作机器人，这是一个CK这个数据集要做的一个事情，以及我们一些符号推理的逻辑。就比如说我们这个last data的拼接和我们的这个硬币的翻转，我们待会会细讲，都取得了很好的成绩。
	首先我们看的是在数学问题上面，通过思维链达到了一个什么样的好处呢？我们能看到这个数这个数据集或者说这个基准测试叫GSM8K它是一个由人类的问题的撰写者创建的一个差不多8500个高质量的，并且多种语言的一个小学数学的应用题的数据集。我相信大家都上过小学，小学的数学的应用题基本上是小学数学里面相对来说比较难的问题。但是就是这些问题，以前的大模型完全搞不定。包括像这篇文章，就是chain of thoughts这篇文章的作者也有提到。
	在年初的时候，这个大语言模型花了上千万的成本训练出来的。这个大语言模型在一些非常简单的我们叫99乘法表的这种算术问题里面还做不对。那这是为什么呢？那大家就在想能不能把这件事情，就把这个简单的数学问题也好，我们叫这个应用题也好，变成一个的基准测试，然后把它用来作为我们评估模型的一种手段，一种可量化的指标。这里这个GSM8K就是这么一个目的用来做创造的。并且这里还有一个重点，就是说这里的这些问题，它通常我们开始有提到最重要的事情是把一个问题的思考变成多个步骤。
	这个测试集就是他的所有的问题通常都是需要2到8个步骤来进行解决的那整个我们看这个测试结果来看，首先使用了chan f sort的效果和没有使用有很大的区别，尤其是在我们看这幅图，尤其是在大规模的模型上面。首先palm是google开发的一个大约模型，GPT是OKAI我们一直在讲的。然后在这两个模型上我们能看到有非常夸张的一个解决率的一个上升，就简你可以简单理解这个解决率就是我把这个问题做出来了，通下面这根线呢是我们的这个标准的prompt的方法，而上面是使用了思维链的方法。然后这根线呢其实是之前的有监督的最好的效果，或者说达到的水平。可以看到其实它已经超过之前的这个水平了，尤其是在我们模型规模比较大的时候，我们下面这个X轴是这个模型规模。在这个模型规模比较大的时候，你看那个pom就是google的第一代的大元模型，540B就5400亿的这个参数上，通过chino lt取得了非常好的成果，并且他的鲁棒性也很不错。就是说整个模型它其实是由不同的人来构造的范例，以免出现这种偏差，仍然具有非常好的效果。
	就我们看这幅图的话，标这个黄颜色的是我们的标准的提示词的方法。然后这根橙色的是我们的使用了思维链的这个方法，右边是通过不同的抽样来的这个方法，它的鲁棒性仍然很好，包括我们刚刚提到的这种常识类的问题，整个常识类的我们刚刚有提到有五类。在这篇文章当中，这些常识类的问题都通过我们的sherm source取得了一些提升。然后右边是通过表格的方式跟大家展示在不同规模的不同类型的大语言模型上，使用这个CHNF source带来的提升。绿色的部分就是我们看见这些是比之前更好的，大部分时候是比之前更好的，并且是在越大规模的模型上越有体现。
	Ok然后一个简单的结论是什么呢？就是说对于我们的我们的思维链的这种提示手段来说，首先它对于小模型它的性能提升的不多，甚至有可能带来性能的下降。因为它不一定能够理解你这一长串的这个逻辑是什么，反而变成了干扰。但是对于大模型来说，这个思维链这种提示的方法，涌现出来了一些新的性能，尤其是对于一些复杂的问题，它能够获得更多的性能收益。比如说我们刚刚看到这个GBT4的例子，我们一个物理题又需要理解这个视觉信息的输入，还需要理解这个文本信息的输入，还要把这两个输入去做合并，然后变成一个问题的解答。通过这个思维链的方法，我们把这个事情给做到了。
	那这个事情你怎么做到的呢？其实有一个论文当中提到的，我们像咒语，像黑魔法一样的一个prompt的词就叫你一步一步的去想，就像我们在教导一个小朋友一样，你告诉这个大模型，一步一步的去思考怎么样去解决这个问题，就是这么一句简单的词。这就是我们思维链一开始的黑魔法。我们研究这个大语言模型一开始就这一句词，然后这一句词被反复的使用，应该在今年上半年，尤其是Q1甚至到Q2初期的时候，这个词还简单的prompt还被大量的使用，就think step by step，确实是有用的一个简单的例子。
	我们还是实测了一下现在的这个大模型，3.5GPT3.5我问了他一个很经典的问题，就是我六岁的时候，我的妹妹只有我年龄的一半，对吧？然后我现在已经70岁了，那么现在他多少岁呢？理论上这个问题小学这个应该算是小学生都可以回答的问题，对吧？那么GPT3.5回答对了吗？
	没有，他怎么回答的？就是首先他他把我的妹妹只有我年龄的一半变成了一个世界，知识变成了一个常识。所以他写的是当我70岁的时候，我的妹妹年龄还是只有我的一半，就是35岁。所以他得出来的结论是35岁。这个其实就是他跳过了年龄一半这件事情的更深层次的含义，对吧？就是不是告诉我有一个事实，谁是谁的年龄是谁的年龄的一半。而是说我现在六岁，他年龄只有我的一半，算出来我们是差三岁的。所以同样是这样的一个gd 3.5，我在接下来来的提问里加了这样的一个词，它到现在仍然是有效的。
	所以这个词这个小的技巧，这个trip到现在依然是有效的。那么问我们还是问他，就接着问他，他就把这个step by step这件事情给听懂了。所以他就会发现，我要是细想一下的话，我六岁的时候他只有一半的年龄是三岁。所以核心不是告诉你一个事实是年龄一半，而是说告诉这个差值是三岁。那么当70岁的时候，可以利用年龄偏差的不变，变成了70减去三变成67，所以最终是67岁，这个他就答对了。所以你会发现这个trick到现在也依然有效，这个是一个很有意思的trick。
	然后也是这篇论文第一次让大家发现跟大模型沟通是有艺术的。然后或者说是需要学习的，是有工程的这个思维在里面的那怎么样去让他能够思考，这里我们就会引入后续的一些发展。就是当我们的一个学科也好，一个研究方向开始去从0到1的时候，是最难的。就是我们需要有一个chain of sorts这么一个开放性的一个成果。但是再往后走大家就会发现有很多学术研究的套路和可可参考的点了。
	就比如说接着我们要讲的这个自洽性，叫self consistency，就是这么一个思路。是干什么的？一句话来说，它其实是用了多路径的推理。这篇文章也是google的团队做的，并且也是接生为接着去研究的。
	大家可以看到这个黑魔法，就我们刚刚讲的这个一步一步的去想这件事儿，是在复杂推理的任务上有一些成果。刚刚我们有看到在各种各样的事例上面，在数学问题、在常识问题，然后在一些符号推理的问题上都有这个成果。但是有没有可能把它做的更好一点？有，首先这篇我们叫自洽性的这篇文章发在了ICLR，这个也是一个计算机的顶会上面。2023年的这篇文章在已有的CHAF source的这个基础上又取得了更多的提升。有其实在这个数学问题上，就这个GSM8K刚刚有上面解释，小学数学应用题对吧？还获得了一个将近20%的提升。
	那他是怎么样去提升的呢？这个逻辑也挺简单的，就是一句简单话就是multiple different way。就是我已经链式思维了对吧？我能够一点一点的去想了，那我能不能多来几条链？就跟开始我们讲这个咖啡的那个问题上，好像他GPT的这个3.51开始想的那个逻辑是剩余情况和喝掉的情况。这两条链，但是它合并的时候没整明白。那么那那一部分的问题其主要出在尝试的这个就是常识知识的这个上面，就跟我们刚刚聊这个年龄差，他明明应该学到的是这个年龄差值是3，而不是年龄差是一倍。
	这件事我不再展开，但是我们讲一下思路，就self consistency它的核心是什么？它其实按照中国一句俗话来讲，就叫三个臭皮匠顶个诸葛亮，对吧？我不管你的语言模型本身怎么样，我跳告诉你的语言模型，我提供了一套思路。这个思路是在语言模型不变的基础上，我可以让语言模型有多条思维路径。然后这多条思维路径我可以根据大家的你说加权也好，平权也好，根据你们不同的这个结果，我选一个少数服从多数的答案，对吧？这个其实一句话来说明白，就是这个多路径推理就是干这么一个事儿。
	我用多条不同的思维链条，来做这个CAL of source的推理，然后推理出来的这个结论在合并。但其实这里跳出来看，就是如果大家了解这个计算机的基础算法的话，会知道有一个算法叫做贪心算法。那么标准的这个chalk source pro prompt这个逻辑会被又被定义成叫greedy的decode，叫贪心的编码。朴树贪心的编码可以简单理解成就是以前大家用贪心问题就贪心算法去解决问题的时候，通常就是我每一步都选择当前的最优解。然后我期待通过这样的方法能够拿到全局的最优解。
	但是这种算法它只有一定特定的满足一些特定条件，满足一些特定问题定义的时候可以去这样做。但大多数时候局部的最优解的叠加并不能变成一个全局的最优解。那我能不能在这个多条思维链的过程当中去找不同的解。其实在这儿开始就已经有这个数据结构，就我们经典的计算机的数据结构，包括这个计算机的一些算法，跟这个大模型开始结合的一个点。我们最早讲那个雷达图，大家如果还记得的话，就是我们知道这个最重要的是动手实践的能力跟大模型应用。然后接着是我们能够有这个meta knowledge的能力，然后我们有跟大模型交互的能力。这个其实就是跟大模型交互的能力。我们的prop的engineering的水平就决定着我们能多能能怎么样去挖掘出大模型的潜力。
	这里的这这个三条路，其实就是三个不同的思维逻辑。你可以理解成三个不同的位也是可以再去增加的这完全只是一个算力和最终结果的一个平衡的问题。通过这样的一个手段，我们又进一步去提升了这个思维链的一个能力。我们看到这幅性能的指标里面，这个self consistency就是下面这一行。然后右边这个括号里面是指它提升的这个性能，相比于我们直接用这个CAAPP store，其实是有蛮多的提升的。然后包括右边我们能看到在不同的这个基准测试上都有提升。
	然后在下面这幅图，其实是指我们的不同的采样。我们通过这个single pass，就是我们叫greedy的decode，叫贪心。因为它只走一条路。局部最优对吧？只不过这个部最优的这个算法，就怎么样算是局部最优或者单步最优是大模型来决定的，咱不知道。
	通过局部最优跟多种方式，就我们的self consistency去做对比，能看得出来在一些常识问题，包括数学问题上都有非常多的提升。但是通过不管是我们聊思维链也好，还是讲这个self consistent y也好，我们都看到了大语言模型的一些特点，或者我们叫大语言模型的优点和缺点，强和弱的地方。首先大模型在逻辑和推理这个能力方面，它确实不算特别擅长，这个是我们已经看到的，到现在还停留在这个小学数学问题上，对吧？他强就强在哪儿呢？
	就是随着模型规模的变大，我们的语义理解能力，大家还记得这个GPTE叫improving language understanding，对吧？我能理解你的语义，至于这个语义有没有多深的多多深的这个逻辑，我们就是这个语义背后的意思，有几层逻辑。这个理解其实是更深的一个理解能力，但我们至少你表面说的话我能理解。然后在一些符号映射，符号推理，比如说代词，包括一些连贯的文本生成方面，是有一个大的能力的飞跃的。然后也因为这些东西，我们使得这个多步骤的推理，就是我们讲的这个chair of sorts成为了可能，然后才带来了智能的涌现，就比如说我们以前的大元模型，就是干点感觉就像是这个人文学科中文系干的事儿。但现在因为有思维链，它能做一些逻辑推理的多个步骤了，甚至是多条思维路径了。这个事儿是非常让人兴奋的。
	但是也正是因为这一点，反过来看，其实暴露的他其实依然是所谓的这个鹦鹉学舌，而不是真正有意思。这也是为什么乐坤一直在抨击这个大模型，我们现在也不好直接去判断说这个是不是鹦鹉学舌，只是说这打了一个引号。但是确实暴露他没有这种复杂逻辑的推理能力，就是大模型原生不具有这种能力，或者说我们人类还没有找到一个非常好的方式去挖掘出他这个能力。
	Ok, 但是我们能看到的是，如果我们不使用这个思维链，就我们在这个china f sort这篇论论文当中有看到我们使用这种标准的提示词的方式。它其实是不太能做逻辑推理的。无非是说如果我们提示词人做的不够好，我们能看到现在OpenAI它的CATGPT本身自己开始把人的输入手动的，或者说通过他的这个CHATGPP的这这个应用，再它拆解成类似于这个思维链的方式，然后去给到人，相当于是降低我们的使用成本。因为最终你会发现，提示词的这种使用手段，肯定只是一个中间状态。更多的还是更符合人的交互的这种方式是能推广出去的。所以他会把这种提示词的工程逐渐的做到应用本身去。
	对ok这里再引申一个点，就是说为什么会出现这样的一个现状，这里引用了这个新资源的一张图，实在是找不到很好的一个图。就是在认知心理学这个领域其实有一个，而且这个教授他其实是提出了一个概念，就是人去做思维也好，人去思考问题也好，其实是有两个系统的，有点类似于我们以前经常提到左右脑的这个理论，就只有两个系统。然后这两个系统通常来看一个系统是叫做下意识的，或者说无意识的一个思考模式。它的特点就是很快速，然后是几乎是自动的，就是你都不需要再做什么深度思考。我们讲肌肉记忆也好，讲这个下意识也好，讲潜意识也好，它是这样的一种思考模式和系统。那我们的大语言模型现在就非常像左边的这个系统。一还有一种系统是叫做这种有意识的，它相对来比较慢，他是深思熟虑的，他需要去做规划，去做设计，他很有逻辑，然后他能不断的抽象。就是为什么我们看到马斯克现在要去做一个公司叫X点AI他其实是想说我们能不能通过AI去解决system 2的问题。
	就是我去不断的从世界常识里面去提取出世界的运行规则，我们这个世界到底是如何运转的那这种原则性的东西，普遍性的东西，逻辑性的东西，其实是目前我们的这个基于自回归的这种大语言模型还不是特别擅长的，至于它是不是完全不会，这个我们不能下结论。对好，刚刚我们有提到跟大语言模型沟通需要技巧。然后我们有通过思维链的方式，让他去把一个简单问题解决好之后，复杂问题能够拆步骤解决。然后拆步骤解决，如果都不太能回答好问题之后，能够有多条思路。
	三个臭皮匠顶个诸葛亮，对吧？大家一起来想群策群治，然后我们少数服从多数来解决问题。既然都已经到这个状态了，那是不是我们可以把这个source这个思维的格。去再打开一点，把计算机的各种手段再引入进来。Google和普林斯顿大学，他们最近有一篇文章，其实就是在解决这个事情，并且把很多经典的计算机的算法的内容都加进来了。
	简单来看我们发现他跟之前讲的这个self consistency仍然是有关联关系的。首先他做了什么事情？他做了一个评价，就是说之前不管是最基础的方式，就最基础的这个standard的的方式，还是我们的这个chain of source，还是我们的这个self consistency，都有一个问题是什么？它是一个从左到右的，就是left to write答案这个感觉又来了。
	今天我们又提到这个GPT1，我们的这个GPT1最早就是一个从左到右的序列，对吧？然后从左到右又被拿出来讲了，是一个只会从左到右看的一个决策过程。然后同时他他虽然用了多种不同的思维链条，就我们讲群策群治，但是他因为没有往回看，所以就是大家没有反思，对吧？吾日三省吾身，他没反思，他没往回看的话，他的这个决策是做不得非常好的。并且大家虽然有了多条思考路径，但是在这个思考路径的方法论上，没有给出一些非常好的指导意见。就是我只知道我要多个人来一起想，那怎么想呢？怎么样尽可能让三个不同的人都想的不一样呢？这个其实是一个更需要去探讨的一个手段。
	所以在这篇论文里面，他把之前的这个几种提示词的方式做了一个示意，然后这个示意我觉得很直观，大家可以看一下这个示意，第一就是我们最早的这种standard的这种提示方式，它叫做inside out。就是很直接的就给你一个什么就就给你给模型一个什么样的输入，那他就直接给你一个输出。中间是没有这个拆解的步骤的，它可能直接就是一个基于概率的抽样，一个分布的抽样，就把结果拿出来了。然后我们的chain of thought，其实是有一个拆解的思考过程，有可能在大模型的内部，你可以理解成它分成了多步的问询。
	就是他先把这个问题拆成了几部分，每一步都会跟大模型去做一次思考。这里的每一个灰色的小方块都是一个完整的sort，然后一条线考虑完，然后给你一个答案。然后我们刚刚讲的这个self consistency，其实是我有多条线，然后我都会得到答案。这个多个答案我最终来一个少数服从多数的一个投票，对吧？那这个项目像以前机器学习统计学学习里面经典的这种model，就会有多个不同的模型，不同的模型能得到答案。就GPT4本身也在内部也有一个这样的一个就是有N个大家可以理解。现在我们看到至少目前披露的是八个大模型。八个大模型会大家来做群策群力的一个投票。
	那么我们的train of thought，我们的这个思维数其实更进一步，就我不再是一个多条不同逻辑推理的一个线性关系。我其实是一个树状关系，并且我这个树状关系本身还可以分叉。就我第一我能节约资源，第二我能并行？第三这里面还有很多数据结构和经典算法的文章可以去开展。
	那具体怎么做的呢？我们先看它的效果，它有什么样的效果？在一些比较复杂的问题上，比如说24点游戏，我不知道这个大家玩过没有，就是给几个数字，然后你去铺排这个加减乘除，然后让它最终变成24。在之前的这个几个方法里面，我们能看到这个K等于100是只有100个这个思维路径。然后我们可以看到其实在24点这个游戏上是压倒性的一个胜利。我们最直接的不给这个chell source，然后给shelf source，然后给了这个sales self consistency 9%。然后用了这个四位数，就tree of sorts达到了74%。
	这个B等于五是指它的那棵树。我们最终可以看到那棵树状结构，它可以用两种方式去去搜索这个结果。他用的这个广度优先搜索的层数到5层的时候，你可以理解成思考五步，简单的写成能达到74%的一个成功率。这个是非常夸张的一个进步了，这几乎是一个数量级，就七八倍的这么一个增长。这个是在24点游戏，然后在这个创意写作和这种填字游戏上，也是取得了非常大的一个进展，几乎是翻倍的性能，这边是四倍的一个性能。然后这个我们就不再细展开了。
	我们讲一讲这个设计灵感的来源是什么？就是为什么我们从这个标准的in input output到这个chain of sorts，再到这个self consistency，这个动机是什么？为什么这帮人要想做这种复杂数据结构，包括搜索来跟大数据，跟这个大语言模型的一堆数据里面去找出我要的答案呢？其实这个是一篇非常早的论文里面有提到这么一个思路，这也是他们讲好这篇论文故事的一个关键。
	就在1959年的时候，有一篇论文里面有提到。就是一个真正的问题解决过程，其实它是涉及到要反复利用可以用的信息来启动这种搜索。就是去找个通过搜索来找各种各样的信息，然后进而去揭示更多的信息，直到你最终发现达到解决问题方案的这个方法。这个描述就特别跟这个tree of sorts的设计思路非常贴近，也是他们在论文里面直接去引用的这段话。
	我们具体来看下面的这四个步骤，就是我们的这个TOT它是怎么样去做的。第一个就是说第一步要做的事情跟shelf sort一样，我们要把这个思维去做一个分解，就要把这个问题去做一个分解。但是它的区别在哪里？就是像chell source，它其实并没有给我们的大模型太多的偏这种方法论，或者说meta的这种信息的摄入，或者说引导它更多的是给你一些参考样例。就比如说我现在要让大模型去做，开始看到那个私立去做这个网这个有几个网球和有几个苹果的事儿。然后我只是给了你一个示例，就是我的这个网球有11个是我算了的。我本来有五个，然后我有两个筒的网球，每个桶里有三个，就这样的方式去给他一个参考示例，但是没法去用逻辑的这个方式去描述它。
	在这个TOT里面，他是非常希望说我们一开始能够把这个问题给他做一个思维上的一个分解。就比如说我们把它分解成几个部分，就24点游戏来说，我们分成几个部分。第一个部分是它有input，比如说四个数字，然后有output是有一个方程或者说说一个等式。这个等式的目的是为了用输入再加上运算符，最终变成24。它需要有这个中间过程的等式，或者说我们叫这个恒等变换。好的，这个等式的变换也好，通过这样三个步骤去描述出我们这个24点游戏对于我们的这个TOT来说是什么样的一个概念。
	然后这里会有一些技巧，也是这个作者在这个描述的时候明确有写的。就是说一个思维它应该足够的小，他这样能够方便语言模型去生成有前景并且多样化的样本。有每一个思维或者说每每一个节点。我们还记得刚刚那幅图里面，一个思维就是一棵树里面的一个节点，它有足够的小。但是这一颗小的思维，它是能够生成有前景并且多样化的样本的。
	这个地方的前景你可以理解成可以往后多想一步，并且是多样化的，那这个地方怎么样去理解这个小或者说这个大呢？他他举了一个反例，比如说在这个创意写作里面，你如果要去生成一整本书，通常就太大了。就跟我们开始举了一个例子，我们让让GPT4去生成一个AI大模型，这个训练营的网页。这个其实相对来说就是比较大的一个事儿。
	你最好能够让它变成像这里描述的一样，就是你要写四个随机的句子，这个其实就是一个比较具体的事儿了，然后我大概应该把这个问题描述清楚，对吧？就是你要能够有抽象的逻辑步骤，然后你对每一个四维数当中的节点尽可能是精确的，并且让它能够往下一步去做生成。然后它还能有多种选项，以这种方式这种思维的方式去构造你的这个source。然后第二个就是说我们要做一个思维的生成器。不好意思，我看到有助教给我发信息。好。
	好，第二步是做思维的生成，我们会做一个思维的生成器。然后这个思维的生成器它是干什么生成的？首先单来说他首先会给这个树一个状态，然后这个状态要生成K个候选项。我们这个树你总得每一个节点，你就简单说这棵树每一个source那个小的树的节点，他都不是说我直接就给你的。
	就跟我们开始举例子，这个大模型都会给出top k的这个选项一样，它会有K个候选项。那这K个候选项一般会怎么样来的呢？就有两种方式。一种是比如说像创意写作这样的，它是符合一个独立同分布的一个抽样的思维，那我就直接去做这个抽样就好了。第二个是说它是这种逐个的提出的思维。比如说这个24点游戏和这个迷你闲置游戏，然后它是逐个的去往后去做这个填写的那它其实是就这两种方式。那这K个候选项就是为我们这个数往往深度去生长的时候，去生成的一种方式。通过这两种方式我们能知道怎么样为下一不去做这个生成。
	然后生成了之后我得去做评估，吧？就是我到底要用哪个？这里其实他参考了之前的一些方案。就比如说比较有名的两个人工智能的里程碑，一个是深蓝，一个是阿尔法go。然后深蓝其实是通过这种编程实现的方式。阿尔法狗是通过这种learning，通过学习的方式这两种方式去解决的。
	但是这两种方式的启发是他们核心都是用来做启发的。因为我们是一个搜索问题，大家了解这个搜索问题的话，启发式搜索是为了提升搜索效率而做的一种思路的一个方法。这种这两种方式都不是作者采用的方法。作者其实是选了第三种方法，就他自己想的一个方法。这个方法是干什么呢？其实他用到了语言模型的优势，他让这个语言模型去所谓的做有意思的一个推理。就他他主观的有意识的在去做这个状态的推理。然后这样的一个有意思的启发式的方法，可能比你手动的去编写规则更灵活。
	因为深蓝其实是一个偏专家系统，偏知识图谱的这么一个系统。学习模型相对来说又比较昂贵，就是它的算力成本，包括它运算的资源比较贵。这个我们在讲GPT3的时候已经提到了，就是你要去做一个learning的模型，会在每一次迭代过当中会消耗大量的资源。那这个code很高，那我们就能不能用现成的？跟GPT3的这个逻辑很像，就用语言模型现成的能力让他去做这个推理。
	与生与之前的第一步骤的这个生成器是类似的，然后就用两种的策略来独立或同时的评估这个状态。一种就是说独立的对每个状态进行评估，然后也可以去跨多个状态进行投票，就大概是这两种方式。那这两种策略都可以多次来提示我们这个语言模型本身聚合或者就聚合它的值，或者是投票，就是离散的来改这个结果，就对这个状态本身进行一个评估，然后去换取一个更好的启发式的方法。最终去取得一个平衡，就是我们的时间资源和这个成本的一个平衡。
	最后其实还有一个点，就是在这个过程当中，我们已经知道一开始要怎么去设计这个source，然后要怎么去生成它，怎么样去评估一个结果。但最终它是一棵棵树的结构，对吧？那最终是一这个树状结构，什么意思呢？就我们知道搜索算法通常是说这个解空间很大，然后我要在这个解空间里面去找到一个一个的答案，然后每个答案我会有一个评估的结果。
	然后通常来说我们搜索算法最常见的两种方式，一个就是我们的广度优先搜索，一个就是我们的深度优先搜索。广度优先搜索的意思就是我每一次只往后考虑一步，但是我把这一部的所有的可能的这个条件分支都去给他做了枚举。然后第二种是叫做深度优先搜索。然后我会规定一下这个深度优先搜索的边界条件。这个边界条件有可能是这个树的深度，也有可能是有一些边界值，比如说我的这个年龄不可能是负数这样子。那么深度优先搜索跟广度优先搜索，在整个TOT的论文里面其实都有讲，它适合的任务不太一样。然后通过这两种搜索方式，其实我们可以就整个完整的完成TOT这个我们叫tree of sorts。
	就基于就类似于这个数这个搜索空间数的一种很复杂的去构造到我们的prompt的这种手段来解决问题。所以要实现这个TOT其实本身也还是有难度的。这个作者也开源了他的这个论文的代码，大家有兴趣也可以去深入去研究。但这肯定是一个未来的一个发展方向。就是我们可以看到原来的经典的计算机去去搜索最优解的一些方法，被成功应用到我们的这个prompt的engineering这个领域里面来了。然后从目前我们来看，就是TOT作为这种用语言模型来做这些通用问题的求解的这些方法上，还是有一些优势的。就比如说我们看到的它的泛化性的点，在之前的提出来的这种standard的这种prompt，或者是我们的这个chief source，或者是chief sorts加上这个self assistances y，他们都可以看作是一个特殊的TOT。
	这个在论文里面其实有写前面的这个图，就图一就我们开始看到第一张图是有的。然后第二个就是说这个模块化，我们在做这个过程当中，其实刚四个步骤的每一个模块它都都可以去做演化，这个演化就会如果我们去简化的话，就会简化成前面的这个简单的提示词的这个方法了。然后同时它还可以针对不同问题去做调整。然后他刚刚有提到我们在时间资源和成本上可以去做这个调整，这个是它的一个适应性，还有一块就是说他不需要额外的训练，他只需要使用原来就已经预训练好的这个语言模型的能力就够了。然后通过这个语言模型再加上它的巧妙的设计，去完成我们复杂的提示式工程。
	Ok我们这里就把这个tree of tree tree of thoughts跟大家做一个简单的介绍。希望能开拓大家的视野去了解到。其实我们平常在公众号也好，在各种地方看到这种提示词的玩法，其实是正儿八经有人在做研究的。并且他的研究的深度现在也在逐渐的加深。这些论文都是一些很新的文章。然后我们其实大模型的理论基础的这个内容到这儿也就差不多结束了。
	然后我们已经追到了最前沿的文章。大家能看到2022年的lips，2023年的SAR和和上个月才刚刚发的这个true of thoughts。这些文章其实都是学术界最前沿的文章。如果有对大模型应用和理论本身非常有追求的同学，也可以沿着这个作者的研究思路去看他后续的一些研究进展。
	今天的这个授课的内容就到这儿结束。然后我这边正好做一个更正，就是之前有一页这个PPT应该是有一定的刊物的。这个主要问题是在我的检查上，就是在这个是刚刚助教发给我的，在这里就是我们的这个GPT1、GPT2和这个GPT3。这就是整个这张表其实也是由GPT4生成的，然后其中有一些内容是我做过调整的，在这个模型类型上面，这个单向语言模型和双向语言模型，包括这个多项语言模型确实是造成了一定的歧义这里可能不能用这个单向双向多向来表达。对，因为它本身更多的这个语言模型的核心还是在这个transformer的叠加上，在这个方向上并没有更多的调整。所以我们可以先不关注这个维度，更多的是看剩下的这些维度和我们刚刚讲到的BT1提出了这个pre train的预训练语言模型加find tuning的这个范式。然后GPT2希望把这两个步骤合二为一，变成一个多任务的无监督的一个学习机制。到最后的GPT3提出了少样本学习，就我们的in context learning和我们的prompt的引入，包括这个数据规模的增大带来的涌现，关注这几个维度上。对，好，那我们应该就到这儿。然后我看应该还有十分钟的时间，我看看这个直播的同学有没有评论区的问题，我们来挑一些解答。
	稍等，我进一下这个直播间。
	我看到有一个钱先生在问这个向量数据库的相关优化会不会讲？这个会的，就是我们会在南线的开发当中会去讲这个相关优化。这个同学问，下周三就开始实战了，要提前准备什么环境吗？这个是一个非常好的问题，下周三我们会开始使用这个embedding了。然后需要准备基础的就是我们的pythons的这个3.10的这个版本。然后我们最好是这个如果大家之前完全没有接触过pythons的话，先简单了解一下怎么样用这个pythons的安装环境。然后你喜欢用什么样的IDE，通常我们会推荐要么你使用这个VS code或者patroon这样的IDE，要么你就使用这个to pattern notebook这样的交互式的网页的开发环境。
	还有一个同学许宁问在做这个in contact的时候怎么样节省token？这是一个很好的问题，因为我们会发现token很贵，尤其是大语言模型交互的时候，有两种思路。第一种思路是说，如果我们做的这个应用场景，通常是有很多先QA的场景的话。其实大多数时候，我们都知道很多网站去访问的时候，都会有一个东西叫FAQ，叫最常问的问答。那这个思路就会直接被引用到向量数据库里。就是如果你是一个QA的应用，然后你会有一些常用常见问答的话，使用向量数据库一定是能帮你解决问题的。因为你都不需要再去访问大模型了，那这个头疼就会还好。
	第二种就是说这个in context比较复杂，我还是必须得去访问大模型怎么办？这儿其实就会存在一个我们刚刚讲咖啡的例子，很好的一个示例。就GPT4它其实在我们回到这个例子，GPT4在我们找一找在解决这个问题的时候，他其实关注的点是什么呢？他关注的点是几杯咖啡，对吧？那么几杯咖啡跟什么拿铁，还是什么美式、冰的日子都没关系。这个时候你就会发现上面的context是不是有很多内容都不用再输进去了。
	这里是需要咱们去做预处理的那其实南线的价值也在这儿。因为我们在做这个预处理和这个后处理的过程当中，其实最好是能用语言模型本身，对吧？就跟刚刚我们讲这个trail of thought TOT1样，能尽可能借用语言模型本身的能力来帮我们做处理，这个是蛮蛮重要的。然后这里就很tRicky。对那个逻辑我相信我表达清楚，就是你在给他上下文的时候，能不能让他去简化他的上下文？就是你因为你之前历史的每次都会发全量文章，全量的这个内容，那你让他直接输出一个简化的内容，关注这个问题的，然后把它作为后续的上下文。
	对。有没有p two 0的实战？这个我不清楚他问的具体是什么。Tony, 然后对大模型的参数量怎么理解？就是什么6B13B175B这个很好理解。
	我们刚刚有看到，我们整个首先这个同学我不知道有没有听上一节课，上一节课我们有讲transformer对吧？Transformer这篇论文叫attention，就是OND的。所以首先里面没有RN了，但是他有有注意力机制，机制其实也是需要去去学的对吧？我们记这个注意力机制有哪些地方需要学吗？我们的alignment function，我们的这个对齐的方法需要去学。那这个对齐的方法是一个什么？是一个个矩阵，高维的矩阵。
	那这些attention位置需不需要学？那么这些更新位置一开始在这个transformer里面可能是还比较少的那到了GPT3的时候，都已经快100层的这个transformer了，那GPT4可能更多。这些参数就是我们刚才讲到的attention位置可能是当中的一部分。还有一些它没公开的架构，这些参数就是我们模型的参数。
	然后有同学问对对于这个论文的代码，该怎么样去结合代码理解论文，学习论文的代码有什么技巧吗？比如说要带着什么样的目的去看代码？首先这个论文和代码一定是两个东西，并且能公布代码的论文是非常稀有的，就是算是非常好的论文了。如果这个论文它公开了代码，首先你可以通过代码去验证它的结果，对不对？就是有因为有很多论文，他为了投稿也好，用了什么也好，他其实不一定那个实验结果是好复现的，尤其是现在大语言模型对吧？
	那如果我们现在是学一个特定的技术，比如说我们要学这个trial of sorts，那这个时候我觉得有两个点。第一个点就是说对于一些特定的关键算法流程，就比如说我们刚刚说到的这个状态评估，他可能会给出一些典型的实现。那些典型实现是有论文代码的那这个论文代码其实如果让我来说的话，我现在肯定是不会自己一点一点去读这个代码的。我更多的是可能会通过这个大元模型丢给他，然后告诉他这个代码可能是一个什么样的内容。就跟他的就相当于把它论文本来对这段代码的描述丢进去。我这下面这段代码是实现这样的一个功能的。然后你帮我去解答一下下面这个代码跟上面这个论文之间是什么样的一个对应关系。可以先尝试直接去这样提问，他能不能帮你解答？
	如果他能给你一些还比较粗的解答，就可以沿着他继续去深问。但是也不可能是说你把它整个代码库直接丢给一个大模型，然后让他跟论文去做一个直接的映射，这是比较难的，还是需要我们去找好这个问题的切片。Pythons 3.11可以。
	扩大的环境，包括我们后面的这个模型的微调，我们其实今天的热点问题就有聊。这个是在私有化部署的时候才会需要然后用公有云的服务器或者用自己私有化的卡都可以。TOT是如何被发现的？首先这个不是被发现的，它是基于这个设计的灵感来的。这个TOT是一个很巧妙的把计算机的经点的数据结构和算法，和我们的这个提示词工程学做一个结合的一个实践。所以我们更多的是说沿着这个我刚花那么多时间，我的小明同学需要在在回去看一看怎么样从这个in note到这个chain of source，到chain of sorts of这个self consistency，就是我们的自洽性，就是多条思维路径对吧？再到多条思维路径本身还可以再做优化，这其实是非常自然的一个过程。
	在哪儿有TOT的开源代码？在论文里就有。大家去好好看一下，我们这个地方摘要里面就有写，这篇文章的摘要里面就有写，大家可以去看一看。对，3.10或者更高的版本就可以。对大家关于pythons的版本和这个pythons的编程环境这件事儿，我们回头在这个群里面单独发一个这个怎么弄的指导手册。对，TOT是用在提示工程上，它不会动模型的参数。
	林鹏问从哪里可以学习到大模型最新的资讯，有什么学习路径或者网站可以推荐一下？从我们这儿，从我们的群里问，群友的智慧是无限的，大家都是同学会一起群策群力的。第二个就是说去关注一下像OpenAI、sam奥特曼、mask这些些最牛逼的人，他们的twitter他们也会去发的对。这个问COT至洽和TOT给例子的。其实刚刚论文的截图里有例子，然后论文里面也有例子，我们就不再这儿再展开了。
	问构建应用的时候，这个CHF sword TOT怎么应用的？模型实现还是工程实现？这个是好问题。首先你们要理解CATGPT本身就是一个应用，然后你会发现ChatGPT正在实现这些内容。因为这些内容就跟当年CHIGPT在做IHF的时候，把这个反馈的结果这个top k的这个top 1做的更让人觉得舒服。他就是在应用侧去实现的这些内容。未来来看的话，一个好的应用一定是应用做多一点，用户才会感觉舒服一点，用户才需要做少一点。
	然后模型是肯定不会通常去实现这样的功能的，因为模型的微调成本是很高的，并且模型的微调现在是很玄学的对，就是你一个最简单的例子。为什么今天这个ChatGPT的GPT3.5还在使用text达芬奇002？这是两年前的模型了，为什么还在用它而没有用text？达芬奇003对吧？有可能是他能力更强，有可能是他的结构更好，有可能是他的这个巴拉巴拉各种原因，所以是一个玄学问题。现在这个大模型的微调。
	阿里云上的虚拟机可以作为实战开发环境。课件中的论文在极客APP中怎么找到？这个我建议班主任回头一定要有个截图发一下。本来今天的热点问题也有回答，就是我们的相关论文在极客APP里，但是没有写的很细。还有个同学问这个prompt learning tuning COT都是in context learning。这一题刚刚讲过的知识，怎么就忘了呢？这个我们在。再给大家跳到这一页。
	我们刚才有提到这个from的关键是引导输出这个上下文是为了让我们的大模型获取更多有效信息，这是不一样的。一个侧重的是输出的内容偏任务，一个是任务能回答的比较这个好，会给一些上下文，包括指代之类的对，但这两个未来会越来越往中间走，这是比较明显的。好，我们最后再再回答两分钟的问题，到10.05我就得去吃晚饭了，同志们。
	这个TOT有没有类似的提示词？没有，我们刚才讲了TOT是一个偏这个真的是一个工程设计了。他他还是这句话，就是no free lunch，没有一招鲜的东西。这个think step by step，咱们先用好。
	然后再就是我觉得最好的一个实战，就是包括跟大语言模型本身，跟GIGPT的交互。就是咱们像我今天举的很多例子一样，跟3.5跟四去聊，然后换一些这个不一样的，这个其实持续跟他聊。涌现能力这几篇论文咱们先消化掉，就是今天推荐的这几篇论文。咱们不贪多，先把这个基础的整好。然后这几篇论文看完了，大家一定会有新的启发。然后这些论文本身也会引用很多好的事例。
	能不能这样理解，TOT用树的形式寻找最优的不放？不是，它这个数的形式只是一种搜索算法的体现，他其实是在这个解空间里面去找好的prompt，而不是说用树的形式，树的形式只是它深度和广度优先搜索展现出来的天然的数据结构。对，然后在这个一直放到下面。
	16G的显存是够用的。
	老师你觉得南倩这个框架可以使用的对，南倩就是我们开发的这个主要的应用框架了。我没有太理解够实现蓝线是什么意思，因为这个蓝线本身是一个中间件，这个中间件我们调用它比较比较直接的就是用它跟大模型交互的能力和以及跟大模型生态交互的能力。就比如说它能够让你引入一个大模型，然后让你去方便的管理你的prompt temper，然后能对你大模型的输出结果进行规范化的输出。然后能对接向量数据库，对接关系型数据库，对接redis等等传统的中间件。
	我觉得大家可以直接实际试一下，就是CHATGLM6B用chair source到底好不好用。对，这个大家可以试一试。好，我们今天就直播到这儿，回头大家有什么问题我们可以群里再再交流。