	今天的这个课程是我们的第五次的直播课程今天我们讲AI大模型的应用最佳实践，因为我看最近群里有很多的同学都在陆陆续续的在跑我们的demo代码了。然后在跑的过程当中也都在探讨，我们目前学到的这些东西有什么用。所以今天我们会分成两部分，中间会留十分钟的时间有一个提问和探讨。
	然后两部分的第一部分，我们来讲一讲一些具体技术上的手段，怎么样来提升我们GPT模型的使用效率和质量。然后我也提前预备了一些例子，我们可以在这些例子里面去进行学习。这例子就包括文本创作与生成，摘要和总结都是最正常也是最常见的。然后包括我们有些同学在使用这个网页版的ChatGPT的时候，遇到了遇到了这个监管的问题，那这个内容监管肯定是有必要的。我们上一节课也讲到了这个moderation这么一个模型，然后这个模型其实就是加在了ChatGPT上，面对它的内容是有这个过滤的那我们也会讲，其实通过API的方式，你是可以绕过这个过滤的，会直接去使用这个GPT模型。那我们要怎么样去实际的我们自己在开发应用的时候去做这个监管，同时一些复杂的任务，我们能不能分步骤的去执行，然后上节课也有人问过，就我们在输出这个大模型生成内容的过程当中，能不能去评估它的质量，这个其实是可以的。
	包括怎么样能够通过我们的这个大模型来帮我们去造这个训练数据，甚至帮我们去调试代码。然后这个是上半部分，我们大概会花40分钟左右的时间，下半部分可能我们会花1个小时的时间先去讲这个一个很新的特性，是上个月6月20号的时候，OpenAI刚刚release的一个新特性叫function calling。就函数调用这个function calling其实是一个加在chat completions API，就我们上节课有讲的这个API上面的一个功能。我们会有一个notebook，去详细的讲怎么样用这个feature，怎么样用这个新特性。然后这个feature也从某种程度上去印证了我们上面提到的一种就是能够评估模型的输出质量，就我们让我们的大模型帮我们生成一些可以拿来作为函数调用的，要么是函数本身，要么是这个函数的参数。
	好，那我们就进入正题，第一部分就怎么样去提升GPT模型的使用效率和质量，我自己这边是有一些实际的使用，每天都在用GPT。然后我自己的这个实践的感受，我列了这么几个点。但我知道这个官方网站上也有这个就OpenAI的官方网站上也给出了一些建议。大家如果去搜的话，待会我们也可以打开看一看。
	GPT最佳实践也给了六个原则。然后那六个原则我认为它不是分的特别的相关性，其实还是有有一些奇怪的。对我这边找了一些这个点，其实是我自己的一些见解，也是跟大家探讨，大家待会也可以提问。
	我觉得最重要的几个点，第一个点就是最好是能够给我们的这个GPT。在使用它的过程当中，我们首先理解了它的理论。咱们之前花了两节课的时间给大家讲了很多理论，通过这些理论其实跟这儿的原则和技巧，跟这些tricks就会有关联。比如说fuel shot，上节课有人在提这个few shot，我们已经学过了。这个大语言模型本身在GPT3它就有这个instruction learning这么一个能力出现了。然后在GPT3这篇论文里面也有讲到这个few shot learning，one shot learning和zero shot learning。在GPT3的论文里面，大家如果还记得我们讲的这些内容的话，future learning显然是效果最好的。这个是一个很重要的点。
	除了这些以外，包括像这个指令的注入，分层的设计，这些也都跟我们讲prompt learning这个理论课程的时候有提到。我们用这个of thought，用这个self consistency，用我们的这个trial thought，这些其实都是属于把一个复杂的问题通过多个推理路径，然后去综合获取这个答案。这些其实在我们的实际的GPT模型的使用过程当中，也是希望把这些理论上学到的东西用起来。
	然后怎么样去用，我们也会有对应的工具，说回来这个技巧与原则，第一点我觉得最重要的就是我们最好要能够给我们的这个GPT这个system一个角色。我们要相信在大量的语料的训练下面，它其实是能理解角色这个含义的。但如果你只给一个抽象的角色设定是比较难的。就比如说你告诉他你用system这个role。我们上节课讲过这个chat completions API，如果大跳有些同学这会儿听直播没有参与我们上节课的学习的话，需要去补一补。我们在chat这个completions API这个最新的对话型的API里面，其实官方是在这个API里给出了我们的参数选项。
	我们可以再给GPT3.5和GPT4去给信息的时候，给prom的时候，其实是可以分角色，分你是属于system，你是属于assistant还是属于user，对吧？Assistant通常来说就是我们的GPT模型，它生成的内容是这个角色。我们用户提交的通常是user这个角色。但是system通常是我们作为一个外部系统，或者说作为一个上帝视角给我们的这个assistant，也就是我们这个GPT这个生成式模型给它一个设定。我们既然官方就已经开放了system这么一个肉，那我们一定要把它用好。
	在用的过程当中，既要能够去有一个标签化的设定，比如说哲学大师，待会儿我们也会有。同时最好这个哲学大师也有一些具象的描述。比如说他是什么方面的哲学大使，对吧？他是中国哲学大使，还是是什么西方哲学大使？哲学里面也有细分的一些点。
	从我们的这个使用者的角度来说，我们本身希望有一个什么样的就这种设定通常跟你的任务有关。比如说你设定成一个大师，那一定是你希望他能给你的最终用户提供一些这种比较有高的这种回复的见解，就是比较高层次的这种高屋建瓴的见解，是形而上的东西。你的用户是喜欢什么样类型的那那其他的设定也是一样的。包括我看有的这个同学在群里面写你是育婴专家，对吧？你对0到3岁的小朋友你特别懂，那0到3岁的小朋友应该懂一些什么样的内容，可以给他做设定。比如说你是一个编程的专家，你是一个python的专家，是一个java的专家，那甚至他会具体擅长什么样的python库和java库，这些东西都可以在system里面去做设定。
	这个是第一个技巧，第一个trick。第二个就是说除了给他去描述他的这个角色和他的一些具体的任务以外，其实我们还可以在system当中去做一些常住性的任务指令。这个其实在GPT的最佳实践六个原则里面也有提到，就我们包括我们上一次课也有提到。在很多时候我们最早的这个completion CPI是直接给GPT1个prompt。但是我们在新的这个chat completions里面，我们不再会强化这个prom的概念，而是强化了这个历史记录聊天记录。
	就我们给到模型的是一个聊天记录，一个对话的记录。这个记录告诉我们之前的上下文是什么，以及我们现在正在在聊什么，然后让他去生成一些内容。从这个视角来看的话，如果我们能把一些你要让他经常做的事情，甚至说你一直在让他做这个事情，那么可以把它做成一个常驻任务。那这个常驻任务就能够第一节省很多的聊天记录。因为不然的话，你会把它放到你的这个user的这个需求里面，对吧？那你每一次跟它交互，user里面都要附上这么一句话，是很浪费这个上下文的。那么你把它放在system里面，你可能就只需要说一次了，然后甚至这种设定，其实我们在function calling，就是我们今天要讲的第二趴，就怎么样去做外部函数调用的时候，也是一个非常有效的设定。
	第三个就是说这个问题拆解，就我们如何把一个复杂的问题拆解成多个子问题。这些子问题之间，它是没有强强的依赖关系，这种是最好的。如果有依赖关系也没问题，你把它的依赖关系说清楚。就比如说你要先执行第一步，再执行第二步，然后再执行第三步，或者说第二步跟第三步可以并行，它们都依赖于第一步的结果。把这种复杂问题给它拆解成小问题，相当于我们手动的在帮他做这个TF sorts对吧？那么把这个问题拆解之后，其实GPT不管是3.5还是4，都能给我们一些更稳定的更高质量的答案。
	第四部分就是这个分层设计，跟我们刚刚那个分步骤有点类似。但分步骤是说你人把一个大问题拆成子问题了，那分层的设计最好理解的就是写书，或者说我们做这门课程，我们我看也有些同学在做类似的事情。比如说我们现在要写一本小说，要写一门课程。那一门课程首先要给的是这个outline一个概览。那这个概览可能是一个你可以认为是一个提纲，是一个课程大纲，是一个书的目录都可以。把这个概览给出来之后，我们可以让。PT先去把概览调整到我们满意的一个状态，那这个盖其实就可以存下来了，对吧？你可以存在向量数据库里，你也可以存在任何地方，甚至存在内存里。那这个盖你就可以作为一个类似于刚刚我们提到的指令注入里面system的东西。这个概览让他一直记住。
	记住这个概览之后，我们可以再让我们的GPT去不断的去丰富每一个章节，甚至到每一个细节。这个过程是不是就很像一棵树的这个trio source。我们讲其实有点类似于这个逻辑，但我们其实跟实际上的这个数又不太一样。因为这个过程其实由我们来把控的，而不是说我们一次性把这个复杂问题交给大模型来完成。这个数的设计和多条通路是由我们来做这个事情，我们来寻找这个最优解。我们在不断丰富这个树的生成过程当中的一个个的细节。
	甚至因为我们来操作这个事情，所以我们也可以突破这个token的窗口上下限这么一个设定。因为我们记住了什么是主要问题，什么是主要矛盾。这些东西记住之后，我们可以在适当的时机注入到system里面去。这个是很重要的一个思维逻辑，也是在用GPT模型的时候，不管是我们直接用ChatGPT还是我们调chat completion的时候，都需要去分摊我们的任务，给到GPT模型的时候，给到不同的角色里去。
	第五点就是说这个编程思维也是非常重要的。就是我们在有一些同学已经在用南签了。我们在用南迁的时候，其实有一个很重要的概念叫prompt templates，就是我们的提示词模板。什么意思呢？
	就我们一直在讲，其实未来的这个编程语言的重要性会被慢慢弱化，因为代码可能就是用我们的GPT模型或者类似的模型来生成的那这个时候我们更多的是要去学习写这个代码应该学习什么？我们叫meta knowledge对吧？那些原知识是什么？到底写一个代码它最重要的设计的部分是什么？然后它怎么样能够解决问题，中间这个部分的思考，这个部分的这些知识是最重要的。
	在这个过程当中，其实我们在用这个prompt去跟大模型交流的时候也是类似的。以前我们可能刚刚开始用的时候，只会想到我跟你是一个自然语言的交流。到现在为止，其实很多人已经发现你给这个大模型去交流的时候，有一些内容就是我们正常的交流。我们把姑且叫做正文，就是它的这个test这些正常交流的这些正文。
	但除此以外，其实我们也可以预留一些变量。比如说我们用一个中括号，我们用一个双引号，我们用一些不常用的符号，我们提前先把它设定好。这个设定可以放在我们的system里面，也可以放在user，这两种角色都可以放。然后你放在里面之后，你就告诉我们的这个大模型，这样的符号包裹里面的内容可能是一个占位符。未来我会在实际的user阶段再填进去，有可能是一个风格。客服他把我们的多个任务分割成了几个子任务，或者说多个任务其实是相同的那我一次性给了你多个任务，你都得逐一回答。通过这样的方式，其实我们就把变量给做进来了。
	我们跟GPT模型交流的时候，除了正文我们也能设计变量。这个变量可以是在正式的那次对话的时候，就像我们代码运行的时候，在运行时再去注入的，这个就类似于变量。当然也可以去做一些模板，这个模板就更先进或者说更综合一点。我们把很多的正文和我们的变量组合成一些模板，然后这个模板里面甚至还能嵌套引用组合。这个就越来越类似于能欠去抽象这个prompt template的设定，这个也很重要，尤其是我们发现一个问题，单轮对话，甚至说我们跟GPT模型的这个交流过程当中，一个上下文或者说为我们在这个ChatGPT聊天的时候，经常会看到你可以起一个新的，然后左边就会加一列对吧？那这个可能通常为了质量，我们会希望这一列里面，就是这一个聊天窗口上下文里面，他是担负着一种角色身份，或者说一大类主题任务的那如果是不同的那可能我们最好是再开另一个。针对这种情况，其实南茜做的一个很重要的工作就是说，我ChatGPT左边有这么多个不同的聊天对话框了，能不能串起来帮我解决问题？
	Function call某种层面上也是想做这个事儿。就比如说我的function call，我的第一个设定是让我的大模型帮我生成一个函数。然后第二步可能是要去执行这个函数。
	执行这个函数，简单一点的函数我就可以人来写，复杂一点的函数，这个执行函数的函数也可以由我们的大模型来写。甚至说在中间还可以加一个评估它生成的函数的这些自然语言也好，代码也好，是不是可用的那这个也是一个点，这个是编程性的思维，就我们把prompt变成一个编程语言。那自然语言的编程语言应该是什么样的，我们人要会去设计。而且在这个过程当中，我们通过对比也明显发现，确实因为训练语料GPT是以英语为主的那这个时候类似于这种模板化的东西，如果我们用了中文，可能它的效果就没有英语好。这个我们也会在待会儿的这个示例里面给大家去实际的看一下这个效果。
	然后最后讲这个full shop，这个是一个我认为非常底层，非常贴近于GPT3以及之后各个系列迭代的大模型的很重要的一个底层逻辑。所以我们只要给了few shot，一定会比给zero shot的效果要好一些的。如果你你是同一个人，你水平差不多，那你能给参考示例一定是比这个没有参考示例要好一些。对的，而且这个参考示例你还要尽可能造的，让我们的GPT模型能够理解你到底要让它参考的是什么。比如说你是让他参考的输入输出的格式，还是你让他参考的是这个推理的过程。比如说你要让他参考这个推理过程是分成了123456七八步，每一步是在干什么？这也是一种参考。
	所以这个full shot本身的核心还在于我们怎么样把这个few shot里面要让我们大模型去学的那个东西。因为核心叫feel完整，叫few short learning。到底要通过这几个小的事例让我们的大模型学到哪些内容？针对新问题，我可以鹦鹉学舌一样的针对这几个fuel shot再去学好。
	这个是我个人总结的这个GPT模型实战，就我们真正在用GPT模型的时候，有哪些技巧和原则可以去把握的。但我相信除了这些，大家也可以总结一些其他的技巧。我们也都可以把这些我们认为不错的一些GPT的生成结果，可以提交到我们的这个项目里面来。我们接下来就看一看刚刚那几个技巧要怎么在实战当中去使用。
	第一个就是我们刚提到的角色的设定。首先需要给大家介绍一下的是这个open I官方提的提供的这个playground，大家理解就是一个用来让大家测试，然后能实际去体验我们的GPT不同模型，然后不同的API甚至不同的参数。我们就能看到在调API的时候，有一些重要的核心的参数在这里也可以去做调整。那待会儿我们也会实际的去跑一跑比如说像这个地方，我们就是想强调这个角色的设定，这也是比较简单的一种system的prompt。比如说我们用这里的这个system的描述，能看到对于我的所有问题，那么你都要用这种所谓的大道至简的这种佛学或者中国哲学来解答。吧？不要啰嗦，如果没有加不要啰嗦，他可能会非常长，这个待会我们都可以试，要有大师范儿对吧？这是一种角色设定。
	第二种就是说我们能够去做一些内容创作与生成。在做内容创作与生成的时候，我们可以给他一些常驻的任务。比如说像这就是一个典型的常驻任务，对于陈列出的每一个话题，创作100字的内容，体现话题的论点。这里可能我们就开始在这个过程当中我们会去聊，然后他会有这个不同的论点，不同的角度，每个是100字左右，然后要风趣幽默，这些我们待会儿都可以实际去看，然后包括用这样的一个我们要短横线去做分隔。这样相当于把这个任务做成了多个任务的需求。我们的GPT也都能理解。
	然后他就能够去总结每一篇文章的论点。所以这里其实就是三篇文章，而不是一篇文章。那这三篇文章他就能够去把这个论点先每一篇都抽象出来，然后再去做一个比较，说这三篇哪篇写的好啊。这个就是通过这个标签分隔符来做的。并且这种标签分隔符是有点类似于我们开始提到的，我们把prompt当成一个编程语言。
	这个标签分隔服务其实就是一种特定的分隔，除此以外，像我们刚刚提到这种监管性的内容，我们在ChatGPT用不了。但是这个其实就是直接去模拟了。我们调这个chat completions API的时候，他是可以写的那我们需要去对这种内容做监管，包括去帮我们去做这个代码的调试。可能做代码调试的时候，很多人会直接把这个问题甩给ChatGPT，然后说你帮我看看出了什么问题。
	这个是一个实际群里的同学遇到的问题。那么把它抛给这个ChatGPT的时候，我们会说你将收到这个debug的问题。我们先对这个system这个地方去做一个设定，就是他收到的大部分都是debug的问题。然后我们要将每个问题分类成四类，然后分点去乘列。格式如下面所示，这个就有点类似于我们的这个one shot learning对吧？
	分成了这样。只不过我们我们只让它参考了格式，没有让他参考的内容。并且我们还把这个常驻任务都已经放到了这里。所以如果我们待会儿在这儿附上另一个bug，他也会依次的把这个四点分类列出来，并且按照这样的格式列出来。
	除了这个以外，还有一些比如说我们去评估这个模型的输出。就我们上次有同学聊，我们让GPT去生成一些内容，那这些内容我们能不能自动判断它生成的好不好？这样的一个例子就是说我们给GPT这个system去预设一些正确的信息，或者说常识性的信息。这些信息它是可以用来判断它自己生成的内容。它比如说这里我们让这个GPT去判断他自己输出的这个观点是不是对的。并且把这个判断是不是对的这件事情还帮他做了多步骤的拆解，然后最终让他回答的最后一步就拆了四步。但最后一步是让他判断这个事儿是不是对的。是对的我们就说说yes，不是对的就输出no，大家简单这么理解，然后最终针对每一个论点，这就是一个嵌套了，对吧？
	因为我们要针对每一个问题，首先我们能它能逐步的去做做这个四步的执行。然后这四步执行完了之后，再执行下一个任务的这个判断。然后针对每一个论点，这四步都做完之后，他最终在system里面还给了他一个要求，就是说每一个论点我都会判断一个对错。然后这个对错我去统计yes和no的这个数量，那其实就统计出来我的正确和错误的这个事儿了。
	好，还有一块就是我们去构造这个标注数据，就我们未来要去做反应称。那这个反应称的训练数据是不是可以由我们的GPT模型来生成？这个其实也是可以的那我们就实际来看一看这些demo。刚刚我看到有反映这个字有点小，那个是在PPT。没关系，我们现在到这个网页端来，那这个字应该就比较大对吧？现在这个字可以吗？大家可以评论说一下，现在这个字能不能看得清楚。
	OK对吧？好。
	我们刚刚提到第一。
	首先这个是大家能看到去访问OpenAI的话，这里都有一个playground这么一个功能这个功能其实是非常顶部的一个功能，大家如果之前没有用过的话，我建议还是可以去尝试使用一下。那它有几个好处。第一个点，就是说大家看整个聊天界面，它跟我们的ChatGPT不一样。ChatGPT是只会给你开放这个user和这个assistant，然后你是没法对这个system，这个角色去做任何的输入的。然后同时还能在这儿去看到它的这个源代码，然后你可以方便的去做复现，直接把你现在这里的调试结果就可以拷过去了，这个是第二个好处。
	第三个就是说这里会有多种mod对吧？就我们这儿其实是我们上节课有讲，现在97%的API调用都是调用的这个chat completions API。其实还会有原来的几个老的API，包括这个complete和edit，但我们现在可以就只使用这个chat，包括我们的这个function calling，也其实也只是支持这个chat model，就我们的上节课聊的这个chat location API。所以你可以在这儿去做各种模式的调整。但目前来看这儿我们选用chat就够了。
	然后第三个就是说我们能在这儿去调模型，用GPT3.5的，或者说用这个3.5的加长版，这个GPT s的标准版，那它会有更多的，你都可以在这调。然后包括我们的temperature这里也能调，我们的这个窗口的上下文长度，这里也是可以做调整的。包括我们的停止词，我们的top，我们的这些常用的都可以在这儿做调整。
	调完之后也是立即生效的，并且这个可以保存下来，像刚刚这个PPT里截屏的这些都可以保存下来。甚至你可以把它共享给你的朋友。但是他目前没有做很好很好的权限的验证。所以如果我把它共享给大家，大家就可以直接在这做修改，那可能改的最后就完全就不一样了。所有人就看不到他最开始的样子了，那就比较麻烦。所以刚刚的PPT的截图就是为了保留他一开始的这些样子，把这个system留下来，让大家能够理解这几个事例分别是怎么样去做设定的，大家也可以在这个地方去做这个尝试。
	好，比如说我们看到第一个就是这个问题，就我们的这个角色设定的问题。这个角色设定其实我们在做这个设定之前，这些东西其实都是可以随时调整的。我们看到这里写的这个内容其实还是不复杂的那我们可以尝试去做一些修改。假设我们只是这样写，就我们刚刚说的什么不要啰嗦什么的，我们重新来看看这些内容。这都是一些经常大家会问大师的话。
	我不清楚大家能不能体会到这个变化，其实我们刚刚只是给这个system这边剪了一个不要啰嗦这样的一个关键词，其实他会把这个写的更复杂。那么我们假设重启一个。先保存一下。
	大家可以直接通过这个域名。
	进到一个新的这个里面来。然后我相信有很多还是有小白的用户没有去这个界面，或者说没有自己去设置过system的这个front。我们实际来对比一下，看看会有什么样的区别。
	假设我们什么这个system设定都没有然后直接去做这个提交。我们把这个模型写到GPT4。
	看他会给你一些什么结果。其实首先它不会有任何的偏向性，他会给你一些很客观的回复。
	大家会觉得这个很很琐碎，很繁复，对吧？我们可以取消这个，也跟这个在ChatGPT页面上是完全一致的。然后我们假设现在我们把这个擦掉，大家这个界面上跟我们调API的感受是完全一样的。
	我们在调API的时候，大家会去维护一个messages这么一个变量。整个这个界面上看到的其实就是这个messages。这个是playground做的还挺让人舒服的。大家可以理解成整个这个页面上你能看到的所有的内容就是它的messages。然后它这个消息记录里面如果你在这个页面上输出的内容太长，比如说超过了这个8K那可能你都没法再用。所以他是完全为了让你能够理解这个API可能会去怎么运作的，所以在你自己还想还在摸索怎么样去设置这个prom的时候，其实这个页面比较方便的让你能够去做调整。而不是你一直在那改代码，然后又重新运行这个界面就能让你去试，然后试出一个还不错的prompt能达到你的效果。
	比如说我们把这儿直接干掉，然后把system的这个简单设定给他，让我们重新提交这个任务。就相当于API调用的时候就传了一个system是roll，是这样的内容。然后user是这样的一个内容，他会给你一个这样的回复。
	assistant的回复。
	然后当你把这个assistant的擦掉的时候，相当于它已经没有这个上下文了。我不知道这个表达够不够清楚，所以整个这个界面其实就是在模拟，我们在调用它的chat completions API。然后model是用的一个特定的model，参数用的是这边特定的参数。
	大家会发现其实说的也很多，对吧？因为我能理解就是可能拆GPT包括GPT4，为了让这个回复有更多轮的对话，然后他可能就会做成这种尽可能多一些输出，然后让你能针对它的输出再去深度提问。我们开始有一个很简单的一个process，就是这么一句话，我们可以重新试一试。
	它就差不多是这样的一个变化，并且我们不断的去去跟他提问，这个system是常驻的，比如说这个。
	你跟他聊各种各样的问题，他还会依然保留这个system的设定。这一点其实跟我们的API是完全一是的，所以大家可以在这个地方去做各种各样的设定。我们再挑几个比较有意思的，我认为可以值得分享的。
	第二个就是说怎么样去做moderation和这个分步骤的执行。我这边我们能看到其实有同学在问，就是在用这个chat GP的过程当中，我好像没法输出一些敏感内容，被moderation的模型给监管了。实际上要给大家提这个，其实是想从另一个角度跟大家讲这个安全的问题。因为在国内其实我们做AIGC的应用，我们生成出来的内容，如果我们自己没有去做这个安全过滤的话，是很容易出现问题的。而我们自己去直接调这个chat completions API的时候，和我们用ChatGPT是不一样的。就我们在网页页面上用那个ChatGPT，OpenAI会帮我们过滤内容。如果咱们直接只包了一个chat completions API，就直接提供给大部分的C端用户去使用的时候，大家其实是能绕过那个内容监管，然后会获取一些各种各样的信息的。当然我们在这儿是能开启这个内容监管的选项。
	对呃，但是很明显我今我我写了这个故事，他也没有完全的任何的提示，就告诉我这个是内容敏感的，或者说内容是不安全的。但其实有一些内容比起你在ChatGPT上用的，都已经非常的不是特别的面向，所有人都可以去看的。就比如说我看有一个同学写了一个帮我编一个故事，在ChatGPT上就直接被被禁止了，可能他的moderation模型做的更激进一点，那在这个里面它就不会有。类似的我们就能想象得到，如果我们直接去使用这个API会有这样的危险。所以咱们一定要去，如果真的要面向C端用户的话，一定要去把moderation这个模型给加上，并且去设定一些不同的分类标准。然后它的使用方式其实就是把我们的这个内容，就assistant输出的这个内容再调用moderation，让他去判断里面会不会有一些十几种不同类型的偏向性的事情。
	然后这里可以再看第二个有意思的点就这边写了非常多的内容，那我一直在继续，然后他他也在继续的把这个记下来，这个地方其实在利用什么呢？在利用的是整个聊天记录，这个聊天记录里面我们让他去要多一些什么元素，它也有。然后我们希望把它扩展成一个一万字的短篇小说，他也给了章节目录。但是在ChatGPT里面我们经常会发现，聊得多了之后，他就记不得前面是一些什么样的问题了。那是因为ChatGPT它不会去触发那个窗口的这个超越contest上下限的这个问题。
	他自己会去做一些调整，使得你们这个聊天可以一直聊，就你跟他的一个窗口的这个聊天记录可以一直聊，他自己会去做一些设定。但是实际上如果你用这个API的话，你就一直去去记录这个message，就很快就会超过他的这个窗口上限了。我相信实际动手写过代码同学都会遇到。如果我们没有去做任何事情，他可能会记得住他之前说过，因为他会重点关注assistant就他自己说了什么，那他会记住有这么一个目录。所以大家可以看到我们让他写第一章，然后他会写。然后我们把第二章到第四章他也写了，然后我们再去让他写的时候，我们就直接写的继续，他会记住他在干什么事情，以及他也会记住他前面几章是什么样的内容。
	大家可以看到它一直在往下去生成内容，并且它的生成的这个结果里面的这个章节标题一直是跟前面去匹配的。这是因为整个上下文这个message它还是没有超过这个界限的。但是我们这里再让他继续的时候，就他第20章下面其实还有一个小结。然后我们再让它继续的时候，它就会触发这个很明显的标志。就我们现在这个模型的这个context的长度，已经超过了它的上线了。
	所以说我们开始有提到一个很典型的做法是什么呢？就是我我们其实完全不需要把这些内容每一次都传给他，我们其实真正要的是什么？要的是这一段内容。这个其实是他的章节。标题在这里，对吧？然后。
	然后我们只需要把剩下的这些东西都删掉，它其实都不需要在在我们的这个记录里面去记住之前的这些内容。这样我就不一一展示了。我用这个意思应该表达明白了，那他就知道我现在正写到第20章。那我让你继续的话，其实是写第21章，就是我们这个结语这里他已经写不下了。那我们把前面的删掉，把一些比如说他现在他的上一个对话是这几张，那中间的这些都可以删掉。并且我们告诉他在system的prompt里面告诉他你现在在写小说，然后你需要按照章节顺序一张一张的往下写。
	你可以节约大量的token要去完成你的创作。这个是一个非常重要的针对长内容生成的一些技巧。甚至包括这个章节标题，我们也可以做一个滑动窗口？让他知道我现在应该关注什么。所以这些都是可以用来既能节省token，同时又能让你去生成长内容的时候，不被这个message去限制的一些手段。
	然后除了这个以外，我们还给大家可以看两个很有意思的示例。一个是我们开始看到的这个评估模型的结果，这个其实是一个任务的嵌套，那这个任务是什么呢？就首先我们用我们首先用中文看一下，可能大家对中文比较友好一点。这个中文其实就是把刚刚的那段英文做了直接的翻译，没有做任何其他的工作。然后大家如果看这个中文的话，就能明白我们给这个system这个角色做了什么样的设定和注入。第一个就是说我们会让他知道三个引号分割的这个文本是我们丢给他的。然后这个文本的设定就是一堆问题的答案，该文本应该为问题的答案，这句话描述的很清楚，那就说这个是问题的答案对吧？检查以下的信息是否直接包含在答案中，比如说第一个就是这个人，这个阿姆斯特朗是第一个登上月球的人，然后登上月球的日期是这样的一个日期。
	然后对于每一个point，其实就对于这里的每一个point要执行以下的步骤。第一就是重塑，就是重新描述。提供与这个答案与这个point最接近的一个答案的引用。就有点类似于我们最早在embedding课程里面去做的这个，把它的要点去做完embedding之后，然后再去做相似性的搜索，找一个最接近答案引用。
	第三个就是说考虑一下第三个步骤，考虑一下如果这个主题的读者他不太了解这个阅读引用的话，那么能否直接去推断出该要点。然后在做出这个决定之前，甚至还要解释一下原因，简单就是我不了解这个主题的一些陌生的读者，能不能直接推断出这个结论来。因为有可能这段话并不是一个非常明显能够推断出这两个论点的。然后最后就是说针对这个第三点，我考虑了半天，然后我再考虑读者能不能直接推断，然后如果能推断的话，我就回答是然后写入yes。否则的话就是不能直接推断出来就写成no。然后在这四个事情执行完之后，最后还要执行一个提供有多少个yes的回答，然后将此计数放到这样的一个描述里，就像一个代码的这个片段一样，就作为了这个count，然后这个insert come here，然后这个count技术就计数的这个事儿。
	好，整个我们看这个system prompt，其实它就比刚刚的我们看到那些要复杂很多。第一他去定义了我们的输入是一个什么样性质的内容。这个内容会被下面的这些任务所引用。这个内容是一个文本，是一个答案，是一个标准的东西。我们要把这些论点跟这个输入去做比较，我们每一次都会可以变换这个输入，这个是第一个点。第二点就是说有一些常驻的他需要去做判断的论点points。第三个就是说针对每一个points要分步骤去执行，对吧？那分完步骤执行之后，第四个把所有的事情做完了，然后我们还有一个任务，就相当于整个system的这个prompt又分成了几个大的步骤。
	这个其实就有点类似于我们最早学编程的时候，会告诉大家编程有这个结构，有循环的结构，然后有就有有for循环，然后有依附判断，然后有面向过程的顺序执行。那这个prompt的其实大家去仔细的去回味，它的这个写法就已经很像在写这个编程语言了。只不过它是用的自然语言，而在自然语言里面会穿插一些这种类似于变量的东西，那我们来实际执行一下，我们可以把这一段先删掉，提交一下。大家可以看到这里就开始出现问题了。他只执行了这一条，就是我刚才已经描述了对吧？他应该去把这两条都针对这四个步骤去做一下。第一个，他说他是第一个登上月球的人。那这里为什么？
	因为在这个事实判断里面，阿姆斯特朗因为成为第一个登上月球的人而闻名。就他把这里面相当于把这个输入用户的输入切成了几段，然后这几段会去变成一个embedding的向量，然后把它的这一段论断跟这个向量比较起来是最好的佐证，相当于它的事实依据。是的，他能得到这个要点，那yes结束了。所以理论上这个prom他没做完，他只做到了这句话和这个判断。第二个points没做就没有做。这第二个points的四个步骤以及最后这个步骤他都没做对吧？这个还是我们的OpenAI官方给出来的一个最佳实践里面的一个例子，就没做好。
	然后我们继续点这个submit，直接输出了这个count 1，这个也是一个很有趣的现象。大家如果玩的比较深的话，会发现在中文的这个prompt里面去做设定的时候要非常小心。就是我们在中文里面会有一个在介绍这个prompt这个黑魔法的时候，有一个叫think step by step。就是我们让大模型一步一步的想一想，然后让他把这个问题一步一步想之后，它会产生这个chain of source的效应，它就能够把复杂问题给解决好。但是这句魔法如果你用中文去讲，经常会造成一些啼笑皆非的问题。
	第一种情况就是他可能会把你的这句话理解成你的这个prompt是要分成几次来回复的，就是你要你比如说你去分步骤执行的时候，它会点一次这个调用去执行当中的一步。那第二次调用去执行它的下一步。那现在这个现象就有点类似于它把整个这一部分当成了一个步骤，把下面当成了另一个步骤。所以当我们直接去提交submit，没有任何user的信息的时候，它会去执行这个system prompt里面的第二个步骤，就把这个count输出来了。这个是一个很典型的一个场景。
	然后有一些什么样的trick一些小的技巧在在你使用中文proof的时候能解决？就是你把整个这个里面，我们我找一个典型的例子，分步骤执行的例子。对当我们要用中文去分步骤执行的时候，这也是一个跟刚刚那个接过来的，就我们有这个多个步骤让它去执行，多个步骤让他去执行的时候，假设我们把这句话注释掉，那他最后就会生成一个什么样的效果呢？
	我们把这个。助手的信息干掉了。就假设我们现在让他做什么事情，就是让他把这个用户输入的信息去做一个总结。然后总结完之后，输出的是一个以总结为前缀的句子。然后第二步是把这个总结翻译成英语，第三步是把翻译成日语，然后都会有对应的前缀，分别是总结english和这个日语的这个单词的意思就是日语。对，然后作为这个前缀让我们把这个提交过去看会发生什么。
	他会首先把这件事情第一步完成的非常好，他会去总结我们这个三个引号包裹的文本。大家也要注意，我们现在使用的已经是最新的这个GPT4的模型了。那就完了。大家发现没有？他并没有去执行我们的第二步跟第三步。然后你什么都不干，你去点这个submit，它会去执行这个第二步。
	这个在英文的prompt里面，我是暂时没有发现过这个情况的。我们再去点一次，他把这三个步骤当成了a assistant应该去处理的三件事儿。而且大家发现一定不会是因为我们要回复的这个nars的原因。因为我们调到2048就远远超过这个嫩。
	这是一个很有意思的中文的prompt的里面的一个黑科技。我们把这个单次回复全部执行完就相当于一个硬的指令。告诉他之后，他就能理解你其实是要把这三步放到一步里面来做，我们把这个全部删掉，这个删掉的过程我们刚才已经讲了，就相当于把你的API调用重新改成了只有这两个message，然后我们去做提交。他就会把这三个事情放到一个assistant的回复里面去，一次性给到你。这些都是一些咱们在实际去构造，这里是一个bug，我看看这边没有steam。
	有可能他的GPT4，现在连这个prom他也接受不了了。上一次我们刚刚看到那个assistant给我删掉的那一部分，是用这个单次回复全部执行完这个prompt它是能理解的，能理解这个中文的意思是要把这个任务一次性执行完。你现在又可以了，应该是刚才没有save，所以它的这个assistant的这个删除没有被删掉。
	好，所以这里有个细节，大家删掉之后还要点一下save，它才会改这个API请求的这个参数，变成最新的结果。这个是一个很典型的一个场景，就是我们中文的prompt确实没有英文的好用。即使是直接翻译过来，并且用的是我们OKI的最佳实践的样例。输入和输出仍然会出现这样的问题。对，然后你把它保存一下，我们再看一个再看这个标准的这个例子，就是我们刚刚看这个评估模型输入输出的例子。
	这个就是在OPI的这个官网上的例子，它会给不同的用户的描述，然后从这个描述里面去抽取跟他最近的这个表达，这个就是我们刚刚看到那个中文的版本。它会很清楚的去执行这两个论点的验证，以及最终的统计，一次性解决好。这些都是通过英文的prompt能够很很好的去执行的。所以某种程度上来说，大家如果真的要去开发这个AIGC的应用，这个英文的prompt明显肯定是要比中文要好的。这个是大家在使用的时候能直接有一个质的提高。
	然后再看一个最后我们要看的这这么一个事例，接着我们就可以大家一起来讨论了。这个是我在做文心千帆的这个大模型微调的时候的一个典型事例。这个事例是干什么呢？就是大家可以看到，首先这个事例里面，我是希望他给我做的这个事情，就我们的这个大模型跟我做这个事情是去帮我造这个标注数据，训练标注数据他怎么造呢？他需要去按照一定特定的格式以及一些特定的内容来找。这个时候我们看一下这个prompt，首先它一定要放到这个system里面，对吧？这样即使是我在ChatGPT里面用的时候，我把这个东西放在第一行，然后我给它输入这一大串，他也能理解到。但因为他自己在处理的时候，如果你的这个内容过多，他可能会忘掉你一开头的这个system里面的内容，那就会出问题。
	但如果我们是啊但如果我们是一个调API的模式，因为我们造数据肯定量很大。如果我们是一个调API的模式，那这个就很简单了。我们只需要常驻一个system的message，然后剩下的都是我们要去把这个无监督的未标注的数据构造出的这个样子。那它就会输出对应的内容。这个其实是一个既节省了你的token数量，同时又能达到比较好效果的一个策略。
	具体他要做的事情，第一就是要保持一个特定的格式，这个格式是文心千帆的这个反应作用需要的。就我们要造的是一个prompt，再加一个response，并且是放成了这样的一条一条的记录，这一条它的记录里面就类似于一个我们像在构造message这么一个数组一样，里面有prompt，有response，甚至可以有多个response。这里有多个response它也是支持的那我们就只造一个就好了。
	那这个怎么来的呢？其实它是把一本我们所谓的建筑设计规范里面的内容直接作为答案。但是这个大模型要针对这个内容去构造一个对应的问题。就比如说我们看这里找一个比较典型的，比如说这个甲类厂房和人员密集场所防火间距不应小于50米，与明火或者散火花点的这个防火间距不一定小于30米。这个是一个要求，是一种规范。这种东西如果我们要让人去给他想一个问题出来，然后再把这个规范当成他的一个答案。
	这个就类似于我们要去做问答机器人。我们这里可以做一个预习的铺垫，怎么样去造这个问答机器人的数据。因为很多人都会说我要造一个问答机器人在我自己的数据集上，但是我不知道他人会怎么去提问题。那这个时候首先你就可以让GPT来帮你想人会怎么提问题。甚至你可以针对你的目标用户的用户画像。
	我们刚刚讲过角色设定对吧？那你把你的这个角色设定交给你的这个system的这个prom里面。然后同时把提问的这个问题，你也可以让他同时提多个。就比如说这里你就可以造成提三个问题，就是三个prom，然后对应的是一个答案，这样也是可以的。
	然后我们就以刚刚看到的这个3.2.1这个问题他会怎么去弄呢？他会把这个问题提成，这样我们看它直接的输出结果，3.2.1这里甲类厂房工业建筑中甲类厂房与人员密集场所的防火间距要求是多少？这个就是一个比较典型的提问方式，他会给出我们这样的一个结果。类似于这样的手段，就能帮助我们去造很多的标注数据。因为我们要去做SFT的时候是需要标注数据的那这也是通过大模型能够帮我们实现的一种很高效的去构造这个训练数据的方法。
	好，我们第一趴就到这为止，就是我们怎么样去提升我们用这个GPT模型的这个技巧。我们介绍了一些这个原则。然后这个过程当中我们介绍了一个OpenAI提供的官方的工具叫playground。然后这个playground可以让我们在开发API的时候去做各种各样的实验。然后这个实验就通过这么一个界面，你可以去设置三种不同类型的角色的信息，然后维护一个message。然后这个message的这个参数你可以在这调整，包括它的模型它的这个模型的类型，以及我们的其他的一些重要参数。然后你也可以把它保存下来，甚至可以把它共享给你的研发的协作人员，然后让他来看这个结果。那你就可以共同的去构造出一个还不错的system们的prompt，然后去支撑你下一步的应用开发。好，我们现在留这个八分钟的时间，到九点之前我们回答一些问题，看大家有什么问题可以再提问。
	官方的prom示例在哪找？这个同学问的很好，我给大家打开看一下。在官方这个目录上面，这个debug的例子是我们弄的，是不是官方的对，官方给的这个例子，在就我们现在屏幕上应该能看到，这里有一个GPT的一个最佳实践。他有总结一些，比如说他给了这个6 strategies for getting Better results，就他给了如何能拿到更好的GPT结果，给了六个原则。比如说把这个指令写的更清楚一点，提供一些可以参考的文本，就类似于我们说的这个few short learning对吧？然后把一些复杂问题变成一些小问题子问题，然后给这个GPT一些时间去让他去想，跟我们说的这个shots有点像，对吧？然后用一些外部工具，这个外部工具就有各种各样的外部工具了。包括我们待会儿会讲的这个function calling，就函数调用，也是属于典型的外部工具一种用法。
	然后还有什么系统测试，然后这个挑战。其实我们刚刚有点类似这个模型评估里面做的这个内容，就我们刚刚看到他去根据一个用户输入，然后把用户输入里面的一些内容和我们想要去做这个测试的这个点去做这个比较，然后得出它是yes or no。这个事情除了去做事实性的比较以外，大家刷过你code也知道，我们可以针对这个测试数据的样例，把这些功能结合起来。比如说你要做的是代码生成，那么你就可以类似于这个function calling。我们待会儿要讲的方法，让大模型生成代码，这个代码用我们的这个函数去执行，执行完之后有一个结果。但是这些执行的输入就是这些样例输入。那些样例输入的输出，我们就可以提前给它预制好。那它就只需要去比较每一个样例输入跟输出是不是一样的，然后再去用一段话去比较，对吧？用那个count就我们最后看到的有几个yes几个no。这样其实就相当于在帮我们自动的去做测试，或者说自动的在帮我们去做模型输出的评估。
	我们再挑几个问题。
	开源模型当中经常提到的benchmark是否使用这个评测model去完成的。我理解可能还不是，因为开源的这个benchmark各种各样，不一定都能通过这个方式来解决。还有个同学问这个full shot里好像只有样例的答案，GPT生成了很多是GPT门模型里本身就有这些防火规范吗？不是，我再回到这个playground里面，是我输入的这是user输入了一堆这个规范。就比如说你也可以让比如说我们把这个场景换一下，它不是防火规范了，是你们公司的这个企业守则，对吧？
	小学生行为规范，大学生行为准则、校规这种东西。那这些东西，它都是一条一条的陈述性的内容，那你怎么样把它做成一个问答机器人，那一定是要有人问对吧？那你就去构造这个问答。对这个问答队是可以把变成一个监督的标注数据给到我们特定的模型去做微调的。比如说你现在要私有化一个ChatGLM26B这么一个小模型，这小模型跑到一张T4的卡上面就够了。然后你要把它变成一个你们这个学校的问答机器人，那你不就得把学校的这些规范学一遍吗？那这个学的话就需要构造数据，这个数据是不是可以通过这个方式来构造？构造完了之后，你至少能启动就完成了，你可以把这个部署起来了。
	部署起来之后，你会发现很多时候同学问的问题跟你想的不一样。那你把它记录下来，记录下来之后，你还可以再去做标注。然后你还可以让你的这个system prompt里面去把同学提的那个问题，你就不只是参考这个prompt response care这个格式了，而是把同学提的问题，你带了标做的，让你的PPT去参考同学的提问方式，那他造出来的就更像是同学提的问题了。
	还有同学问，如果我的输入特别长，就像行业规范这种大文档的内容，是否有输入限制？如果要拆分应该怎么处理？我们这儿就是一个例子，我们没有把整本规范丢进去，我们是丢了一部分，那那实际也是这样的，我们可以比如说我们这个模型支持的就是4K长。那你在在in bedding第一课我们就知道怎么样去判断embedding的出来的长度，对吧？然后我们在南茜的这个框架里面也会有文档分割器，以及去统计文档长度的，以及最终去算token长度的那这些东西其实都可以结合着起来用。结合起来用之后，你会发现一本大的规范，你可以把它拆成几十份，你就拆成100份，然后每一份你让它保证，比如说不超过2000个token或者1000个token，这些部分你就可以直接按照这样类似的方法。
	因为prompt的不长，system的prompt不长，然后你只需要把user这一部分不断的去刷新system的这个prompt，你甚至可以保持不变。然后你就能持续的输出你要的这这个assistant的这个输出，assistant输出就变成了你的标注数据。Debug的prompt可以再展示一下效果，这个是可以的，debug这个完全是看咱们的需求。大家可以看一下，我们输入的就是一个报错日志，对吧？那甚至还有艾特我们助教的这个信息，我都没有删掉，因为对他影响不大。他是能知道第bug的问题是哪一部分的，他会去分成这四部分，这四部分我们也是可以改的对比如说他会发现这个报错日志发生在API连接过程当中，类型是API的connection error。然后主要可能是由于巴拉巴拉更新的可能性，它给了三个可能性。第一个网络问题，ACCL问题，其实也是属于网络问题一种，对吧？第三就服务器问题，就比如说OpenAI本身服务器出现了问题，那有可能连接不成功。解决方案，检查网络，更新SL版本，更改网络环境，联系客服。也是对应的这个更新来的，然后他的参考资料也给了出来，就比如说SSL它的更新判断来自于python 3的这个库。因为我们用了这个库底层，那OpenAI因为我们调OpenAI的API，所以他给了API的这个官方文档。
	对，就是今天是给大家打开一个窗口，就我们前面这今天第五节课了，我们学的一些东西已经可以串起来用了。大家串的过程当中怎么串？然后这个playground就是一个让大家去试手试练的这么一个很轻量化的网页端的UI也很友好的一个界面。大家如果通过他的话就能够快速的去去学习。然后我们应该怎么样去设置这个prompt，我们的课后作业是不是都是这么生成的？我们课后作业的选择题是这么生成的，包括它的答案，所以大家可以自己交作业。
	行，那我们就九点钟，我们开始下半部分，我们的function calling。这个function colony很干，基本就是实战为主了。我们会基于一个notebook来讲。对。
	然后首先继续讲这个开源项目，很开心大家现在有越来越多的贡献者了，都是课堂中的同学，然后大家也都在提各种各样的PR，然后也很积极。我们现在有247颗星了，大家都在持续的关注。这个项目如果大家还没有拉过这个代码，还没有去跑过这个demo的话，今天这门课结束之后一定要去试一试这些代码，也会有很多有趣的东西留给大家。
	然后我们的这周星期二的时候，就应该是昨天的时候更新了这个课程进度与安排，后续我们都会持续在这更新，就类似于大家在什么国外的大学，如果去上课的话，都会有这样的一个schedule。那里面会放我们的上课时间，我们的主要的上课的内容以及我们的一些参考资料。这些资料都是线上可以直接访问的资料，为了大家方便去访问，有推荐阅读，也会有扩展阅读。比如说针对第二次课，我们讲了从GPT的第一代到我们的GPT4，然后以及我们的这个prompt的相关的一些内容，它就会有一些相关的资料。像这个prom比较新，我就没有放太多，这个GPT相对来说比较多一点。然后这个扩展的阅读，既然是扩展的阅读，就是推荐这个学有余力的同学可以再去研究，让我们的选择题会放在这里。但我们接下来可能都是以这个代码为主了，所以可能后面几周都会以这个代码为主，大家可能可以持续关注一下。
	对，然后像这个上一次课，因为讲的是这个OpenAI的相关的内容，所以我会给到这个OpenAI的一些相关的参考资料，可以在这学习。类似的我们有很多同学都做了这个开源的贡献，就比如说这里我已经合并了有八个pro request给大家做的，包括专门留的这个小作业，就我们这个invade e的这个DF这个变量名，包括增加这个FAQ。这个我觉得很有意思，也希望大家持续去加FAQ，包括一些警告的消除，我们的这个给我们的这个怎么做贡献，有一些建议。加了这个review的一个小的batch，然后我们有这个REDM的中文版，也是一个同学提供的，主动把我们的这个REDM留了一个中文版，我们故意留在这个空缺的。接下来每次课更新之后，我们都会逐渐的去丰富这个进度表给我们的这个schedule。然后包括我们的tiktok上次也留了一个小作业，就我们能不能把这个GPT3的统计也放进来，也有同学做了，欢迎大家继续去在这个项目里面去去发掘去贡献。
	因为我们整个这个项目的demo都有这么三个很重要的观念想分享给大家。第一个就是说我们的这个课程的demo，它不是一个死的demo，这不是说跑一遍就结束了。用notebook的一个很重要的点就在于它是一个交互式的动态的一个开发环境，所以大家在这个notebook里面可以不断的去执行，按照不同的顺序去执行，然后去调试。所以我们希望整个demo它是一个持续开放的一个状态。
	然后它也是一个自由可探索的一个notebook。那大家可以在这个notebook里面去，我看有的同学在embedding的里面提了一个PR还没有合进来，它增加了中文中国新闻联播的CSV。这个就是一个很好的一个新的探索。我换了这个新的数据集对吧？然后今天的课程也留了两个编程的homework，也是留给大家，希望大家能去实践这个function calling。同时它也能支持扩展，这个扩展就在于你可以在这上面改数据，然后改这个新的实现方法。
	好，那我们就直接上到这个notebook来学。然后我们的这个课程的介绍也在这儿。整个这个notebook我们其实已经同步到代码库里了。我不知道大家有没有注意到刚刚的这个我们的截图，可以给大家再看一眼，在我们直播之前已经把最新的这个notebook提交上去了。在大家可以看到3个小时前，我们提交了这个demo。
	是这个function call，大家点开这个demo，就是我们待会儿会投在这个投屏直播里面去演示的这个notebook。对，然后我们就直接开始这个demo的演示。首先整个这个function calling它是一个很新的东西。他自己的官方的这个代码也在不断的针对这个新功能也在做调整，所以有关注到这个的同学是非常好的，就说明大家还是很很关注新的进展。那如果能够在实际的去用它就更好了，甚至可以给大家分享。我个人的认知是说整个ChatGPT的plug in也是构建在这个function calling的这个功能基础上才能去做的比较好的。就ChatGPT的它插件能够做好，跟这个function calling的很多实现是有底层逻辑上是相通的。
	那6 6月20号的时候，OpenAI的官方的这个blog里面，在原有的就我们刚刚前1个小时，一直在讲有三种不同的角色设定。然后是在我们的chat completion SAPI上面，可以去设置system，可以去设置user，然后让我们的GPT以a system的角色来做回复，在这个基础上新增了这个function calling的功能。也有一个月前在这个blog里面，我这边也附了这个原文的链接，大家有兴趣可以去读一下，还有讲清楚。因为这篇文章除了介绍了这个function calling的更新以外，也有一些别的更新。对，就在我们的这个notebook里面有这个跳转链接，大家可以去看一看。对，这边有写到我们的新新的这个function calling的这个能力，加载到了这个chat complication API里面来。好，然后这个是不是有点小字体，要不要开大一点，我看一下，好像是有点小调大一点。
	现在这个大小可以吗？
	大家回复一下，现在这个大小是OK的吗？好好，然后整个整个这个function calling其实很简单。我们把这些新东西复杂问题，我一直有一个观点就是太阳底下是没有什么新鲜事儿的。所以大家把为什么一开始要教理论，也是你会发现刚刚说的好多什么技巧，然后怎么样去给system去做prom的设定，理论课都讲过对吧？
	因为3点GP3.0开始，他学会了用这个plush al learning了。所以你用photo al learning这种方式，它一定好用的。因为大模型GPT3的论文，就20年的时候就已经告诉大家这个事儿是靠谱的。那那既然是这样的话，你后面一直在用这个方式去训练，包括3.51系列的魔改，那不也都是instruction的处理，那不都是这个类似的套路，所以它大模型就这么训练的那你去用它用训练的这个方式去用，那肯定是好用的。然后包括step by step这种分步骤去想问题，对吧？那我们可以大模型内部能引导他去这么想，那我们人也可以去这样想，那人这样想的时候就把问题给拆解了，然后再去复用上他给我们赋能的这个system的角色，就更好的把这个问题给解决好。
	Function也就是在我们上一节课讲的这个chat completions API上面的一个功能的叠加，新增加了一些参数，就简单这么理解。那这个参数用来干嘛的呢？首先它使我们的GPT模型开始能够去生成一些我们想要让它去生成的一些函数，甚至一些函数的参数。然后这个是第一个点，也是我们今天会展示的，就是相当于让GPT去生成代码，然后这个代码谁来执行它，我们会第二部分去讲。
	所以第一件事情大家简单理解成就是，不是说这个GPT模型就能直接去执行所有的函数了。它自己不会去把什么python的解释器，C加加的编译器，包括它的运行环境，都做到大模型里。不是这样的，而是说说你现在要去执行这些代码，要去写这些代码，要去生成这些代码。那这些代码让大模型来帮你生成，然后你要怎么去执行它，其实很简单的。因为我们现在从来就不缺一个去执行环境的执行代码的环境。我们缺的是写代码的人，写高质量代码的这个人，或者说程序员、开发者。他来帮你写，然后他再告诉你怎么样去用这个代码，这样就很完美了。
	所以首先他是干这个事儿的，他自己不是一个解释器，也不是一个编译器，这个很重要。然后第二个就是说他还做了一个很重要的点，很牛逼的点，就在于ChatGPT仍然是一个聊天对话的机器人儿。但是它还能去生成一些代码，从你的输入就从用户的输入里面去知道你想要什么，想要的也许就是代码。但是他要是做成了，只能给你生成代码，也就很傻，失去了他语义理解的能力了。所以它有一个很巧妙的设定是它来判断你现在是不是要用这个function，你现在是不是要去生成这个function，或者说生成这个function的一个特殊的调用参数。
	我们具体来看一看实际的例子，大家就能理解了。首先有两个参数，一个参数就是这个function的参数。通过这个参数我们相当于定义了一个函数，大家可以简单这么理解。还有一个参数叫function call，这个function call可以设置为none。设置为none就是相当于让我们的ChatGPT，或者说让我们的GPT3.5、GPT4不要去用这些函数，就不要去用我们开始定义的函数，就是强制不用，就是让他别用。不管你现在有多强的意愿，认为我的user是想跟这个相关了，你也别用它，强制不让他用。但是你也可以去给他设置，不是那样，那就设置成一些特定的function。
	那这个insert function name，这个function name在哪定义的？在这个functions参数里定义的。不好意思，在这个functions参数里面定义的，待会儿我们会去看，相当于用functions参数你可以定义好几个函数，这些函数的名字你可以插到这个function call里面来，然后由我们的GPT模型来判断什么时候来call这些function。这个应该整明白了，绕绕清楚了，对吧？然后我们可以看一下官方的API文档，其实上节课里面故意没讲，就放到这儿来跟大家说。就是大家先把这几个角色用明白，其中就增加了一个新的参数，一个是functions，一个是这个function call。就我们刚刚看到的这两个东西，待会儿我们会来用OK就这两个参数大家回头在这个API官方文档里面都有啊，我这就不赘述了，大家也可以去细读一下。
	然后整个这个notebook干几个事儿。第一个就是说让大家整明白怎么用这个functions这么一个参数。第二个就是怎么用function call这个参数。第三个就是我们用GPT模型来生成一些函数和参数，就是按照这个要求来生成。第四个就是说去实际的用这个执行一下它生成的函数。我们让相当于我们最后一部分让GPT模型生成一些circle语句。然后这个circle语句我们再把它执行一下，就能实际的去查询了。这个场景就跟我们现在很多同学在聊agent对吧？Agent现在很火，不管是一些投资人，有很多投资人让我帮忙去看一些新项目，确实给大家做客没时间，推掉了很多这些事情。
	然后agent要做的一个事情是什么呢？就是我们都知道ChatGPT的上半场是他语义理解能力很强，他能跟你侃天侃地，能跟你闲聊聊很久，你都会觉得好像他还肚子里有货，然后你还没给他挖掘完agent的就是想说OK他能理解你想要什么了，但他自己的能力有限，对吧？那他能不能作为一个大脑去调用各种外部资源？大家还记得刚刚看这个GPT的最佳实践里面有这个external的tools。就我的GPT变成一个大脑中枢，然后他去调动很多资源。这些资源不一定是GPT本身的能力，但是他会告诉那些工具我要怎么用你，对吧？这个就是现在tour learning也好，agent也好，就是各种包括这个hugging GPT，有各种各样的agent相关的研究都在干这个事儿。就是怎么样把GPT模型变成一个杠杆，变成一个大脑，用这个大脑用这个杠杆去撬动更多的工具，然后让我们的人能够用这些agent，用语言的方式，用这个语言交流的方式去实现很多以前要写代码才能完成的工作。
	这个circle查询就是一个典型的例子，让GPT来生成circle查询，我们只需要告诉这个GPT模型我要查什么，我要了解的是什么，他就帮你去查库了。以前很多面向数据库编程的CRUD的程序员就很慌，对吧？就这么个意思。OK那我们就实际来看看，首先我们还是有一些安装包需要在这执行，我在这儿再强调一下，因为我看上节课还完了之后介绍了用百分号来安装。但是我看很多同学不看注释的，就只管执行。其实注释说的很清楚，百分号是为了跟你的环境适配。然后这个感叹号是直接执行，需要脚本。然后你通过感叹号来执行，你是不需要去重启这个notebook的。因为他直接去执行的这个消耗脚本就装进来了。
	那你用那个百分号来执行的话，你是需要去重启这个脚本的。因为它装完之后，它是没有去像那个命令行一样去执行。它是跟这个patent notebook的一个什么magic，对吧？我们上节课讲了叫一个黑魔法一样的一个指令，所以是这么一个逻辑，那为了这个顺序和跟大家实际使用的这个场景一样，我把这个重启一下。因为很多同学对这个序号好像也不是很很很理解，但其实它就只是一个执行这个cell的顺序而已。
	那重启之后，我们首先来执行这个安装依赖安装包的这么一个事儿，这些都已经提前预装过了，所以它这就检查完就直接开始往下走了。然后我们需要去引用一些依赖库，包括这个Jason OpenAIr request，这些库我这边就不再赘述了。这个是用来维护一个在GPT请求的，然后这里是为了我们打印输出好看，待会有用，然后我依然使用了这个GPT3.5 turbo这么一个模型。因为考虑到有同学不一定有GPT CAPI的权限，然后这个GPT model我们会把它放到这个函数里，作为它的一个默认参数这一次我又补全了这个注释，我看很多同学希望有这个注释，然后这个demo特别有意思，我把它稍微放小一点，不然一个函数都看不完。
	大家会发现我这儿定义了一个函数叫chat completion quest，然后它套了一个python的装饰器是用来做重试的。如果这个请求它没有发送成功的话，它会重试三次，然后最大的间隔是40秒。因为有的同学经常有这个key的read limit，那可以调整这些东西，让他去隔一定时间去请求。因为我看有同学没办法写了一个time sleep对吧？这个多少秒之后再重新请求。那用一个装饰器能更优雅的一点实现这个事儿，这个是第一个点。第二点就是说我们没有用这个chat completion create那个方法，就是我们上节课在model里面用的这个方法。我在这给大家打开一下。
	在这个教程里面，我们有教大家用chat completion API。然后用了这么一个方法对吧？用这个OpenAI这个python的酷的chat completion去create一下，就能他内部帮你去完成这个请求了。但是这一次我们没用，为什么没用？待会儿大家可以感受一下。首先大家就知道这里没有用那个方法，而是我们直接用了比较底层的request这个库的方法，有两个有两个点。第一个点是让更多的同学就非python的这个编程的同学能理解这个过程。
	首先我们这个请求就是一个HTTP的请求而已。这个HTDP的请求就两个东西很重要。第一个东西就是这个header，就请求头，请求头里面要包含两个很重要的key。一个是我们的content type，我们的内容的这个类型是Jason的。第二个就是我们的验证，要包含我们的APIK这两个header里面。
	那第二个就是我们请求他其实就是请求丢一些Jason数据。刚刚说的它类型是Jason对吧？那这个Jason里面有model有message，这俩就跟我们这个models里面，它应该可以这样设定。稍等，好，这样大家应该能看得更清楚一点。在这儿。
	我们的杰森。
	里面放了model跟message，对吧？就跟这儿放了model跟message一模一样，这个没有什么区别。然后你要说还有什么区别的话？相比上一节课，我们这里新加了两个参数，一个叫functions，一个叫function call对吧？这两个我们在上面API的部分也介绍了。然后整个notebook前面就是教大家怎么用functions和function call这俩参数的。那这两个参数我们也会把它传到这个js里面来。然后如果我们直接用这个的话，其实就是用它的Jason的参数就好了，用它的这个functions和function call的参数就好了，就这么个区别问，区别不大好。
	因为是用的request这个库，这个请求HTTP请求的库，所以它有可能会出现问题。那我们加一个try catch去做一个异常的补货，当他这个没有请求成功的时候，我们去输出一些日志，让我们看到他到底有什么样的一些问题。在请求的时候，好，就这么一个区别。然后这是第一个函数，相当于我们用这么一个函数实现了这里的这个chat completion create这个方法。
	然后大家如果不是python的这个同学，也可以自己去构造其他语言的。比如说诺基S是官方支持的对吧？那其他的一些语言肯定也能对它进行请求。因为只要是一个HTP的请求，你把你的请求体变成一个Jason，那就可以拿到这样的一个结果，你可以把它解析成你要的这个编程语言里面的数据。
	好，然后第二个就是我们打印一下这个内容。我们刚刚其实看到这个playground里面有三块，一块是system，一块是user，一块是a system。我们在这个输出里面，也做了这么一个函数，然后这个函数里面，我们稍微把输出做了一些比较好的效果。第一个就是我们会把这个不同的角色的system和这个user和assistant，我们的颜色会不太一样。甚至我们还会有一个角色是function，就我们是function call，对吧？所以这个function这个角色我们会单独一个颜色，有四种颜色。
	然后在assistant里面又会有两个细的区分。一个就是说我们用了这个function，我们还记得上面有讲对吧？我们回到这儿，我们有讲它可以强制不去使用它，也可以让他自己去选择什么时候使用它。那用没用就是两种场景。我们会把这两种场景区分出来，在下面的输出里面我们也会比较明确的看到这个区别。好，我们去执行一下这个，已经执行过这两行了是吧？
	好，然后怎么去使用这个方式参数呢？比较关键的事情是方向参数。它是一个大家可以理解成就是定义一个函数，但这个函数跟我们自己实现又不太一样。
	为什么叫自然语言编程？就是你要告诉这个大模型你有一个什么样的函数，但是你不用把你这个函数具体怎么实现的告诉他。就相当于你现在是一个产品经理或者提需求的人，而那个大模型就是那个接受需求的人。那你现在写的这个functions就有几个要素，这个要素第一个就是说名字，这应该叫函数。这个自动翻译的这个呃自动补全的这个注释有点小问题。到时候大家可能帮帮忙把这个注释修改一下，这个功能都是函数，就这个function。对，然后你要把这个函数的名称告诉他，然后把函数的描述也告诉他。
	这样的话大体首先就能说清楚这个是干嘛的。比如说这个函数的名称就是我们的函数名，我们大家都写过函数对吧？就这里的这个两个都是函数名，这个应该说你都知道了，函数名你要写清楚。
	比如说这里两个函数，一个叫get current weather，一个叫get n day weather forecast。简单来说就是一个是对当前的天气你给我一个结论，或者说给我一个预报。第二个就是说给几天后的天气给个预报，那就是天气预报的两个函数。他们需要什么样的参数呢？就我函数需要有入参。
	获得当前天气预报的这个函数，最重要的参数是什么呢？是location，就我们这一个practice对吧？就这个parameter是三要素当中的一个name，和这个parameter是必填的。这里应该有写，放在这里了。
	我们需要去告诉他这个permit里面有什么，有这个object。那这个object里面的这个属性是什么呢？第一个是这个location，第二个就是这个单位。所以说这个函数是用来给出当前的天气预报的那它的入参是什么？入参是我们的这个地点，你一定要告诉他是哪儿他才有天气预报，对吧？然后你告诉我你要的单位是什么，是这个华氏度，还是说这个摄氏度，然后这就是一个函数的定义。
	我不知道有的同学用没用过这样的语法去描述函数。但其实这个在有一些编程语言里面也是一些比较常见的疗法。或者说在这个压秒，在这种标记性语言里面其实是也蛮常用的。
	然后这里还会有一个很重要的点是什么呢？就这个parameter里面还会有一个词叫做required，就跟我们有点像嵌套了对吧？就OpenAI告诉你这个functions里面有两个参数是必填的，name和parameter。那你现在用这个功能去定义了一个函数，这个函数也有两个参数，这两个参数是必要的那当然你也可以进行一些不必不是必须要传的参数，由OpenAI来判断。
	现在用户给没给你那些optional就可选的参数，这个就很神奇，就把GPT当成了一个研发人员。你只告诉他需求，告诉他功能，要由他来判断这事儿是不是应该让你来干。然后来干的话需要什么样的输入。所以他其实曾经变成了一个很重要的桥梁，就是你可以简单想象成，首先你给GPT布置了一个需求，这个需求你说清楚了，就是你能能要干这些事儿。GPT就去跟那个用户聊，然后用户聊的过程当中，他就会去判断用户有可能就是在问这个天气预报了。但是你还设定了要问这个天气预报必须要有哪些信息，那他在跟用户交流的时候，他也许就会去主动找用户要这些信息，或者说直接就判断出用户没有在聊这个事儿，就完全不调用你这个函数。所以这个GPT扮演了一个中间桥梁，他来帮你判断用户有没有去聊跟你function相关的事儿。
	第二个也是一样的，就是需要几天后的天气预报。这个几天后的天气预报里面，除了我们刚刚说两个参数以外，还有一个很重要的参数，就是到底是第几天后，对吧？就是你要预测的是第五天还是第六天，还是明天，这就是一个新的参数，它也是一个必要的那整个这个其实就定义了一个functions，这个functions就是我们开始上面提到的这提到这个functions。
	好，那这个functions我们执行一下，执行完了之后我们看看下面实际怎么去用它。大家还记得我们刚才那个playground里面有这个不同的肉，对吧？我们把这个system给它填了一个什么样的prom呢？首先这个prompt告诉他是一个system的角色，然后让他去不要做这个。简单来说就是一句话来说就是我把这个换下来，只要能看的全一点大家。
	这里有一段消息，这个消息的核心就是首先我们要去判断这个用户应该是在跟这个天气预报相关的问题的时候。如果我们发现用户的表达是有一些歧义或者不清晰的时候，这个GPT就我们现在跟他聊的这个chat completion的这个聊天的这个GPT模型，要让用户去澄清他到底要问什么，这个是一个很重要的沟通技巧对吧？就是首先你判断意图，判断用户是在问天气了。好，那用户如果是在问天气的时候，你又有两个功能。你有一个功能是预测当前的天气，你还有一个功能是预测几天后的天气。
	那你现在在判断用户他有没有在问题，如果有在问天气的话，给的信息够不够？不够的话，那你就要找用户要信息。其实整个prot就是干这么一个事儿，大家可以简单这么理解。
	这个是给system的这个角色写的prompt，然后我们接着给用户会问什么问题。比如说我们让用户问的是what's the weather like today？就今天的天气怎么样吧？然后我们把这两个message就装到这个message里面，然后这个应该之前都跟之前的这个方法是一样的，对吧？这段代码大家如果跑过上一节课的models应该是很熟悉的。
	然后调用我们刚刚定义的这个方法，就chat completion request，把这个message传进去，model是没有传，因为model我们给了它一个默认值。大家如果还记得的话，在这儿给了一个默认值，那这个默认值是GPT3.5，这个你也能改。如果咱们有GPT4的权限，主要是改GPT4就完了。然后我们的function和这个function call这两个参数都给了默认值是no，就默认不用你传了，我再用好，然后我们去实际执行的时候，我们把这个function传进去了，function就是我们刚刚定义那两个函数，对吧？
	我们描述清楚了，有两个可以查天气预报的，然后我们把这个结果获取回来。这里会跟之前有一些不同，因为我们用的是request的code的这个方法，要拿到的结果要先用Jason把它变成一个序列化的数据。后面这个是一样的，因为它内部结构是相同的，如果大家用的不同的编程语言，也都是需要做前面这一步。
	变成一个序列化的格式的反序列化的结果。然后就可以去把里面的数据结构存取出来，取出来了。取出来之后，我们知道这个接口你丢给他的是message，是一个聊天记录，返回的是assistant的那个回复，所以回来就是assistant的这个message，然后把这个assistant message可以加到这个message里面。
	到这一步大家就能理解为什么我要用这样的方法来实现了，对吧？上一节课我们专门有讲，标准的这个方法返回的很恶心对吧？它是一个OpenAI的object，我看哪里我没有写到，这里就在这儿，它是一个OpenAI的object。
	我们再对比来看这两部分的处理手段。在我看一下。在这个位置我们直接把这个assistant message添加进去了。但是在上一节课，我们从这个chat m complication API里面获取出来这个new message。我们打印出来没问题，我们加进去有问题，因为它是一个OpenAI的object，对吧？然后这个open ID object我们还得去做处理，怎么处理呢？我们在这儿用的这一句prompt，把这个OpenAI的这个object变成了一个message，dipt就是变成了一个字典，然后这个字典才能加进去，对吧？
	所以这个步骤就很烦，每一步都得操作。那用这种方式至少有一个好处是说，我拿到的就是一个python的字典。然后这个python的字典就能直接put到我们的消息列表里面，这个是一种方式。当然我们也可以去实现把这一部分封装到一个新的函数里。我们可以用原来这个方式也是一样的，这些都是大家可以去接着扩展的，也是家庭作业之一。
	好，我们实际执行一下。这是我们给system的这个prompt，这个是我们user提的问题，然后这个地方是我们的回复，我们把这个已经添加进去了，然后用了这个输出，然后你看这个是content对吧？这是直接的回复。
	这个我们刚刚在上面的代码里面有定义，如果这个assistant判断不需要调用函数，他就会回复这个content就跟我们上上节课这个hello world一样，他说hi，what can I do for you? 对吧？我记得好像是h how I how can I assist assess you today？你就跟这类似对吧？但是不同在哪儿？不同在于他们没有闲聊。
	我们的第一个问题问的就是天气。然后我们的assistant让他提供什么呢？让他提供location对吧？大家看一看提供location，这个location就是我们刚刚在function定义里面要的一个必传的参数，所以他其实已经在往这方面去引导了。
	好，然后这个是我刚刚验证的我们的assistant message是一个字典类型，不需要做转换。然后我们下一步是什么呢？这个是持续聊天的，跟我们刚刚这个playground一样。那他让我提供这个位置，我就提供我在上海，对吧，你继续执行一下。
	大家看这个聊天记录是往下走的，这就出现不同了。就是我说我在上海，然后这个地方assistant去调用了这个function，调用的哪个function呢？调用了也不叫调用了，叫叫走入了这个里面的逻辑，它其实就是在走get current weather这个逻辑。然后这个里面，首先它它这个地方判断出我是在问天气了，但是缺地点，那我提供的地点它就构造出了这么一个function call的结果，就是这个是一个get current weather的function。然后有两个参数，一个参数是地点叫上海中国，这个单位是C那就摄氏度，然后这俩就都有了。所以拿到这个其实就可以往下一步做的话，如果我们真的有一个函数是去获取上海的温度，并且是摄氏度这个单位的话，那其实就能进一步把这个答案给出来了。
	所以到这儿为止，其实大家应该大概能明白这个意思了，对吧？就是我们的function call是我们能定义一些方向，然后把这个能力告知我们的GPT模型。然后让GPT模型在跟用户交流的时候去获取一些有效信息。这些有效信息最终就可以组装成我们的那个函数的一些重要参数。
	并且有多个函数的话，还能让我们的GPT去判断他可能在问哪个函数的事儿，那这个想象力就更大了。我们要去做助手的话，其实我们可以把你这个平台里面已经有的很多种不同的API都以刚刚的那个functions的方式写出来。它都可以通过对话的方式去调用你这些API了，这个是一个很夸张的能力提升，然后这个是一个示例，就我们能够跟你系统内部的API对接起来了。第二个就是说我们还可以通过一些不同的方式告诉我们一些其他的功能。我们具体去看这个输出比较直观，我们这里就故意去刁难他。
	首先我一来我就告诉他，我现在想知道上海的天气，但是我没告诉他具体是哪。这几天后我写了一个X这里我们的系统的判断，他没法直接的去帮助我们，对吧？然后他就让我们去了解一下到底是几天后，所以这里他给了一个很有意思的回复，对吧？因为他没有直接调用，他其实是用的他大语言模型的能力，用他的语义理解的能力OK。然后这个模型因为信息不够的情况下，他不知道多少天，我们就直接告诉他五天我们看到会发生什么事情。大家可以看到这个聊天记录在这里，我们告诉他五天。那告诉他五天之后，他就知道他现在不能用get current weather这么一个函数了。
	因为那个是不能查未来几天的，而是得用这个get n day weather forecast这么一个方法，这么一个函数，然后给的参数它也都整合好了。所以从这个角度来说，其实把很多以前我们要写的胶水代码，尤其是那些CRUD的业务逻辑的代码，通过大模型可以动态的帮你去做生成和组装。这个是非常强的。
	然后甚至我们也可以让他强制的去用某一个函数，所以就相当于强引导，就比如说我们这儿给了一个需求，我们问这个森迪阿狗，就我曾经待过的一个美国的城市，问森迪阿狗的这个天气是什么样的。但是我们强行给到这个需求是只能调这个，就不能调当前的。这个它有两个函数，大家还记得对吧？就我们传进去了两个函数定义，但是我们只让他调这个，而不能调这个current to weather这么一个方法。
	那我们看怎么说就正常。如果他自己来判断的话，他很有可能是会直接给你这个结论的。就是因为你已经说了地点了，对吧？然后无非就是他在向你确认一下你是要华氏度还是摄氏度。如果是美国的话，他会基于他的这个逻辑，可能会给你一些预设的判断。而且你本来这个format也是有我印象中给了一些结论的。那么即使是当这个当天的，他也会把当天的这个事儿变成一个one day，就相当于一个等价转换。
	然后把这个结论给你就是因为你强制的设定了这么一个玩意儿，这个在不同的场景里面都是可以去给我们留下了充分的空间可以去做这个设定的。就跟我们刚刚说那个system的这个prompt和我们的这个业务场景可以做对标。那现在又多了一个武器，就是你有这个system的这个prompt了。
	然后同时，你还有这个function call，这个function call可以设置成打开了所有的方向，也可以设置成只打开部分的方向，也可以设置成全部打开，交给GPT t GPT去判断你现在要用哪个方向，好吧？然后我们这个也可以不去设置，关键就在这个调用上，对吧？让他自己去判断这句话没有变化，就我们的system的prompt和我们的user的这个prom user prompt都没变，就这俩内容是没变的。我们单纯只是把这个function call给改变了。那他现在可能默认认为这个用户的问题更适合用这个carbon weather。然后他就直接给出了这个current together这个调用，然后信息也都是够的那这个应该就是相当于我们大家应该已经整明白这个意思了，对吧？
	就function用来定义能力，function call这个参数是用来告诉我们这一次对话的时候你能够用什么，或者说你压根就什么都不用。这里就是我们压根就不用，那不用的话，它大家可以看到其问题都没怎么变化，甚至这个问题更明确。我们直接就问他能不能给我当前的天气，还用了这个单位，然后在地点就是非常强烈的一个信号了。但是他没有这个能力，开启放心后这个能力被关掉了，那相当于就看不见这里的任何方向了。那么他就没办法，他就只能给你一个大语言模型的回复，和这个回复给了一个这样的结论，对OK。
	到这儿为止，其实我们讲明白了这个function，怎么去定义这个函数，以及他需要的一些参数，还有它的描述。然后同时用function call，我们可以去开启这些functions的能力。在每一个对话的调用的时候，在每一个chat company可以chat completions API调用的时候都可以去设置。然后接着我们再看看那些函数都生成出来了，能不能执行，对吧？
	这个时候我们引入一个新的数据样本数据库，这个样本数据库是一个叫做清货清了，应该这么念的这么一个样本数据库。这个样本数据库是跟是跟音乐什么相关的，就是跟多媒体相关的，具体我没去研究。这个是官方给的一个推荐。然后在这个里面，其实他要做的事情比较简单，就是刚刚上面是查天气的那如果我们能对接一个查天气的系统，就能真的给用户信息了。因为如果我们有这么一个系统，这个系统需要的输入就都有了。那现在假设我们要去从一个数据库里面查数据。那假设我们这个时候有一个数据库，然后我们又生成了查数据库的对应的这些方法查询query，那我们就真的能查了。
	那我们用了一个什么样的数据库呢？其实非常简单的一个circle lite，就circle light。这个我不清楚大家用没用过。简单来说就是它是一个最轻量的数据库。然后以文件每个文件其实就是一个数据库。大家可以在如果是mac的话，可以装一个很轻的小的应用，叫DB brother for circle LT。其他的windows、linux应该也都有类似的circle light这种查看器。
	我们把这个文件下载下来，就这个目录在这项目里面我们也都下载下来了。大家如果把代码clone下来的话，这里就能看到这个文件这个文件。然后这个文件打开其实是这样的，里面有13张表，然后这十三张表里面存了很多信息。然后我们通过这个python的库CLET3就能够跟这个是我们这个文件的路径，就能连接上这个数据库了。
	可以这么理解，然后为了获取这个数据库里的数据，我们还定义了三个函数，获取表的名字对吧？获取每一张表的列的名字。这个大家用过excel都知道对吧？有表的名儿，有梅列的名字，对吧？然后包括具体的这个值信息，返回这个字典的信息，然后我们定义好去获取一下这个数据库的信息。这报错了，我看没有执行这一句话，不好意思，压根就没建立连接，跳过了。
	我们来定义一下，这儿获取完了之后，我们查看一下，这个就是我们刚刚看到的，就我那个截图里面的这是这个DB文件里面的数据。然后里面会有不同的表的名字，对吧？专辑，这个艺术家，然后包括这个employee，这个发票，收据什么的，这里面就是一个数据库的查询的结果，把它存到了一个字典里面，这些不重要的信息我就跳过了。
	然后同样的套路定义一个函数，这个函数干嘛的呢？把这个缩小，这个函数干嘛的呢？这个函数是用来回答用户问题的，回答用户关于音乐的问题的。所以这个description大家现在再来品一品，这是一个什么东西？这其实是一个prompt对吧？这个prompt是用来干嘛的？这个prompt其实是用来告诉我们的GPT，他对于这个函数的理解就是如果我们把这个description写的越好，其实对于GPT来说它越能清楚该不该哭，对吧？就我们有两个参数，functions, functions里面去描述了我们有哪些能力。Functions description其实是一个可选参数，但这个可选参数又极其关键。
	你一般人描述不来这个函数的功能，就跟你跟牛逼的PM聊天，他能把这个description写的特别好，他会有他的feature，有他的user story。但是这个一般的PM可能就只能告诉你1234你要这么做对吧？那么这个description其实就是去告诉GPT模型这个function能干什么。然后如果你的function call这个参数里面又有这个function，那你的GPT模型在这一次调用的时候，就可以通过这个description和用户现在这一次user里面的这个content去做比较，对吧？然后就知道你现在这个user的content和这个description的关联度有多高。如果关联度很高的话，甚至你的system里面的content都已经比较明确的写了一些你要干什么事情了。那他就能知道他该去找哪个function。
	那这个时候他也就知道这个function里面又需要什么。就是它是层层递进，环环相扣的对吧？他他找对了function就会去看这个function的参数，这个function的parameter里面哪些是必要的，它就有一个request，这个request里面的东西有没有用户提供的，够不够？不够的话就会像上一个例子一样，你缺地点，我就问你地点，你是要缺到底是几天后的，我就告诉你是几天后的。所以这个function这个功能的设计就充分的把大语言模型的这个语义理解能力又提到了一个新的高度。把这个跟大语言模型结对编程这件事儿，为什么说要用自然语言来编程？这种范式就真的是开启了一个新的窗口，一个里程碑，让大家能理解原来还可以这样写代码，还可以这样去跟API交互，还可以这样去跟库交互。
	那我们继续执行一下，定义好了这个functions之后，我们看看下面代码就很简单了，这里有两个函数，这个函数很关键，就相当于模拟了一下我们的这个刚刚天气查询的那个真的有一个系统。那这也是一样的。假设我们真的把这个circle语句给造出来了，我们能不能执进这个circle语句上面，我们已经跟circle light建立连接了，有个connection对吧？这个句柄这个用过数据库代码的是这数据库编程。大家接触过就知道，这玩意儿就是跟数据库建立了一个连接。然后这个连接只要不断开，你就一直能访问数据库。通过这个我们已经查出来所有的数据了，所以这个数据库连接肯定是建立了。
	建立之后，那能不能去执行一些circle查询呢？可以就通过这里来执行。这两个函数就是用来干这个事儿的，具体怎么干的呢？就是通过其实具体的执行就是通过这个connection的execute来执行这个query。就是相当于假设我们人来写的话也是这么写的。就我们执行一个circle查询语句，通过这个连接就找到了这个对应的数据库。就我们刚刚看的那个有十几张表的数据库，然后把它的执行结果feature all就全部拿回来。
	相当于在这个circulate上面去执行一个特定的query，拿回它所有的结果，就这就这个函数干的事儿。但这个query不是人写的，是由我们的大语言模型来生成的对吧？那这个就很不一样了，这个curry怎么生成的呢？就从哪儿拿的，就从这儿拿的，你看他怎么构造的。就假设我们判断出来了，我们有一个大语言模型是知道用户要查这个数据库了，那他会去取这个函数的名称，然后会去取这个函数的内容，我们往下看就懂了。到这一步就很明确了，大家就能理解这个意思了。
	上面套路都是一样的，对吧？System里面去说，我们的这个system的这个content是干嘛的？就是我们现在整个这个对话环境要解决的问题是回答用户的问问题，怎么怎么解决？怎么回答呢？通过生成circle的这个查询语句，并且是面向特定的数据库的。这个说的很清楚对吧？
	这是一个我们再回想前面1个小时讲的事情，system要做什么事情？第一要做指令的注入，那他接下来这个system就不用变了，就一直干这个事儿。第二个要更具体回答用户的问题，怎么回答？这是一个具体的任务，生成circle语句，并且是面向这个数据库的。
	好，然后我们看user提了什么样的问题呢？嗨就是who are the top five artist by number of tracks？他就是问了一个这样的问题，这个问题其实挺挺常见的，就是我想知道这个比较出名的，然后他这个艺术家通过什么来判断呢？通过这个number of tracks来判断谁谁算是top的，谁这个排行榜排的高就他的，那他tracks比较多。那这个问题如果正常人来回答，他就拍脑袋，对吧？或者你就把它输到这个谷歌搜索引擎里，输到百度的搜索引擎里面去查呗。但是我们已经有这个库了，所以其实这个常识我们是有的，就跟刚刚我们去做模型评估质量这个例子是一样的。
	那个例子是直接就告诉了你一段话，然后这段话你去做比较，但现在是给了你一个数据库，你要去做比较。那怎么做比较？通过circle去查数据库就能做比较，那怎么查呢？首先你要去查艺术家，吧，然后你要去查这艺术家对应的tracks是有多少，然后再排个序，其实就干这个事儿。
	大家如果把这个捋清楚的话，然后我们能看到这个地方他去他去生成了去查，然后他怎么去查呢？首先他调用了这个function call，然后这个function call里面有一个函数，就指定了一个函数叫做ask这个database，ask database里面去找这个circle查询语句怎么写。这个的这个基础大家如果不具备的话，就通过GPT来学一学简单的circle的语法。它其实就是从这里有一张表叫tracks，然后去构造了这么一个数据。这儿出现了一个问题，就没有这一列，我们看看具体是什么问题，先往下执行。
	Artist有这个RTSID的，是在哪个表？Tracks这个表。
	再往下看一下。
	这好像是我可能给的数据有一些问题，他在这个表里没找到这一列，下来我看看问题出在哪哪里。但下面这条是执行成功了，就是问这个专辑这个track最多的是哪一个专辑？然后他给出了这个名字，他构造了这个circle查询语句。那这个circle查询语句去这个数据库里做了实际的查询，就从这一段话里面，我们拿到了这个data base，就他现在要确认我在调用的是不是这个函数，那是这个ask data base，就是我们上面定义的这个函数。然后同时又去从这个function call里面去拿到了这个query，我们再回看一下，这里相当于这个是assistant的返回，就这个其实是assistant message对吧？从这儿加进去的，然后我们拿到了它的这个name，这个是函数名称，这个是它的query，这个块里面就构造了一个circle的查询语句，它会去执行这个circle查询语句，在这个函数里。构造出来之后调用这个ask database。就这里的ask database就在我们的这个里面去做了实际的查询。
	然后到这儿为止，其实我们总结一下，就是整个这个notebook干了四个事情。第一个就是讲清楚我们的functions参数和我们的function call这俩参数怎么样去使用的。然后我们构造了查天气的这些用助手生成的这些函数和它的参数。这个函数和这个参数大家其实可以把它端到端的最后把它做完，这就是我们homework的这个第二个？
	就是我们刚刚提到了在上面的部分我们构造出来了怎么样去查天气。有两个函数，这两个函数的参数我们也都让大模型生成了。而我们能不能拿到这些参数，然后再进一步去对接搜索引擎的API也好，或者对应一些像什么慕克这样的这些天气的这些APP也好，或者说这种服务也好。把这个天气查询的应用也像这个circle查询应用一样给它做完，这个是一个homework可选，大家可以试着来做这个事情。我们如果做好了的话，可以提交这个pull request到这个代码库里。然后第二个就是说我们刚刚使用了这个chat completion request这么一个方法去封装了，对吧？因为它可以直接从我们的API返回结果里面拿到一个python字典，这python字典就能直接加到我们的这个message这个记录里。
	好，然后那我们原来上一节课讲的这这种方法，它就不能用了吗？它其实也能用，它怎么用呢？其实它就是我们把刚刚说的这些参数，以这个方式与我们这边鼠标可能看不见，以这样的一个OpenAI的python库的方式仍然是能去调用的。拿到的这个返回结果其实就这儿这个结果这个data也好，我们叫completion也好，叫message也好，这个结果其实就是这个助手的返回结果。不过它的结构是一个OpenAI的object，我们需要对它稍微进行一些处理。处理之后就能变成一个python字典，也就能跟上面的很多代码就接上了。这是一个更清亮一点的homework 1，大家如果有实现的话，也能把它做好，然后变成这个pull request提上来。
	今天的这个function calling和我们的这个GPT的使用技巧，包括这三个角色。其实今天一句话总结就是把这个chat complication chat不好意思有点卡，把这个chat completions API这个最重要的API也是我们调用OpenAI的大模型的话，主要就是这个API了。把这个大模型的API里面，不管是我们年初的这种不同角色设定的这种用法，要把prompt设计好，要把这个token message都用好。还是说我们现在上个月刚刚公布的function calling这个功能，能够把它接入进来，实现类似于ChatGPT plug in这样的一个体验，这些都是我们再往后一步要去真正去做一个实战项目的基础。今天的这个分享就到这儿，然后我们再回答问题的环节，看大家有什么问题。
	第一个问题就是这里问题比较简单，表设计的比较复杂，问的问题涉及一些多表关联统计，这要怎么搞？这个问题问的很典型。第一你的表首先就是我相信你的问题还是在关系型数据库里。那如果你的关系性数据库里的一个查询要连接七八个表，那你这个问题就该被拆解，或者说你的表应该重新设计。这是从另一头来做，就从表这头来做。第二就是说从大语言模型这一头来做，就是把你的问题拆解成多个方向。相当于把你的多表连连接多表joint变成多个function，然后让你的大模型step by step去join。
	有个同学做的挺好，circle直接ORM对应起来就成了。对，ORM是关系型数据库非常重要的一个里程碑，这个O能不能变成你这里的functions parameter里面的object就很关键，对吧？我们看看讲了这么多parameter type object practice，对吧？如果这里的O能够变成不是这个O我们就要这里，当你能到这一层定义，那更抽象的更高那更好。就我们这一堆的参数能不能变成你的一列的数据。然后这些东西通过语义的表达能描述清楚，大语言模型能做的复杂，逻辑整合挺强的。
	举个简单例子，就是小说人家都能写你的人物关系有多复杂，对吧？关键是你描述的好不好，就是大家角色发生了变化。以前我们是一个研发工作者，我们是一个开发者，那现在你要变成那个提需求的人了。大家老说提需求的人水平不行，提不来需求。那现在你来提一提试试看，大语言模型的理解能力肯定比你强。我坦白来说比绝大多数人要强，他都理解不了，那说明你的需求提的真的不好。而且坦白来说，绝大部分人没有经历过这个沟通技巧，包你训练的人是提不出来好的问题的，包括我自己，所以在不断学习。
	有个同学说刚刚拉了代码，没看到今天的代码，这个就很玄学了，怎么可能呢？对吧？这个不科学的。
	大家问问题问的跟我们这节课关联度高一点，然后问的准确一点。对我一个提问涉及多个function的串联，chat BT可以吗？当然可以。这个问题大家不要把function想成一个很复杂的东西，function也就只是一个大模型的解决问题的步骤而已。我们刚才已经讲了，大模型是可以分步骤解决问题的那那你把你的每一个步骤大模型去解决问题，就是难道你的function不能写到你的system的prompt里面去吗？也是可以写的。就是这里为什么前面1个小时要先讲system有各种玩法，那function是在这个功能上叠加的对，那你system的problem里面能不能给他写清楚有哪几个步骤，哪几个步骤分别对应哪几个function，然后再告诉我们的这个大模型user提的这些问题里面，要从里面怎么样去拆解到多个步骤，那他就一定能做的。
	还有个同学问language到circle的转化正确率高吗？这个问题我要批评一下，问的很不专业。对，就是这不是一个正确率高不高的问题。如果你水平高，你设计的prompt好，它就高。对，如果你的prompt，你的content、你的message做的不好，他就必他甚至都不知道你要查circle。优秀的函数描述有哪些特点？好问题，你现在就可以把这个问题丢给GPT，对。
	刚学python理解很吃力的同学有两个解决办法。第一个就是我们的课程应该有送即刻时间的python课程去学一学。第二就是我们整个代码里面都充满了注释，如果这个注释都还不能满足你的需求，那你就可以再问一下GPT，你还有哪句话？哪段代码不太懂。
	还有个同学问。
	这里的function. 
	必须是大模型output的吗？这个我没太听懂，对，是什么意思。然后。
	还有一个问题，这个例子当中OpenAI是怎么知道数据库结构的呢？那我们再来好好看一下system prompt要怎么设计。
	有没有看到这个system from的有一个很重要的一句话，就是他要回答用户的问题，所以这是他第一件要干的。就他相当于他他做的这个回复的最顶层逻辑是要回答问题。然后怎么回答方式是生成circle的查询语句。Circle查询语句怎么生成？要面向一个特定的数据库生成，就特定数据库他是不是能去查到，他是不是知道这个数据库里有哪些表，有哪些列，那他是不是就能访问了？
	这个同学说大家都这么看不起产品经理的。首先我觉得我不知道大家怎么看，我是非常尊敬产品经理的。因为讲道理，CEO基本就是产品经理这个角色要干的事情，描述公司级别的需求，然后让所有的人理解需求。所有问如果用怎么写一下，是不是更好一些，更准一些，效果更好一些的同学实际动手去跟GPT聊，自己去动手看。不要都到用大模型了，还想要有一个人告诉你一个准确答案，这个世界不存在这样的黑魔法了，就没有谁说了一句话你信了，你不觉得也很可怕吗？他说什么你就信什么。
	还有个同学问什么这种方式和自己什么构造circle，然后执行巴拉有什么优势吗？没有什么优势，因为这跟你的自己的实际情况有关。信息不够无法判断是否有优势，只能说function calling给了大家一个窗口，让大家可以用不用ChatGPT的plug in，也能享受ChatGPT plug in的这种模式对。
	我看好多都在问这个数据库，杰哥刚应该已经回答了，可能是我刷的比较慢。大家跳出现在的编程语言，就是有人同学问function code实现java go语言这个functions的定义支持其他语言吗？首先对于大语言模型来说，就没有人类的java go的编程语言的明确界限，它生成的就是一段自然语言。大家再仔细看看，这是一串字符串，只不过这个字符串恰好符合人类的circle query。它就是大语言模型理解什么叫circle query。所以他知道这个query的一些范式应该满足什么样的条件。然后如果你是一个特定的，很小众的，不是这种像circle全民皆知的这种知识点，是一个特定的库。那你需要对它进行funny，你需要让你的大语言模型具备你那个库的一些规范化的能力，它才能生成对应的代码，不然它生成不了。
	我们最后再挑五个问题。
	有一些同学问的问题，其实刚才回答已经覆盖了，我这边就不再讲了。然后我们看看有个同学问function code是在自己的服务器上执行，还是ChatGPT通过HTTP回调服务器的这个问题我再还再赘述一下。第一，function call没有执行任何东西。我在讲notebook之前就讲了，function call大模型不帮你执行function call的任何东西。所以说为什么第一个例子没有查出天气来，对吧？因为他不会帮你执行的，他也没法帮所有人都执行。他没有做一个万能ai它就是个语言模型，它不是解释器，不是编译器，不是搜索引擎。好，所以他帮你干了什么事儿，他帮你把你的的需求转换成现有的能查询，能提供这个服务的人能听懂的语言了。所以它是一个桥梁，它桥梁连接了谁？连接了user和functions，对吧？
	User有需求，functions有能力，但是经常对不上号，那怎么办？大语言模型来帮你把他们的需求和能力匹配上。怎么匹配？你说清楚一点，你现在有什么能力？你的能力里面要解决这个问题，你的能力很强。但你有没有什么必要的参数需要用户提供的，那大语言模型帮你去问，他来干这个事儿，所以是干这么个事儿的。
	好，那现在functions的能力具体要具体怎么执行，是要我们这些做应用开发的人提供能力的。就比如说这里我们实现了一个执行circle语句的函数，对吧？这个函数是可以实际去执行circle语句的。比如说下面我们有个家庭作业，让大家去执行天气查询的这个端到端的应用。那要找一个能查天气的API，或者说直接去查搜索引擎。对倒数第二个问题。
	第二倒数第二个问题，又有人在问这个description描述的多清楚，有没有什么标准模式才能知道是否返回方形后？这个问题跟刚刚问怎么样好不好一样，自己去试，playground上面去，playground还试不了，但playground上面能试各种prompt了。然后方形扩我相信未来他应该也能支持他的UI上。如果他支持不了，咱们有同学能做GUI的对吧？基于radio的去做一个自己去试好吧？每个人的问题都不一样，没有一个一招鲜的description。最后一个问题。我从道中回来。
	好像没有什么问题了。Function是能在其他大语言模型中用吗？这是最后一个问题，function是不能在其他大语言模型当中用。
	这个第一行就讲明白了，大家去好好看一下，functions是OpenAI的chat come completions API里面的一个参数提供的功能。所以这个API才有这个能力。我们上节课讲的completion API都没这个能力，所以自然其他大语言模型也用不了。但是其他大语言模型能不能提供类似的功能呢？我觉得一定是可以的，但是我们现在又讲的这个functions和function call的用法，是特指OpenAI的这个API的能力。好那么。我们就这样，我们这个translator，对啥时候讲自己实现translator，下一节课下一节课我们就来玩open a translator了。
	好。
	我们今天的分享就到这儿。