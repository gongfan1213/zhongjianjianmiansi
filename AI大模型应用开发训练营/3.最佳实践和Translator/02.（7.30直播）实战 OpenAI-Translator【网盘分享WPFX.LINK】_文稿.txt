	我们今天就直接开始。好，我看大家都都显示能听见能看见。今天我们开始第一个实战OpenAI的translator，我们会分成这几个部分跟大家做一个分享。从实战课开始我们就会着重到代码这一侧，就减少理论的分享了。我看这周有同学在群里面问这个理论课能不能再多讲一讲，讲一讲最近这几周发生的一些新的AI的一些进展。这个我们就暂时暂时会在这个已经计划好的课程。如果我们都能够按期完成，然后大家反馈都还不错的情况下，也许我们在最后一期的这个直播视频课程里面可以跟大家再来分享，就看我们各个同学的这个进度了。
	然后从实战课程开始，其实我们还会有一些奖励。我看班主任也在群里面做了关于我们实战课程的一些奖品。待会儿我们会在今天的这个直播最后的部分跟大家讲我们要做什么。
	然后今天的这个OpenAI translator作为我们的第一个实战课，也很有代表性的意义。因为目前上传到我们的课程项目当中的这个版本，是用GPT4写出来的一个版本。我自己并没有去做很多额外的开发。这个很很巧，正好我们班主任跟我们教研组的老师们也设计好了，有这么一个环节。我们接下来就希望各个同学能在这个基础上，把我们的这个GPT4写的这份代码再优化。然后看看能不能有一些非常优秀的同学做的非常好啊。
	好，那我们就切入正题。首先讲讲这个OpenAI translator这么一个项目，他到底有没有这个市场上的需求。在讲需求之前，先给大家看一下这个之前课程里面的图。我相信看过课程应该都知道，左边是我们第一节课就讲过的sequence to sequence的这个网络，以及加了注意力机制之后的一个网络结构。右边这幅图其实是红山他们在红杉这个资本他们通过PT4写出来的一篇报道，就讲这个大模型，中间我们看到这一部分大模型在过去的这几十年来，尤其是最近这五年得到了一个飞速的发展。不管是模型的规模还是在各种类型的任务上面，包括视觉的，包括我们的这个语言层面上的。然后最右边这张图是我们的计算机视觉和我们的这个自然语言跟人类的比起来就是一个human performance。跟人类比起来，其实我们在视觉任务和这个自然语言任务上，AI都已经开始超过人类了，超过人类的平均水平了。
	这幅图一个最典型的一个点，其实包括它的意义，就是是我们上面说的这句话，就我们今天要做的这个事儿叫OpenAI。Translator其实就是一个做翻译的一个项目。机器翻译其实从我们第一节课开始，大家就知道是我们最广泛和最基础的一个自然语言处理的任务。并且通过我们前面几节课，不管是理论课也好，还是咱们自己动手实践，用了这个prompt去做实践也好，翻译是一个非常常见的过程。包括我们在使用前GPT的过程当中，我们也可能经常会用到这个翻译的这么一个任务，包括自己也有去用。
	那么GPT4在多语言任务上到底强不强？其实这一张也是之前有跟大家讲过的，在多语言的任务上面，其实GPT4已经有一个质的提升了。我们能看到这里的绿色的准确率，其实是974达到的。我上面是一些之前的一些任务，包括google的pm，这个是第一代的google的单元模型，他的英语水平其实跟GPT4比起来已经有非常大的差距了。GPT4除了在英语，在其他的多语言任务上也都有非常高的一个提升。在这样的一个基础上，我们再来看一看我们每天的这个日常工作当中，翻译是不是一个能赚到钱的事儿。我们除了说这个技术具备以外，翻译这件事儿本身有没有人愿意为他付费，有没有这么的一个需求和市场。
	这是我在google上面去搜索了一下，就现在有没有一些线上的翻译服务？其实是有的有人来做翻译的服务，这个网站叫translated点com大家可以去访问一下这个网站，这算是在google里搜索量比较高的了。他们是一家已经服务了24年的一家比较专业的人工翻译的公司。他也有选项，就我们能在这张官方网页上能看到，它也有中文的这个版本。从任何的语言到另一个语言，这都能学选。甚至你还可以多语言。比如说我输入是英语，我可以同时输出法语和中文，这样也是可以的。
	它的统计方式跟我们现在用GPT。GPT比较多的时候，我们都是按1000个token来算，那么翻译也是按一千字来做这个统计和报价的那他可以直接在这做字数统计。如果你自己本身去算过这个数字的话，有点类似于我们之前教了大家怎么样用这个take token去算我们的一个from加上我们message的这么一个token数量一样。这个翻译也是按照这个来来的那当然你也可以直接把文件传上来，他帮你去做一个统计，同时他也可以选不同的级别和专业领域，当然他对应的这个钱也不一样。如果你要的非常急的话，加急还需要再额外付费，大体来看，就是这样的一个收费模式。
	从统计的角度来说，跟我们用GPT4方式很像。它支持不同语言，不同语言的价格也不同。交付的时间越快，就包括这个专业领域，它如果越小众，质量要求越高，那么就价格越贵。大概是这样的一个收费模式。并且这个需求是长期存在的，我们的大学也有这样的专业，包括我们在这个研究生阶段也有对应的这种偏外语类的这样的一些穴位，其实是一个长期存在的需求，这个是人跟人沟通的需求。只要我们全球化还在，还有不同的语言存在，那这个需求是存在的，并且有市场，有报价，我们能知道做这个事儿带来多大的价值。
	我们简单再做一个对比，还是在translated点com这家网站上给出来的一个参考价格。就比如说我们能提供一些什么样的事例，就use case，我们可以让他去帮我们翻译网站，帮帮他们把这个PPT。就我们现在比如说我们现在在讲的这个课件翻译成纯英文的，或者说纯日语的，纯意大利语的都可以。包括一些新闻通稿，简历等等。这些都是可以去比较典型的一些use case。然后这里也有像刚刚我们报的这个3版的报价，最高级的级别最高，也最贵。然后右边是我们的GPT4和GPT3.5的一个报价。
	为了简化计算，我们假设一个token就等于一个英文单词，简单一点计算，我们可以看下来，如果我们去使用GPT3.5来帮我们完成一个翻译的工作的话，其实它的成本相对来说是比人力要低得多的。我不清楚这个账大家算过没有，这个是我实际今天算了一个账，大概的一个比例是这样。就如果我们选择最低一档，就我们选择最便宜的方式来做这个人力翻译的话，它的成本也是我们用GPT3.5的27倍。这个是一个非常夸张的一个数字。而且我们能想得到的是，人力成本未来应该是越来越高的，而GPT的使用成本相反应该是越来越低的。尤其是说未来我们可能还会看到大家能私有化的去部署一些大模型，那这个成本就会降得更低。那就不是按token计费了，那就直接按你使用的云服务来计费了。那这个是一个成本的角度来说的话，即使是最低一档的人力翻译，也比我们的GPT3.5要贵27倍。
	对，这个是一个实际情况。从刚刚提到的从技术的角度上来，我们看到GPT能胜任这样的工作。然后从价格的角度上来说，成本更低，27倍的一个价差。到安全的角度，我觉得这个也是一个非常重要的角度。
	目前我们看到大部分的线上的，我也是在网上收到的一个提供一个英文外国的公司提供的服务，叫dog translator。这家网站应该是投了很多的钱做了SEO。我在goods上说出来，第一个是这个。也有一些国内的，比如说像这个福昕阅读器，他们现在也做这个翻译服务，包括像有道，他们都有就这样的服务非常多。
	也有这种纯机器类的翻译，大家能看到这有人工翻译，也有机器翻译，但是这些机器类的翻译，就假设我们现在不找人了，人贵，我们找这种机器类的翻译会有一个什么问题呢？其实它需要你上传整个文件夹，大家能看到所有这一类的服务，他都会要求你上传整个PDF文件。但这就带来一个数据安全的问题。就假设如果你的这个文件像我们的课件，我们不希望这个课件直接就丢给了这样的一家服务公司，那他可以拿到我们整个PDF对吧？那这个就流失流流失出去了。如果我们有一些工作相关的文档，那可能就对数据要求更敏感。所以我们希望尽可能有一个服务，它是能够保证我们的数据安全的那这里我们就提到。
	今天这个OpenAI translator最后一部分就是我们数据安全的优势。首先我们如果是使用GPT来帮我们去做这个翻译，就比我们刚刚看到GPT3.5 turbo这么一个模型，有只需要27分之1的价格就能完成这样的一个翻译任务。但是它的数据安全相对来说比直接去找一个完整的文件上传类的这种机翻的，线上服务，相对来说要更安全一点。这个安全性怎么体现的？这里我们列了四个角度来讲这个事儿。
	第一个就是说GPT的服务。首先我们在上面几节课的时候有用过这个embedding的API，我不清楚大家有没有试过。在调用embedding NAPI的时候，有的同学会发现我同样的embedding n的模型，然后我同样的文本，但是调用出来的这个向量它是不一样的，就in bedding出来这个向量是不一样的。我看有的同学也在群里去讨论过这个问题。
	其实它核心是因为我们GPT它的服务，它不是同时只服务一个人的，他要服务全球很多的用户，所以它会部署很多个不同的API的end point。有没有同样的一个API它会有很多不同的end point，相当于你去调他的时候，他会去做负载均衡。但是他又跟传统的外部服务不一样，因为它是部署的模型，所以说大家同样调的是embedding ADA0这个模型。但它可能最后部署的这个实际调用的模型不一样，但出来的效果它是有保障的，基本是没有什么变化的那这个时候，我们如果去用GPT3.5帮我们去做翻译，其实会有一样的效果。就是你就算是一次性就你连续去调用，把一个文档拆成了多个，然后把它把这个文档拆成多个之后，都去调这个GPT3.5的模型，但他也会路由到不同的大模型上面。我不知道这个我表述清楚没有，就相当于其实背后有成千上万个不同的GPT3.5的模型，他们都在去帮你做这个翻译的事儿。
	所以其实在OpenAI的服务端看起来，它是不太会拿到你整份文件的。即使你把整份文件按照顺序一个一个去做调用。所以这个是GPT本身的这个服务部部署模式带来的一个好处。
	然后同时，OpenAI它的隐私协议相对来说也是一个比较可靠的这个隐私协议，大家也可以去上网访问一下，它有比较明确的privacy policy。这个一个网页上面有去讲调用不同的API，它会对你的数据采用什么样的一个隐私协议。包括他会暂时留存的时间，以及是否会使用你的数据拿去做训练等等。而且我发现这家公司，一个海外的公司，相对来说它的这个契约精神和法律保障，咱们也有一定的好处，这个是一个。从另一个视角来看。
	最后一个点就是说如果我们真的想完全解决这个隐私安全的问题，还有一个最稳妥的思路就是说我们去部署一个私有化的大模型。不管是部署像质谱的ChatGLM，还是我们的nama two这样的一些模型。那这些私有化的大模型，那就是最安全的了。因为这个数据压根就不会出你的服务器，你在服务器上传了你的这个文件，然后你把你的这个文件通过你私有化的这个环境里的模型跑完。这个翻译要得到了一个翻译好的成果，那整个可以完全做到跟互联网断开离网的一个环节。那整个怎么样去做，其实我们在后续课程里面也会涉及到。
	同时今天的这个open I translator的项目里面已经可以去调这个ChatGLM了，但是需要你去给他做一个配置。我们这个项目本身它是不管这个大模型的，只要我们按照TGLM的这个官方文档去把这个模型部署起来，然后把这个端口暴露出来。那我们现在这份代码就能够去访问这样的一个GLM，那我们就能用ChatGLM的特定的模型去做翻译。这个是我们从数据安全的角度给大家做的一个考量。
	OK我们既然看下来这个事儿是值得去做的，从各个视角来看，不管是刚刚提到的安全成本，还是我们GPT本身的技术成熟度，都可以做这样的事情。那我们要做它的话，应该怎么样去规划它？就是我们第一步做什么，第二步做什么。假设我们现在是一个产品经理，我们要找到他的MVP对吧？就是这么一个小小的软件，小好的项目，最重要的事情要把什么做好？我们这边定了一个简单的规划，就产品规划的V1.0。
	我们认为这是第一个版本。它需要带有什么样的一些特性？这些特性也都是目前我们在这个课程项目里面已经支持的功能。
	第一个就是选择了PDF这个文件格式。就目前来看的话，PDF应该是在互联网上流传最多的一种文件格式了。就是我们正常这种偏工作类的或者说偏阅读类的。不管是电子书也好，还是我们的一些论文等等，都是主要以PDF在进行这个文件的传输信息的传输。所以说我们选择用PDF来做这个文件格式的解析，是相对来说也是一个比较难的事儿。因为PDF本身会有为了广泛的信息交互，它支持的表达方式也非常的广泛，甚至还支持扫描件。
	这里我们把PDF这个文件格式如果能够搞定的话，其实你去支持一些其他的格式解析就更简单了。比如说这个mark down等等。我们把这个PDF做成了一个重要功能，也是一个差异化的功能。如果能够把PDF文件格式解析做好，本身就已经有很大的竞争力了。所以在后续的版本里，我们也会对这个PDF的解析做更多的工作。包括今天的课程，我们也会引入一个PDF文件格式解析的一个库。这个我相信对于大家做其他的一些工作也是有帮助的。
	第二个就是说我们第一个版本，我们能不能只实现一个翻译的这个渠道，就我们从英文翻译成中文，然后我们在后续的版本里面再去考虑一下其他的翻译。因为这个翻译本身在我们的项目里面不是一个难点，是由大模型来完成的。但是通过这个项目，我们能去打开一个门，就是怎么样去做一个基于大模型的应用，虽然它很轻就整个这个项目可能from的分量不是特别大。但是我们在尝试让大家去理解，如果我们要做一个大语言模型的应用，它应该把大模型放在什么样的一个位置，在这个项目里面，然后它应该未来还能去做什么样的扩展。
	我们也有了一定的可扩展性的设计，同时我们希望在第一个版本已经支持了多种模型。一个是这种OpenAI的GPT模型服务，它是一个纯公有云的服务，像这个SARS1样，你可以对它进行调用，按token计费。同时我们也支持私有化的这种大模型。比如说这个ChatGLM，那只需要你把这个GM模型的地址给他配置好就可以了。这里就说到配置，就我们作为一个开源项目也好，作为一个小的产品也好，我们都希望他能够进行灵活配置。那这种配置通常有多种方式。一种是以这种文件方式来进行配置。比如说这个压描文件格式，这是一种标记语言的文件格式。
	在cob火热起来之后，这种标记语言格式就受到了广泛的使用，就yarm这种格式。第二种就是说我们希望它简单一点，它就只是一个小小的工具。我们也可以支持直接通过命令行参数来进行配置。那你在启动的时候，只要把参数配置好就可以了。
	第三块就是说我们为了它未来能够定制和扩展，做了一些模块化的设计，以及一些面向对象的设计。当然这些设计还很初级，因为它是GPT4设计的，可能我只是给了一些比较早期的一些prompt。未来大家可以在现有的这个模块的设计上面再去做扩展。整个就是我们希望把OpenAI的translator的1.0完成的所有功能。这些功能目前都已经实现了。大家如果去拉取最新的这个课程项目的代码的话，也都已经能够拉到这些代码了。我们做了一个2.0的规划。如果我们现在在这个1.0的基础上，大家想要再去做一些额外的工作，把它这个项目或者说这个产品做的更好用的话，我提了一些这个思路和想法，让大家也可以去补充。
	第一个就是说这样的一个产品能不能给一个图形化的界面，这个应该很直截了当的一个想法。因为我们看前面几层几次课程，这个evening也好，包括我们的这个chat的这个API也好，大家都在给他用radio去做这个GUI。有了GUI当然会非常好用。我们直接点点一个按钮就文件上传，等他跑完之后拿到结果，甚至在过程当中还能给你一些进度日志等等。这个GOI我们认为是如果要做这样的一个产品，是除开MVP以外的第一个功能。因为前面1.0是为了支持它，可以用一个最小级实现了中到英的翻译，然后能用能配置。
	如果我们要说这个产品要更好用的话，第一个就是说提升它的应用性，在GUI这个角度上面是非常对用户友好的那第二个就是说提升它的翻译质量。我们知道PDF它本身是一个为了打印而做的一种文档格式，所以它里面把我们的整个文档的布局是做了非常好的控制的。但这些布局在解析过程当中，如果你解析的不到位，有可能就会丢掉。甚至说我们一个PDF最简单的是文本，那文本里面可能会融合一些像表格，甚至可能表格还会有复杂的表格，会有这种合并单元格的情况出现。那这些布局能不能够被很好的解析到位？解析到位之后，你在翻译输出的时候也能够保留这样的一个原始布局，甚至说还会有图文并茂的这种PDF的文件存在。那这些图能不能保留下来？这个是我们认为要除了这个翻译对以外，它原来的布局那样最好也能够把它尽最大可能保留下来。
	第三个点，就是说我们能不能以一个服务化的方式来提供这样的一个open I translator服务。因为我们开始看到像这个福星，也好像这个dog translator这样的一些海外的公司也好，都在提供这样的服务。那我们做出来一个这样的产品，我们能不能也对外提供服务，或者说在公司内部我们把它部署起来，用一个私有化的模型，或者说用一个公开的GPT都行，变成一个服务化的东西。这个服务化甚至有GOI，还能对原始的布局做一些支持。那这样的一个产品其实就已经很可用了，就是已经很好了。
	同时我们看到第四个就是对其他语言的支持。我相信大部分同学可能工作当中接触的就是中文和英文，而且产品都是英文翻中文多一点，很少会有中文翻英文。但这些都不重要，因为这些东西都可以通过prompt的设计来完成OK，这个是我们规划的一个V2.0，也其实就是我们想要让大家去开始参与的这个实战的作业，这边就简单做一个披露，它的一个使用示例是什么样的呢？
	首先我们支持我们是用一个PDF的文件作为输入，而输出的其实也是一个文件。在目前的这个版本里面，我们输出的文件格式是输出成了一个markdown的格式。这样也是为了方便大家去做扩展。Markdown的格式本身就是大家如果有这个markdown文建的编辑器的话，是可以导出成很多种不同类型不同类型的文档格式的。然后本身我们这个项目里面也是把我们要输出的内容放在了内存里面，用一些特定的变量。大家如果要把它转成其它的格式，你只需要去扩展我们已有的这个文件导出的模块就可以了。
	好，我们做了简单的一个市场需求的分析和一个产品的规划。接下来可能我们会去花一点点时间跟大家去做这个技术方案的一个分享。然后整个这个技术方案，其实核心就两个点。第一个点就是比较难的部分，就是我们的PDF格式到底要怎么样去解析好。第二个就是说解析好之后，我们拿到了PDF里面的内容，要怎么样去跟我们的大模型生态去做结合，然后最终变成一个我们要的成果，这个设计思路我跟大家简单做一些分享。整个设计思路讲完之后，我们会进到实际来操作怎么样解析一个PDF，然后接着我们再会去讲整个OpenAI的translator，所以今天可能会分成上下两部分。这个设计思路其实我会逐步跟大家加深。
	第一部分大家能简单看一看，这里是我们的这个测试文件之一，就是这个老人与海这个小说是一个英文的原版小说，海明威的我相信不少人可能都看过这个小说。那这个小说就作为我们的测试文件，它是我们要去翻译的一个要带翻译的文件。然后它的格式是PDF的格式。我们要做的这个事情，其实你仔细来看就是分成三部分。
	第一部分就是说有一个PDF的输入文件。输入文件需要被我们的这个open I translator这个项目能够进行加载。加载进来之后我们还能够把它解析出来，对吧？
	其实我们大家会发现整个课程设计是循序渐进的。就我们之前还讲过，在计算机里面的数据表示是怎么回事。大家也可以去花点时间课外去研究PDF这个文件格式是怎么样进行数据表示的，怎么样把这些图表文放在了一个文件里，对吧？那么现在这个文件需要被我们用一个解析器进行加载和解析。解析出来之后，其实一个比较直观的逻辑就是这是一本书，对吧？一本书通常是一页一页页承载下来的那在PDF内部其实也是这样一页一页去存取数据的那这一页一页的数据，每一页里面都有一些内容。
	现在假设我们只考虑文本，就text这样的一种文本格式的内容的话，那我们可以把整个解析器抽象成一个中间这样的格式。就假设我们实现了一个PDF它的功能，这个模块就是用来解析PDF文件的。解析之后它存储的形式就是一页一页的内容，这些内容的格式是文本，这个是我们最核心的中间这一部分PDF它的，这些内容需要被我们翻译成一种特定的语言。那在我们的V1.0这个规划里面，我们希望是说输入是英文，然后翻译成中文。这个时候就会用到我们前面的一些知识了。我们需要去给他设计一个prompt对吧？怎么样去设计一个prompt才能把它翻译过来。
	同时我们讲了前面GPT，假设我们现在以GPT为例，有两种接口，一种是completion接口，一种是chat completion接口。那它的prom的设置方式也不一样。如果我们使用了completion这个接口，假设我们就简化就叫chat这个接口。
	假设我们使用的chat这个接口，它其实是一个维护消息列表，消息记录的这么一个接口。那这个接口如果我们要去使用的话，我们应该怎么样给它输入内容？应该要保留他的历史记录。按照我们之前的说法，那在翻译这个场景里面需不需要保留历史记录？其实不需要对吧？这样也能节约token，但是需不需要给他的system这个role设计一些比较好的prom，这个地方就能体现出大家对from的设计的一些不同了。我们故意把这个地方做的非常简单，在目前这个版本里，希望后面大家能在这门课之后，在这节课之后去尽可能的去尝试不同的from设计，看什么样的一些方式能让他翻译的质量提高。翻译的质量本身也会作为我们实战作业的评比的一个很重要的指标。
	好，那么说回来这个设计思路本身，假设我们现在有一个GPT，我们通过chat API把这个原文和我们的翻译prom的这个指令一起给到了GPT。GPT其实通过它的调用会还给你一个译文结果。只要你的这个prom写的不是特别的离谱，他应该都会理解你的需求。然后把这个原文当中的一页或者这一页的一部分，看我们怎么样去跟他交互了，把这个译文的结果给我们，给我们之后，就会得到一个翻译的内容，就是对应着我们输入它。假设我们一页输入的这个原文的英文，那回给你的应该就是一页的中文。
	这个是最粗糙的一个想法，就是我们有这么一个三步走的过程。原文件解析，解析当中就是一页一页的内容，然后这一页的文本交给GPT，GPT翻译给你，然后回给你一个中文的结果。实际来看，其实我们只是拿到了翻译结果，这结果也没法真正为我们所用，对吧？所以我们希望能够把这个结果存下来。
	这个时候我们引入了一个新的模块叫writer。这个writer它就不只是能够导出这个PDF吧？我们给他留了一些空间，他如果要导出的是一个PDF，那OK我们去对接一个PDF导出的这个库就好了。如果要导出一个markdown也可以，所以这个writer是做这个文件导出的那最终导出了一个文件，就我们刚刚看到的那个对比输入，其实就这个原文的音。
	我们的PDF输出的可能是一个中文的文件格式。假设我们就是mark down，他们对应的关系也都是按照原文的英文的内容一点一点给它翻译下来了。那最好我们能够把他的这个布局结果也都保存下来，这是一个更好的质量。
	这里我们就要引入一个实际去解决PDF解析的库第一个，这是应该是第一次给大家正式介绍一个开源的代码库。这个代码库是我横向比较了五6个PDF解析库，相对来说比较好用的。它有几个点，第一个点是在于它的还很活跃，大家能看到11小时前，这个是我今天的一个截图，今天他还有人在更新这个项目。第二就是它的star数量也还是很高的，4.2K4000多个人。然后他的使用的人数也很多，3.8K3800个人。所以这样一个相对活跃的开源项目是衡量我们要不要去选择一个开源项目，作为我们自己的这个代码库当中的一个支持部分的一个很重要的指标。如果它不活跃了，那假设他出现了bug也不会有人去修的，除非就是你来修，或者你直接fork出来一个版本，作为你的一个私有化的版本也好，或者作为你的一个代码分支也好，你再去做开发，那那这样成本就会比较高，对吧？
	这个是第一个指标，就是很重要，它很活跃，并且它有比较多的star的数量，还被广泛的使用了。第二个就是说它实测下来确实还挺好用的，它的接口相对比较简单，那抽象的也抽象的比较简单。我们待会会实际的去给大家有这样的一个demo并且提供了一个拍的notebook。让大家能够在这个单开源的这个PDF发布这个库上面再去做进一步的扩展。也是为了在这个实战作业上面去做扩展。
	好，那我们就讲这个三步走当中的最重要的第一步跟第二步到底怎么走的。这里我们尝试使用这个开源项目库PDF flower里面的一些概念，后面跟我们的demo会紧密结合起来去做一个对应关系，让大家理解我们刚刚这个设计思路是怎么落地的。首先这个虚线框表示我们在使用这个开源库，这个是我们这个开源库本身。然后这个红色的部分是这个开源项目库里面已有的一些代码设计，它是一个class一个python实现的一个开源库里面已经定义好的一个类。
	然后我们刚刚那个设计思路里面有讲，这是一本书。我们其实是希望把这本书从一个PDF的文件格式变成我们这个项目里面的一个已经解析好的数据格式。有点类似于我们把这本书变成了这个项目里面能够解析的一本书，对吧？我们尽可能照顾到很多同学，就这么一个类比。其实在这个PDF club这个项目里面，它就有一个抽象，就叫做PDF luber的这个P点PDF这么一个类，它就等价于这么一本书。所以如果你解析了一个PDF，在这里就会有一个对应的这个类的实例。
	具体来看，其实我们会希望说操作的是一页一页的实际内容，就跟PDF对应起来的那在这个系统里面也是一样的，他们把这个PDF变成了这个PDF flab点PDF这么一个实例之后，这个实例本身就有一个自己的成员变量，就叫page。这个待会儿代码里面也会有实测其实我们整个这本书有52页，那其实就会有52页的这个配置。那这一个一个的配置，其实就会变成我们PDF farber的这个配置实例，这个也是一个预定也好的这么一个抽象。大家可以理解这里的每一页就变成了这个库里面已经预定也好的这么一个实例，就叫这个配置OK。
	除了这些实际的内容以外，我们知道一个文件还会有一些原数据信息。这原数据信息在这个系统内部也会有这个抽象，也在这个PDF下面，叫meta data。所以它最重要的两个抽象，一个是page，一个是meta data，非常简洁，跟我们去解析任意一个文件夹基本都是这样的一个模式。一个文件有它的原数据，有它的真实的内容。对应这里的，待会儿我们也都能看到这些数据能够被解析出来OK。然后我们就来实际看一看怎么样用这样的一个开源的代码库来完成PDF的解析。
	在我们最新的这个项目上传里面，其实已经把这个传上来了。在52分钟之前大家可以看到这里有一个OpenAI translator。这个目录进来之后，有一个主拍摄的目录。在这个里面我们有去放置如何去使用PDF club这么一个项目，也就是我们待会儿会看到的这样的一个文件。
	重新启动一下。
	我看到群里正好我这网有点卡，我这边打开可能会稍等几秒钟。有同学在说拼音字母的问题，这个其实就是在考量咱们的from怎么样去设计了，包括在待会儿讲怎么样去获取这个PDF文件内容的时候，也会有一些技巧。现在这个大小需要再扩大一点吗？这个大小大家能看清楚吗？
	可以看清楚对吧？好好，那我们就正式开始继续讲一下这个项目。这个项目其实是基于一个很有名的底层库叫PDF minor，甚至这个库现在也有人直接在用。然后这个项目是基于这个PDF minor的sem的一个底层来开发的。它支持解析PDF文件，就我们刚刚看到的三步走当中的第一步跟第二步之间的关系，然后支持我们把一个PDF文件变成一个内存当中的，可以用我们的这个python来表达的一个PDF的文件内容。也能获取除了文本以外的，包括一些据形、线条，甚至是图片、表格等等这样的一些内容，他都能够获取。他也是他也跟python的这个图像渲染这一部分做了一些简单的打通。我们待会儿也可以看一下，它支持这个可视化的调试。
	然后这里还要提到一个额外的内容，就是说包括我们自己也在做这个PDF的一些项目。因为PDF这个格式实在太包容性太强了。我们的一些扫描件大家知道也能变成PDF对吧？但是扫描件的解析，现在是一个很难的问题。你在adobe他做这个PDF的格式这一块，就是你可以理解成扫描出来的这些内容就已经失去了文本这种类型的一些基本要素了。它就变成了一些简单的位图了，就变成了一些像素了。那它是无法直接去解析这个文本的，所以扫描的PDF目前这个库是不支持的，而且大部分应该都不支持。
	业内如果要针对扫描的PDF去做进一步的处理，通常也是通过类似于OCR这样的方式去获取文本。当然如果这个扫描的PDF里面不只是文本，还有一些图之类的东西，那可能就不只是用OCR，还得去做一些图像相关的一些识别的方法。这个开源库它支持的python版本是3.8到3.11，所以跟我们的课程要求是兼容的，大家也可以继续去使用。然后这个notebook就我们现在展示这个notebook，主要向大家介绍五个部分的内容。第一个就是说怎么样把PDF加载进来。然后第二就是说怎么样去提取它的内容，包括我们的文本表格，然后怎么样用它的这个可视化的调试工具。他自己其实跟这个python的页面做了一个打通。
	就你为了看看你现在这一页有没有解析，对吧？可以把它这一页直接变成一个图片，就有点类似我们刚刚说那个扫描PDF的意思。不过它是逆过程，就把我们的一个机器导出的PDF，然后把它变成一个图片。然后把这个图片在我们的主拍当中的book里面渲染出来，但也可以保存下来。那我们就可以借助这个可视化调试页面的功能，包括它配置时里面的一些方法和成员变量，去尝试把页面的图像给提取出来。但是这里需要指明的是在我们的V1.0的这个OpenAI translator的项目代码里面，没有实现页面图像的这个提取功能。因为实际情况下来说，还不只是提取页面图像这么简单。
	大家想象一下，如果我们有现在这么一个book需要去做翻译的话，其实图文是穿插的。所以你不只是要提取图像，因为这个图像和文在一起，那怎么样能够把图和文的这个位置保留好，布局保留好。然后翻译过去之后，其实会发现还有一个很很严重的问题，可能在刚刚讲的时候没有把这个困难点讲出来。就是不同的语言它的文本的长短是不一样的。就比如说文言文，你要把它翻译成英文，可能五个字能翻译成小小半页英文文章，那这个东西你要翻译出来之整个布局肯定就都乱掉了。那你这种一页到一页的映射关系也就有了一些变化。这些都是我们在V2.0的时候，需要大家发挥这个智慧去想办法解决的。
	好，那么言归正传来正经的来看一下，这五个部分怎么处理。第一个就是说要加载我们的这个PDF文件应该怎么做？使用过这个python的同学应该都知道，这个非常常见的打就在python里面去打开一个文件的方法就open。PDF buber差不多就是复用的这样的一个方法名。打开然后打开打开文件，它除了能够支持一个PDF的文件路径以外，他还有额外的两种方式可以去做这个扩展。进一步的一个就是说作为这个字节就这个but就字节来加载的这种文件对象，以及类似字节的这种加载方式。那这里我们不再展开，大家有兴趣可以，这边我们有留一个超链接，可以通过这里直接跳转到这个开源项目上面去，大家可以自己去做扩展，我们这就不再赘述。
	整个这个方法，其实你把它这个文件加载出来之后，返回的是一个什么呢？是一个PDF buber到PDF类的一个实例，我们就简称叫一个PDF类的实例。就跟我们刚刚那个PPT里看到的一样，对吧？你现在在脑海中就想象有一个PDF的文件，这文件被这个方法打开之后，反我的一个实例，相当于这本书就已经全部存到了我们的PDF这个类里面了。
	那大家用过PDF就还会遇到一个问题，就是PDF是会有时候会设置密码的那它也能够通过传递这个password这么一个参数在这个open函数里面传递一个password的这样的一个方法，就可以使这个密码能够被输入进去，那就能打开。那它为什么能传密码呢？因为它也能支持meta data相关的一些解析，在这我们就不再赘述了，包括一些别的参数布局的分析的参数等等，这我们就不再展开了。
	好，我们现在实际来看一下怎么样去用它。首先PDF这个类在P在这个库里面是属于一个最高级别的抽象，也是一等公民。这个最高级别的抽象就对应着，因为我们通常认为这个open就打开一本书，那一本书就对应的这样的一个类的实例。通常这样的一个PDF类，我们就认为它就是等于一本书了。
	那那在刚刚那个PPT我们有讲有两个最重要的成员变量，一个叫meta data，一个叫pages。然后当然还会有一个close方法对应我们的open方法。如果我们使用这个python的这个位置上下文来管理，就不用close，对吧？那如果我们像现在讲，没有去使用这个未上下文的话，最好去使用close去刷新缓存。因为有的时候PDF文件会很大这我们就关注重点就是回到这个meta data和pages，那这个pages就对应着PDF里面的实际内容。就每一个已加载的那个PDF的页面，每一页就对应一个配置，它使用这个配置来简单做管理一个列表，这个列表里面的每一个元素就对应着我们刚刚PPT里看到的这个PDA club的这个配置实例OK。
	实际来运行一下，首先这里有一个PDF就叫老人与海的这个PDF，就放在这个目录下面，大家可以看见。然后我们先看meta data，这meta data就是我们刚刚能通过不管是windows还是my book任意的这个操作系统都能看到一个文件的原数据。那通过这个库也是拿到它的原数据的，包括他的创建时间，然后作者的一些标记，这来源于这个网站的对，然后包括他的这个标记等等，这些都能拿到。我们重点是看一下这个配置，这个配置一共有52页，就对应着我们这本书的这个52页，每一页都是严格对齐的。然后这每一页都是一个我们的配置类，我们这可以做一个简单的一个类型输出。
	啊那这里呢是对应着我们的一个配置的这个实例ok那么这个到这儿为止呢其实我们就把刚刚ppt里给大家展示的我们怎么样把一本这个电子书也好在pdf的文件也好变成这个库能够解析出来的一个pdf的内存里面的一个数据表达但是到目前为止呢好像也只有一个空壳子就我们拿到了它的原数据拿到了有五十二页但每一页里面具体有什么内容在我们刚刚的分享里面呢我们是把它抽象成只有text啊对吧那么实际情况来说呢呃我们在这个在这个notebook里面我们会去讲除了text以外其他的包括像表格和图也都会抽取出来那我们就一步一步来看怎么样抽取啊为了简化问题啊这个老人与海这个书比较复杂我们专门去上传了一个这个test点pdf我把这个test点pdf把它下载下来给大家看一下长什么样子的这里有一个两页的测试文件，这个测试文件包含了标题、两段文本、一个表格以及一张图片。
	这张图片来自于OKAI的这个官方的一个blog的截图，所以是它基本上覆盖了我们要去做PDF解析的一些例子了，在我们的V1.0的范围内，当然他没有包含这种一页里面出现了图文并茂，包括表格之类的一些情况。大家可以自己通过别的方式去造这种测试数据，很简单，造一个PDF而已。然后这个PDF的这些内容本身也是由GPT生成的，你看这个文章，看这个内容就能看得出来。然后我们现在要把这个作为我们的一个测试示例，来跟大家讲解一下这个PDF club er的配置到底是怎么表达这些内容的。
	好，我们回到这儿来，我们重新打开这个test点PDF。我们能看到它只有两页的内容。然后它比较有意思的事情是说，它在这个pages里面，为了跟我们的PDF的这个页码对账号。所以它其实是自己内部实现了一个单独的成员变量，叫配置number。你可以理解成就是页码。因为在python的list里面，或者说在python的任意的这种数据结构里面，我们都是从零开始作为下标，作为index。但是这个PDF页码都从一开始的，所以你会发现它的这个配置是0。就我们这个列表里面的第10个元素，其实它的这个页码就一对应着我们这本PDF的这个页码，实现了这么一个很有趣的成员变量。
	大家在实际去做判断和业务逻辑的时候，通常可以直接使用它。因为整个PDF都已经被放在了这个配置的成员变量里。那么除了输出有多少页，然后每页的页码以外，它还提供了一个很很有用的参数。就我们的这个宽度和高度，就我们这样的一页PDF它的内容所占的这个宽高，我们能看到是这样的一个595到这个842这么样的一个宽高。
	接着最重要的一个功能来了，因为我们要介绍第一个这个重点的功能是我们的这个可视化的功能。就我们实际在解码它的时候，或者说在解析它的时候，我们除了拿到这些比较抽象的文本和表格以外，它提供一个很有用的工具，就是我们的这个to image的这样的一个工具，这个方法名字也很简单，我们拿到一个特定的一页，就从这个配置里面取一取一页出来，to image就能直接让它渲染出来。当然大家能看到这个渲染出来效果很差，有很多的锯齿，这个我们会去讲，它其实是有抗锯齿的一些参数，包括我们可以去设置它的分辨率。这是我们能看到它的第一页解释解析对了的。第二页是我们的这张图片，它一样会有很多的锯齿。那我们接下来会去尝试调整这些东西。OK好，这个至少能说明我们这两页把它变成一张图渲染出来是对的，也没找错。
	那接下来我们看看这一页里面的内容要具体怎么提出来。首先在这个配置里面包含的这个文本是有一个很直接易懂的这样的一个成员变量的。这个配置对象叫做extract text，就是抽取文本。这个方法大家能看到我这边付了很多的翻译好的方法和他的描述，我们今天主要要讲的就是这个extract text的方法，用来做文本提取。并且在这个方法里面有一个很重要的参数就叫layout布局。但这里大家需要理解一个点是说，就算你把雷奥的传承了，这个错了，他也不一定能完整复刻这个布局，原因就在于PDF本身它的这个布局格式是很复杂的。
	然后通过这个参数，它其实是调用了底层的这个PDFI minor的方法来做这个布局的解析。但也不能做到百分之百。所以大家不要想象成，尤其是遇到自己下课之后，去做一些这个PDF解析的时候，传的true感觉好像没有把那个布局解析出来，那是正常的。
	OK那我们实际来试一下调这个方法会怎么样。首先我们把第一页的文本简单一点，用一个比较明确的变量叫做PE的这个text把抽取出来，我们打印输出一下。那能看到这里有一个文本的输出。然后把我们的第一页里面的所有的文本基本都已经全部拿出来了，我们待会儿也可以去做确认，我们尝试一下把这个layout设置为处，看一下它的输出会有什么不同。首先我们明显感觉这两个输出的格式有很大的差异，我不清楚这个应该还是挺一目了然的。就是这个地方应该是一个heading，有我们的标题，就是我们的正文。当然他没有把这个字体大小弄出来，这个是需要再去配置别的选项的。然后这个table也基本上把这个table的缩进保留了下来，这个其实已经算是一个还不错的layout的解析了，也是取决于我们本身PDF不够复杂，所以他能够解析的比较好。
	但看到这儿，其实大家应该会发现有一个比较烦的事儿。就是他虽然是解析文本，但他把表格给解析出来了。就是理论上大家应该认为这个表格不属于文本，对吧？我就解析的只是文本，为什么表格也出来了？这儿其实大家稍微深入想一想就比较好理解了。因为在PDF这个文件格式里面，这个表格本身就是一个很抽象的东西，它就是一堆文字，而且这个文字组成的这个表格，有的时候甚至连表格的这个边界框都没有，所以就更难定义什么是表格了。所以对于一个PDF解析的库也好，软件也好，通常来说表格的识别都是要额外处理的，所以我们才会接下来跟大家讲讲怎么样把这个表格再进行出来。
	PDF的这个club的表格提取。首先表格提取是一个很常见很通用也比较难的事儿。这个大家一定要有概念，就怎么样把一个PDF里面的表格准确的识别出来，是一个很难的事情，并且也是一个可以挣钱的事情。大家如果去百度云、阿里云、华为云这样的公有云网站上面能看到，他们会有OCR的这个API服务，也有表格提取的服务。因为这是一个确实很难的事情。
	这个方这个PDF club这个库的表格提取方法，借鉴了这一位的硕士论文。然后也受到了tabler的启发，对他原来的这个官方项目里面就有提到的一些引用和借鉴，保留了下来。大家如果有兴趣可以作为扩展阅读。
	他的工作原理可以简单做一个说明，他其实就是对于我们的任意一页的这个PDF，就我们刚刚看到这里的一个对象实例，那对于任意的这样的一页，他都是去找到一些明确的线条和一些对齐方式暗示的线条。说人话就是说所谓的表格，我们人是怎么理解表格的？这样这里看着就像是一个表格，对吧？
	一个markdown渲染，markdown格式的这个内容渲染的表格，但他没有分隔线。大家如果仔细看的话，这里其实是没有这个竖线的。每一行，这里也是没有横线的那我们为什么人认为它是一个表格呢？那你脑子里面直观的视觉是说它会有对齐，左对齐也好，右对齐也好，居中对齐也好。这些东西其实就是我们能理解表格的这个逻辑，他其实就是这么去干的。
	所以你看他整个这个逻辑五条线下来，就是找到那些明确的分割线。然后通过一些对齐的方式，不管是明示的还是暗示的，然后再去把它做交叉。交叉之后就会有各种焦点。这些焦点最终划出来了一个一个的格子，这些格子呢我们就最终认为它有可能是我们的单面格。
	那我为什么又说表格拾取很难呢？因为在实际大家在自己做过很多excel就会发现，有的时候你会去做这个合并单元格。然后你的这个合并单元格甚至是一个树状结构的，你还会嵌套的那这个时候又怎么样去把一个表格还原出来呢？甚至这个表格就不能用一个简单的二维的列表来做存储了。这就是为什么表格提取难的地方。
	OK我们实际来操作一下，通过这个extract table这个方法可以拿到这个单页的表格，然后还会提供一个额外的方法叫做extract tables。他其实就是找如果我这一页里面有多个表格的时候，那我就把多个表格都抽出来。那它的存储方式也就比较明确了。
	我们直接运行一下给大家看一下。首先我们能看到这里是一个多维嵌套的一个数组播作列表。每一个表其实在这里面都对应着最外层这个表里面的一个元素。如果我们使用的是这个extra tables的话，就会发现整个这边框，整个会变成tables里面当中的一个table，对吧？这个逻辑应该好理解的那我们获取单页表格，它当然就只会返回你一个table的这个二维数组了。但如果我使用这个extract tables，就假设我们这一页有多个表格的话，你就会发现这个多嵌套了一层，对吧？
	就我们刚刚讲到的，我这是为什么呢？就是因为他要多个表格，所以自然就在相当于变成一个三维的数组。大家想象一下，这个三维数组里面的每一个每一最外层的每一个元素就是一个二维的数组，这个二维数组自然就对应着这里的一个表格。如果是我刚刚讲的有那种合并单元格的场景，大家可以去做做实验，看会不会解析出问题。是值得去做这个尝试的那他还提供了这个debug table final这么一个方法，这里跟我们的这个实际的这这门课的关系不大，我就留在这里让大家去做这个探索。然后我们刚刚看到那个形式就很恶心，对吧？是一个二维的数组。
	这个二维数组跟我们之前从这个表格的方式不一样。我们之前在一些课程里面跟大家讲到了这个pandas as这么一个库，它有一个data frame很适合用来表达表格。所以这边也给大家留了一个简短的代码。
	后面大家要去做V2.0我们实战作业的话，可以尝试用这个方式去存储我们的表格。我们把刚刚的二维列表变成一个data frame。通过这一行代码就可以做到了，其实也比较简单对吧？就把我们刚刚那个表里面的，大家一个二维数组，把这一坨取出来，变成它的这个列的名字，剩下的变成它的内容，这个是一个简单的python的list操作，我就不再赘述了。那就会变成一个data frame。这个就是一个最简单的一张二维的表格。怎么样通过我们刚刚的方法从PDF里面提取出来，提取出来之后是一个二维列表的数据格式，这个数据格式可以用panda的data frame存下来，以这样的方式很直观的展示出来。
	OK到这里的话，其实我不知道大家有没有想过怎么样去把文本里面的表格给去掉，就是我们刚刚提到了这里会解析出表格里面的内容。那怎么样能够把我们的这一页，文本的归文本，表格的归表格，有很多种方法。最直接的一种方法就是直接把它移除掉，对吧？从我们的text里面移除掉，这个是一个最直接最暴力的方法。可以去使用，也可以去尝试。然后在实际翻译里面，我觉得也还有另一种思路，就是把这一部分表格处理的逻辑交给GPT，这就体现出以前我们写一个代码的时候，可能大家会思路比较明确，就一条路去做这个数据处理。
	但现在你会发现GPT变成了一个类似于你的小组成员，或者说这个工作的小伙伴的这么一个角色。以前可能这个任务是要通过写代码来完成的，但现在这个表格处理是不是可以尝试让GPT直接来完成？你告诉他你的输入里面可能包含有表格，然后这个表格即使是以这样的一个layout的一个形式交给GPT，我理解他应该也都是能够识别出来这是一个表格的。并且我相信大家用起来GPT的时候应该去试过。
	你直接把这个东西粘到复制到TIGPT的这个对话框里。那你告诉他把这个表格给我翻译成这个中文，他其实能做到的。并且他还会保留表格的形式，然后你把表格加上这些正文一起丢给他他也能够翻译出来。所以这里大家会发现，你可以在你自己PDF解析完之后，把表格和文本分开处理，然后分开交给GPT去处理，这是一种方式。那还有一种方式就是你直接把这一整块都丢给GPT，让他来处理。你甚至在内部都不再区分这个表格和文本，这也是一种方式。这两种方式各有优劣，因为最终我们不只是要翻译，我们还要翻译后的结果。所以就算你交给GPT去处理之后，你也需要从GBT的结果里面把表格的内容提取出来，然后存成一个表格的样式，对吧？
	但是无论如何，刚刚是想告诉大家，表格的处理方式就会有多种了。你可以在翻译前，也可以在翻译后。然后如果是翻译后的话，那你甚至可以让GPT帮你把这个表格和文本摘出来。然后一个特定的，我们上一节课教过，就是用分隔符也好，用一些特定的标志符也好，让你跟GPT约定好啊，这样的方式你去解析一个。如果你能让GPT的输出结果稳定的话，你去解析GPT输出的结果，把这个表格识别的难题甩给GPT，这是一个可以去尝试的思路。
	在1.0里面我们没有这么做，在V1.0里面我们是把表格和文本做了前处理，我们分开去做了存储，然后我们去分开让GPT翻译的，因为整个这个项目是四月份的时候实现的，那会儿也没有做太多的prom的一些设定。但欢迎大家在微点2.0，就我们的这个实战作业里面去做尝试。我刚刚那个思路就是我们把后处理的结果，把翻译后的结果再来做这个区分处理OK。我们可以把这个表格存下来了，对吧？那我们再来看看，通过可视化的调试页面的进一步的深入了解，我们有没有可能去把图像也抽取出来。这个也是在V1.0没有。但是我们希望通过这些东西，让大家在V2.0的这个实践上、实战上面去做一做这个呃尝试。所以我们回到刚刚这个可视化调试的方法，刚刚我们只讲了这个方法，没有讲具体的一些怎么用的这个方法。
	其实我们刚刚已经说过它的功能了，就是把我们一页PDF变成一张图片，变成一张位图，而它支持的这个参数有这几个，一个是分辨率，一个是这个图像的宽度，一个是这个高度，然后以及是不是使用抗锯齿。我们刚刚其实看过这两页了，我这就收起来。我们以这个第二页为例，就是我们尝试在第二页这件事情上，对这个two image和我们的图像这个事儿有更深入的理解。首先我们看了PDF的原文件在这个。
	地方在这个地方。
	PDF的原文件里面，它就是以每一页为分隔的。然后在第二页里面，我们这张图片也没有撑满我们第二页的所有内容。那我们有没有可能通过一些手段把第二页的这个图片给拉出来了。
	首先刚刚有讲让大家去理解PDF这个数据表示是怎么回事。图在这个PDF里面是怎么表示的，是一个位图吗？还是什么东西，这个需要大家去了解。因为PDF本身是一个矢量格式，大家如果是有之前有过一些预备的知识的话，那在这个里面去获取图片是一个极其有意思的操作。那我们怎么样把这个图能够筛出来？可能就首先第一步得找到这个图的位置，有它的坐标，那他可能就能够通过一些方式把这张图从整个一页里面提取出来。
	那具体来看我们怎么去做呢？我们把这个第二页渲染出来了，然后怎么样去提取它？这里需要讲的事情是我们刚刚通过提取文本和提取表格，可能会很直接的去想有没有一个方法叫做extract image。比较悲哀的告诉大家是没有这样的方法，有这样的方法也很难，就跟表格也无法直接很好的提取一样，这个图就更难了。
	对图它跟这个文本之间有没有本质区别呢？这个涉及到PDF的底层表示，我们就不去展开讲。但一句话来说就是没有这样的一个很方便的方法让你去提取。但是我们可以通过截取的方式来做，就跟我们在这一页里面，我们想要去截取一个缩进，我们想要去在这一页里面获取一部分的内容。用过微信截图也好，用什么截图工具也好，就知道我们能划一个坐标，左上角右下角就能把它截出来。这个思路其实放到页面提取里面依然是靠谱的。
	那具体的做法就是我们要使用配置类刚刚没有介绍的另外一些成员变量，包括它的宽高，这个宽高就决定了这一页就整个这一页一个配置它的宽高。然后同时这个配置方法除了extract text，extract table, 包括上面其他的一些方法以外，还会有一些方法，比如说裁剪。不知道这个就是一个裁剪的方法。那这个裁剪的方法需要提供一个bounding box，大家简单理解就是提供两个坐标。这两个坐标就决定了我们去裁它的这个对角线的这个坐标，就决定了我们怎么裁它，就这么一个简单的方法，跟我们去做微信截图的这个逻辑是类似的。
	具体来看，首先我们要从第二页里面去获取这个image，这个是不是跟table刚刚就有点像了。我们刚刚方法叫extra tables，他会把这一页里面的所有table都返回回来，然后以一个二维数组的方式去表达一个table。那这个image方法是类似的，他虽然没有extract image方法，但是他会告诉你他的一些判断，包括这个image可能包含的一些有效信息。那这里就有image这个对象的一些内容。
	我们不展开的话重点关注四个。这四个就跟我们要去裁剪的一样。你可以理解成他虽然不能直接帮你提出来，但他能找到坐标。他为什么能找到坐标呢？跟去提取表格逻辑类似，因为他能找到一些边界线，对吧？这个图还是有很明显的这个边缘能扩的。
	他找到了这些坐标，有四个坐标很重要，一个叫X0，这里有写X0、top x1、bottom, x0X1 top bottom对吧？当然如果不想去深究这个数据格式的话，就无脑的把这四个关键的参数，按照裁剪的需求组合成一个四元组，就丢到这里来。我们这里可以实际操作一下，给大家看看效果就明白了。
	假设我们有一个页面ge就是我们这第一张图。因为只有一个，我们就直接取0，就相当于取得这个地方的内容，我们去把这个四元组给造出来，这里需要构造一个剖析框，帮您box，然后它的四元组跟我们刚刚上面要求的是一样的，X0 top、x1 bottom跟他的要求完全一致。然后我们把这个四元组构造出来之后，我们去重新获取一个裁剪后的image，要crop the page。其实大家看一下这个方法，它返回的是什么呢？是一个裁剪到边界框的一个页面版本，什么意思呢？就是把我们的配置一个大的完整的一页裁剪成一个小的一页。这小的一页的这个裁剪范围保留的就是这个四元组的范围。
	裁出来之后，我们仍然可以使用这个做页面方法来做渲染，就跟这个图一模一样。首先我们会发现这个坐标基本上是找对了，对吧？但是还是有很多的锯齿，那怎么办呢？我们可以使用这个to image的抗锯齿的方法，OK大家能比较一下，这两个图其实在细节上已经有很多的差异了，就这样CH这包括像这些字这个锯齿已经做了一些抗锯齿的操作了。如果我们想要把这个分辨率做的再高一点的话，其实是可以给他一些revolution的提升。就假设我们在这儿不做抗锯齿，我们直接把它的这个分辨率给它提高，比如说1080的。
	稍等它这个分辨率比较大的话，会消耗一定的算力去生成这个图片。那大家就会发现这个生成出来的效果就会很好了，这个分辨率就很高，这样也是一种方式。抗锯齿是在不改变分辨率的情况下，通过算法去解决这个效果。所以它算力消耗稍微小一点，并且它消耗的存储也小一点。通过这样的方式，我们其实是完成了图片的提取。这个提取出来图片自然也就可以塞到我们要导出的这个翻译后的文件里面去，对吧？
	并且我们这个怎么筛呢？两种方式。第一种，首先这个是一个图像的对象，这个图像对象是可以转成这个离线的文件存下来的。就是我们把它这个有点大，我们就不存了，存一个小一点的。我们待会儿可以看一下，把这样的一个文件，我们直接不在这显示渲染出来，我们把它存到一个叫IM的对象里，然后这个M对象支持一个save方法，我们可以看一下。这个是新生成的，一秒钟之前生成的。然后这个是我们刚刚通过PDF的页面提取裁剪，然后保存下来的一张图片。这个图片能够保存成这个PNG，也可以保存成别的格式，自然也就可以在我们翻译后的整个文本里面去做输出OK。
	到这儿为止，其实我们把这个PDF club er这个库做了一个相对完整的介绍，覆盖了几个内容。第一个就是加载，我们第一步能够把它变成一个PDF的实例第二步我们能去做提取，能有通过extra text的方法提取每一页的文本。我们也能通过extra tables方法提取每一页的所有的表格。然后我们也能把这些表格变成一个pandas as的这个data frame，更好的能够去获取它的列，甚至在列在上面去做一些操作。比如说这个表格我们还需要去做二次处理的话。
	同时我们介绍了怎么样用这个库来可视化的调试这个页面。你比如说我们判断是否解析对了，有没有一些页是因为格式损坏的原因无法解析，解析出来结果通过这个to image的方式，我们能把它渲染出来。然后我们也能通过这个配置的images这么一个成员变量去获取页面当中一些可能是图像的坐标。然后通过配置的裁剪方法，pro可以把一个页面按照坐标裁成一个小页面。裁剪后的页面能够变成一个图片，甚至这个变成图片过程当中跟可视化调试它那个功能有一些结合能抗锯齿，能调分辨率。那这个图片自然就通过这样的一种方式，一种偏trick的方式就提取出来了。所以通过这个库，其实可以完整的实现这三种内容的提取。只不过提取出来之后怎么样保留它的布局会是一个比较难的问题。好，我们上半部分就到这儿，然后我们看看大家有什么样的一些问题我们可以提问。
	我把耳机取下来了。hello. 大家能听见吗？可能是耳机的那个问题。行，那就还是不用耳机。那那刚刚那个问题解答可能也没听到。就有同学问现在这个跟PD这个PDF解析和大模型翻译的关系，我们的大模型要能够用到这些解析出来的内容才能够进行翻译。所以我们说了三步走。第一步就是拿到PDF文件，然后解析成我们python内存里面可以表达的这个变量。然后接着我们要把这些内容提取出来之后，交给大模型才能让他去做翻译。然后还有一个同学是问这个PDF页眉页脚的文本能和正文文本区分拿到吗？这个其实是一个蛮好的问题，然后没有特别简没有特别直给的方式。
	对，这个也是涉及到。其实刚刚有一个思路，就是我们的文本和表格是前处理还是后处理，是交给大语言模型来处理呢？还是说让我们自己在交给大语言模型之前就先处理了。类似于这样的事情，我估计页眉页脚是不是也能通过这个system的role来说来设计一些内容。或者说像刚刚康明老师讲的，通过这个function call，就这些东西都是以前为什么叫现在要用自然语言来编程？包括我们上节课讲讲的这个天气的查询等等。所有的这些我们要写代码来处理的。其实以前要写代码来做数据处理的，都可以尝试用方形后来做处理，包括一些信息的提取。
	然后还有同学问那个扫描的PDF是图片的怎么办？要不要加一层OCR识别？大部分时候是这样的，如果我们是扫描件，或者说我们给到的这个PDF压根就没法去做文本提取。它可能是艺术字，那这种就比较难，这种可能是要用OCR的。我们最后再再回答三个问题，看看大家还有什么问题吗？没有的话，我们就进入到这个三步走的后面一步了。
	有个同学问，将PDF中的表格保存成向量数据库，然后搜索向量数据库中的表格结果。有什么好的方法能在输出界面还原这个表格的原始布局？说到底我没有太看懂这个，首先向量数据库和这个表格肯定不是一回事儿，我觉得可能是不理解，有点混淆。向量数据库里面不会存这种这种表格第一感觉是像excel一样，然后就这个表格大家肯定一眼看着像excel。我把这个data frame，对，那这个表格如果是excel肯定存的就是类似于mysql l这样的一些关系型数据库。那你直接存就好了，你哪怕存成一个CSV都可以。那你原来存了这样的格式，那就继续存好了。对，然后向量数据库通常存的是一些in bedding的结果。
	然后OCR识别是算法的内容吗？还是工程就可以直接做了，OCR也有一些开源的模型，用TensorFlow写的，用python写的，用python pata写的都有。然后可以直接去调这个公有云的服务，或者说像ChatGLM1样，就跟我们大模型这个课程是类似的。你也可以调一些私有化的模型。我之前有用过那个paddle的OCR，它的预训练的那个模型还行。
	有很多同学问作业是在这个基础上开发，如果可以的话那也行。对，但其实不是给大家做了一个版本的实现了，如果就在这个基础上开发，可能有的同学会比较僵硬。对，就是我们在这个AI translator这个目录下面会有一些代码，这个代码也都传上来了，大家可以去拉下来去实际试一试。我们接下来也会去讲这个代码，给大家去做这个拆解。
	还有个同学问字体大小和颜色这些是怎么还原的？这个是好问题。我们的V1.0MVP里面没有这个实现。因为整个这个项目核心是OpenAI translator，核心是做翻译。像这个布局、字体颜色等等，各种各样的这种样式型的信息，这种style型的信息，我们把它留给了实战作业。也就是大家如果能在上面百花齐放的去做各种功能实现的话，那就非常好。
	那这个不就卷起来了吗？卷起来了大家就可以去争一争评比一下最终的结果。我记得好像班主任是有实物的奖励和现金的奖励的。
	好，我们现在就继续回到这个课程内容当中来，大家有什么问题待会儿讲完，还会有这个提问的时间。
	OK, 我们就回到这个模块设计。刚刚其实把这个三步走我们做了这个尝试，实际来看我们还有很多的点，可以把这个MVP本身还有一些可以稍作扩展的，让大家能够更好的去完成这个实战作业的一些必要的功能模块，我们这边做了一些简单的设计，简单跟大家分享一下。第一个就是说刚刚我们整个代码里面，我们完成了什么样的一个部分？我们把一个待翻译的文件通常是一个PDF，在我们的这个项目里把这个PDF加载进来了。通过我们的PDF club这么一个库，这个库里面有一个PDF的抽象，一个PDF的实例，还有一个配置的这个实例配置的实例。我们把整体刚刚那一部分可以叫做这个项目里面有一个叫PDF poser这么一个类。就我们OpenAI translator，我们现在在聊自己的这个设计了，对吧？
	Open I translator里面可以实现一个模块叫PDF的puzzle，是用来解析PDF的。解析完之后，我们应该能够获取到文本表格，目前图像我们没有做处理，获取文本和表格。然后这个文本和表格都可以通过我们的GPT以一个特定的来做翻译。这个是下一步我们待会儿会在代码当中看到的。
	这个过程当中，这个prom首先就是可以去做各种各样的设计的，我们可以去设计不同的prom的模板。这个模板可以用来，比如说我简单跟大家做这个设计思路，这个已经涉及到大家实战作业里面可以去做的一些尝试了。第一个就是说这个prompt我们针对不同的语言段的翻译。比如说现在实现的是英文到中文，那假设我们要实现中文到英文，英文到法语，英文到意大利语，它的prom是不是不一样？这个是第一个点对吧？那这个不一样的prompt应该怎么样去设计一个它的模板？然后这个prom的不一样，通常还会是一个输入侧的需求，吧？就比如说我在输入的时候，我的我给你一个源文件，这个源文件要翻译成什么文件，应该是我给你这个文件的时候我才告诉你的那这个时候就涉及到第二点，我怎么告诉你？
	有一个简单的叫做arguments power，就是我们的命令行参数的解析器，就是我们能够在输入的时候，在加载的时候，不仅解析原来这个文件，在这个地方给它做一些赋能。除了丢一个PDF以外，我还能解析一些其他的要求，甚至包括我输出的格式。就我们刚刚在看到，我们最终要导出成一个文件，一个writer的输出的格式，是不是也能去做扩展？都可以通过这个argument puzzle去作为这个传递。然后除此以外我们针对不同领域的文档，我们开始看到这个收费也是，它有这个专业领域的那不同专业领域收费价格甚至差了有三五倍的那不同的领域是不是可以设置不同的prompt template？
	Or还记得我们上一节课讲怎么用好GPT去提效的这个技巧策略。是不是可以给他一个在system层面上给他一个角色，然后在system层面上给他一些特定的常驻任务等等等等。这些东西其实都可以在这儿去做设计，包括我们的function call是不是可以引入进来。那如果把function call引入进来，怎么样跟我们的这个prompt template模板这一块去做结合，这是一个点。
	除此以外，还有一块就是我们会去扩展，就除了GPT这个公有的open I提供的公有云的这个API以外，是不是还能去调用一些私有化的大模型。在这儿我们可以把这个大模型再做一层简单的抽象。这一层抽象就使得我们整个系统对于GPT都其实都只是一个大模型的一种特定的实现，对吧？那么把这个大模型这个地方做一层模块，然后最后加一个日志的模块，这个日志的模块就是用来我们我们之前在上一节课也有给大家看啊，就是哪怕是一个最简单的demo。如果我们把日志做得好，也能提升我们的debug的效率，对吧？
	我们能看到来自于不同角色的输出，有这个system的，有这个user的，有assistant。Assistant还可以分析它的正常输出，没有调用方calling，还是说他调用了function calling。通过这些不同的日志，包括日志的级别，我们都能够把这个简单的OpenAI translator这个项目做的更加的好用，不管是面向最终用户还是面向我们的开发人员。所以总结一下这个核心模块其实就这几个，我们的PDF的pazz，PDF文档解析模块。Writer就是把我们的解析出来的内容通过大模型然后翻译最终导出，有一个writer的模块，包括我们各种大模型的抽象。那大模型可以有一个单独的模块，去把我们的GPT和chat GM这种类型的不同的大模型都放在这个model下面。参数解析器，比如说我们通过这个命令行的参数，也可以通过我们的e mail文件，我们的日志模块，最后我们的这个prompt，这个提示词的这个模块OK。
	然后这个项目这个open I的这个quick star这个课程项目，目前已经有109个folk了。希望更多的同学勇勇于来folk，尤其是我们实战作业来了，一定要folk这个项目，去做自己的这个实现卷一卷这个实战作业。第一个实战作业也是我们基础篇的这个要最终结题的，这个是基础篇结题的第一个实战作业，希望大家能够放下。然后基于自己的一些思路，把我们刚刚提到的V2.0这个产品规划里面的一些feature，甚至咱们没有提到的你觉得足够好用的这些feature都做好，然后提上来。我们就实际来看一看这个项目。
	这里大家能看这个字是不是有点小。
	大家能看看这个VS code的界面字体大小合适吗？我把这个调大了一点。
	好，这里再额外花五分钟时间跟大家讲一讲。首先我们整个OpenAI的这个quick star这个项目是被我放在一个远端服务器的。然后我们我们在这个之前的课程里面有讲过需要什么样的一些开发环境，其中就提到这个IDE。目前这里使用的是这个VS code的这样的一个E这个IDE当时还有同学问需要什么样的插件，目前我这边使用的这个插件，叫做可以也可以推荐给大家使用。
	就怎么样去管理一些远端的服务器，可以通过这个remote这样的一个插件来做管理。就这个remote explorer，如果你有多个机器的话，那么他们就可以很很方便的来进行管理。然后就有点类似于像本地的这个服务器一样，它能够打开这样的一个有状态的一个窗口，能在这儿去管理你的文件。这里这个目录就跟我们看这个主拍摄的目录有点像了，就是一个完整的OpenAI的quick star的这么一个目录。如果我们clone下来，然后我们又是在云端开发的话，那可以装一个这样的VS code的插件。然后我相信其他的ID也有类似的插件可以去使用。OK就是模拟出一个本地开发的环境，那我们可以再看一看这个项目的read me，让大家去了解了解。
	现在还卡吗？应该只有一个同学说卡OK好，那我们继续这个项目。Sorry，不是我们的这个quick start的这个read me，是我们OpenAI translator，这个read me。
	整个当前这个版本，V1.0的这个版本是完全由GPT4来生成的一个版本。包括这个文档，然后包括他的中文版本。所以它的中文翻译大家会有的地方觉得很奇怪，就是因为是用它来翻译的，就用这个项目本身来翻译的。然后做这个项目，前面有讲为什么做这个？就是因为有一些需求还没有被满足，并且我们做一个可以保障自己的信息安全，然后实际的运行效果就是这个是我们这个测试样例，就我们的这个老人与海的英文原文，然后有它的输出的一些结果，就翻译好的这个中文的版本，然后他的一些feature，也期待大家去做完之后，把这些feature都能够打上勾，就我们做的更好。
	然后怎么样去使用它呢？这里不需要再克隆它了，就是我之前的那个项目，大家直接克隆我们的quick star就可以了。然后这个地方一样的，跟我们之前说过的，要把OpenAI的API key给设置好。因为我们如果用OpenAI的GPT的话，是需要输入这个key的。然后同样的，如果我们是一个私有化的，比如说ChatGLM的这样一个模型，那你把这个ChatGLM的模型的URL给设置对你就可以了。因为它私有化的也没有涉及到这个健全的事儿，就可以去实际的去连接这个大模型了。那怎么样去把这两个输进去呢？之前有介绍过，这就不再赘述了。
	具体来看它的参数输入这个项目有两种方式来做支持。一种是用环境变量，那这两个可以直接设置环境变量，它就会去读。第二个就是通过这个压mail文件这样的一个设配置文件。这个配置文件的格式是长这样的。就在我们的这个项目里面，这个config高压mail这样的一个文件在这儿，通过这样的一个配置文件咱们也可以来解析出我们要的这个参数。跳转了OK就这个配置文件。
	实际上去运行它的方式也比较简单，就是我们去执行在这个目录下去执行这个python的这个AI translator min点PY文件，点PI文件是它的入口文件，待会我们也会讲。它的日志输出结果是长这样的，就是它的日志级别会有多种级别。然后你调整它的这个logo，就我们说的这个日志管理的模块，可以去调整你的日志输出的级别。
	然后它是几乎是一页一页来做这个处理的，大家能看到这里有一个debug的日志写的非常的粗糙，我们为了不给太多的预设，现在这个版本的prompt的设置是非常粗糙的。大家能看到这个地方，这个图片当中有一行就是翻译为中文，然后下面就是对应的这个内容。这个其实就是现在的prompt非常的粗糙，待会我们在代码当中也能看到。对，然后如果是使用命令行，不是使用配置文件的话，那么可以通过这个方式，比如说导出这个OpenAI的这个API key，或者说导出这个GLM这个模型的UIL。然后这个地方你就可以通过这个方式去启动它。当然这个book刚刚book就是说我们要翻译哪本PDF，通过这个参数可以输进去，然后通过这个model type是用来指定你现在是使要使要使用的是OpenAI的model，还是说你要使用这个chat GLM的model。
	这个是一个目前的REDM，大家可以下来读一读，它也有对应的中文的版本，对，这边就不再赘述了。我们就从这个win点PY文件我们开始看这个项目其实非常简单，我们这个是项目的入口文件。这个项目其实几个主要模块，从这个命点PUI也都能看得到，它分为几个目录，比如说这个工具类的目录里面定义了我们的参数解析器，以及我们如果是从我们的配置文件里面去做解析的话，会有一个config loader。然后在python里面我们还实现了这个日志的一个管理器模块，用了一个开源的实现。然后在上面做了一些简单的标准化日志输出的格式。同时还会有一个我们叫大语言模型的接入模块，里面定义了两类模型，GLM的model和OpenAI的model。然后我们在PPT里刚才还有讲我们有一个PDF translator。这个translator包含了一个poser和一个咱们的writer对吧？以及我们真实的这个translate的逻辑，也在这个成员函数里面OK。
	我们一个一个来看，这些参数是怎这些模块是怎么样去实现的，以及我们还有什么可改造的空间。第一个就是我们的这个参数解析，是通过这个argument powder去实现了一个具体的去解析命令行参数的实例，这个是一个非常典型的paton实现，你给跳转过去定义了这样的一个类。这个是由这个PAI的GPT4生成的这个类。那这个类的需求其实通过刚刚我们的这几个解释，应该看的比较清楚了。
	第一个就是说我们是否去使用配置文件，然后我们使用什么样的这个模型的类型，是OpenAI还是GLM。然后如果是open，这里它还会有这个，我把这个缩小一下，有一个choice的这么一个参数，包括这个required这两个参数它的含义和它的使用是比较常见的。如果当你标注为它是一个必须要传的参数的时候，那这个时候通常需要引起重视？我们这个参数非常重要，需要去传递。然后这个时候还给了一个附加的参数叫choice，就说明这个是有候选，它不能随便填。虽然它的类型是一个字符串类型的，那么你也只能填这两个才能被正确解析。然后如果我们选择了GLM这种模型的类型，那么就传递这个GLM model VIL如果你传递的是这个OpenAI的model的话，那可能就要给这个OpenAI的APIK，这个是一堆对称的。
	然后还有一个就是我们在请求API的时候，尤其是OpenAI的这这种API调用的时候，我们通常会设置一个超时的一个时间time out。这个time out也可以通过这个命令行参数去进行指定，然后这个是我们的需要去解析的这本书，其实是一个文件路径，有点类似我们刚刚看到那个PDF partner里面的那个老人与海的PDF，或者说test点PDF。然后这个file format这个地方是指我们翻译之后的这本书，就我们的writer模块，应该把它导出成一个什么样的格式类型，现在是支持这个已有的类型，后面有写。整个这个模块其实非常简单，我们通过一个argument part这样的一个类，去实现了从命令行里面来解析我们必要的一些参数，或者说我们一些可选的参数。然后如果大家要去做扩展，可以在这儿去add一些argument，那它就会自动的去增加解析了，甚至你可以把这个类丢给GPT4，然后你告诉他要增加什么，按照这样的格式去做增加，那它也会给你对应的一些结果，这个是没有问题的。然后pass arguments就是实际去调用了一个解析的结果，就我们的这个实际去从命令行解析，就是继承了我们的这个阿格pass的方法，这是一个比较典型的用法，我就不再赘述了。
	那这里是做了一个判断，就是当它model type是为空的时候，并且我们又没有从这个config就我们的配置文件里面也没去指定的时候，会做一个异常的抛出，告诉你模型的类型是必须要指定的，你要么就配音，要么就GLM。好，那我们回到这个argument pother这里来，我们看一下这个config loader又做了一个什么样的事情。很简单的一个实现。首先config loader它要去从一个特定的配，它是一个加载配置文件的一个实例一个类。那它要加载的这个配置文件一定得传进来，对吧？那这个conflict pass要有，那就conflict pass给他之后，他会去打开这个config pass的这个文件，然后以这个读的方式去取。然后这使用到了一个依赖库叫压mail。我们知道它是用压mail来做定义的对吧？然后有一个safe load的方法，通过这样一个库的safe load方法就会默认变成一个我们可以看到这个文件。
	这里就能比较好的直接获取到这个config的数据，并且是保留了这样的一个城市化的。是的，通过这样的一个简单的SIPO ad的方法就可以了。好，通过这两步，其实我们拿到了什么内容？就我们看到整个三部里面的第一步，就我们从一个PDF文件，以及这个PDF文件要被解析成什么样的格式，以及我们要用什么样的大语言模型来做翻译，甚至说要没有要不要给他一些附加的一些配置项，包括超时时间等等，都可以从这里去做配置的输入。刚刚那个config loader的实际加载，就通过这个note config就能去调用我们这里的这个方法来做实际的调用，然后返回的就是这个config OK。
	接下来我们整个三步走？把输入的这一端，输入的配置项什么的都定义清楚了。接着我们需要去做的是把模型这侧，就我们大语言模型这侧去做一个实例化。
	这个实例化我们这里可以看到有两部分。第一个部分是我们的这个模型名称。那模型名称去哪取的呢？是从这个OpenAI的这个model命令行参数里面去取的。如果我们是使用的config的话，那可以从config里面去取。这个保留了它的二级目录的结构，包括它的APIT，然后这里就可以实例化一个OpenAI的model。
	我们可以看一下这个实例化的OpenAI model是怎么定义的，首先这里为了兼容各种情况，我们把2个API都做了实现。这个make request有点类似于我们上一节课里面去做的那个request。当然上节课我们还加了这个装饰器，这些东西都是希望大家能整合之前课程的内容，能够自己再去丰富的那简单跟大家看一下OpenAI model这个实现。
	首先我们定义了这样的一个类，就叫OpenAI的model。然后它可以支持各种各样open I的这个模型实例，我们之前看过它现在支持的模型列表有56个，对吧？这56个模型列表里面，大语言的模型可能有一半就是抛开那些嵌入的模型。
	那大语言的模型里面又有两类接口都可以拿来干这个事儿。一类是最早期的接口，就这个completion的接口。还有一类是chat completion的接口。然后chat completion可以去调用GPT3.5和GPT4.0。这个可能可以调一些更老的模型，但从我们的视角来看，其实包括各种成本的这个角度来看，我们希望他能够然后我们希望大家能够使用这个chat的接口。因为GPT3.5相对来说更便宜一些，毕竟我们是做翻译的，这个token的量就更大了，包括大家在实际去做这个示例的时候，也希望待会儿我们把一些参数指明之后，大家做实验的时候可以要么就先用那个test的文件，就只有一页文本的那个文件。要么就是我们在直接用这个老人与海小说的时候，可以不用把52页都全部丢给OpenAI，而是我们可以只使用其中的，比如说第一页、第二页。
	先把这个流程跑顺，大家理解了这个过程，然后再来去做相关的一些研究。好，然后大家可以看到OGPC4生成的这个代码，其实它的耦合性还是有的。它的这个模块之间的解耦还没有做的非常干净。
	就比如说这个make request，其实是最终我们要去调这个GPT的时候要发起的那个请求。也就是我们三步走里面，不是中间是我把这个图再给大家强化一下。就在这幅图里面，我们有看到这个加载通过刚刚的。这个地方加载。通过刚刚的这个argument puzzle，我们可以拿到除PDF文件以外的内容。
	然后我们定义了这个大模型。然后这个大模型有两类，我们现在正在看OpenAI model这一类这个class。这个类里面我们可以发起一个请求，其实就等于这个红框的部分。就这个红框的部分我们再发起一个请求。然后发起一个请求之后会拿到一个翻译的结果。就是我们马上会看到我们定义了一个叫translation，这个地方叫translation。所以这一部分其实就相当于我们在通过翻译prompt再发起一个请求，再给我们的这个GPT3.5这个found message。
	我们没有大家可以看到这里，我们没有在引用它的历史记录跟之前可能大家用上节课的function call in的这个notebook也好，还是之前我们在学习chat的这个也好。其实没有再把这个message是一直存下来，只需要这一次要翻译的内容也就好了。这个是最简单的一种实现方式。如果大家想要把它的质量做好，我刚才有提到就把我们的system roll用起来，能够把它的翻译质量去做提升的。
	然后它的翻译结果，我们直接通过这个结构，大家应该用过之后就已经很熟悉了，把它拿出来，拿出来之后，把它放到translation里面，就是我们的译文的结果，然后把它返回出去，至于什么时候调用它，我们待会可以再看。这里还做了一些异常的处理，就比如说触发了这个rate limit error，那可能我们最多尝试三次。这里有一些简单的sleep的方法，包括一些请求超时、异常等等，在这边做了一些异常的补货。
	好，然后我们有这个OpenAI的这个model了，我们也可以看看它的GLM的model是怎么用的那如果我们要去使用这个GLM的model，因为这一部分其实是本来放到生态片里面去的，所以今天的V1.0我们默认没有去把它实例化。但如果大家已经动手去部署过一个chat GM了，那就可以在刚刚的这个命点PY里面，把这个GLM model给实例化，然后去做调用。调用的方式也都是类似的，跟我们现在这个open I的model是类似的。在PDF translator里面也都是可以直接去引用的。因为他们都共同继承了这个项目里面的一个model类。目前这个model类对一个鸡肋共同的鸡肋。
	然后这个GM model，其实它有一个model URL就可以直接访问了，不需要这个open I的APIK。他他的请求方式也比较粗糙，就是发送一个payload，然后里面是这个prompt，然后和他的history。这个接口大家看起来就有点像这个completion的接口，这个是之前对应的ChatGLM16B，之前就叫拆卸M6B现在有这个第二代的6B了，对应的一个方法，通过这个request可以返回这个结果。
	好，我这边就不再展开了，跟这个open I是类似的。好，那么我们继续往下看啊，就是这个面临PUI接下来做的事情就是把我们的PDF的这个文件从这里面取出来，然后它的输出格式从这里面取出来。然后真正实际的这个代码的逻辑，其实就在这个translator这个核心里了，就我们看到的中间这个部分，有PDF的translator这个实例，它包含了PDF poser和writer OK。
	那我们来看看这个PDF translator具体做了什么操作。首先这个PDF translator它是有三个重要的成员变量。一个是这个model，这个model就是我们刚刚看到的OpenAI的model，或者说我们的GLM的model。因为他们都共同使用了这个鸡肋，所以可以复用。第二个就是这个PDF poser，我们刚刚这节课的上半节讲的，我们使用了这个PDF的这个liber这么一个开源的库来实现了PDF的解析。然后这个writer就是用来做文件导出的，我们实现了这个解析之后，我们要把它导出成一个文件，那就对应着我们刚刚看到整个几个核心模块。
	这个translate PDF这个主要的函数就实现了怎么样把一个输入的PDF源文件翻译成一个我们最重要的文件，然后就对应着我们这里先实例化的一个translator。然后实际要translate这个PDF需要两个参数，就是我们从这儿拿到两个参数。一个是原文件，就我们的PDF的源文件，它的一个文件路径，然后以及我输出的这个文件要导出成什么样的文件格式。OK那就对应着我们这里的这个函数。那一个是通过这个PDF的，我们可以去解析PDF，把我们的这个PDF的这个文件路径传给他就能解析。
	然后这里就涉及到我刚才说的一个参数，我们的这个pages，这里pages就这个我相信刚才上节课听过讲的同学都知道，这就是我们有多少页，因为一个PDF就决定有多少页。为了给大家省一些token，所以专门预留了这个参数，它默认的是那就不填。但如果我们这里pass PDF把这个参数填写了的话，就这里大家可改。
	我改了这个参数的话，其实这个参数的含义就是在pass PDF里面实际要解析多少页。这里我们应该看一看这个代码就能理解了。就是我们有52页对吧？我们可以不用全部都解析出来。比如说我们就只解析第一页或者第二页，那就把这个配置写成一或者2，那就只会解析这么多内容。那大家实际去翻译的时候，就可以只翻译一页或者两页。给大家可以节省一些token去做这个研发测试，是这么一个重要的参数。我们可以看一下这个pass PDF具体干什么事情，到这儿应该就已经跟上节课接起来了，对吧？
	我们使用了一个open来管理这个上下文。它会及时的去运行完之后去close回收这个缓存，回收这个内存里面占用的一些资源。然后因为有这么一个参数之后，给大家做了一个简单的逻辑判断，以防大家填错了。就比如说我现在只有52页，我们配置是强行要解析到100页，这肯定不行，对吧？超过了这个PDF的本来已有的页码了。所以做了这么一个判断。
	如果我们的这个配置是没有设置的话，那么就等于我们的这个PDF有多少页就解析多少页。如果有设置的话，就只解析到或者说只使用到我们的当前设置的这个页数为止，就做这么一个事情。然后具体来看，就我们这里的这个配置，就是我们的PDF的这个barber里面这个配置就这一页，我们希望把它变成这个，呃，就我们回到这一行代码，这个地方我们其实就等于我们上一节课讲到的有一个PDF club里面的配置。然后我们可以调它的extract text的方法，可以调他的这个extract table的方法。
	然后我们现在这个版本的实现，我们是自己做了前处理，没有去把这个处理的逻辑交给大模型，而是我们自己来做这个处理。所以自己来做这个处理就会有一点点的，你会觉得有一点点烦。因为我们就要处理上节课说的问题，就是怎么样把我们的text里面的这些表格里面的内容给去掉，那具体怎么来看呢？首先几大块的这个代码，第一部分就是我们定义了一个自定义的配置，就我们这个open a translator里面的一个配置。然后这个配置要用我们上上半节课讲的那两个方法，把里面的一些数据处理干净，处理干净之后，再放到我们定义的这个配置里面去，大概就这么一个逻辑。
	那具体怎么做呢？首先我们可以看到这个配置的定义非常简单。我们用了一个content这样一个列表，这个列表里面可以去增加内容，要么去增加我们的这个text，要么就增加我们的这个table。好，我们回到这儿来，这个是解析出来的原始文本，你可以理解成我们从这一页，就原本的这个PDF club er的这一页里面解析出来的所有文本，并且我们还解析出来了所有表格。
	现在这个表格首先是一个三维的数组，我们上节上节课有讲对吧？那这个三维的数组你就需要三个follow去取出最终的每一个单元格。最外层的这个完了就是去for loop每一个我们取到的table。然后在这个table里面，因为它是一个二维的这样的一个表，对吧？所以你去for row一行一行的，然后再去取一个单元格，然后把单元格里面的的内容从我们的row text里面去做替换。这就是我提到的最简单粗暴的一种实现方式。
	就比如说我们把表格里面的，因为表格已经被这个protect包含了，对吧？那你就把它里面的内容给去掉，那这个地方会出现一些什么问题？就是这种处理方式。首先它有可能出现一些原本我在这个正文里面有一些文本的内容，刚好在那个单元格里面也出现，比如说一些常见词汇，所以这个方法也有一定的缺陷，这个是目前最粗暴的方式带来的一些潜在问题。
	就大家需要去去做这个对应的处理，也是在我们实战作业二里面的一个得分点。OK, 这个是一个缺陷。第二个就是说如果我把这些东西都替换掉了，但是它就会出现一些空行，对吧？就是如果我有一些表格全部处处理干净了，就是多了一些空行，那这些空行也可以从原文本里面去把它移除掉掉。然后移除掉之后，就变成了一个相对干净一点的row text。并且我们可以把这个干净的row text变成一个我们刚刚提到的，在我们OpenAI translator里面，我们自定义了一个page，为了writer的干净。这个配置里面我们把这个text content，就文本内容实例化，并且我们刚通过这个context的方法，告诉他是一个文本类型的内容。它的输入就是我们刚刚已经处理过的，把表格移除，把空行移除，然后把一些不必要的一些停止符移除之后重新拼起来的一个相对干净的文本，然后传到这个context里面去，content里面去。
	对这个content其实我们做了一个比较简单的处理，这个就是我们刚刚提到两条思路。第一条思路是我们来做数据的预处理。然后我们处理好之后我们分类交给大模型去做翻译，这是一种方式。这样的一个content，大家如果去去理解这个代码的话，其实我们也可以做到说我们在大模型翻译完之后再来实例化这个content也是OK的对吧？
	就这个实例化放在什么阶段，包括我们自己的这个配置放在什么阶段，这个地方其实是留有余地的，大家可以去感受一下。就一个是翻译前我把这个配置做好，然后我一段一段去翻译，然后我塞回来，然后变成了一个我可以导出的配置。也可以我把这个prom的设计的足够好，让我把这里的PDF配置把这里直接显示出来。这个PDF文本以一个比较好的prompt再加function calling的标准化输出处理好，然后再去实例化这个content。甚至在这个content里面还可以去扩展布局，就我们怎么把布局存下来，最终再把这些配置也好，content也好，导出给这个writer，让它变成一个文件。
	好，那么table也是类似的，我们把这个table变成了一个table content。大家可以看到，这里变成一个table content，然后它是把它存成了一个data frame。我们刚刚有讲其实那个二维列表很不方便，对吧？那我们把那个二维列表变成一个table frame，那这个table frame就可以去做处理了。然后这个地方其实set translation我们待会儿会讲，就是在翻译之后我们怎么样把这个结果存下来。
	好，然后最后我们还定义了一个实例叫做book，这个book就是一本完整的PDF，我们可以把这每一页加进来。这其实整个抽象，就我们这个分层的抽象，大家可以再继续回看一下。我们定义了这个book的这个代码包，或者说叫模块，里面有三层，是为了让大家更方便的去理解这个PDF的这个结构和概念。因为我们在整个刚刚上半节课有讲，包括这个PDF club里面的抽象，它有PDF就类似于我们这儿的book，然后它会有这个配置，就约等于我们这个配置。然后它会去extract text，extract tables, 然后我们把这些东西都放到content里面来，然后在content里面我们再去细分，有不同的类型。我们这里有这个不同的类型，有文本，有表格，甚至未来可以去增加这个图像。那这个概念就对标这个对标的概念也是方便大家去理解这个过程，我们在内存里面有一个原文，按照它的那个格式是最原始粗糙的，然后我们可以把翻译后的结果按照我们想要的方式存下来。OK. 
	那么整个PDF的这个part puzzle，就这个实例，它的这个核心方法就是这个pass PDF就已经梳理完了。然后到这儿为止，其实我们就把这个PDF在open a translator里面解析并且存下来了。看到这儿为止，大家有没有什么问题？
	有一个同学问的很好，这个逻辑是已知页面结构，先文本后表格，还不完全一样。这个地方是这样的，就是我们在刚刚的这个notebook里面预留了这个部分的设计，我们可以去获取到很多的坐标。在获取图像在提取图像这个事例里面，其实我们就主要去highlight去着重讲了坐标这个事儿。就整个PDF的club，我们用的这个库是能获取很多有效的坐标的那这些坐标就是用来进一步帮我们把布局给还原出来的。只是我们这儿没有去细讲，是希望留给这个实战作业里面来做这个区分的。
	如果我们能把这个坐标提出来，那自然也就不是所谓的纤文本后表格了。而是说我们能够知道这段文本和这段表格在整个配置的位置相关的位置信息。那我们也就能够更细的去还原这个布局。比如说我们这里说到的这个配置，那这个配置就可以专门留了很多的抽象。因为content是纯的内容，那我们可以在配置上面再实现一个layout。这个一页完整的配置就应该是layout加content，那我们就可以还原出整个这一页完整的内容。
	有的同学说代码不要讲这个太细，但是还是有很多同学希望讲细一点。这个我还是照顾大部分同学稍微讲细一点。大家如果想觉得太细，可以再深入研究，研究怎么把这个代码留下来的。这些可以去做扩展的部分，在讲的时候去思考。因为我们其实整个代码是留有了大量可以在扩的空间的。就包括我刚刚讲的这个雷out的部分，就是这里的三层实现留了大量的待实现的工作，然后对就layout跟content组成的这个配置，甚至我们的这个配置还可以再去做扩展。
	就我刚刚讲的，我们我们在讲进一步的这个思想，就是说如果我们想要把布局问题处理的更好，首先在配置上面可以实现layout。我们这只实现了一个contents对吧？Layout跟contents组合起来能有一个完整的一页。并且这一页怎么样去跟我们翻译之后，我们刚刚讲过文本长度不一样。那是不是一个52页的英文书翻译成了一个中文书，变成了48页或者说56页。
	那这个过程当中怎么样处理我们的配置是严格的这样一页一页只能筛下来的。比如说我这一页塞不下了，我把字体再调小一点，对，我们也实现了一些字体的部分，在writer里面就是我是把字体调小，还是说我这一页就是写超了，那我就写到下一页去。那那这就带来一个问题，下一页是直接在那一页序上，还是新起一页？这些问题都可以在book这一层抽象里面再去做设定，对吧？
	就我们的这里其实是蛮多可以操作的空间的。我们的self点pages就可以不再是一个简单的列表，那就可以类比成我们的PDF plumber。它其实就没有说我们只做了一个简单列表，对吧？它的配置是里面是也是一个配置。然后配置实现了page number，实现了宽高，实现了各种各样的成员方法和我们的成员变量。这些成员成员变量和方法其实可以在这个book里面去做扩展，我这边就不再赘述了。
	然后再看看还有什么问题。老师提取的翻译文字如果有乱码会出现异常吗？怎么处理这个问题？我有点没太理解这个问题，提取的不会有翻译文字，提取的是我们需要翻译的文字。所以这个地方这个同学可以再重新提一下问题，我没有太理解这个问题。
	然后有个同学问，这里有些代码是GPT4生成的是吗？那一部分怎样实现的？这里所有的代码都是GPT4生成的，我只是会跟他多轮对话去做这个调整。对怎样实现的？其实上一节课我们有讲，怎么样通过各种技巧去跟GPT4沟通。会不会有每次请求GPT翻译的人名是不同的问题，这个是一个很好的提问，就是说人民这件事儿，包括一些地名这个是一个非常好的实践性的一个问题。这里没有一个准确答案，但是我觉得是一定有概率出现这个问题的，就是人民的问题。
	这里要么就是说你如果想稍微奢侈一点的话，那就是在翻译过程当中去处理这个问题。就跟文本和表格这个事儿一样，你在翻译过程当中你就去处理。还有一种，那你就可以把它放在你识别出它是一个人名，那你就把它放在这个messages里面让他记住，这是一种方式。也可以在后处理里面去做处理，甚至是翻译完成之后的后处理里面去做处理，那可能就不是用大模型的手段了。
	还有同学问有没有图像里面有文字再转成纯文字的，这个是一个什么概念？是指扫描的PDF吗？也请这个同学在写的问题写的再更清楚一点。
	页面排版需要处理吗？实现你有吗？这个版本的实现里面没有严格的页面排版的实现，是留给大家做这个实战作业二的比较的时候拉出区分度的。我刚刚有讲怎么样去把它做扩展，但那也不是只有这一种方式，咱们只要能够做出这个功能就好了。老师代码给一个函数调用栈或者UMM图吗？其他同学的提问，这个项目应该已经足够简单清晰了，还需要一个UML图吗？也不是不可以，回头我可以拿那个代码生成一个ULM图，这个有专门的项目可以去生成的。讲如何用GPT生成该项目的过程加1。可以，我回头把那个整理一下，就是把生成这个项目的聊天跟GPT的聊天记录整理一下，然后我给到大家。
	这个项目没有用copilot，就是直接跟GPT4对话的。还有同学问如果配置出来超过一页怎么处理？这个我刚刚有提过，要么你就直接追加，就是追加到第二页去。要么然后第二页的内容就从此排版就乱了，对吧？要么就是你别管它，就按内容写的都都可以。对，看你最终输出的是个什么格式。如果你输出是个markdown不就没这烦恼了吗？对吧？
	表格有表明的情况，如何处理很好的问题。但其实如果你不关心layout的话，这个地方不用额外处理，对吧？
	但如果你关心layout，又希望它的表名跟表的顺序没有变化，那就要用我刚刚说到的一些方式去去识别出它了。就是通过GPT的能力来识别出它了。因为本身这个表明就是一个很玄学的东西，它可以出现在任何位置，它可以像我们这样有一个标题，它也可以是在像论文一样，在整个表的下面或者是上面或者居中，这些都是无法通过PDF club的extra tables提取出来的，需要你额外去做处理。但是比较好的是，表明的模式通常是固定的。就是这些需要就相当于如果我们要把这个东西商用的话，那就需要在后处理阶段再花一些功夫。比如说这个表它是有特定，那因为它本身是一个相对规范的一个PDF，它的取表明的方式应该是有一定format，有一定格式化的那如果这个事儿我们能鲜艳的告知我们的GPT模型，那这样不就很好吗？从这个视角来看，是不是我们就可以扩展一下功能，在我们的argument poser这里，我们是不是可以再增加一些功能，增加一些这个table format？然后这个table format传给我们的prompt text，然后让我们的prompt template ate去生成对应的这个table format，告知我们的大模型，然后让他看到这个内容的时候知道这是表明表头。
	对，这里就整个是有很多可扩展的点，然后每个人我发现他看到的视角不一样，但最终功能如果都能达到的话，那这是我们想要的。
	也可以有同学说是不是能在翻译之前加术语表，可以翻译前后都可以。
	GPT生成的代码不是很好吧，这个看你见仁见智。因为大部分人写出来代码应该更差。毕竟ChatGPT是拿github上面的有质量的代码库训练出来的对，然后很多同学包括这个同学说生成出来代码bug一大堆，这里就要考究一下了？是不是本身prom的用的也没有那么精深？或者说给他的这个输入通过一些方式描述的更好的话，他就能好用一点了，毕竟这个项目就已经生成出来了，吧？
	然后我们实战也是用GPT生成，我不会管大家实战是不是用GPT生成的，但关键是核心是咱们把这个实战的这个功能做出来了。然后我不建议在你这个ChatGPT用的还不够熟练的情况下去实兑让它生成代码。而是先想清楚，我们先设计出这个思路，就跟刚刚我们改进的这个设计思路里面，我们觉得这里可以再扩展一些内容。在这个情况下，我们应该让现在这个模块达到V2.0的这个产品规划的特性的话，还需要加什么模块？或者说在现有的模块上应该要怎么样去细化深化。
	还有同学说如果自己扩展的话，似乎大部分工作都跟大模型本身无关了。我严重不同意这个观点，我刚才讲了很多思路都是跟大模型处理高度相关的。然后ChatGLM6B是一个私有化部署的模型。
	老师问一下，怎么在获取PDF的时候，就区分这个文件是扫描文件还是一个标准PDF文件？这个问题挺好的。坦白来说我也不知道这个答案，但大家应该查一查，能知道这个答案。我觉得一个可能的思路是说，也许他的meta data是能区分出来的。然后第二个就是说你如果是一个扫描的文件，你把它变成了一个PDF的pages。然后这个PDF pages你去extra text的这个方法取不出来内容，那肯定就有问题，对吧？就是比如说你通过meta data发现这个PDF文件有几百KB甚至1兆以上，但是你怎么都提取不出文本来那这个时候大概率可能就是一个扫描文件了，就是这些方式都是可操作的。
	还要识别一些不需要翻译的内容，比如代码。有个同学是这样说的，我觉得不对，就是不需要识别，这就是prom的设计的好不好的地方了。我这儿故意设计的很糙，就是希望大家考察一下前面这三周的成果，谁的prom的设计的好，谁的prom的设计的差。因为整个大模型的应用开发有一大半的功力都是体现在prom的设计上的。比如说你能不能告诉他代码就别翻译了，对不对？就是这些东西都是不一定要你写代码来实现的。老师用GPT4生成这个项目时，代码中调用了这个函数，是在提示时中告诉GPT4还是怎么处理的？这个问题挺典型的。
	比如说我们要让GBT4来生成这个代码，首先还是一个很核心的观点。这个课一直在灌输的就是不要把它当成一个很难很神秘的事情。生成代码和生成文字、生成小说对于GPT来说没有本质区别。
	好了，那就回到生成的问题上来，那怎么样生成呢？就是我们说一段话也有很多漏洞的，就是也有很多bug的。我们说话的时候，只不过好像没有一个解释器和编译器来运行这段话，你就觉得好像没事儿。但其实沟通技巧不太好，不就体现在这个地方，对吧？所以首先bug和这个生成文本内容没有本质区别，这个观念我觉得大家一定得能get到。
	第二就是说怎么样去怎么样去让他能够去学一个这样的库也好，或者说这样一段代码也好。其实我们之前有讲过？一个很关键的策略，包括论文也好，上节课讲的技巧也好，就是我们的few shot learning。好，future learning怎么用？其实是一个具体的一个技术侧的技术上的一个事儿。怎么用free learning让它去生成好好的高质量的代码？
	两个最典型的方式，第一个就是few shot，给他一些示例对吧？我们刚刚给了那么多notebook的这个示例了，能不能直接告诉GPT3.5或者GPT4。我现在当然这里还是涉及到一些prom的设计，就怎么描述你的few shot，对吧？然后你告诉他这个有一个库是这样的，然后他有这样的两个抽象。你看我们刚刚讲上上节课的时候，关键花了很多时间去讲这个模型的抽象，就有PDF类，有配置类，然后配置类里面组合成的这个就page加meta data组成的PDF配置上面里面的每一个配置，可以再用各种成员函数和成员变量去组合出这个配置。然后又怎么从这个配置里面去提取内容，这些东西是一些偏抽象的概念，能够告知GPT。然后再给他几个事例，这几个事例就是我通过这个方法能获取到这样的内容，那它就能get到这个函数的功能了。
	这个是不是跟我们上一节课讲的function on是类似的，你需要写这个function的description，然后你也需要去告诉他这个function有哪些parameter，然后哪些parameter是required是必要的。其实整个这个是跟大语言模型编程跟以前最不同的地方。然后这是一种feature learning方式。
	还有一种方式就是但是不太稳定，就是联网的方式。就是我们的这个大模型其实有一些插件也好，包括我们自己通过这个function call也好，别的一些方式也好，是能让它连上网的，相当于能让它去获取数据的那这种方式就比较简单粗暴，让他去获取这个代码库的一些网页也好，各种东西也好。然后要么就是去find to你，要么就是直接给他一些网页，让他去instruction tuning，然后让他去学，学完之后让他去输出。
	但这种方式没有第一种方式稳定性。就是无论如何有一个比较明确的现象，就是如你花了心思去设计的这个future learning，通常来说会比你直接甩给他一些UIL的链接，让他去学学完之后就让他学会干活了一样。这两个比起来的前者肯定要好一点。就像你是一个senior的研发，或者你是一个技术leader，一定是你把问题拆解之后，再告知你这些junior的小兄弟，或者说这个新手的研发的效果更好。因为你得先把大问题拆成小问题，这个也是我们前面课程讲过的，把一个复杂的task变成一个小的问题，或者说变成一个有顺序执行的问题，再交给GBG去做，这样是比较好的。包括我们在介绍GPT能力的时候，把它对标成一个新手研发，然后学习能力很快。你只要能够描述清楚问题，它就能够解决好问题。就这么个逻辑架构的抽象是要我们来想的，不是让GPT4生成的，就是整个要用这几个模块，就我们刚刚讲的课程里面讲的是要人来想的对，不是让GPT来想的。
	有同学问有没有用蓝茜，这就是开始让大家感知怎么样去写一个AI大模型的应用了。后面会用蓝欠把这个项目重写一遍，用一些能欠的抽象。还有个同学问，如果PDF1段文字跨两页，那么GPT单独翻译每一页的时候会不会意思不对？可以试一试，这是一个好问题。对，这个问题也涉及到我们到底翻译的时候是按页数来，还是按段落来？还是按什么来？
	对，有个同学说的很对，PDF有很多种不同的格式规范。是的，PDF是一个很神奇的数据格式，大家如果可以去研究。对，包括我们建筑设计的CAD图纸，也可以就是CAD图纸，就是这种好十几万平的机场，也可以打印成PDF的。
	有没有promote？这个同学可能是想说有没有prompt的教程，或者收集了这个prompt的什么网站。这个很多，就这样的网站很多，大家随便搜一搜吧。但是别老想着这个prompt有一个直接复制粘贴过来就解决你的问题了。就是学会怎么用prompt。这个prompt的engineering，prompt的design是一个核心能力。这个东西大家得学会授人以渔，就学会怎么设计这个prompt。包括我们设计这些实战作业和之前留那些notebook的这个开放式的问题，都是为了让大家去实践，去用、去设，是这个prompt对。
	能不能让GPT连项目的框架也自动生成呢？这就看你的语言沟通能力有多强了。其实，因为框架也可以被抽象成模块。
	我们再回答几个问题，到9点20分，我们往后讲。有没有对应的？对，有官方文档的。就是我我们之所以没有去着重讲CIGLM，就是为了这个留给后面，免得我们把问题展开了。这个实战作业的最大的一个目的就是让大家第一次有感触。就是怎么样写一个跟大模型交互的应用程序，一个小小的项目，跟他要交互。
	好，就是这一张核心的图，大家再来回回味一下这个设计思路，就我们需要核心关注的这个模块，大模型在这个位置，然后最有价值的部分在这个prompt template。因为其他他模块的诉求都是通过这个prompt的template来延展出来的。包括我们怎么样去设计这个prompt的template，是分领域，分语言各种这种都决定了我们最终要增加什么样的参数，要导出的时候要增加什么样的参数。然后我们的大语言模型本身，因为简单来说刚才有个同学问有没有一些好的prompt，就是你把一个特别好的prompt换一个大模型用，可能就不好用了，这就是不建议。当然你前期去去学习它的时候，你多看一些好的prompt肯定没问题的。但我们其实一直没有专门开课讲这个prom纯prom纯粹这个prom的什么好什么差，更多讲的还是怎么样去设计出一个好的prom，然后给了一些例子让大家去理解。因为这个玩意儿还是要动手才能学会的。并且你用的越多，你越能知道什么样的问题场景适合什么样的prompt，以及是在什么样的大模型上用什么样的prompt。好，你同一个prom的在GPT4上好用在3.5上不一定好用的对。
	有个同学问关于function calling，如果我有很多function，调用的时候，怎么确定我应该传哪些function？如果我有一百多个。这个我有点太没太理解，你是指什么意思？就是你这一百多个都是开放式聊天里面要用到的吗？那如果是的话，你就都应该传进去，让GPT来判断的。但是这个时候就比较考验你的水平了。如果你有一百多个function都想加载到这个GPT里面来，那你就得把这一百多个的区别描述好啊，不然他他就区分不出来。就是我这个同学问的这个例子其实挺实际的，也是现在大家用大模型function calling或者ChatGPT plug in的时候会遇到的问题。
	首先你要理解function calling是在替代什么。就是现在我们做软件开发设计有GUI，有图形化的界面。那这个图形化的界面我们还是会吐槽，就比如说我们现在看到的这个PPT的界面，这里有这么多按钮，有home，insert, draw, design, transition, animation, sled, slide show. 
	我怎么知道我的哪个功能在哪呢？这是通过了windows这个操作系统以来，包括可能最早最到施乐实验室这三十多年来的一个GUI，就是人机交互。基于GUI的人机交互的进步，我们逐渐的这些产品经理，UEDUX工程师一起做的产品，让人知道了怎么用好GUI。我们才知道那个功能在哪儿，然后我们才知道去哪儿点，然后才会有一级菜单、二级菜单、三级菜单才能做出来。
	那你现在想想LUI我们叫这个自然语言UI或者说叫这个function calling在干什么事。他在把这一堆按钮让你用自然语言描述出来，然后你现在不需要去找按钮了，是GPT来找那个按钮。只不过它现在不是按钮，而是你的那个function calling的描述。
	你品一下这个区别，这就是考验你，为什么我说LUI这种基于大模型的研发，自己就是一个产品经理。因为你现在真的就是一个产品经理，大模型是你的用户，也是你的copilot。你要告诉大模型你现在到底在设计一个什么玩意儿，那你怎么告诉他？当然未来我们能想象得到，大语言模型一定会跟视觉系统去做对接的，并且也是现在的研究热点。但是在这个东西出来之前，现在就只有通过语言来描述它。那你要怎么样把一百多个，这里差不多也有一百多个，这一百多个描述清楚，然后还要让大语言模型判断什么时刻什么场景应该给他什么参数，这是很难的。
	所以我不建议大家一来就搞这么猛的一个产品，包括这个场景真的需要LUI吗？就是你的场景里面到底哪些需要GUI，哪些需要LUI。我们从来没有说LUI就完全打败了这个图形化的交互，就一定是要找到差异化的竞争力。
	好，那我们继续。继续到代码这一部分这一趴。对我们把这些关掉，回到我们刚刚是把这个解析PDF讲完了，对吧？就到这个里面来了，解析了PDF，所以我们现在有一本自己的book了。然后这个book是传入了两个参数，一个是PDF file path，就是我们需要解析的这个PDF的文件路径。一个是我们需要解析的页码数量，就总共解析几页，最多也就是解析这本书原有的这个页码数了。
	好，那现在我们怎么翻译？现在这个实现是一页一页来翻译的，而且这个for loop也就比较简单了。大家可以看到我们从这本书里面的每一页去做翻译，取出了这个页码和这个page。然后这里相当粗暴，为什么我开始就说有两条路，我们这里的方式是说，我们把每一页的内容先给它构造好了，放到了book里面，放到了配置里面，放成了每一个content，就放成了每一个内容。然后针对这每一个内容，我们去进行大语言模型的调用。所以整个这一段，你就会看到非常简单粗暴的一个实现。就是从每一本书里面的每一页再去for loop，再去for循环每一个内容。
	然后我们三种内容还记得吗？就文本的、表格的、图像的，都可以用content的这个鸡肋来表达。就和我们在model一样，我们定义了两个鸡肋，一个是model的鸡肋，所有的大语言模型都可以继承自model定义了这个content这么一个鸡肋。就内容的鸡肋。各种类型的内容都可以基于这个content来做派生。每一个不同类型的内不同的内容，我们再去调用这个模型里面的这个translate prompt，就我们的翻译prompt。大家还记得我们刚才我们整个PPT里面讲的那个设计思路，翻译prompt。我是真的把这个PPT和这个代码做了几乎是概念对等，让大家能理解这个代码，翻译的这个prompt巨简单无比。
	首先这个是模型的鸡肋，我们实现了一个模型叫做它实现了一个class叫model，叫模型。然后这个模型大家能看到里面有这个翻译的这个prompt。这个翻译的prompt它针对了是我们的文本还是我们的表格，会有不同的prom的设计。如果是文本，就去构造一个文本的prompt。如果是这个表格，就是制造一个表格的prompt，那就在这儿，很简单，这个非常粗糙，我希望大家一定要把这一部分最好能单独抽出来，变成一个prompt的这个template。
	为什么要让大家自己抽出来，而不是我把它写好？就是因为这一部分南茜做了一个很重要的抽象。就南茜自己把prom的单独抽象成了一个prom的template的，是他做了一个很重要的工作。我希望大家先手动手撸，自己来搞这个过程，后面我们进阶篇再跟大家分享，蓝倩是怎么样去做这个事情的，让大家有这个对比，就是这个设计目的在这儿。
	好，那么针对这两种不同的内容类型，我们可以看一下，文本非常粗暴，翻译为target language。这是用了一个f string，就是相当于这个地方是传入的参数，翻译为target language。那那大家可以看到target language，我们这默认传的什么呢？默认传的是中文，翻译成中文相当于就这地方我们其实是预留了目标语言的这个参数类型的，只是我们没有把它放到这个argument puzzle里，就是为了希望大家未来能去做扩展，所以这里其实是翻译成中文，传了这个参数。然后内容就这个content，就我们传的这个内容content original，就我们原始的这个内容，然后传到这儿，那就构造出了一个prompt，就相当于翻译为中文冒号，后面是我们要翻译的内容。那表格，就是翻译为中文，保持间距，比如说这个有空格，有分隔符，以表格的信息返回，我们这个表格的形式返回。
	这个地方也是一个能欠里面的一个构造，就在能欠里面我们为了把这个输出能够做的比较好，有一个抽象叫output poser，就输出的一个解析器。你可以这么理解成，按照我们现在的翻译术语，其实就是把输出的内容能够以一个规范化的形式，然后把它返回出来。就或者这么讲，就是在我们刚刚的这个流程图里，翻译prompt给到GPT，GPT会把翻译后的结果给我们。但翻译后的结果给我们，它的内容形式可能是不稳定的。那么output power就是在它给我们和存下来中间再加一环，把这个返回的结果变成一个固定的结果，然后存下来，这就是output power的意思。这个地方以表格形式返回，其实就是somehow就是某种程度上就是在做这个事儿，大家其实就可以在这儿开始尝试做这种抽象了，对吧？那那我们就不再展开了，那就通过这两个方式我们去构造了两个prompt，针对文本和表格，这里再重申一下，我们可以不在这儿做这个事情，我们可以把翻译后的结果再用来区分文本和表格，这种思路也是OK的。
	然后这个部分我们应该讲清楚了对吧？那就构造translate这个prompt，然后把这个prompt再传入到模型的make request的方法里。刚刚这个只是为了构造出一个prompt，两种类型都构造出来了。一会儿我们日志也会打印，我们再去调这个具体模型的请求的这个方法。
	这个方法我们刚刚在model里面看到了，是一个在鸡类里没实现的方法，需要由子类来实现，那子类是什么呢？我们刚刚看到了我们定义了这个OpenAI的模型，OpenAI的模型里面实现了这个子类叫make request的这个方法，对吧？那我们再来回看一下，这个make request的方法，接受一个输入的参数叫prompt，然后自己会有一个重试三次的机制。然后我们假设我们用的是这个GPT3.5 turbo这个模型，他会把这个模型传进来，然后message传进来，并且把prom带进来，就这么一个简单的构造。然后把它的这个结果放回到这个translation里面这里如果他没有成功的话，它就会返回这个status是false，那么这里就可以获取到这个结果，然后把这个翻译后的结果，再根据我现在是在这本书的第几页的什么内容再给他set一下。这里也是为了让大家能理解对齐，我们做了这么一个设定。大家仔细看这个代码的这一行，其实就概念上跟我们那个图是完全对齐的。我们再来看一下这个图，一定要跟大家把这个逻辑整明白。
	就这个图为什么要整刚刚那么一个设定，就是我们有一个prom的这个template，其实就是我们刚刚那个翻译prompt对吧？Trans translation prompt, 然后去构造了针对不同的文本类型，针对不同的内容类型，比如说文本还是表格，去构造不同的prompt。然后找大模型拿到了这个翻译结果translation，然后我们把这俩放在了一个content里，就是我们从解析这儿开始就为了存下来，我们构造了一个content，一个内容这么一个鸡肋。所有的原原文件的内容可以放进去，解析后的内容也放进去，并且是一一对应的。就每一个content它有它的original，那他最终的这个翻译后的结果一一对应的那这样针对某一段特定的content，你就能看看他翻译的好不好，就是做这么一个设定，让大家比较好理解。所以这里我们会把这个translation放到这个set translation方法里，我们可以再去这个方法里看一眼。应该是在我们的。
	Content里面对吧？这里有一个鸡肋。这个鸡肋是指我们需要去设置这个类型，在这个设置类型里面跟刚刚那个model的make request很像，在具体的这个子类里面再去实现的。
	比如说我们这里有这个table的，它会有自己的这个set translation的方法，那就是把一个翻译好的变成一个data frame存进来。然后我们的那个文本类型也会有对应的这个方法。好，这边就不再展开了。文本类型就直接复制就好了，就不再展开了。主要是这个table它需要涉及到一个重新构造成data frame。刚给大家搂了一眼。
	好，到这儿为止，其实大家有没有发现整个三步走就讲完了，最后一步是什么呢？最后一步是把我们刚刚在内存里面都把它存下来了。就现在我们执行到这儿为止，就是在执行最后这个self点writer之前，其实我们所有的内容都存下来了，存在了self点book里面，然后每一页里面都有很多个content。首先一个book有很多页，每一页里面都有很多的content，每一个content里面都会有original和translation。整个这个逻辑应该就闭环了，大家应该就理解了对吧？
	把PDF解析进来变成book，然后把book拆解成到content这个级别。根据不同的类型然后把每一个content构造出它的prompt，然后把这个prompt加上content丢给大模型。大模型把这个结果拿回来之后，我们把它默认为这就是对的translation，要把这个translation set回去到对应的这个内容里面去，然后把这个内容一一对应的放回到原来那个content里面去。
	好，那这个时候大家就会有问题。如果translation的时候他prompt的没有理解到位，出了问题怎么办？很好，这个时候你可以针对性的看看哪些content的有问题，方便你去debug，看什么样的场景。现在这个巨简单无比的prompt是失效的，一定会有的。大家相信我，一定会有的。因为现在这个from太简单了，一定咱们这个实战作业二交上来的时候，一定得改造。至少你要让我看到有一些system road的信息，或者说prompt设置进去。对，只有这样你才能把翻译这个事儿真的做好。
	OK那我们现在就到最后一啪，就是这个writer这个模块。我们在三步走的这个过程当中，已经走到最后一步了，对吧？都翻译完了，在PDF translator里面已经有一个book，然后它既有original也有translation了。现在我们要通过这个writer这个模块把它导出成一个文件存下来。那我们再看看这个writer是怎么做的。首先这个writer的实现很简单，我们搂一眼在这儿。他用了一个库叫做report lab。然后通过这个库我们去写文件，然后支持两种格式，它可以输出成PDF，它可以导出成PDF，它也可以导出成一个markdown，当然也可以支持别的，这留给大家去做这个延展了。
	然后怎么样去存，就我们怎么样去save。大家可以看到刚刚就调用了这个方法，save translate, save translated book, 我们把这个翻译后的存下来。那按照我们刚刚逻辑，其实就是把book里面每一页的content的translation输出出来就好了对吧？Original就不用输出了。但如果你的需求是有点类似于字幕组翻译，你要中英对照的那你这样不就很好吗？中音就都有了。然后我们看一下具体的，就是如果我传入的这个file format，就是我要最终导出的这个格式是PDF的话，那我们就调这个save translated the book PDF。如果是mark down的话，那就得要mark down，PDF相对麻烦一些。
	我们先看那个markdown，怎么存成markdown的格式。如果我们让它存成markdown的格式首先给它一个文件名，一个构造一个文件名。这个文件名就是在原来的book的文件名里，我们这个PDF file pass也是存在book里的。有没有点类似于我们的PDF的这个plus的这个不是叫这个名字，就我们用的这个库，PDF解析库里面不是有个meta data吗？其实我们也可以去扩展成meta data，而不只是存一个PDF的path，对吧？
	这儿其实是也给大家留了足够的空间，包括我们的导出文件的文件名，也可以去做设置，我们现在比较粗糙，就是直接在它原来的输入文件的文件名上面加一个下划线，加translated的。然后如果你输出的是不同的文件格式，再给它调整一下不同的文件格式。因为输入的一定是PDF，对吧？然后把这两个都通过logger打出来，待会我们也可以简单看一下logo，然后info级别的日志，输出这个文件路径，然后输就是输入的这个文件路径和输出的这个文件路径，然后开始翻译，巴拉巴拉。然后这儿我们就可以实际的开始看一看这里的这个地方大家可以看到，还是通过wace来进行打开一个新的空文件output file，就一点一点写进去，这个应该就不用细展开了，对吧？首先这里有一个小小的判断，就我们我不知道大家还记不记得刚刚有个translation的时候要返回一个status。
	我们默认如果它status是true的时候，我们现在设定是它就翻译成功的。但有可能它里面实际内容翻译的不够好啊，但它只要给了我们结果大模型，那就认为他翻译成功了。我们就把它直接输入到这个markdown文件里，并且加一些换行服务。然后如果它是false，那说明你连那个大语言模型都没有顺利返回结果，那就跳过它，先跳过它。好，如果是一个表格的话，那通过这个方式可以组合成一个markdown的表格。Markdown表格的形式大家应该用过的都知道，我这边就不再赘述了。
	表头就是通过这个竖线来区分的表头通过这儿table columns为什么要用data frame对吧？就这取表头各种都很方便，然后把这个黑的弄出来，然后表头和内容之间会有一行通过这个竖线加短横线去做分隔的一行内容。我给大家打开一个楼眼就明白了。我看一下我们的这个read me，这个read me没有整个项目都有，就比如说这个对吧？我们的这个课程的这个schedule就是一个典型。通过这个date，然后description cos然后中间是一个分隔行，下面就是对应的这个就模拟的这个表格里面的这个竖线分隔符。大家如果不了解markdown语法的可以回头再看看。
	然后把这个构造出来，然后body就是表格里面的内容，然后一个单元格一个单元往里填，最终就构造出一个markdown的表格OK，这个是markdown导出的一个方法，最终就把这个输出输完。然后这里有一个点是说mark down它本身不像PDF是一页一页的，所以增加了一个这个玩意儿，就加一个换页的这个OK，然后怎么输出PDF对吧？输出PDF相对来说导出PDF文件相对来说麻烦一点。有一些简单的点。第一个就是说因为我们是把英文翻译成中文，所以会引入一个字体文件。这个字体文件在代码库里已经有了自包含的，大家就不用再去额外下载了。但如果你想扩展成不同的字体，那请你更换这一行代码。这里注册一个中文的字体文件叫Simon。这就很也是挺常见的字体。然后包括这个字体的字号，然后一些简单的格式，巴拉巴拉的这都定义好了。
	这个是创建一个PDF的一个标准套路，就包括这里给他输入一些page size，就这边有定义的，然后包括它的输出的这个路径，我们跟刚刚那一样，就换成那新加一个后缀，文件名的格式文件格式是一样的，就文件名加一个后缀。对，然后在这儿会略有不同的，在于还是在表格这里。首先文本类的，同样的我们去取这个content的这个translation就是文本。然后要通过这个，大家还记得我们这个解析的时候要构造每个配置，那这儿也是一样的，它是通过paragraph，这个paragraph简单一句话理解就是通过paragraph是我们的那个解析库的配置的一个有点逆向的过程，大家能理解，相当于我现在要重新构造出一个配置。
	那这个配置里面加字体的时候，开始不就有同学问，加加文本的时候怎么去弄字体，用弄字号弄颜色，就在这儿，在这个parp里面，大家如果有兴趣可以去研究，然后就往里面加。然后如果是表格的话，需要通过这个去设置一些表格的信息。包括它的这个background text corner对齐方式，这个字体，然后字号等等等等，包括它的pending，这儿我就不再展开了，然后构造出这样的一个table，然后把它加进来。然后这个story就有点类似，写过前端的同学可能也大概理解。就把这个都加到那一页里，然后这一页就变成了完整的我们的那个PDF文件里面的一。然后这两种导出方式就使得我们可以去把翻译好的这个内容，通过我们的writer导出成一个PDF的文件格式，或者说是一个markdown的文件格式。对OK。然后到这儿应该就把我们这个项目的整个实现都讲完了，然后核心还是回到这张图，我们还有个log再给大家看一眼。
	这个logo在我们的工具这个模具下面，实现的方式也很简单。首先这个库是python蛮常用的一个日志的库叫logo。然后它能够其实它就在标准的这个python原生的这个logo上面做了一些简单的扩展。
	我们在这儿是怎么做的呢？第一，我们首先这个logging是可以自己去做一个运行的当入口文件，去测试一下它的样式，有日志的样式。然后它会打印出不同的日志样式，不同级别的第八个级别的infor warning。
	然后这个class logger本身它是实现了什么呢？第一，它能够实现滚动日志，就简单的这个事情，当然也都是原生的python就支持的它能实现滚动的日志。比如说这里实现了一个rotation name是凌晨两点。如果我把这个东西变成一个网络，变成一个服务化的东西，就我们2.0的版本，那它就会一直运行，对吧？那你可能会时不时的给它丢一个PDF文件。那你不用担心这个日志会每天的凌晨两点变成一个新的日志文件，然后自己截断，然后它的日志会放在这个目录下。
	我们这边也有定义，在这个logs下面会生成这个log，然后名字是这个translation，再加上一些时间。然后这个logo本身是可以加一些标准输出的这个格式和样式的。我们这里用了默认的一些样式，这一行是用来设置这个日志的级别的。
	就比如说我把这个debug设置为true的时候他会是输出debug这个级别的信息的，他还在开发阶段。但如果我们把它变成一个服务化的一个正式上线的东西，那可以把这个debug设置为POS，那么像debug这个级别的日志就不会打印了。这个时候我们在代码当中去设置日志级别的时候，就要注意什么样的日志是给用户看的，什么样的日志是给开发者看的。通过这个就比较好去实现了。然后我们在这儿定义了一个全局变量log，这样我们就可以在任意的python文件里面去导入这个log，然后去直接输出这样的一个实现方式。大家可以看到在这import的这个log，那我们其他的地方就都能用这个log了，比如说我们这个writer里面就用了这个log。对，故意用这个全局变量，大家就比较好理解了。好，那到这儿我们就可以实际的把这个代码就差不多讲完了，看看大家还有没有什么问题。
	在哪里麻烦？有什么问题？
	大家可以现在提问。有同学问，不跑一下吗？可以跑一下，等一下我去拿水了。
	大家有什么问题吗？我们重点提问。这个跑随时都能跑的，拉下来也能跑。对。
	我们看一下怎么运行，这边有写。
	看我们没有，正好这些大家都能看得到。我们实际下载下来可能很多人都会遇到问题。第一，我们python这个AI translator main点PI文件没有指定这个model type是吧？那么他会告诉你这个model type是一个必要的，必须要指定的。好，我们指定一下。
	大家可以看到这个日志输出，我把这个就跳上去了。正在翻译完了看见没？这个日志里面跟我们之前那个逻辑很像，这个debug的颜色要跟这个info的颜色是比较好区分的。然后这个日志的format是这样的，就是这里是执行的时间日志的级别。然后当前输出它的这个位置，在这个代码里面的位置，比如说translator的PDF，powler的pass PDF，这个46行里面的这个role text，这row text，包括我们的这个table，然后这是我们的prompt，对吧？然后测试数据find the translation，然后这是我们的table prompt翻译的这个结果debug的信息就是set translation了。最后我们有一个writer的输出，因为我们刚刚默认是输出这个markdown对吧，然后有这个PDF的path，开始翻译，翻译完成OK可以搂眼，这应该是输出到test目录下面的test translate ted。就这个，对，就这个我们给他。
	还没出问题了，这个就没翻译对是吧？所以我没有保证说这个prom能完全搞对的。3.5不行，4.0好像这个地方他能理解正确。所以期待大家把这个这一定要设置的很有意思，我们才能看到不同的测试结果。回头我会传一些这个PDF到我们的项目里面来，然后作为这个实战作业二的考题，但优先看大家的这个结果。
	对，所以看看大家还有什么问题。就今天我们要讲的这个实战核心，一定要把刚刚那个三步走三个环节整明白，然后是一个环对吧？从PDF来然后把它解析对，然后解析对之后有我们定义好了一个抽象叫book，塞到book里。然后把这个不同的内容构造出prompt交给大模型。大模型翻译完了之后塞回对应的content，content再写回文件里，就这么一个循环，这个循环里面有很多的工作都可以去做这个扩展。包括是不是要一开始就把这个content的分类这个prompt，怎么样给system role设置一些很好的prompt等等。
	作业的deadline是什么时候？作业deadline好像我记得班主任给了个时间，大家以班主任为准。好像群里有说，我记得是两周还是什么的。对，反正不对，是有deadline的哟。因为它涉及到评奖的，所以大家还是要关注一下班主任应该会给一个时间。对。
	有个同学好像一直在问这个大模型的问题，这个大模型chat GM6B肯定跟GPT3.5和GPT4还是有差距的。然后我记得第一节课就有写就有写这个叫啥来着？咱们说的这个hugging face有一个open LLM的benchmark，我们在生态篇也会去讲，就是大模型的一个天绑。对，然后还有同学问这个字体格式的文件路径有没有问题？没有问题，这不是吗？在这儿，这我不过它不好渲染，这有一个字体文件的对。
	好问题，这个问题首先它肯定是对的。然后你说面点PY和它的这个路径什么的，你研究把代码整整的再再细点，你会发现有一些有意思的东西对。
	大家还有什么问题吗？怎么都沉默了？这个实战课的问题。
	有个同学说的很好，使用大模型要有架构和产品的思维。对的，一定要把顶层设计做好。所以今天的那个PPT就是把这个三个阶段怎么去的，怎么回来的，给大家花了很长时间讲，也是希望这么弄，也是希望大家能理解对。老师一定要把如何生成这个项目的prom的整理一下。这个我再强调一下，就是我整理出来了，大家一定还会有N个问题的。这是一个套路和思维方式。对，甚至我下次再生成一个类似这样的项目，可能都不一定用同样的prompt了。因为GPT4已经迭代了几个月了。
	而且最关键的事情是，咱们如我没有生成它的这种套路和系统性的技巧，你都不一定知道哪一部分它生成的不好，因为你是在不断跟他对话优化它。
	我们还有七分钟的时间，看看大家有什么问题。Prompt都在哪些环节使用？只是翻译部分。这个同学问的问题还挺好的。我再解释一下，就是大模型的能力是需要我们去挖掘的，你可以只把它用在翻译部分，但正如我刚刚讲的，你也可以把它用在文本和表格的识别处理上。对，就是你把它用的越强，你就能省越多的事儿。这个区别就在于是你去学那一堆的代码怎么写，还是你描述清楚你要什么东西，就你描述清楚你要写一堆什么样的代码，让它来帮你写，或者说用它来帮你处理这个数据。因为你写代码也是完成一定的任务，你把你要完成什么任务，输入输出怎么样去完成这个任务，我比较复杂，就拆成多个步骤，把这个东西给他说明白了，那么一定是用它来做会更好一点。
	能券的框架是用来简化大模型的API吗？能简化这份代码吗？第一，能券的框架不用来简化大模型的API的大模型的API已经够简化了。我们两节课就讲完了，一个是chat API1个是completion API这俩未来都没有completion API了，只有chat API了，对吧？然后第二个可能你要硬算的话，还会有个embedding的模型，那也算是一个API就这俩API了，所以现在不用再简化了。
	大模型简化的是跟上一个问题相关的，prompt用在哪些环节？Prompt可以用在任意环节，从逻辑上来说，那是在任意环节用的时候怎么样管理，怎么样把它的模型输入输出抽象好，这个是南茜的主要工作。这份代码一定是可以用南茜的优化的，但是南茜优化的应该是大家交出来的实战作业二的代码。实战作业一的代码是留下了一堆的可扩展东西，这可扩展的这个空间给到大家的，然后大家一定会写出一堆代码。就是为什么要在这个环节这个节点做这个实战，就是让大家先动手做一遍南茜，尝试想要解决的一些问题。然后大家现在这个小的case上面去自己动手做一做，然后接着再来讲南茜的这些概念和抽象，大家就更有感觉一些了。
	还有一个同学问，java和python调用OpenAI的API的时候有差别吗？这个我不好说，但是你看上一节课的function calling，我们没有用OpenAI的python ASDK，我们是直接用的request这个库，所以从这个角度来说，他们都是调的HTTP那个请求。而且就算你用的OpenAI的那个python的SDK，它也是调的request，所以不应该有什么差别才对。就是从API的调用上，这俩语言应该是没有什么差别的。
	Python能连上java老师，其实超时有没有可能是proxy出了问题？翻译的时候会对句子分词，分词不一样翻译出的效果也不一样。大模型目前怎么分词的，老师可以讲讲吗？请左转回到理论课，大模型怎么分词？请左转回到理论课。
	国内开源的大模型哪个好用不做评价。这个这个评论太危险了。大家看公开数据和评价吧。
	老师如果要把翻译后的中文和表格还原成原来英文的版面格式，是不是需要把解析PDF时，原来的PDF的所有的原数据都抽取缓存下来，按原来的原数据一步一步还原。这里我可以这个问题提的很好，我稍微讲一下。首先不用所有东西都存下来，就是你想一下布局是什么？布局是一个很说简单句简单，你要往难了去想，有很难的这个布局的，就比如说芬兰，就是大家见过那种布局吗？就是我可以这一页里面就跟你看的所有的r cap上面论文一样。我这一页我中间给你来一个横杠，然后这一页就被一刀两断了。左边是一列，左边是一页，右边是一页。那这个左边一页右边一页对于代码来写还是挺痛苦的对吧？你需要把你的配置变成了一个左页和右页，甚至还有分三栏的那更变态对吧？
	那这个时候关心关键点在哪儿呢？我们先考虑不分栏的场景，部分栏的场景里面图表格文怎么处理。核心还是坐标和顺序的问题。就是你需要知道那一页里的文本和表格是什么样的关系。比如说有几段的文本表格是塞在中间的那表格是塞在哪一段文本的中间，这个还蛮关键的。然后你只要按照那个顺序去输出应该就可以了。
	我们也不考虑翻译出来之后一页装不下的情况，那这个时候你只要把表格塞回到那两段中间就可以了，所以关键是找那个插入位置，这个是最简单的恢复布局的方式。稍微恢复的好一点，就是说我不仅把那个表格塞回原来的位置了，甚至跟原文的那那个相对位置都是一样的。就说明我还适应了比如说行间距什么的，保证我原来一页的图在正中。我翻译之后没有因为翻译的那个原因导致什么上面那一段文字变多了，下面这段文字变少了，那这个图的位置就变到下面来了。这些东西都是在布局层面上可以无限去往深处去想的，就看你要做到那个布局还原度有多高了。
	怎么评估翻译的质量非常好的问题，目前来看的话，只有你的客户能评估。现在我们这个课程的客户就是助教的老师，还有我们的这个教研组的老师们。Prompt是控制输出结果的方式吗？Prompt是跟大语言模型交流的方式。
	优秀获奖者的代码可以看到吗？这个应该是可以看到的。我觉得这个肯定是大家提交到github上面，然后我们还得找个方式给所有人都分享。
	大模型的并发吞吐能力有多高？这是在拷问OpenAI，这个之前几节课也有的，大家去看一看OPI官网吧都有给并发的指标的对，最后三个问题。
	对，康明老师很专业的，大家在群里和直播这个问题回答上，大家应该都能感受得到。
	老师刚才说的两个方法，few shot和联网，自己学习是用来做什么？没听明白。这个是有的同学在问，就是怎么生成代码，尤其是怎么基于一个特定的代码库来生成使用这个代码库的代码的时候。回答的两个方法就是few shot，让他去学这个代码库的一些shot，或者是这个联网让他自己去查资料。
	最后两个问题。
	请问老师如果有2个PDF里面有重复的内容，翻译完一个PDF后再翻译第2个PDF的时候，如何继承第一个PDF重复内容的翻译，节约GPT token特别好的问题，用这个时候适合用向量数据库了，然后这个向量数据库怎么用呢？第一，首先你如果要复用，你就不能在一整页丢给他了，对吧？这个一整页都对他复用的几率很低。因为有可能你这个排版不一样，就导致你一些错位。错位之后这个in bedding结果就肯定差很远了，也不一定看你这个内容。
	那比较好的方式是以比较固定的文本长度，或者是一段一段的文本来切割。切割之后你去调这个翻译，然后把把这个要翻译的内容本身，你也可以给它存到向量数据库里。然后你在下一次别的PDF要翻译的时候，你先去看看向量数据库里有没有这一段落的文本跟他是比较像的那如果有的话，你看这个时候为什么要专门设计一个content的抽象。因为你可以把原来的这个内容和你要翻译的这个内容以一个比较好的方式映射的关系存下来。这个时候你就去调用你向量数据库里已经有的这一段待翻译文本的这个内容。然后找到它的翻译后的结果，取出来就直接可以丢过去了。那这样就不用去找大模型去做翻译了。
	这个同学说的挺好的，评价翻译的好坏，可以翻译之后再翻译到原文做比较。对的，这个肯定可以的，只是稍微贵了点。但其实还好，大家调用token成本没那么高的。
	后面会有向量数据库的实战吗？会有类似于现在我们这样的demo，但不会深入展开向量数据库，因为那又是一个大的命题对。老师模型抽象能力如何提高？这个我其实没有特别看懂。是你要find tone一个模型，把这个模型的抽象能力提高吗？最后再找一个问题，看看大家有什么问题。
	可以先把PDF转成markdown吗？当然可以，但是你都能把PDF转成markdown了，你不都已经到pyy内存里了吗？你干嘛还要再去解析一遍markdown呢？
	老师，头发为什么这么多？老师无法回答。对。
	好，那我们今天就到这儿。然后大家如果还有什么问题，我们可以群里再交流。好，谢谢大家，我们先到这儿了。