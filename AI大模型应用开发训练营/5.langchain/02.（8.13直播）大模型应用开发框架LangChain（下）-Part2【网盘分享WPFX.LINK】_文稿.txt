	好，我们讲agent。那到agent这一部分其实就更有意思了。Agent是一个更灵活的东西。我们看到这幅图里面目前要补全的这个部分就在agent。Agent还在这幅相对来说有点早了。这一两个月前有人画的这样一个抽象，我觉得挺好画的挺好的。这其中关于这个agent它里面放了两个，一个叫two k一个叫agent execute。我们待会儿再具体讲年券agent模块设计的时候，会跟大家细讲一下。
	但简单来说agent要解决的问题，它被设计出来要解决的问题就是说我们一个复杂的应用要怎么样去做设计。通过agent是一个比较好的实现方案，它是用来构建很复杂应用的一种系统。那么具体这个agent的实现，这个应该叫什么？缘起何处？就它是怎么想到这的？为什么要做这么一个东西，跟这篇文章很有关系。
	就有一篇文章叫react，跟这个前端的框架那个react不是一回事。这个react就是一个我们所有这个课程同学应该听的理论部分都知道，这个技术的发展有很多套路。其中一种套路就是三个臭皮匠顶个诸葛亮的套路。
	这个也是一样的，我们在讲chaf source的时候，就讲思维链的时候，包括self consistency的时候都有提。通过思维链可以去把一些复杂问题拆解成小问题。小问题通过大语言模型，小问题他能想明白，就复杂问题拆成小问问题，小问题他能推理明白。就比如说我们当时举的例子，不管是这个拿铁和这个美式咖啡还剩几杯，还是说我的妹妹比我小三岁，我这个70岁她多少岁，类似于这些问题。这个chain of source这个东西思维链这一类型的操作也好，这个prom的技巧也好，都被这篇文章归结为一种叫做reason only，就只做推理的这样的一种操作模式。
	还有一类是什么叫act only，就我不去做复杂推理，这里有一个项目叫web GPT，我不知道大家听过没有？这其实是一个OpenAI发布的官方发布的一个网页，大家可以去搜索一下。然后是21年的时候发布的，就那会儿ChatGPT没出来，GPT3.5也没出来，tex w7003都没出来。
	Web GPT干什么呢？他就是做了一个网站，这个网站能通过语言模型帮你去做一些简单的操作。然后简单来说，act only就是我构造了一个语言模型和环境的这么一个交互的这么一个模式。然后语言模型会给环境一些操作，比如说生成文本，比如说调一些API。现在把它扩展这个概念扩展开来的话，调一些API联网都属于这个f only。
	这个环境会有一些结果，回到语言模型这边来，就变成有这个环也很像这个强化学习的一个环。但它本身这个环里面的语言模型是不会像强化学习的这个模型一样，参数不会去做调整的。他只是以这样的一个方式在进行运作，能够跟环境去交互了，不再是一个死的模型。然后只能通过from的引导去做深度思考，而是能跟环境交互，能去去对接外部的API了。
	但是这两个都有他们的缺点，所以一个直观想法就是能不能把这个reasoning，把推理能力和这个action这个操作的能力结合起来，变成右边这个形态。就是我内部能推理，外部还能够去调用。甚至我内部推理是在像我应该用哪种方式去跟外部环境交互，相当于把我们一直讲的这个大脑跟四肢给补全了。就是这个reasoning、这个推理能力、这个推理路径这种chain of sorts的方式，就是大脑我们分分步骤去思考问题，那这样我就有深度思考的能力，我有action，我就能够跟外部的各种API平台去做连接。通过这两者做成一个react这样的一种agent的。但是那会儿它不叫agent，做成这样一种模式。
	那这种模式可以使得我们的大元模型的能力进一步给扩大，怎么扩大呢？第一个就是我们看这个是论文当中给的一个表格，然后standard的这个IO这个已经看过读过不少论文的同学都应该很常见了。就标准的一个输入，就相当于没有做各种连chaf source都没做的。
	我们讲chef salt这篇论文的时候，就已经看过这样的一个表述方式了。最最标准大家可以认为是这个GPT用户的小白用户的输入，甚至可能比那个还好一点。然后第二就是这个chaf sorts叫reason only，我们用了思维链的。然后第三个就是act only，我没有用思维链，我不会引导他think step by step，或者去用一些别的chill source的一些技巧。不会有不告诉他这些东西，也没有feel short learning。
	最后这个是这篇论文提出来的最好的react的一个方法。然后我们能看到这里有一个什么呢？就是有不同的基准测试，这个hot pot QA就是一个问答的测试。然后fever就是有一些假的一些信息在里面的一些测试。然后这里面给了这个6 shot，就是指给他一些full shot参考，然后依次有不同的校舍的递减，针对不同的基准测试。那从这个结果单纯来看，react这个方法是好的。
	这篇文章也有一些，这个也不是最近这几个月发的，是有一些这个年份了然后这个方法出来之后，我们拆解一下这个方法，它的直观设计动机是符合人的直觉的。然后他的从这个实验结果来看，也是符合我们的预期的。就它更好了，更强了，在这几个基准测试上都是如此。他具体的做法其实就是把我们的这个我找一个我们已经学过的概念。就在我们学这个function calling的时候，其实跟这个react是一个很类似的一种设计思路，甚至我们可以说是等价的这个agent的这个execute。
	那么function calling大家回想一下，我们当时做过这个ChatGPT的plug in的black in里面。我们当时做了一个最简单的function coding的设定。就是写两个函数的描述，这两个函数的功能是什么，需要什么样的入参。然后用我们的大语言模型来判断什么时候该去调用这些函数，然后如果他判断不需要调用的时候，我就是陪聊，我就只跟你聊天，不去调这些外部函数。大家仔细回想一下，这个模式其实跟react想要做的事情是一样的，就是function calling这种范式和react这种范式其实本质是一回事，就是大语言模型来判断我的action什么时候应该去做，然后大语言模型怎么样判断呢？他肯定得就是我们很多同学都在问，到底我这个大语言模型是怎么判断我该不该调用的？是我这个description要写的足够好吗？就是从我们人设计的这个视角来看，就是有两块可以去让他更准确的去判断。
	一块是我这个function描述足够的好啊，第二块就是这个方程描述这个问题，拆解本身也是可以分成几步，每一步都可以去匹配一些function，甚至每一步里面这个问题解决的这个路径，在这个react from就是我们react本身也有一种特定的prompt。在他的这个设计里面，他提出一个概念叫feel short。这个task serving的这个路径，你可以理解成就是我们去让这个react去这种模式去学的时候，也可以给几个参考示例。然后这个参考示例里面甚至还会不只是有一个简单的问结果，问结果还会有路径，就这个问题需要被解决的一个路径。那个路径里面甚至包含了函数，包括这个环境里面的一些反馈，这个其实是把prom的设计的更复杂了，对吧？感觉起来。但是这些更复杂的东西如果被一个框架实现了，你看不见了，那其实就很方便了，就这些复杂的问题交给框架了。然后你这样做的事情，其实就真的只是把那个描述写清楚，甚至那个描述你都不用写。因为你要描述的那些函数，那些被你去扩的这些方向，都已经被他预先实现好了。那么南线的age其实就是在干这么个事儿。
	这稍微花了一些时间去解释，他在获取一些新数据方面有优势，这个是他做的一个对比测试，问了一个问题，这个问题的答案用standard IO是错的，用这个只用推理也是错的，只用这个action也是错的，然后用react是对的，因为他去连接了一些外部数据，做了推理，做了各种事情，去做了搜索。那么这个论文当中示例比较尴尬，看不看不太清楚，我就给大家实际一个示例。就最近刚刚结束的这个大运会，我们都知道今年大运会举办地是在成都。那么在南泉里面其实就两三行代码就能实现。
	刚刚我们论文里看见的这个react，它有一个预定义好的这个agent，那么我们待会儿也会实际跑这个例子，这个react的这是使用react的方式对吧？那下面这一行的这个LLM其实就是一个人人only，甚至都不是人人only，我们都可以把它理解成是一个standard IO直接用大元模型去问他不知道这个信息，因为他是无法去获取外部信息的，没法搜索。他可能在他的信息里面有一个奥运会是在东京举办的。我印象中应该是20年左右还是哪一年的奥运会是在东京举办，最近一届，所以他回答说一个这个。这他也尽力了。但是用这个react的方法最好的好处是说他去做了这个搜索，所以搜索完之后，把这个搜索的结果给到了我们最终的这个答案里面，这里有一个概念叫做agent execution in。我们待会回去细看一下，给大家理解这个能圈的设计。
	React在微调方面也有一些优势，就是我们把这个react的这种套路拿去做反特。它有两个维度，一个是说在各种相同规模的这个模型里面它的翻译成效果最好。第二个就是说我们经常会有这个扳手腕不同重量级对吧？他这个小小规模的这个模型，比如说我们能看到这里红色的这个部分。这里是有一个8B，这个是他用的基础模型的大小，这里有一个62B他是想说这个standard IO在62B这个差了一个数据量级上面，我的这个react也超过它了。当然这个地方的比较我们不去做进一步评价。因为本身这个62B的基础模型也许就就在那个特定问题上做的不够好。这个大家看一看就好了。
	我们实际从直观感受上面去理解，最大的一个好处是跟外部的平台去做了对接，然后最最能体会到这个体感上的变化，就是连接了更新的数据。就我们刚刚举的这个例子，他知道这个刚刚发生的事情，通过搜索引擎也好，通过一些别的第三方平台也好，把这些能力嫁接进来了对。那么在南泉的agents里面，我们看到右边这张图它是怎么实现的。有一些比较重要的抽象，我们已经学过了，在这个nation里面的这个chain是什么东西，比如说这个sequential chain和这个router chain。为什么讲只有券的话是硬编码呢？我们知道在上一次课里面，我们的router chain，它实现了这个语言模板，对吧？它实现了from template的这个模板，就是模板的模板。然后在模板的模板里面，可以去把一些我们要用来做条件判断的内容埋进去。然后通过两次的解包，最终才把真实运行的结果传进去。
	但这种方式特别像我如果我们对比现在学习的这些编程语言的话，它特别像是一个面向过程的这么一个方式。就是它是按照你的既定的这个顺序去执行，按照你既定的条件判断去执行。因为我们最终做的那个事例，我让大家可选的一个作业，就是最外层套了一个sequent圈，然后里面有transform的这个券，然后有root的券，后面接了不同的2个LM券。大家如果还有印象的话，那这个很面向过程对吧？没法根据我的实际梳理入实际生成的结果和上下文来动态的做判断，所以我们把这个东西理解成硬编码，是从这个视角来看的，因为他失去了大语言模型的灵活性。
	从agent的这个设计原理和它的设计目标来说，还要解决的就是怎么样把大语言模型的优势给放大。让语言模型能够去判断也好，去调用也好。这就是我们在在这幅图里面想要进一步跟大家去让大家好好理解的这个agent的一个设计核心的一个思想。
	下面这幅图我们简单做一个拆解，左边这个user input就是用户的输入，然后我们的这个completion其实是大于模型生成的结果context是上下文对吧？这三个基本可以表达一个大语言模型应用的一个范式了或者说它的这个内涵了。因为用户输入你可以做各种处理，最终变成prom，你也可以跟你的prom template去做结合。这个prom template可能放在context里面，然后completion是它的一些生成结果，历史的生成结果，或者说message，这三类就几几乎包含了我们一个单元模型的输入内容了。中间这一部分这个绿色框框里面的是这个agent这个抽象，就是里面这个agent这个模块的抽象，它包含了三部分。第一部分是大语言模型，它的底层依然是大语言模型来驱动的。
	驱动单元模型需要提示词对吧？需要提示词模板，这俩加起来就像是一个LM chain了，大家如果熟悉这个人券的这个机制的话，那么这个简单的券构成了这个agent的驱动就是有这个驱动之后，这个agent知道我要干的事是什么了，他要干什么事呢？他要去选我到底要用要首先他要去做一个二分类去选，我要不要用这个工具，或者说我要不要去调一个函数，还是我就是跟他聊就完了。我都不涉及到下面的各种各样的工具，我就只是跟他来来回回聊就好了，这是一种情况。那假设我现在判断出来我需要去用工具，需要去调一些特定的函数了，那怎么样去判断的对吧？这个地方我们再再拆解一下，大家可以在自己脑子里面去模拟一下捋这个过程。现在我们判断了不是要跟他聊天，而是在这个阶段用户的输入就是要去调一个特定的工具。
	假设这是这里的工具一，那这个工具有两种方式，一种是我们去自己实现的，就比如说我们在实现这个天气查询的时候，我们实现了调第三方的API，我们在做这个circle的这个语句生成的时候，我们去调了这个circle的实际的去执行它的一个特定的那还有一种方式是框架帮你预定好的，就比如说这有一个two kids其实就干这事了，我这个框架已经提前实现好了，不用你去实现了，因为它很常用。就比如说联网的查询，去连这个谷歌的搜索引擎就很常见，非常实用。那它就被框架提前实现好，你只需要去指定清楚你是要用它就好了，甚至这个指定的方式都是由框架来帮你去写清楚的，你都不用写那个description，这个是一种方式。
	这里其实刚刚聊的是这个被调用的这些工具和函数是怎么样去实现的。有两种，一种是框架实现的，一种是你来实现。但是我们刚刚还聊到一个关键点，在于要用大语言模型来判断该不该用你那该不该用你呢？我们之前写这个function calling的时候，是通过description，通过需要哪些使用场景，它的输入参数，这也对描述来进行描述的那这种方式其实就是OpenAI的functions，就我们已经做过的一个操作。
	我们在学这个opening function call的时候，其实就已经干过这事了。大家回想一下，用一个压mail去表达。我们现在对于ChatGPT的plug in来说，就是写一个压mail来表达我的这个插件到底有哪些功能。如果是这个open I的chat，API的function calling，那就是通过一个特定的字符串的方式去表达我这个方选到底有什么功能。这个相当于是我们手动的在写prompting的这个strategy，就是我的这个提示词的策略。大家还记得我们刚刚有去了解react的这个实现思路的时候，它里面有一个叫做react这个prompt你可以简单理解，其实就是一个策略。
	再再把它往底层理解，其实也就是一堆提示词。这堆提示词它有它的特定的设计目标，它的设计目标就是用来给我们的大语言模型去判断我后面有多少个工具可以调用，我在什么样的场景下去调用它。然后这个提示词的写法就会有不同。比如说OpenAI的function call是一种写法，ChatGPT的plug in是一种写法，那react也是一种写法。并且react这个论文没有明确像这个open AAI1样给你说应该明确怎么写，它提供了一个思路。
	那为什么说南倩是基于react实现的呢？就这个话是不准确的。应该说南倩实现了react这个论文当中的这个思想，然后这个思想的载体是一种类型的agent，这样是一个比较完整的描述。而这个react的这个实现方式上本来就有多种。所以大家在南线的agent的类型里面就会看见有什么zero shot的这种react，还会有别的react，这些都是大家去实际操作之后会有更深的体验。
	包括我们刚刚看到这个，我需要先去联网查一个内容，然后针对我联网查询的结果，我返回一个内容给到你。而不是我通过大语言模型已经训练好的语料来给你反馈知识，是要跟互联网上的知识去做结合的那这个也有一种特定的预定义的类型，就叫做self ask research。也是我们待会会去实际操作的一个实战案例。
	具体这个agent刚刚描述了这几个关键模块了，对吧？它是预定义的大模型驱动的，然后它有各种各样的实现的类型。然后这些类型有的是OpenAI已经实现了，有的是他自己实现的，有的是大家可以再去做贡献的。然后在这个实现的背后，核心还是在于语言模型本身的能力有限，需要去对接外部的工具。那么外部的工具也可以是你去实现的，或者说框架已经实现好的。那框架实现好的在他的tools列表里面就已经给出来了。如果你要去实现，你就把它描述清楚，按照他的agent的类型要求去描述清楚。
	这个事儿我们也干过几次了，只是说不是以年轻的方式来做的。最终这个agent它要变成一个可以运行的东西，对吧？我们刚刚都讲的是静态的定义，它变成可以运行的东西就有一个运行时。这个运行时在南区里面叫做agent execute，就是它的这个agent的一个运行时。这个运行时要干的这个伪代码，其实就上面干的这个事，简单来说就是这样一个伪代码。
	这个伪代码的逻辑是跟我刚才描述一样，我现在这个大语言模型的应用里面有一个agent这个代理需要去获取一下我接下来要做什么样的操作，它就叫做next action。就下一个操作是什么？大家如果看得懂这个代码，应该也不用我再反复讲。首先拿到这个操作之后，因为操作本身就会有两种，这个很像图灵机的最典型的设计，这个操作有两种，一种是我直接就停下来不干活了，它是一个特定的标志叫agent finish。我现在拿的这个下一个操作是停止干活，就今天就下班了。
	如果他不是今天要下班的这个agent finish的操作的话，他就会去执行这个操作，对吧？那怎么样去执行呢？其实就是run这边的two，就跟我们去调天气平台的API去执行这个circle的指令一样。
	然后执行完之后有个结果，这个结果叫observation，就我们执行完了一个操作会有一个结果。就是我们看刚刚那篇论文里面，他在跟环境交互之后会有个observation。这个结果会给到我们大家可以看到这给到我们下一次操作，就我们这儿写到有一个结果，对吧？就是大家看鼠标这应该能看到这有个agent get action，然后next action和这个observation。那么这个结果就像是我们左边这个输入里面的一部分，completion是不是我们的结果，对吧？Context里面可能也有我们的结果，甚至memory里面的结果，这些东西都会重新用来判断下一个action是什么。下一个action如果不是停止的，就循环这个过程，一直到我停下来。
	这个是最典型的national的一个agent的一个run time。除了这个以外，还支持一些别的，比如说在这个plan and exit这个agent，这是另一种思考方式，或者说你可以理解成这个代理也可以设计成不同的伪代码，对吧？这就是大家看这个模式，就是我不断的去查我的下一个操作是不是应该停止了。如果没有停止，我就继续去用我的大元模型判断接下来该干什么活。基于我的这个输入和当前的这个操作。
	还有一种方式就是像plan excute agent，他他是说我拿到一个问题，就比如说我有一个用户，我去问这个agent一个问题agent。先去做规划，然后再去做执行。而不是像这儿我们每做一步看一步，做一步看一步。这个是先做完规划，规划好之后，按照这个规划的结果去执行一遍，这是两种execute，两种运行时的方式。除此以外，像我们前面看到order GPT也是一种，ABAGI也是有这些东西都是最终去维护这个agent实际执行的这个操作。
	大家可以理解成前面我们讲的这一页，就是这一页是在讲单个的agent针对一个特定的一次逻辑需要怎么样去操作。有输入有不同的策略，然后有不同的这个to可以去选。然后基于我现在使用的大语言模型和提示词，我能做出一个判断，我现在应该用哪个to来执行，结果应该怎么样和我现有大元模型去做组装。实际运行起来之后，我每一步串起来之后，也会有很多种不同的方式，有的是做一步看一步，做一步，然后拿到一个结果。这个结果如果不是一个我满意的结果，不是结果，就和我现在做的这个操作，和我现在拿到结果一起给到agent去判断，agent去判断你现在该干嘛，这个就是一个比较典型的一个人权的实现方式。除了这个默认的以外，还会有别的一些实现方式，就跟我刚才讲的plan and excuse是另一种。
	实际要去做这个，我们刚才说这个茶大运会，看起来很fancy。因为实际上我们在拆这个T里面，现在都不能使用联网的功能，除非你使用插件。那现在我们让你能够用OpenAI的API加上联网的功能，就能够去做一个应用了。这就是一个很实在的一个实战。
	那这个时间要怎么做？第一要解决联网的问题。首先你得就首先你得知道你去连接一个搜索网站，他也一定是需要收费的，他也不是免费的，这种免费的事情是很少的，免费的事情一般也更贵，那么这种这种API网站也很多，这里选了其中一个用来支持谷歌搜索的API的一个平台，叫serve API。然后具体的这个实现跟我们调open API，调这个天气平台很像，它会有一个APIP，这个APIK你这个环境变量设置进去可以。然后我看最近有些同学遇到了环境变量各种问题，那么通过这样的方式也是可以的，就是直接import一个python的操作系统的模块，在这儿设置这个变量，它也是能用的。然后整个self ask research这个代码很短。
	大家看这个部分，其实对应着我们刚刚那幅图里面的，我们需要有一个大元模型作为agent的底层驱动。这里直接默认使用了这个语言模型里面的这个达芬奇003。然后他会作为我们这有一个叫做initial agent初始化一个agent的输入。除了输入这个单元模型之外，还需要输入一个tools的列表，对吧？就我们刚刚看到有一个tools的这个列表，在右边去选我们现在有哪些tools。
	现在给的这个tools只有一个是用来做搜索的，叫tool里面有一个预定义的这这个图我是从我们的南茜框架里引用进来的，导入的这个图里面就是相当于南茜提供哪些图，我们这都能直接用。那这一条就是导入了一个用来做搜索的，然后相当于这就相当于我们以前写过的一个function calling里面的function了。只不过现在是南茜写的，不是我们写的。框架预定义的，然后这你可以自己去调这个name和description，对，然后把它作为agent的另一个输入。
	第三就是说这个agent需要一个类型给它的类型叫做self of research，然后verb这个很熟悉了，就是打印的内容要不要多一点，然后同样使用rain方法。你看底层其实还是走的这个券。大家可以看这个输出，其实这个结果也是比较详细的给大家做个展开。首先他问什么是2023年大运会，是我们的这个问题的一个转换，我们一开始问的是这个举办地在哪？他这个self ask research这个agent要做的拆解，它就是一步一步拆解，并且在拆解过程当中把它简单理解成这个agent的实现。它的strategy就是我把我现在这个问题去做拆解，这是reason only的这个部分，就我们change of source的这个能力。
	然后他现在首先得理解这个问题是在问什么。然后他就会发现举办地现在还不是最要紧的问题，他还不懂什么叫2023年的大运会。这个有可能就是他现在的这个达芬奇003这个语料里没有的，实际上也没有超过他的训练时间了。他就问什么是这个？在拆解出这个问题之后，大语言模型判断这个答案是语料里没有的。就是这个大大的复杂问题的子问题的答案训练语料里没有，他就得去调搜索引擎。调搜索引擎之后，问了这个问题，相当于在谷歌上面搜了一下什么是202320大运会，然后拿到了一个中间答案，中间答案是这个英文的。
	2023年的这个大运会慢慢讲了一大堆。然后讲了一大堆之后，他才会去问2023年大运会的举办地在哪里，然后这里也收到一个结果，在东成都的这个大运会有点像是一个某一个社交平台上的，还带带了这个警告这个超话的这么一个内容，在哪里举行还知道了，是在成都。所以这个其实非常短的一个代码，但是实现了一个非常有用的功能，就是把我们的搜索引擎和我们的这个大约模型结合起来了。然后我们在这个案例里面可以自己再回头去试各种各样的问题，包括用不同的语言等等。
	第二个就是说我们有看到有一个react这种prompt的strategy，那他怎么怎么干的呢？其实也很简单，我们把这个问题抽象一下，就变成我们需要定义一个agent的类型和tools的列表。我们先不管语言模型的更换，就我们现在假设语言模型就固定下来，用同一个的话控制变量法，那么agent的类型是可以换的。有这个OpenAI的function，有self ask research，也有这个react，这都是人权。已经内置实现好的。
	那么这些东西定义好之后，就是候选的to有哪些吧？那我们得去看一下候选的tour列表，哪些是黏性框架就已经实现好的，哪些是需要我们针对我们的特定问题在自己去实现的。按照tools的要求就可以灌进去，就跟我们写function in是一样的。我们把这个react的这个toss列表，我们给了两个，一个还是搜索的能力很重要，你丢进来了。
	第二个就是数学计算的能力。因为本身这个是大语言模型的弱点，需要单独去作为一个工具去做查询，直接丢给单元模型去用的，它可能会出问题。那这儿我们可以看到代码里就导入了一个叫surf PI，一个叫LMS。这个就是我们从这个task里面加载进来的，这个跟刚刚那个代码略有不同，大家可以待会儿在实例里面去看一看，把大元模型传进来，就把这个two定义好了。这个task就是我们的这个agent可以选的这个工具集。那其实有等于我们在方向里面定义好的那个可以选择functions。然后我们也可以使用这个语言模型来提问，也可以使用这个聊天模型来提问。
	就是我们刚控制变量法的这个agent要用的那个单元模型。它也是支持用简单的model或者是chat model都可以，这个是年轻人自己可以去支持的。我们刚刚提到最关键的一个点就是模型可以换，然后我们的prompt的strategy也可以换。
	有三类了，刚才已经介绍了。我们的拓那实现了哪些？我们刚刚看到的google的这个super API，这个是我们今天实战用到的一个tools。然后包括这个大语言模型的数学计算的能力，大家都没有放在这儿。已经作为一个比较简单的一个功能。我们用的这个service serve API。对，然后其他的像直接寻求这个网页request，包括像这个AWS上面的这个lambda，上面的这个API的这个to API这个FI就是有各种各样的tour都已经被预实现好了。
	包括这个VCPDA，这些tools都是我们在刚刚看到去实例化一个agent。有一个agent的时候可以去选的。那么就跟我们这儿能看到，比如说我们要除了刚刚讲的这两个实战以外，大家也可以去试一试。比如说我们要去用纹身图跟大语言模型结合起来，已经有这个打理。就是我们在这能看到有一个打理e image generator，就使用OpenAI的这个纹身图的这个产品打理，可以用这个图，这里鼠标应该有能看到这有个dari e的一个image generator，通过这个load two就能加载进来，这个agent就能在合适的时候去做纹身图，然后去run的时候，比如说我们要create an image of hot llyw all night at哒哒哒哒哒。他看得懂这段话，其实是想要生成一张图片，就会去调用对应的这个to，那比如说这里还会有像什么hugin face的一些to，我们也可以通过这个方式去进行加载。然后包括我们的。
	刚才讲。
	的这个VKPDA，它也有对应的这个to可以去做实现。好，那我们就进入这个时代的这个环节，然后留一些时间给大家提问。首先是still ask research这个agent，这个agent第一步要解决的问题是注册一个账户。然后我待会儿会重新销毁掉的，就为了演示的这个方便，我们把这个留下来了。但大家拉下代码之后，这个应该就没法用了。
	然后这里我们这个第三方平台把这个链接放在这儿了，它是一个google search的一个API的一个平台，我们刚刚截图有看到，然后登录之后我们可以看到这里有使用量，它有一定的免费的使用量。我们能看到，放大一点，我们能看到这里有一个免费的使用量，这儿每个月有100次的一个免费使用量，当然你也可以去充钱，然后这个是APIP。如果我们刚刚看到这个notebook里面的这个APIK，你注册之后可以去生成一个APIT，它每个月有100次的免费调用，然后这也能看到你的这个调用量，每天调用了多少次，然后你的历史调用量，就比如说我从建这个账号到现在调了96次，当然它还会有这个API的一个详细文档。就是如果我们不用大于模型，直接去掉它的API也是可以的，就符合我们刚刚讲的这个直接去操作API平台。在线用单元模型最好的点就在于它能帮你判断什么时候该去调用，甚至帮你把调用结果和输入都去做处理，把它连接起来。在这儿也能看到的这个历史搜索的一个结果，在your search里面。
	稍微有点慢，在这儿对吧？我们能看到莱昂纳多的这个girl's friend就开始问到的，包括你是在什么样的地方提问的对，然后用的是什么样的输入query，问的是哪里等等。那么我们就回到这个例子里面来，我们还是重启一下。这个是第一点，就是我们在这个平台上面需要去注册一下。然后这个平台也是被广泛使用的一个谷歌搜索API平台，所以自然的在我们的这个能券里面做了对应的two，还有个API封装叫做service APIA rapper，然后这一个部分是解决对应外部的调用的问题。
	在内部的agent类型上面我们的南茜的agent模块里面已经实现了很多预制的agent类型，我们用的这个self ask research就是其中的一种。可以看到在。在这里我们能看到有这个agent type。除了我们的刚刚讲的react以外，react本身它会有两种，一种是这个zero shot，一种是这个structure的input，还有我们的OpenAI function，我们已经学会了，已经用过了。今天要讲的这个self ask research也是一种，然后他这边也有写一些要求，比如说如果你是一个订购two，还需要去被命名成这样的一个中间答案他才能找到。然后除此以外还有这个document store也是一种，那这儿就不再展开了，大家可以自己再去根据这个实际文档再去研究。
	我这边把这个附在这里，然后我们把这个APIT输入之后，按照他的要求，这里必须要intermediate answer作为这个to的名称，然后我们把这个A键的实例化变成了一个。Surf API的这个search，就这里我们刚刚调用的这个surf API实例化。然后PAPI的这个封装的实际化的一个run方法。这个方法作为这个intermedia answer的实际的函数。所以这个two最终会去调用它的run方法，对吧？然后我们再去实例化一个agent，然后输出一个结果。
	你看这个答案出现了问题，他把这个夏季世界大学生运动会答案找出来。这个其实是一个不稳定的结果，也是大家在实际使用的时候需要去处理的一个问题。但这一次课我们可能讲不了这么细了，大家理解成问题出现在哪儿呢？问题就出现在他去问2023年大运会的举办地在哪里的时候，他只取了其中的某一个结果，但是这个就跟我们用同样的prompt可能会拿到不一样的结果一样。我们可以再尝试运行一下，这个完全就比较随缘的去取决于。可能这个缩略的。
	会2023年. 
	的编辑大学生都下去。好像是对的，因为原计划的2023年的世界大学生运动会被推迟了。那我们可能应该不应该用这个年份来讲，因为这个大运会因为疫情的原因有推迟。我们应该看一下，我们换一个问法，成都的大运会是第几届？
	他这边能查到成都举办的大运会是2023年的七月份。然后成都的这个大运会是第31届。对，我们刚刚有看到那个问题，他查出来的不是31届，好像是得到一个中间结果是三十2节，我们可以再执行一下。应该刚刚问的就这个问题。这个就很典型，这个问题就是因为我们本身取的是这个问题本身描述的不够清楚，就跟我们一开始用这个prom的时候，如果设置的不够清楚，也会造成类似的困扰。这个self ask research这个agent的实现核心解决的问题就是对于我们大语言模型本身语料里面不包含的知识，它能通过搜索引擎去搜索。但如果我们的这个问题提问的方式本身带有一些模糊的歧义，那他说出来结果就比较难处理。
	就比如说这个问题，这个举办地他给出来的这个结论其实是对的。因为按照原计划，2023年是第32届的大运会。然后这个大运会的这个举办地也确实是在俄罗斯的某个国家。我印象当中，然后现在这个好像是会被延后还是怎么的，具体我忘了。但是我们其实想要达到的那个效果是这样的一个中间结果，就是成都大运会的这个举办时间。这个问题对于我们应用开发者来说，可能就得想一想这个要怎么样去设置比较好。
	这个典型的问题也是一个开放性的问题。因为我们原计划问的这个举办地，其实这里就这个问题的问法，它会存在一个歧义点在哪呢？我们细想一下，我们人人来分析这个问题的话，就是按照原计划，2023年的大运会举办地在俄罗斯，但是2023年的大运会的实际举办地在成都。所以这个地方其实有一个蛮关键的一个消除歧义的prompt，我们没有去给到，我们可以来做一个实验看一看。实际的举办地在哪里，看他会得出什么样的一个结论。
	还报错了。这个就是一个我们需要去处理在粮田里面经常遇到的问题。大家可以看到我们来实际考虑一下这个问题怎么做的。这个报错应该大部分在学model IO那一节的，所以就处理过了。因为我们的toss太少了。大家理解一下，就是我们现在有一个大语言模型的这个决策机制来判断什么时候应该调哪个兔。但现在我们只给了一个two，这个two我就是去搜索搜索结果，然后我们的描述也写的没有那么强硬。
	所以这个时候他在处理一些输出结果的时候，就比较尴尬。比如说哪个城市将举办2023年的这个大运会，在他的内部里面不知道该怎么样去处理了，比如说我们这儿去执行它的时候，它在call back当中某一个我们可以看一看face intern manager agents。这一段就是我们开始的伪代码里去讲解的一部分。大家可以看到它其实是在内部用这个agent不断的去判断，在一个agent循环里面，直到return something。这个注释在这也写的很清楚。
	他现在在调用这个内部的是否应该继续去执行的时候，判断应该执行，但是不知道该怎么样去执行了。因为他他的这个输入没有被我们的这个应该叫sip API的这个rapper的实例，就这个搜索方法不接受这样的一个输入处理。那比较好的处理方法就是把这个output的这个partner再去做一些调整。我们这这的有两种处理方式，一种你可以理解成就是在我们这个a agent的实现上面，我们能多给一些to去做处理。就比如说我们的这个search run它的输入我们能给的更宽容一些，那我们得去查一下这个软方法支持什么样的输入，对吧？
	第二就是说我们的two可以多给几个，让他能够去做这个兼容性的一些处理。就比如说我们现在这个中间结构。我不知道理论上应该是一个字符串，这可能得到时候下来再debug了，不在这个会不在这个实际的直播上去第bug了，反复执行这个也是不会成功的对，这应该是一个。他不要的这样的一个输入类型，看来直接这么改也是不可以的，还是得在设计上面去做一些调整，prompt没有那么友好。
	这个是通过我们的这个search加上LM的一个简单的一个组合。就是我们在agent里面可以去加这个搜索的能力，通过这个server API的方式来实现。对，然后直接去使用这个LLM，就是我们上面定义好的，这里有一个OpenAI的，这个LLM是不太能够去得到这个有爱的知识的。你能看到自然就会出现错误的情况。还有一种情况可以处理刚刚我们遇到的这个问题，就是说这个front在他的这个里面处理不对，就是我们可以去修改这个语言模型本身，也是一种调整，我们可以实际的来试一下。你把这个LLM. 
	换一个。
	假设叫这个chat model，应该是从。我们的。
	I don't need to. 
	应该是在这个路径。少了一个模块，这个路径下面我定义一个聊天的模型，然后用这个模型去新建一个图。
	到社区你做这个。看他能不能支持，这个地方要换成我们的chat model。
	一样的会遇到这个output part的exception的问题。那看来我们还是得针对这个特定的输入去做处理了。直接用这个API调用的局限性就体现在这个地方，也没有那么万能，不然我们每每个人都可以写一个web加这个GPT的一个收缩引起。所以说这个地方要处理的话，刚刚换的这几种都是处理手段，但是针对的点还不太一样，我刚刚换这个语言模型其实跟下一个例子有关，就我们换成更强的这个GT3.5和GPT4，对于一些跨语言问题是有帮助的。我们先忘掉这个地方带来的改进，这地方没有带来改进，但是在处理这个特定的输出的时候，只能通过这个poser才能在这个欠的运行里面给对这个输入这个partner。尽可能给一些比较强数据类型和强格式的一些partner，是比较稳健的一种操作。
	好，我们看一下这个语言模型对这个事儿的一个影响。就我们刚刚在展示这个使用A键的过程当中，其实最后那个调整其实换了那个模型就换了这个LLM。这个LM在执行的时候，重启一下这个notebook。
	这里我们可以还是先使用这个聊天的语言的模型，就是我们的达芬奇003这个模型。然后我们从这个tools里面选了两个预定义的，一个就是serb API，一个是这个LM man，你可以简单理解成这是一个能支持这个数学运算的这么一个模型。
	在这儿我们就会发现一个比较有意思的一个现象，就是我们这里使用这个zero shot react这么一个agent类型，刚刚我们在agent类型里面有看到不是一个self ask。我们把这个问题用官方的这个问题用中文的方式去问一问。就比如说谁是这个小李子莱昂纳多利卡普里奥的女朋友，如果你查出来之后，那他现在的年龄的0.43次方是多少？这个是一个相对来说，需要一定程度的数学的函数调用才能得出来的结果，没法直接推理加减乘除得出来的一个结果。所以我们可以去验证这个LM map这个工具有没有被被成功的调用。那么能看到这个内部的实现里面，它通过这个agent excute首先去查了一下，通过surp API去查了一下这个girlfriend是这位叫做卡米娜莫。然后得到了这个人之后，得到这个女朋友的姓名之后，他又继续去查了一下他的年龄。这个observation是上一次的结果，他有一个内部的思考，这个思考的结果是他的action是要继续用search。
	然后这个search查的内容就是这位女生的年龄，得到的结果是26岁，他的思考是说他需要去算26的0.43次方是多少。这个时候我们相当于用了两个工具了，对吧？因为之前是只有一个搜索的工具，然后这个搜索的工具他很拉跨，因为他刚刚就遇到了一些他不能处理的趴着。那现在他得到了一个26岁，这个26岁，因为我们还有另一个工具叫做LM math，并且它还有一个主任务是算算这个人的年龄的0.43次方是多少。
	这个时候大模型它就相对来说比较聪明。他把这个26岁这么一个字符串里面的26提出来了，相当于对这个output进行了一个处理，然后把这个26丢到了这个LM math里面去，作为它的这个sort的结果。它掉的这个这有个action，就是它实际的操作是去掉了这个calculator去就对应的这里的LLM time，去算的这个输入，构造了一个函数的输入是吧？这样的把这个26岁和这个salt里面的关键信息提出来，就是这样的一个结果。然后得到了一个最终的答案，这个答案就是它的最终的access和他的思考。就是我知道最终的结果是什么了，然后给了最终的answer，就是这样的一个结果，就最终的一个券的一个输出。这样其实也是一个非常简单的方式去实现了react这样的一个论文当中的一个成果，也都是预定义的。
	核心的几个点就是在于第一，我们要去知道我们有哪些拓是可用的，然后在我们的这个agents里面，可以通过node two把它加载进来，然后有哪些tour可用，可以去查文档，在课件里也有写。第二我们使用什么样的agent，很关键，它预定义的agent type里面有一些这个agent是我们可选的。刚刚的这个self ask research，还有这里的react description都是啊把初始化变成一个agent，这个agent可以通过跟券一样的run方法，因为底层就是用的券去作为一个输入接收。这个输入它会根据前面这一堆设定，走他自己的agent内部的逻辑，然后来确定应该用什么to在什么阶段结束。
	如果这个过程当中有些问题触发了他的报错，最简单直接的就是当那个问题可以在最外层再加一个track catch对吧？如果有报错，我们要不就换一个方式去问，或者换一个翻译成别的语言去问，这样就可以去处理它。我们同样的也可以使用不同的语言模型这个地方很有意思的是说，我开始用这个达芬奇003，其实他查出来的这个结果是25岁。通过这个surf APP，可能这个google API本身调用的这个结果也会有一些调整。所以当时我用了也用了其他的模型，包括他当时去从这个里面提取出26这个操作也失败了。
	现在他可能比较有幸幸运的到了一个别的API的end point，就能拿到对应的这样的一个结果，所以就把它处理好了。这里可能有点绕，大家得理解一下。就是我们虽然本地跑了这个南券，然后我们本地的这个南泉里面有实现这些拓。我们这儿有俩兔，但是所有的这个大语言模型它的处理还是在OpenAI那边，我们这使用的是OpenAI的这个大模型，GPT3。
	所以如果你运气很好，然后你可能就会在某一个API的point上面，遇到刚刚那种很奇怪的问题。但是你可能就可以比较能让你的代码变得更稳健了。因为他刚好那个API的point上面，他去处理这个salts的时候，因为它核心是在这个部分，我有一个observation，我有个thought，我有一个action，他他那个API的point的时候没有把它处理好。导致你的agent内部的这个逻辑和茜出现了问题。那你如果恰巧碰到了这样的API的point，你可以对你的整个agent的设计和茜还有toss的设计做的更稳健一些。对，但如果你从来都没遇到它运行的很好，那说明你的这个tools描述，包括你选择的这个agent都还是挺稳定的对。
	然后我们同样也可以使用这个聊天模型去考察这个问题，跟刚才一样，我们把这个语言模型换成了GPT4。然后GPT4的这个prompt会有略微有不同。大家如果仔细观察的话，我们看到这个地方是输出的这个prompt的结果，在这个泰达芬奇003里面是这样的这个中间结果，大家如果还有印象就是欠的输出结果。欠的输出结果就是我们大语言模型的输出结果。GPT4输出的这个结果更加的偏向于结构化，包括这个action本身已经很符合它的open I的function calling的一个描述方式。通过这些都是可以让我们去debug的，包括它这个observation，他也给对应的UIL。那你像这个太tax，达芬奇003就没有给出这样的结果。我们还可以再试试GPT4能不能搞定这个问题。提交。
	GPT4就可以搞定这个问题，所以换模型还是有用的。刚刚我们默认使用了这个GPT3.5的模型去解决这个语言的处理，他没有处理好，但是我们把它换到GPT4之后，这个基础模型能处理这个语言的问题了，它的output partner就能正常的运转了，这个很有意思。行，这个是我们今天展示的两个重要的agent，一个叫做self ask research，给这个只用一个，就这里只用一个to，我们就可以。
	只用。
	一个to，我们就可以给我们的大语言模型本身提供联网数据查询的能力。第二个是复现了这个react年前的很好的一个复现的结果。然后使用了这个react里面的zero shot的这个react的形式。这种agent类型也可以很方便的去直接加载预定义的拓，去做这个数学相关的运算。好，我们最后再跟大家说一说，应该今天是我们实战课基础篇实战的作业，open a translator的题旨的阶段阶截止的一个时间，希望大家在踊跃的去提交这个作业，然后我们也会去做这个作业的一个最终的一个review。好，给大家去评价说这个一等奖、二等奖和三等奖，然后看看大家还有什么问题，我们再留十分钟的时间提问。
	使用react的方式也可以回答。对，因为你的two更多，就是react。刚刚那个demo是比self ask要多了一个to的对。
	Agent是怎么实现推理的？这个推理的能力是大语言模型提供的哟。这个同学问了一个可能刚刚还没有人问的问题，大家记得这个大语言模型在中间，就不管是推理也好，还是我们的外部操作调用也好，大语言模型是这个核心。所以这个GPT4、GPT3.5，包括这个GPT3、达芬奇003都是大语言模型来做的输出。然后这个输出交给南茜的prom的去做处理。
	还有同学问这两个agent有什么区别？这两个agent的区别，我们刚刚专门画了一幅图让大家去理解。在这个里面这两幅图的区别，大家看看在这里面我们的控制变量法对吧？我们专门做了这样一页P然后做了那两个demo，就是为了区分出这个点。第一to是可以变的这两个demo toll有区别，第一个to第一个demo只有一个to就serve API。那么第二个demo我们的react那个demo有sert API和LM math两个to就是to这样的区别。第二我们的prompt strategy就是像你可以理解成我们这幅图里面我们一开始做了推理，我们需要去提问，向谷歌搜索引擎去提问。我们给了一个query，query拿了一个结果，这个结果大语言模型是会过一遍的。
	大语言模型过一遍之后，我们的react和self ask with search这俩不同的agent，他们实现的那个伪代码会略微有一些不同。就是一个是会对这个查出来的结果，就我们开始有一个报错。大家还记得在那个报错里面，我们的这个self ask research有一个内部的一个continue的方法，会去判断我现在要不要继续去做查询。对，然后react它的判断方式会略微有一些区别。这个用嘴讲不清楚，大家去看一下它的agent type里面的这个实现就好了，包括类似的问题，这个nero shot的这个react和stracted input的react有什么区别？本质区别还在这个prompt上面，就他们对应的prompt的这个处理是不一样的。
	来我们再看有什么问题告诉我上这个agent是哪个agent？有个同学问这个agent会利用向量数据库吗？是哪个agent？OpenAI出现了function，那么蓝券的agent是不是也要调整？不是，大家看看这幅图，我专门把OpenAI的function放上来了。就是说这个是年限可以用它，而不是要调整。对，agent本身是一个很重要的抽象，就跟茜一样，你说这个嵌需要调整的它不用，它是一种设计模式，agent也是一种设计模式。
	当然这个同学说的很好，大运会那个例子，不同的文章，不同的结论，可以在prompt里面加一条。可以大家想一下，这个逻辑跟我们最早学OpenAI的API1样的，就是在OpenAI的GPT chat API出现之后，它支持不同角色的这个肉和不同角色的prompt。这是一种这本身就是一种做这个agent的套路。大家去想象一下，就是这个不同肉的message就是一种agent的套路，这也是OpenAI functions后面呼之欲出的一个道理。
	在prom的角度上可以做很多操作。因为大语言模型的核心就是prompt。然后你可以在这个agent的输入里增加，也可以在tools里面去做增加。对，就toss的描述也好，包括这个中间的应该description里面也好，后面6节课我们会有4节课是实战的，还有两节课是这个生态篇的。
	Two可以访问mysql l数据库吗？Two就只是个抽象，你想用它干什么都可以。然后。呃。
	我看看他还有什么问题。React是什么都问出来了，这同学是刚上来的，这翻到之前的这个课件去好好学一下。刚刚上线，瑞尔讲了很久，是推理加上操作。对react这种agent会使用向量数据库吗？React是一种设计模式，使不使用向量数据库完全看你自己的图怎么写的对。
	可以自定义to. 
	和agents吗？可以，肯定可以，一定可以。包括那个loader transform transformer也都是这样的。
	我们看看这个agent type，这里会有一些已经实现好的region type，包括他这边也写的很清楚要怎么样去用。然后这些都有一些论文去做支撑的，只刚刚没有讲而已。包括这个OpenAI的functions，它也支持这样的一些age的type。然后我相信咱们也可以去自己根据自己的需求去做。但是建议上面是说先把这些用好用手。造轮子是每个程序员的冲动，但是前提是你先把现有的轮子给玩明白，对吧？然后to toss是比较好自定义实现的，它应该更开放一些。Toss在这里。
	有官方建议的，这个是一定得自己根据自己需求来做的。因为customer tools本质上就跟我们学的这个open I的function calling一样。其实你就customer tools，你就等价于open I你要写一个自己的function calling，你要写function的描述，这几个套路是完全一致的。你想一下函数名称描述，这个描述是给大模型用的。通常来说returned是什么？是不是直接return？它需要有一些什么样的schema，这个pantai在这个蓝圈里面通常都是符合这样的一个标准的这是他自己定义的一种。你可以理解成就跟我们写ChatGPT的plug in的时候，open I也定义了一种描述它的方式一样，这是它定义的一种方式。
	然后按照这样的方式就可以定义自己的这个two了。比如说我们刚刚看到的这个LLM man这样的一个图，其实他他这边就实现了一个叫做这样的一个类似的吐。呃。
	思维树在在南茜怎么实现的？思维树在也能劝没实现。对，因为思维数也是一种设计方式，对它不是一个函数，思维数是一种设计模式，然后它没有实现。因为思维数你可以理解成它等价于reasoning only那一部分的内容，他跟agent还不直接一样。老师在微信群提到的generative agents，generative agents我有提到，这可能得得再提醒我一下，这个是上下文是什么。
	Generated wagons and behaving. 这是指那篇文章，那篇文章是推荐给大家阅读的对，那个是比较新的研究成果，也开源了。
	对，那篇文章是斯坦福的一个研究成果，也开源了，大家有兴趣可以去跟进一下。之前是论文几个月前发布的，最近终于开放出来了。他们也有在一些网站上更新他们那个小镇里面几个二十多个agent的状态。
	还有三分钟大家再提问题对。要是two超过了token的上限，是不是还得再做一层分类什么的？不是，就是兔子跟大语言模型不直接相关。你是想说two o的输出我超过了token的上限吗？还是这种这个two o本身只是一个外部工具。我们再回到这幅图，to只是一个外部工具，它甚至可以跟大语言模型没有关系，是大语言模型判断要什么时候调用这个to，以及给这个to什么样的入参对。然后它的输出是一个单元模型会再去拿过来做处理的一个结果。然后你想说这个拓输出的结果超过了这个大语言模型的输入，是这意思。
	实际举行那个错误根本原因是因为什么？自相矛盾。不是根本原因是那个output power，那个power没处理好，至于那个得debug了，而且你得拿着那个那个视力看看能不能遇到那个错误，我不确定能不能一定浮现出来。
	觉得能欠代码写的怎么样？我觉得run方法这些call方法还挺好的。这不就是比较典型的面向对象和统一接口的一个设计。如果单纯说举例的这个run方法，这些我觉得是做的挺好的。对，但是南线的代码库维护确实是一个很难的问题。因为这个太热了，所以大家都在往里贡献代码。怎么样去做code review，怎么样去取舍，然后怎么样去弄概念。确实奥特GPT会讲的，会有一节课专门来讲的。
	实际用agent最大的问题就是output part没法解析的错误。这其实刚刚我们在第八的时候就举了几个例子。第一个就是换更好的基础模型，GPT4直接就解决了，对吧？第二就是说tools的这个能力尽可能写清楚并且写明确。
	然后能力他输入的这个参数的要求由tos本身尽可能多包含一些容忍度在tos层面上去做。比如说这个toss能支持输入这个字符串，或者就是尽可能不要让拓全是接收一些格式化的数据类型。比如说这个toss只能接收两个int加一个float。那你的大语言模型要把它抽出来还有转化，对就容易出问题，对吧？然后那你要么就把那个大语言模型的那个chain的output color写清楚一点。
	就刚刚没有展示的是你的过程当中，你还可以写一堆处理这个to输出的。这个to就刚刚说的有个同学说的这个再分一层，就你可以针对一堆的to，你可以写一个to，是针对所有的to调用再调用一次这个图。这个图就是做各种format那也行。比如说把内容裁剪短一点，丢弃一些内容，或者帮你提取一些重要的参数等等。当然这的设计非常的灵活，甚至可以跟门门瑞去做结合。行，我最后再挑一个问题，然后我们今天时间也比较晚了。
	有的同学问聚合类问题，可以让agent来实现，比如谁进球多都可以。对agent实现可以to就agent不是用来实现的，agent是用来调度的。你可以简单意思是用to来实现，可以用大语言模型来实现，也可以。因为你说到底你这个问题是一个比较谁进球更多。
	对，就是有一个经典的小品，可能我这个年代的人听过，就是把大象装进冰箱分几步，一步、两步、三步，对吧？那用大语言模型就是你得把大象放进冰箱这件事，你得把它拆成几步。对你拆成三步有三步的做法，你拆成十步有十步的做法。因为你拆成三步的时候，你没发现你的抽象就是大象冰箱门和塞，对吧？但是这个时候如果大象塞不进去不就麻烦了吗？因为大象太大了，那你可能就拆成五步得得找一个小的大象，或者把大象给或者换个大的冰箱，对吧？就是这样的意思。行，那我们今天就到这儿，然后这个代码我也会待会儿就提交上来。在我把那个API处理好之后，然后大家有什么问题我们群里面再交流，今天时间也比较晚。