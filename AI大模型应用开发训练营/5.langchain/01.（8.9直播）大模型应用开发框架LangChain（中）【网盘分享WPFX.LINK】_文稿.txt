	是今天这个大模型应用开发框架能欠的。中间整个南茜我们它的基础概念，包括它的一些基础的API使用SDK层面的内容，我们会有上中下三节课来把它学会和搞定。当然整个南线的API非常丰富，我们不可能把它每一个特性API都给大家介绍完。更重要的是覆盖到它的所有的重要模块，核心模块。同时让让各位同学有一个学习和掌握他的方法和思路，这个也是我们整个这门课程一直在强调的meta learning meta local的概念。
	今天我们主要讲两个部分，第一个就是欠，我们讲能欠最重要的就是这个欠到底什么叫券？我给他的一个概念定义叫做大模型应用的最佳实践。我们把这个所有的能券里面已经预定义实现好的一些。现在我们可以以这样的一个名字也好，这样的一个定位也好，去理解它，就会很轻松的发现，其实也没有那么难，没有那么多神奇的事情。就跟我们上节课去讲这个model IO一样，其实很多上面叠加的复杂概念，都能够通过我们底层的一些拆解，包括我们去看它的代码实现，看它的API文档，开发者文档，都能逐渐的去了解它。
	第二个部分，我们会简单的介绍一部分的memory。因为memory这个概念是一个大家可以理解，它是一个给我们的大模型应用赋予这个记忆能力的这么一个模块。那这个模块既然是跟着应用强相关的那自然就是我们有什么样的应用就会有什么样的memory。是一个高度自定义的，可以由着大家去根据自己的需求去实现一个特定的memory这么一个模块，我们今天会介绍一部分跟对话系统聊天对话这样的一些相关的一些memory的设定，主要就下面这三个，conversation buffer conversation buffer window和conversation 3 mary buffer。名字就看着就很绕，其实没有那么复杂。我们今天核心把这个券讲明白，大家再去理解别的券就很好理解了。
	在讲这个券之前，我们再花一分钟复习一下，就我们上节课讲的这个model IO有一个同学上节课在评论区里讲，能不能再讲讲这个model IO？这3个小时是讲了什么内容？有一个同学恢复的很好，他说其实老师就讲了三个，一个叫模型的输入，一个叫模型的输出，还有一个就是模型的本身，这个就是大模型model IO这三个单词其实是model input output，这个大模块的抽象就干这三个事儿。那这三个事儿，这个流水线组成了一个最标准的大模型，应用的输入输出和它的核心。然后在这个模型本身真的抽象上面，我们的大语言模型有两种类型。
	一种类型就是我们以前学的completion API，它就是用来做生成的。并且绝大部分的大语言模型其实一开始也就只做到了这个能力。也就是我们这看到这个LLM language model前面再加一个l large大语言模型，这个LLM的抽象是绝大部分模型现在的一个能力。
	这个check model并不是所有的模型都支持的，就比如说我们最早GLM这个清华资源的模型就只有GLM130BGLM的这个6B像这个ChatGLM就是专门为了对话又去做了很多的研究。我们在前面理论可以讲这个chat到底做了什么样的事情，其他的还有很多的语言模型并不都具备chat的能力。就有很多同学问，那那这completion都要被丢掉了，为什么现在我们还要学习这个LLM这个抽象和这条路径呢？就是因为这个道理，因为不是所有的模型都支持chat model，而我们的又不只是服务于一个OpenAI的GPT系列。所以考虑到大部分的模型都还没有chat的能力，那南茜当然要去支持上面这条实线。就我们的LLL。同时今天我们学到的一些memory的能力，为什么要讲服务对话系统也是这个视角出发的。
	我们考虑到如果我们不是对接OKI，我们国内的应用可能就必须得用一些协议友好，可私有化的，然后数据安全有保障的一些本地化的方式。的模型的话。它如果没有chat model的能力，它只有这个生成的能力，我们通过memory也能一定程度上去实现一个check model的能力。这个是我们的大元模型抽象。当然它的输出可以去做模式化、规范化，这儿我们就不再展开了。那整个券是要做一个什么事情？比较好的一个词叫做他山之石可以攻玉，给我们学习一些好的做法。
	毋庸置疑乐高是一个非常成功的产品。我不清楚大家对这个乐高产品有多少了解，大家如果深入去研究，这个产品它不只是一个玩具，它既是服务于小朋友的，也是服务于大人的。每年还有竞赛，甚至它还会有一些稀有的颜色，这个颜色也不是随便可以买到的。
	那么说回头乐高其实就是一个一点一点的这个小的方块。我们能看到右上角这里有一张图片，有单个的这个方块有两个在一起的，然后也有三个的，甚至有有L型的等等。那么这么多种不同的小的方块，最终可以组合成我们现实世界当中任何的物体，都可以通过乐高来实现。几乎只要它是在宏观层面上的，我们不去讲什么微观粒子，不去讲最近韩国的诗文超导这种材料级别的事情，我们只讲这种公益性的产品。不管是这种街景，这个小的商店，小的建筑，包括我们看齐天大圣这种人物类型的，包括像汽车，然后我们看乐高每年的大赛，还有造桥造各种，很有意思的。然后它还有传送带，还有各种这种，我们工业是革命时代带来的很多传送带、蒸汽机、动力源之类的一些设定，都可以通过乐高来造出来。
	那乐高其实是一个能欠，我理解。虽然他的这个创始人也好，他的这个开发者也好，没有去讲，但其实模式上是非常像的。整个券的一个设定，其实就是讲围绕着我们能不能把各种小的零部件，小的组件组合起来，变成一个很厉害的应用，然后这个chain everything这个chain本身的操作就有点像乐高，我们可以拿这个不同的小模块拼在一起。因为它有圆形的一个卡口，就跟我们中国古代做这个木工艺一样。所以欠本身是一个连接各种模块的手段和模和方法，让他自己本身也是一个模块。但是通过嵌的这种做法，我们不是说要定义一个就是什么事情只能这样做。就像我们做乐高，你要造一个什么样的城堡，它不只是一种拼的方式，还可以有很多种拼的方式。
	对于我们学习欠的同学来说，第一我们要整明白左边有哪些可以被串起来的模块。就比如说我们上节课学到的ALLM，这属于语言模型，还会有chat model，都在这个model里面。然后我们有prompt就是模型的输入，当然还会有模型的输出。这两个内容连在一起就可以构造一些很有意思的事。我们如果能够把memory结合起来，包括我们下节课要讲的agent结合起来，让他能够干的事情就更多了。就像右边我们能看到能做很多的事情。那右边这个列表，右边这个应用的形态也都可以无限的去做扩张。就像我们的乐高最终能做出什么样的这个乐高的玩具，能做出什么样的AIGC的应用，完全取决于我们自己的想象力。
	我们今天的这个讲课的过程，也只希望大家能理解嵌的原理，欠的实现，以及嵌的一些很重要的基础抽象，在这些重要的基础抽象上面，我们可以做各种各样的工作，回到我们刚刚这幅图，我们在上节课model IO的基础上，再跟大家进一步去扩展一个券的概念。首先我们看到这幅图里面，我们把这个model IO这三个概念在这幅图里做了一个小的红框，给它框了一下。我们在上节课的prompt template，就是我们左边这个部分，prompt template经过了具体的format，这个方法可以变成一个给到大模型输入的字符串，这个字符串我们也叫prompt。然后经过大模型的生成，变成了一些具体的内容。比如说这个food das巴拉巴拉巴拉，这是一些具体的内容，是大模型的输出。然后我们上节课学到了output partner可以把这个输出规范化，生成一个特定的格式去关个窗，外面有点吵。
	然后我们通过这个output power，可以把它变成一个我们预定义的power的形式。比如说变成一个列表，变成一个字典，变成一个day time，变成一个日期。但是我们再把这三个概念回过头来看，它其实是一条流水线。这个流水线是不是可以再把它做一层抽象整合？
	我们最简单的一个券叫LLM券，大语言模型的券。这个我们在上节课的一个notebook里面也给大家做了一次调用，那么这个LMT他干的第一件事就是我能够把大语言模型和大语言模型的提示模板这两个东西封装到一个抽象里面。我说封装到一个模块里面，那这个模块我们就把它叫做大语言模型的列，叫LLM券。那么LLM change就干这么一个事儿，这个可以认为它是最简单的欠，所有的欠基本上都是基于他再去做的封装，就一层一层的像我们上节课学一些基础的这个类的基层关系的时候也能看到。
	这个LM欠其实也是这么干。他就把我们的输入，我们的模型输入和我们的模型本身合在一起，变成了一个可以被大家复用调度的单元。这就像你在做乐高的时候，一个最简单的一个小方块，你觉得没用，但是你可以造很多的。比如说你把一些小方块造成了一个轮子，你把一些小方块造成了一只脚，造成了一只腿，那它就可以被复用了。LM券就是第一个被造出来，被广泛复用的一个券。
	那大家这样去理解它，具体来看，我们可以在代码里面去怎么样去使用它。我们上节课学到了，我们可以用LLM，用prom这两个东西来定义出我们要调用什么样的模型，我们要制造什么样的提示词模板。LM券是属于这个模块下面的基础类，它不是一个鸡肋，它是一个很基础的类。这个基础类会被大家复用，就比如说这里我们把这个LM chain的这个实例化的构造函数直接调用之后，它会输入两个重要的内容。一个就是我们上面定义好的这个LLM，一个就是我们的这个提示词模板，我们的这个prom tempts。把这两个东西丢到一个LM线里面，它就能够变成一个语言模型的链的实例。
	这是一个具体的实例。然后这个实例要去生成一个特定的内容，我们叫AIGC，对吧？它要去生成一个特定内容，实现了一个run方法，一个执行的方法。通过一个统一的run方法，所有的链都可以来执行，就这样的一个方式。当然我们上节课学到了我们有这个input variables，就是为了把prompt的template变成一个函数，然后把这个pro product变成一个函数的参数，那这个函数的参数将要去运行，它肯定要去把这个参数传进来。
	那这个change点run就变成了一个通用的，有点像我们以前学这个，大家如果学这个拉姆达表达式的话，那这就非常像一个达表达式，只不过这拉姆达表达式的这个nmda函数变成了一个change run，就变成了一个这样的一个形式。我们待会也会看这个实际的例子。从这个角度来看，欠的第一个欠LM茜非常简单，就是把模型的输入模板和模型本身做了一个封装，仅此而已。接着我们再看一个，相对来说我们有了一个可单独调用的单元了，它叫LM欠。很直接的想法就是它需要被我们用起来，那怎么用呢？
	就像我们学编程语言一样，如果大家有编程语言的例子，都会知道编程语言有一些基本概念。比如说编程语言有面向对象，有面向过程。所有的刚开始写代码的同学，比如说我中学的时候，刚刚学怎么样写程序，这个时候老师就会教一些这个函数，你去学一个一个的函数。但因为那会儿我们学的其实是physico这个编程语言，更早的时候学过这个basic这个q basic。这种编程语言它其实函数抽象这种东西很少。它就是写过程就有点类似于我们在食堂里面去打菜，一个菜就像一个流水线。你看到了这个菜，你选择要拿这个菜还是不拿这个菜，然后你就一路走过去，一直到可以取这个主食的部分，然后要不要拿主食，最后结账，还是一个流水线一样的过程。
	然后这样的一种面向过程的编程方法，基本上是大部分学这个编程语言，第学第一门编程语言的同学会写代码的一种形式。因为他的思维逻辑非常的直接，就是一条线一条链路下去。很直接的这个想法就是这样的一种方式。我们都说了要把欠点赞，把这个语言模型变成了一个编译器。我们要用自然语言来写代码了。那自然这种面向过程的思维模式能不能在语言模型里面去复刻出来呢？可以，sequential chain就是这么一个基础结构，就跟我们学这个写代码面向过程学这个pipeline一样。
	Sequential chain其实它就是一个顺我们可以讲讲它是一个串联式的顺序调用的这么一个链。那它调用的东西是什么呢？就是我们刚刚定义的那些LLM茜，对吧？我们的LLM茜刚刚最重要的部分是什么？它不只是一个模型了，你可以把提示模板埋进去。其实模板就是我们的一个函数，对吧？那相当于我们的sequent al chain，就是可以顺序的去调用一堆的函数。那就跟我们写代码一样。
	假设让你写一个业务逻辑的代码，这个业务的逻辑代码是新建一个账号并登录，或者说确认账号登录。账号登录的前提是你有你有这个账号，那你的逻辑里面可能就会去判断你有没有这个账号，这个也是我们待会会介绍，条件判断的这个点。假设现在有了这个账号，你需要输入账户名，需要输入密码，这一步一步的那输入账户可能是一个LM线，输入密码可能是一个LM键，然后去调用一个登录的接口，可能是另一个LM线，这样顺序的把这个执行下去。就叫我们的sequential change。
	Sensual券还有两种形态，一种是最简单的模式，就是单输入单输出的，就一条链连一个分叉口都没有然后我这个分叉口就完全不存在。就你上一个的输入，然后得到了一个输入。那这个输入可能是一个特定的prompt，这from的经过你这个LM chain的语言模型会得到一个输出。这个输出又作为下一个它下游的这一个LM线的输入，那这个输入就可以一直这样顺记得执行下去。这个就叫最简单形式的顺序链，它定义为叫做simple的钱。
	同样的还会有比较通用形式的这个sequences，它就允许多输入多输出，简单例子我们来看一下这个抽象，刚刚我们看到了LM欠那一个AM chain里面包含了一个prompt tempt的一个语言模型。我们的simple sequential chain要做的事情就是给一个输入给到这个LMT里面，串联着把它的输出作为它的输入，然后我们继续给到下游的这个切这个AB可以一直串联，你可以串联无数个对吧？只要最终输出一个结果为你所用就可以了，这是最简单的一个形式。
	我们实际上在今天的实战里面会做一个什么样的例子呢？也是官方给的一个例子，就是我们把两个简单的语言线串起来。第一个第一个的这个欠就我们刚才讲的AM欠的第一个茜是什么呢？它是一个根据题目，根据我们要写一个剧目的标题简介。我们之前讲这个HIGPT的这个prom的使用技巧，也有这种偏生成内容类的，那具体怎么做？
	我们来看一下这幅图的抽象。首先右边是最简单的，就是我们任何一个模型它都会有输出。这里的输出就是一段标题，基于一个特定标题写出来的一个剧目的简介我们这个标题是什么呢？就是我们的三体人不是无法战胜的，这个是一个标题，这个标题它是一个input variables。Input variables在prompt template，大家看到下面我们这个鼠标，这个prom template ate里面有做定义对吧？我们把prom template变成一个函数，那里面的这个变量传进来的这个函数的参数是title。这个title在我们具体的一次调用的时候，我们传了一个这样的字符串，叫做三体人不是无法战胜的，他们合在一起形成了一个print，变成了这个LM chand输入。
	当然我们把这个LM茜可以给它一个名字，就是欠本身我们前面叫它LM欠A，LM欠B我们现在给它起一个名字，叫做写剧本的这样或者我们叫写这个剧目标标题的这么一个券的名字，给它取个名儿。这个里面的这个模型拿到了这个prompt，这from就是把这个三体人不是无法战胜的丢到这个标题后面来，变成了一句完整的from对吧？这个过程大家应该很熟悉了，给到模型生成了这么一个输出的结果，那这个结果就会丢到我们第二个券里面来。
	第二欠我们叫review券，就是我们去基于前面我们生成的这个标题简介，大家可以想象我们在做一个什么事儿，就是你你你在拿到了一个你的同事写了一段这个剧情的介绍，就跟你在帮他review代码、review文档、review文章一样。他之前。生成了一个刚刚我们看到的介绍，这两段是不一样的，都是红色的。我专门把这个类型标成一样，我给大家读一下，就三体人不是无法战胜的，讲述了一个古老而又充满悬念的故事，三个被当做宿命的人之间的奋斗，不同背景不同命运的人共同的做目标是要巴拉巴拉，然后最后去挑战被认为不可战胜的三体人，最终能否战胜三体人。当然首先这个三体跟大牛写的那个三体没有关系，因为我们的这个语言模型里面并没有get到这个三体的概念。这也是后面大家可以去扩展的一些留了这个悬念的地方。
	这个是它的输出，这个输出变成了这里的一个输入，就我们看到左上角有一个review圈，这个review券需要一个输入，那这个输入具体要怎么生成一个完整的prompt，我们就看下面这个prom template。大家要习惯把自然语言变成一个函数的变量。这个变量可以买到一个提示词模板里，然后形成一个新的提示词。这个新的提示词是可以给下游的大语言模型去使用的。
	我们这看到刚刚那个temple ate，我不知道大家有没有注意，一个剧作家对吧？上游是一个剧作家，剧作家的工作是根据戏剧的标题，然后写一个简介。下游是一个戏剧评论家，对吧？他是根据刚刚的剧作家写的剧情简介，为该剧撰写一篇评论剧情的简介。是这个变量，这个变量是由上上一个券生成的，这个结果变成了一个新的券的输入的变量，它的这个input variable就是我们刚刚那个欠的输出，把它塞到这一个里面来。
	然后一下是来自纽约时报巴拉巴拉的最上面的这个上述剧目的一个评论。那上述剧目的评论不就是右边review前生成的结果，对吧？所以整个最终组成了一个我们输入一个标题，这个标题叫做三体人不是无法战胜的，由第一个剧作家角色的欠生成了一个剧目的简介，然后把这个剧目的简介给到了我们第二个券。第二个券叫做review圈，它是一个戏剧的评论家角色是这样定义的，给这个大约模型一个角色，他的工作是基于第一个欠的输出结果生成一个评价。这个评价是我们最终这个sequences钱的输出结果，对吧？这个结果叫做什么？
	一部引人入胜的戏剧，讲述了三个来自不同背景的人有着不同的命运，有一个共同的目标。这儿即使我们开始创作三体内容的的人不懂什么是三体，写了一个跟我们大部分看过三体的人的印象不一样的所谓的三体人，但是我们的review钱，因为他拿到的输入就是他描述的这个三层，所以他一定要针对他想象的这个剧目简介给这样的一个评价，并且是贴合了上游的输入的。所以这个是一个完整的sequential券的最简单版本，我们叫单输入单输出的simple sequential券的一个实例。大家再看这个例子，就非常明确的知道了券是怎么玩的。然后跟我们的乐高非乐高不断的叠罗汉一样的，把一个简单的组件能够叠成很复杂的这样的一个造型。
	我们整个simple al的输入其实就是有一个title这样的一个input variable。我们需要在每一次调用simple critical chain的时候去传一个title。这个title和我们的剧作家的模板一起形成了一个prompt。这个prompt其实就是加了这个title的一个prompt，然后给到我们这里的大语言模型。大语言模型在这个角色里面它会生成一个剧情的简介，就变成了这部分的输入，它生成的这个剧情简介跟我们的这个review chain的模板去做整合，生成了一个新的prompt。这个prompt就是我们要给这个review就这个戏曲评论家的大模型角色的一个输入，最终给出了一个戏曲评论，所以我们整体看下来，一个simple continual就是一个相对来说最简单的一种组合了，把两个基础构建我们的LM线组合起来，串联起来，构造了这么一个欠。
	当然大家可以无限去叠加，这个过程我们刚才有讲过了，那它的代码实现，我们可以看到，很简单，我们在嵌入的模块里面import是导入了这个simple sequences change。按顺序运行这两个列，用一个列表的形式，我们之前在讲这个message的维护的时候，也是一个顺序的形式。然后第一个欠叫做我们的这个3 ery，我还不太会准确的读出这个单词，一个叫什么3a pieces，这个是review，这两个欠以顺序的方式结合在一起。然后第一个上上一个链的输出会作为下一个链的输入的input arise。如果他需要的话，我们把这个东西变成了一个chance的一个列表。这个列表给到我们的simple sequential change。这个verbs我们在上一节课的时候有讲过，这是一个打印是否详细，中就是我们相当于第八个信息，是否要打印的更详细的一个参数。在我们的模型层，在我们上节课讲model的时候就已经有了这个抽象。
	那么他通过这个run方法，我们统一所有的欠几乎都使用这个方法来实际执行，把这个信息其实就是那个title是我们的第一个欠需要的，生成了对应的内容，这里有写山崎人巴拉巴拉巴拉，这个是他的这个剧情简介，下面是他的剧情的一个评论。OK. 到这儿为止，其实我们讲了第一种形态，就是我们把一个嵌以顺序的方式组合起来。那么还有什么方式呢？我们当然能支持单输入和单输出，那么就能直接想得到能支持多输入多输出，对吧？就想象你在吃自助餐，这个自助餐里面它其实一开始你是要买一个门票的那这个门票可能就我们去吃什么寿喜烧的这种自助？它有好几档。不同的档位可能你付了钱之后进去可以看到的内容也不太一样。甚至有的这个餐他只能点一个，比如说什么七这个波士顿龙虾，你就算付了钱也不能无限吃，就只能点一次。
	类似于这样的分叉逻辑也很多，然后这样的分叉逻辑在我们的continual change里面也是支持的。首先对于一个chain来说，或者对于一个prompt来说，它支持多个input variable。是一个天然可以的知识。所以在这儿本身就是模型成就具有的能力。但是在后面我们的刚刚的这个simple secret al chain里面，我们的前面的这个券的输出只能直接给到后面，让我们的sequences的券多输入多输出稍微给了一些自由度。就是我们不仅能够给到下游，我们还能直接给到最后的接收这一整串输出的结果。
	相当于我们几个小朋友一起去这个自助餐，对吧？有的小朋友他很厉害，他一路都能什么吃的他都要去拿一点。还有小朋友可能拿到一半，他就已经拿够了，他就走了，大概就这个意思。那去脑子里面模拟一下这个过程，其实它就相当于这个数据流就可以有更多样的方式去做控制。包括你也能看到中间结果。
	这个就是sequential chain的一个更通用的一个形式。我们能看到其实这里我们刚刚的这个simple sequent change的最终输出只有review，没有拿到中间的这个简介。但是我们使用这个security change之后，还可以拿到整个这个chain的列表里面的任意一个输出。我们最终的输出里面既有这个review也有这个输出，包括输入他当然也能拿到对。好，除了刚刚讲的这两个关于顺序的这种单数端输出和多数多输出的形式以外，这还会有很多不只是说就像我们写代码不只是有面向过程，不只是有顺序的逻辑，也还会有一些预开发的预定义的框架原生支持的一些处理方法，就比如说这个的transform圈，这个是处理超长文本的一种转换链。
	简单来说就是我们之前在讲AI translator这个实战的时候，我们需要去对PDF文件进行解析处理，一页一页的处理。把每一页的内容再分成这个content，或者说这个table content，甚至还会有image content。你要把这个每页都处理好，那这种文本类的处理，因为首先我们的语言模型处理就是文本，这个是所有人应该都都已经学会了知道了一个事儿。那我们要处理文本，那文本天然就会有那种超强的文本。因为你要处理语料，这是你的训练数据，或者你的生成需要的原数据也好，需要去做前处理的数据也好。那这些文本类型的数据有没有可能在框架层面上去做一些原生的支持，让我们少写一些代码，去复用一些成果的那transform现在就是干这个事儿的，他要干的事就是transformation，就是做转换的。具体做怎么转换呢？待会儿我们可以在实战的时候去看。
	大家可以简单理解成，当我们需要处理的不是一个简单的prompt，而是一堆文件的时候，尤其是文本类型的文件的时候，transform券可以帮你去做一些预定义的操作。那接着这个处理好的文本再去接一个其他的LM券，你去预制一个prompt telt，那就可以去做，至少能做摘要总结，对吧？当然也能做其他别的工作，就取决于你后面接的这个券要做什么事情了。这个是一种典型的手段。
	除了transform券以外，我们的年券还提供了其他很多类似的针对特定数据类型，特定场景的内置的欠方便你去处理数据，那还有一个很常见的，我们写编程语言写代码的时候会遇到的逻辑叫什么呢？叫条件判断if else对吧？或者叫case。比如说我们写过典型的面向对象或者说面向过程的同学应该都知道，我们可以用if来做很多的事情。
	比如说我们的if条件判断，我们在在今天的这个例子里面会去讲，我们做了一个万能的老师，这个老师可以回答所有学科的问题，就像十万个为什么一样。但是就算是一个万能的老师，他可能在思考不同问题的时候，他也要去先理解一下。我现在问的这个问题是一个数学问题，还是一个化学问题，还是一个物理问题，还是一个汉语言文学的问题。不同的问题他回答的角度和内容都不一样，所以我们先要识别出我到底在问什么样的问题，所以这个就是我们待会会去讲，我们会造一个route change，大家可以理解，它就是用来针对我们的预设的不同的模板。我们可以把后面的AB不同的LM线当成两个学科的老师，这儿可以整无数个老师擅长不同的事情。
	我们的专家模型也是一个很典型这样的一个逻辑，对吧？我专家模型可能是直接会去过滤所有的专家，然后专家都给出意见。在我们的这个route chain里面，是说我预先就判断我要问哪个专家，当然你也可以同时问多个专家，这个都是你可以去写的if这个判断语句里面的内容，那么这个AM route chain就相当于大语言模型。基于你给这个chain设计的提示模板，它来决定我要针对现在的这个输入去问下游的哪一个欠让下游的哪一个券来回答问题。那可能这里input一问的是一个数学问题，那A可能是一个数学老师就回答了这个input一的问题。那input 2可能是一个物理问题，那可能就有后面的这个LMTMB这个物理老师的这个prompt模板来回答这个问题，然后得到了一个output p这个就是说我们如果把人券当成一个新的编程语言的框架，把prompt当成我们的写代码一样的编程语言。
	Router chain就是一个想要用来帮大家实现条件判断if else这样的一种chain，这么一个很好的设定。那有没有可能把刚刚讲的这几种欠全部都结合起来呢？这个是一个可选的家庭作业，比我们在notebook里面留下的家庭作业稍微麻烦一点，我们在这儿做一个披露，就让大家正好把刚刚学到的东西都整合在一起去梳理一下。首先我们之前有一个OpenAI的translator的一个基础篇的一个实战作业，是这周日截止，希望大家踊跃的去把这个作业完成。好是有实物的奖励的。
	我印象中是有几个一等奖是可以有500元的现金的，然后还会有二等奖，有精美的周边礼品。在写这个作业的过程当中，其实我们现在帮大家打开一个思路去处理这些事情。我们假设我们现在要做一个翻译加上文本摘要的两个功能的助手。那这个两个功能的助手就可以用我们刚刚讲的几种典型的欠去做实践和完成。首当其冲的是我们要设计一个sequences欠这个sequences券的意义就在于一个单独的from the template解决不了一串问题，一定是有好多个不同的template，每个template去实现一个自己的功能。因为我们一直在讲一个template就像一个函数一样，或者说一个方法一样。那这个方法需要在合适的时候去调用它，并且调用它的时候要给它合适的输入参数。
	我们为了去处理文本类型的内容，我们刚才已经介绍了有这个transform圈对吧？它能去处理文本类的内容。然后他把这个文本拿过来之后，我们可以在中间设置一个LM router chain，它可以用来判断我要做什么事情。
	那我们要做什么事情呢？一个是做翻译，就啥也不干。你的transform可能就只是帮我去把这个文件原封不动的拿过来。那这个时候可能会通过AMB去做一个翻译，但这个时候翻译需要的输入是我要翻译成什么目标语言对吧？所以LMTND可能是输入一个source的language是英语，它的target language可能是chinese，可能是我们的中文。那么这个AMTMB就拿到了必要的两个参数，当然还有需要被翻译的这个role text。我们的这个原数据原来的这个待翻译的材料，最后就变成了这个输出是一个translation。
	还有一种可能我只是需要你帮我做摘要，因为这个transform的内容太多了。那这个时候他就有可能去判断通过这个AMA去做这个summary。这个summary是取它的所有的内容，还是只取它当中一部分呢？都可以。这个就是一个很典型的一个应用，也是如果大家要用连券，用这种券的方式去开发大模型应用的一个很小的一个练手的项目。大家如果有兴趣的话，可以选修，把这个作业提交到平台上。
	好，那到这儿我们就把偏理论的部分券的一些最基础的内容给讲完了。我们接着就来实战看看我们的这个券到底有一些什么样的玩法很难认的。然后我们把欠讲完之后，可能剩下40分钟我们再去讲memory。欠这个实战的部分讲完，我们会留时间给大家提问第一个就是我们继续看看这个要不要放大一点。我看看这个字怎么样，有没有有没有需要再放大的，现在这个能看得清楚吗？
	现在我这个notebook的字体大小还需不需要再放大？大家可以看一下。还要再放大一些是吧？现在这样OK吗？
	可以了。好，今天涉及到4个notebook，分别是对应着我们的screens al chain，包括刚才讲的transform chain roster chain以及待会儿会讲的memory。这四个notebook也都放在了我们的这个jupiter下面。首先我们看这个sequential chain。Sequential chain其实最前面的这一部分都是刚刚PPT已经讲过的，我这就不再赘述了。
	就简单一点来理解，就是欠是一个南茜里面的核心模块，然后它定义了通用的接口。这个通用的接口第一个最直观的感觉就是它有一个欠点rn接口，欠点run方法。用来去执行一个欠的内容部的逻辑，或者说它的执执行它的实际去运行这个钱，欠就像一个函数一样，对吧？实际要去运行这个函数，那么这个券是一个很基础的一个类。那基于这个券可以去造各种各样的其他的钱。就比如说首先它的基础类就叫做钱，而且我发现官方的文档有一些没来得及更新的部分。就比如说我们在南茜的这个官方文档里面去看，把这个也放大一点。
	我们在南券的官方里面可以去看到有很多的模块上节课有讲到，比如说他去讲这个券，那他讲这个chain的时候，这里有一个定义是这个base model ABC。这个定义其实在它的最新版本里，在253版本里面已经不用实现的方法了。这个也是我上节课就有讲过的，只看这个文档是容易出现这个alter dated的。就是你你理解的这个文档已经不够新了。最简单粗暴的方式还是看这个代码的实现。代码的实现以及我们的这个API文档，这个是由代码来生成的。
	我们上节课讲的时候是253，大家还有印象的话，就我们上周日三天前、四天前的时候，253现在已经到258了，迭代很快。我们这里也是一样，它的最新的这个券的鸡类的定义，在它的能chain chain base点PY文件下面，然后定义的啥呢？其实就是跟我们的这个S的这个model很像，定义了一些数序列化的输入，就是为了这部分跟我们的这个prom的ten plates的鸡肋，大家如果还有印象的话，非常像。因为它需要序列化的数据作为输入，就跟我们要把这个欠，大家想象一下刚刚讲的这个欠的这个模型，在在下面这这个欠就是包含了这两块。那这两块既然之前的prom的tempt需要这种各种字符串也好，包括为了这个chat model设计的这种chat message也好，那自然的它也需要这部分的序列化作为积累。当然他为了实现各种各样的模型，因为它背后还需要模型，后面也有这个ABC，包括他为了实现这个运行的接口，也实现了这样的一个render的一个方法。这个都是要在他具体的欠里面去做实现的，这儿我们就不再展开了。
	然后使用券这样的一个接口有哪些好处？得到自己的定义里面有三个点。第一个点就是说券是可以有状态的，什么状态呢？我们通过memory，我们待会要讲的就是我们可以把memory丢给一个特定的券，让它变成一个有状态的函数。这个我们写编程语言也是是的，写代码的时候有些函数是可以保存状态的。你只要给这个类的实例放一些成员变量，它不就有状态了，对吧？这个我就不再赘述了。写过这个代码，知道怎么样去定义一个类，然后知道这个类里面有，因为变量同学应该都知道。
	第二它是可观测的，我们向chain里面去传递一些call back，一些回调，可以来执行一些额外的功能。比如说这个记录，这个是这个应该也是很直接可以理解的。就是相当于它在正常的执行逻辑以外，你可以设计一些触发条件，然后来执行你的一些额外的的回调，这个回调可以帮你去观测它。
	还有一块就是可诅可组合的，这个在刚刚我们讲从LM chain到sequences chain，simple sequences chain, road chain, transform chain, 甚至组合一起，可以就像乐高一样随便组合，这个组合可以让它的灵活性非常高。所以这个也是茜一直在强调的一个点，就是希望把券本身变成一个编程语言的最基础的抽象。这样我们才能真正的去使用自然语言，使用prompt来用自然语言来编程，就这么一个概念。
	好，然后软方法这个我刚刚对任何方法，刚刚我们已经看到了。然后这个内部的一个扣方法是执行它的一个主要方式，这个内部的时间我们就不用管了，刚刚提到几个重要的点，第一个就是这个memory，这个是它的一个为了赋能它的这个应该叫记忆，这个羁绊的有点问题，这个我们统一一下记忆比较好。对，保存这个状态和变量。然后这个对象其实是用来我们刚刚讲的，用来存这些中间的结果的，包括他之前历史的一些生成结果，可以有回调。用来是否以这个比较详细的模式来打印它的一些内部的执行结果，包括一些标签原数据，跟我们之前看上节课的这个模型的一些抽象是非常像的那LM茜是一个最简单的链，这个链就由这两部分组成，直接传入直接传入就我们在每一次运行的时候，直接传入也可以从memory里面去获取。大家简单理解成memory就像一个变量，像一个字典一样，可以用来存东西。那存下来东西自然也可以丢给大模型继续去使用，作为它的输入的参数。
	待会儿我们也可以讲一讲library，这就是一个AM钱，去使用它也很简单，我们还是重启一下这个notebook。我们从这个能券里面导入了这两个基本的模块，一个是OpenAI，一个是这个prom template。为了这个生成的内容不会只有一半，我们给max token稍微做大一点，然后定义了一个prom temple，就是给这个制造什么什么产品的公司取十个好名字，并给出完整的这个公司的名称。然后我们实际执行一下，这里定义了一个AM券，然后把这两个实例化的大语言模型和这个提示词模板放进去了。而在实际运行的时候，我们会把这个product放进去。
	这里我们都知道用这个OpenAI默认模型是K达芬奇003，然后他只需要使用prom就能生成内容了。大部分的语言模型也是这样，大家可以看到text这个003其实给的名字很不稳定。大家如果自己去运行这个结果的时候会发现，其实每一次的输出它的这个。结果都不一定很满意，甚至这个样式也不一定是很好的那这儿其实大家如果有兴趣，也可以把我们的这个部分的案例和示例改成使用GT3.5或者GT4的这个chat同步进行API来实现。也是OK的，这个M茜是完全支持这样的输入的。而且怎么样去改造，我相信上一节课如果大家认真学过的同学应该也都知道怎么样去传入，但是我就不再去做展开了。稍微多讲一点这个成员变量，我们默认其实它会把这个verbs这样的一个变量设置为boss，我们可以实际去看一下它的输出。
	默认它会是一个false。因为这个执行其实是一个非常基础的一个执行单元。如果你一直把它开成这个出的话，有的时候如果你做复杂应用会显示的内容过多了。
	我们这儿主要是为了让大家学习和理解券的一个内部机。是啊我们把它设置为true之后，可以看到这里就输出了更多的信息了。刚刚我们去执行这个确认点run的时候，直接给出了10 10个output。那么当我们把这个verbs设置为true，这个时候我们先执行的是6，这个时候已经是true了，那我们这个设置为处的时候，他会给你一些券的一些内部的日志。比如说我们能看到这里进入了一个新的LM券，这个是format之后的一个prompt，大家还记得这个地方通过format之后才能生成真正的prompt。After formatting之后，其实就是给制造性能卓越的级别取十个名字，对吧？就把我们这两个组合在一起了。组合在一起之后，执行完了这个券的结果就拿到执行完的这个券的结果，就是我们最后拿到的这十个内容。
	这里也很神奇，大家有没有发现我们把这个verbs打开之后，它输出的这个结果会更标准一些。就是他给了真正的这这个名字，然后也给了我们后面的这个内容，这儿其实没有很明确的原因，就是他为什么会这样。但是大家可以底层的去看一下他，或者说自己去做做实验，去研究为什么这个会有这么大的不同。但有可能是刚好就是不同的APIN的point。从我自己看源代码的角度来说，没有什么本质的区别。但如果大家有兴趣可以去试试，这个也是很多人吐槽南迁的结果不稳定的一个点。在这儿是把这个命题留给大家去探索。其实从这个调用模型的角度，应该是能找到一些对我们的这个tex达芬奇003本身带来了一些很有意思的特点，那么就不展开了。
	Sequential chain就我们刚刚讲到的这个顺序链，能够串联的去调用我们的语言模型。它有两种不同的形式，一种是单输入单输出的形式。那具体要怎么做呢？我们就来复现一下刚刚在课件里看到的结果。首先我们要去做第一个欠，对吧？然后这是做了第二个券，就这里的这个我们在屏幕里看到两个券，那分别怎么定义呢？定义第一个券，这个券它的核心是template会不一样，对吧？我们甚至LM都可以去复用，因为它现在是没有状态的。我们目前用到这个LM是没有状态的，它就只是一个单纯的API调用。
	我们在这个地方的template是给他定位成你是一个剧作家，你需要根据我们的标题写一个简介。这个标题及冒号跟着我们这个title是我们实际生成这个prompt，就我们去format这个template的时候要传入的一个变量。下面的这个剧作家一下这个的简介。这个其实就是我们完整的一个提示词模板。这个提示词模板通过这个构造函数我们可以做出来。这里需要去做一个校验，把title作为一个必要的参数创建，然后这个是它的这个time plate。好，然后我们这做了第一个LM钱，它就是把这两个做成了我们的第一个欠的实例化的时候的输入，然后标准的这个官方文档通常会在这里去再定一次这个大语言模型这里我们故意把它干掉了，就是想让大家理解AM欠也好，其他的欠也好，到底底层是如何实现的，以及我们专门把memory在这儿就做了预告，什么意思？就这个欠它本身是一个，我们再回到这儿来理解一下，欠它本身就是把两个实例，就我们在拍摄里面的两个实例拼到了一起，变成了它的一个成员变对吧？
	我们去执行券的时候，他就会去在内部去执行它，把我们的这一个特定的券里面的模板变成一个真正的提示词，然后再去调用一下我们的模型。如果我们是非常简单的一个券的话，那其实就只是调了一次。比如说OpenAI的这个达芬奇003的completions AP也就只调了一下API。
	如果你没有给他memory的功能，那么其实这里的模型是没有状态的，没有记下什么东西，这个部分大家一定要理解。所以如果是从这个视角来看，那这个这个例子是成立的。就我们这里我们不需要再去定一个ALM，就复用它就好了，复用它把这个LM也可以传进来这个实例。但是模板是一定要换的对吧？因为模板是这个函数真正的逻辑，就跟我们写这个function calling的时候，我们用了其他的一些压缩的格式的方式来描述这个函数功能。模板也是在描述我真正要给语言模型去做什么样的任务。然后它真正的提示时，也是基于模板加上传入的参数来生成的，所以这里我们故意做了这么一个小的小的设计，让大家去理解券和模型之间的一个关系。当我们没有这个特定的状态的模型和欠的需求的时候，其实这是一个意思。
	好，那我们接着把这两个券执行一下，定义一下。定义好之后，相当于我们有了两个券了，一个叫写写简介的一个一个茜和一个写评论的一个券，对吧？就是他俩在这儿，我们能看到它已经存在了。然后我们现在需要做的事情就是在定一个外围的这个灰色的simple sequential的chain，从我们的chance模块里面去导入了这个simple check。Check它它的输入是构造一个券的列表，然后我们也把它的windows设置为true，看看它内部的一个结果，相当于就把这个定义好了。
	最终我们要看这个review，有一个细节就是我们刚刚在template里面把第一个线的输出，我们第一个线的输出作为了我们下一个券的输入。下一个券的输入是这个，就是我们的这个剧情简介，就是它生成的内容作为了剧情简介，我们也知道前面学过OpenAI的接口，学过open I的API，completion API的结果不包含这些内容，只有它生成的内容，对吧？所以它生成的所有内容就是这个剧情简介本身，而不会带上这些结果，让我们来实际执行一下。这个review就等于我们这个执行的结果，然后verb等于true。我们能看到它进入了这样的一个new simple sequent al chain的一个链里面，这个是他生成的剧情简介。他在持续的去做这个生产，这个时候其实他调了两次OpenAI的GPT3。因为我们的达芬奇003的这个API大家去想象一下是不是要了两次，并且用的是同一个LLM。然后这一部分是他的剧情简介，这一部分是他的评论，这个是使用secret al chain的一个实现。
	假设我们要实现这种多输入多输出，也就是我们这里看到的内容。其实有一个巨大的不同就是之前我们的生成的剧情简介是直接丢给他的，没有做任何的定义。现在我们要把它拎出来，至少要给人家一个名字，对吧？不然都不知道你要把什么拎出来。
	这里会有一个不同，我们可以看一看，首先我们为了给大家理解多输入，我们把这个variable也设置成了两个。但这其实是模型的能力，大家理解了对吧？不是这个欠本身的能力，是因为它的模型本身from template和模型就支持这样的一个设定，那我们把这个输入增加一个参数，比如说时代背景，不仅有标记有时代背景，然后输入仍然是由第一个欠生成的这个剧情简介，作为第二个review chain的这个输入，就这条线是不变的。我们假设不看上面这一条output a，跟上面的这个input 2，就我们的这个时代背景和这个直接输出忽略掉的话，跟simple sequent圈一样，也增加加了一个输入时代背景增加了一个输出。我们把中间生成的这个剧情简介也作为直接输出给出来。
	那这个时候我们需要干什么事呢？我们需要有一个特定的，我们给它加一个特定的标志叫做output k去高亮他一下。就我们在这这个函在这第一个欠的定义上多增加了一个参数，这个参数叫output key。这个output key就是为了我们能获取出这个output a，就我们每一个欠的输出也可以有key对吧？用key来表征它输出了什么。但是我们需要理解这个地方的output key，某种程度上和和这可以不要直接理解混了。
	如果我们把这个地方换成一个别的名字，把这换成一个别的名字也都是成立的，就我们第二个券的这个函数变量，它的这个或者说我们第二个券模板里面的这个input of various，它不受，尤其是在我们最简单的这个例子里，他是不受前面的影响的。因为我们这儿压根就没定义这个名字，对吧？我们是为了概念对齐，我们在这个simple sequence change里面，第一个链的输出结果是没有名字的。然后这完全就是我们自定义的一个名字，是为了我们方便理解，方便去去表征他给的一个名字。所以这个地方大家要一定要分清楚，它没有这个直接关系。
	对，然后我们去执行一下这个新的overall，就我们这个sequences chain的一个实例。它输入了两个参数，然后输出也是两个参数。一个是上一个simple就可以拿到的review，相当于我们之前就有的output。还有一个是第一个欠的结果也能输出出来。对我们的这个剧情简介，通过前面定义这个out the key，我们就可以把一些中间结果找到他的名字，找一给他一些名分，他就被能被拎出来，相当于我们有一个A了，那我们来实际执行一下它，首先我们看到他能够把里面的一些关系能展现出来了，这个展现出来是因为我们把这个，我们再来看看这个区别。
	这个地方我们也设置了这个verbs，对吧？但是我们在定义这两个欠的时候没有设计。大家有没有注意，我们故意做了这样的一个设计，在simple这个show chain的时候，我们没有把这个verbs设置为true。所以执行它的时候就只会看到这一层欠的结果，是因为我们把它给设置成竖了，所以里面这2个LM欠的结果是没有被展开的。我们上面生成这个公司名字的时候是有展开的对吧？但这我们没有给他做展开。在下面我们为了让大家理解清楚，我们把这两个也设置为true了，然后包括它最外层也设置为处了。所以这个verb它是作用于每一个欠本身的，然后不会有这个继承关系的。
	所以在这儿我们就能看到最外层的这个sequences chain，因为我们设置了所以它会展开。然后里面的每一个LM chain我们也设置了，所以它也会展开。那这里就会看到每一个LM券它的prompt是什么。然后这个是我们第一个AM chain生成简介的时候，它的输入是三体人是不是无法战胜的，它的时代背景就对应着这样的一个prompt，我们整合出来的直接输入进来了。
	输入进来之后进入到了第二个review圈。Review chain里面它的输入就是我们上一个券的输出结果，就是它生成的是这个内容，这个内容也作为了它的剧情简介的输入。最后第2个AM欠生成结果被放到了review里面，就我们的这个最终的结果放到了review里面，那中间的这个结果放到了这个output key叫3a process了的这样的一个词里面。所以我们就能从这样的一个运行结果里面，从新定义的在visual change里面拿到所有的结果。这样其实就能实现我们的这个顺序执行，包括我们的单输入单输出和多输入多输出。
	除了刚刚看到的这个以外，我们还讲到了transform对吧？Transform前还可以处理超长的文本。在这儿也是一样的，他们都放到了trance的这个模块下面，这个模块我们刚刚其实有有这个路径，我们给大家看一眼。在github上面我们能看到这些模块的实际的定义。
	在这个chance module下面有各种各样的券，包括我们最基础的这个券的定义。在base里面LLM的钱，还包括这个LLM request的签。Moderation这个词大家应该有印象对吧？我们做这个模型输出的一个道德规范，合规性的检查。这个券就是它最基础的一个定义，就我们刚刚在book里面有引用的一部分内容。
	这个invoke是调用它的这个方法，包括它的异步方法，它的一些关键成员变量，我们刚刚在里面也有看到memory，这个是一个已经要被遗弃的方法，整个能欠的接口和这个实现里面有有经常会遇到你的某一个调用可能未来将会被淘汰了，被遗弃了，这是很正常的，他在快速迭代。因为大家看到也不要紧张。这种警告出现之后，这种warning出现之后，你就照着他的这个提示去把它换成新的调用就好了。并不是一些很很很需要去高度关注和紧张的一个情况那这个是券，然后其他的券我们刚刚在这个地方也看到了，可以自行的去研究。我们在后续有需要的时候，我们会逐个按照需求给大家去讲我们需要的这些券。
	好，回到这transform，我们要去处理的这个超长文本是一个老人与海的TXT格式的文件，放在了我们的南线目录下面的text里面，也方便大家去基于这个文件去做别的测试。这个是一个完整的老人与海小说的TXT格式的文件。那这个文件我们会通过python的读文件流的方式，把它读到我们的代码里面来。我们也把这个重启一下。大家会发现其实这俩是最常用的，最底层的实现如果我们不用券的话，也是可以直接使用它们的。现在我们去用这个LM券和其他的券去做这个封装，实现这样的一一个这这样的一幅这幅图里面的效果。当然我们这里只使用了一个文件，这个文件已经足够大。大家如果要自己去研究的话，只需要把这加几个文件，然后就能去做汇总。我们去加载这样的一个这样的一本TST，你可以打印出来看看非常大，是一个完整的刚刚加载的这个呃小说，还有什么分解阅读，巴拉巴拉的很长。这样的一个内容其实把它收缩起来。
	首选。这样是完整的一个小说的一个结果。我们可以看到有47867这是一个字符串，有478674万47000多个这个字符的一个长度。
	针对这样的一个小说，我们要干的事情是什么呢？首先我们看比较核心的是这部分代码。这一部分代码有两部分组成，一个是引用的这个或者说我们导入的这个transfer m change，第二个是定义了一个转换的函数。大家如果写过这个，把它收起来。
	大家如果写过这个compare这个方法，就我们在实现这个排序也好，或者一些自己的一些特定应用的时候，我们经常会使用一个比较的方法。这个方法也是在面向对象里面去处理，具体应用的时候，经常会去重去重新定义的一个方法。因为它根据你的业务场景不同，很多时候我们不只是比大小，我们可能还会比一些别的方式，比一些别的维度的内容。这些内容是这个语言本身没有实现的那我们就需要去把这个比较函数去做一个实现。类似的这个转换函数我们需要处理文本，这个转换函数也是我们需要要去实现的。但具体怎么实现呢？其实就是输入一个字典，输出一个字典，输入的字典是我们没有处理的原来的这个内容，输出的当然就是我们处理好的内容，这个非常好理解对吧？这儿我们看看它具体怎么实现的，就有一个transform的函数，这个函数就是把我们的输入的内容放到一个字典里面，然后把我们的这个输出的结果分段。
	不是就你可以理解成我们假设我们现在需要处理的一个情况是输入内容太多了。然后输入内容太多之后，我们有多个文件，每个文件内容都很多，我们需要把一些输入的内容先分段，分段之后我们不想取这个完整的内容，我们可能只想取一些前面的内容。因为通常来说就是一些在学小学语文也好，学中学语文也好。我们都知道要理解一快速阅读，理解一篇文章的内容，这个段首和段尾是比较重要的那现在假设我们写了一个最简单的转换函数，它只去取这个段首，或者说这个文章的前面几篇内容，这都可以通过我们这儿去自己去研究和实现。
	根据你的需求，假设我们只去取前面的这几个内容，并且用两个换行符做连接，然后拼成一个新的内容。这个新的内容有点类似于原来那个内容的这个部分精华。因为它只取了段落的前面部分，也是断手的一个部分，凑成了一个更短的文章。更短的文章我们放到了这个以output text为T的一个字典里，这是造了一个字典，这个字典的key叫输出的文本，内容是我们把处理好的又拼接起来之后的这个更短的版本的文本，就干这么一个转换函数。
	那这个转换函数是什么时候用呢？是给我们的transform chain作为输入的。大家可以看到这里有一个transform券，然后这个transform chain它的input variable和output variable就是这个转换函数的钱前后的一个内容。大家仔细去看的话，output key就是output text。这个output variable取得是这样的一个内容。Output the text就是我们最后处理裁剪处理好之后的这样的一个key所对应的value。这个结果输入的是我们的这个test，就是我们的输入的转换前的这个结果。然后有这么一个transform券，所以这里的核心变成什么，大家就会理解这个transform券。
	其实这个transform funk本身是比较重要的，因为它是用来指定这个transform券可以做什么事情的。并且且我们知道当它变成一个确认之后，我们还可以去做很多其他的串联的操作。并且把它不只是放在我们的一个sequences chain的开头，甚至可以放到中间，放到后面，放到任意一个位置。因为它本身它定位就是去做这么一个事儿的。好，那我们去做这样的一个执行之后，我们可以看一下，我们有一个transform chain被我们定义好了，它定它的处理方式是这个地方定义好的一个转换函数。它的输入是我们刚刚加载好的这个完整版的这个老人与海，那我们把这个执行之后变成了一个transform的一个level，对吧？这个test是原文。
	我们。首先我们知道这个transform的这个novel是一个key，它里面有很多的key对吧？有这个test这样的一个key，那我们看看还有什么别的。我看一下能不能识别到，他不能，那不能用这样的方式给大家展示他有什么key了，应该是有一个可以查看他key的方法的。但anyway，我们核心是知道这个字典，它的原文就是我们的处理的这个文章。它输出的这个结果就是我们处理好的这个结果。然后它还没有red，所以它里面只有这个原文，我们执行之后，就可以得到一个处理好的结果。我们可以。
	这个是他处理之后的结果，就是我们拿到了这个transform的方式处理之后放到了这个of the text里面。我们整个transform的level就经历了这样的一个transform的一个方法，经过这个转换，函数变成了一个处理好的结果，放到了这个out of the t里面。
	然后通过这样的一个方式，其实我们首先可以手动的去执行这个transform钱，而不是说把它直接放到一个show券里面。我们可以单独执行每一个券，这个大家应该还记得对吧？那我们刚刚就手先手动执行了一下这个transform的一个券的一个结果。当然我们也可以把它串联起来，这个串联就是说这个文章太长了，我们即使这样处理之后，好像还是不知道他讲了什么内容，假设我们没有看过这篇小说，那我们要怎么办呢？我们希望下游有一个欠去帮我做摘要，他其实就是把每一段里面的内容都提出来，然后再去做摘要，就干这么一个事儿。那我们定义有一个总结下面这个文本，然后我们还需要这个模板是留了一个家庭作业，是希望大家能够把这这个是复制过来有点问题。待会我们再看这个家庭作业，其实是希望大家能够做一个工作，就是按照我们刚刚那个课件里面写的，把那几个全部串联起来。
	我们输入的是一个各种各样的文本，然后通过transform chain，然后再通过一个router chain，然后能够去判断我要去做翻译，还是去做摘要。然后最后再去根据这个不同的具体的LM线，去执行这个实际到底是做摘要还是去做翻译的工作。大家看那个课件就好，这应该是我们复制生成的时候多粘贴的内容。
	好，现在我们接着去看这个实例，我们定义好了这个transform前手动执行的这个结果，然后我们也可以再去定义一个用来做摘要的一个特定的LM线。它的模板很简单，就是总结一下文本。那这个文本是哪来的呢？这个文本其实就是相当于这个地方transform的这个level。
	我们定义一下，这儿需要注意一个细节，就是我们在使用这些欠的时候，其实已经在实际的调用这个大模型了。尤其是后面这个不是指前面这个，就大家理解一下，我们其实在这个transform的时候没有直接调大模型。但是在调这个方法的时候，我们把它传了一个OpenAI进去，会实际调用大模型。
	尤其是处理这种比较多文本的时候，第一如果你处理不得当，你可能直接就会超过它的这个token的限制，然后你还会浪费这个token。因为超过限制的时候通常已经是大几千了，对吧？那第二就是说如果你想要去把它处理好，然后你把它改成把它分割成了，比如说3000万或者4000个token。但你一不注意，你就直接去执行了一个sequence券。那这个时候，这个sequent券可能他就会一直跑。因为我们知道他现在可以把它分批了，然后分批之后再分别去给L去传。那可能你一下就跑了好几万个token或者几十万个token。
	针对这样的情况，我们之前介绍过一种方法，就是你在OpenAI。如果你调的是OpenAI的话，你在OpenAI的这个管理界面上面去做一些设置。这个设置是指你的你当前的这个organization，它的一个上限是多少？它上限就是用五美金，如果超过5美金他一定会停下来。因为他已经到达你设置的这个调用上限了，他直接服务端就给你提下来了。
	还有一种方式是你可以像我刚刚讲的这样，在这个例子里面一样，你去手动的去处理这些文本内容。你先大概了解一下它的这个实现的一个原理和过程。你对这个部分有一个充分的了解之后，你就可以去玩这个更复杂的这个券的一个设计了。但是在非常熟练它之前，我们也是希望通过这个notebook，这个transform chain的notebook让大家去理解。第一，这个欠肯定是可以分开执行的，因为这个是eno茜也是把它串起来执行自动化的执行两个就这么一个功能，所以它首先能分开执行，然后不是每一个chain都会去调大模型的。比如说transform券，它核心是实现了一个transform，自定义的transform，你可以用来处理文本，然后你自定义的这一部分内容就可以转换成一个欠了，而不是一个python的函数。那它如果是一个欠，自然就能跟其他的调大模型的这个欠统一的被sequential欠进行管理和调用了，这是第二个点。
	第三个点，当你去手动处理好这些文本之后，你还可以再去手动的执行这些调真正open IPI这些大模型的接口。就比如说我们这里再来看一下，这应该使用这个output。好，我们刚刚看到我们手动执行了一下这个transform，它变成了这个transform的之后的文本放在了output key里面。然后我们只取这个output key里面的前100个字符，然后我们执行一下，看看会发生什么事情。我们可以把这儿设置为主。让大家看的更明显一点。
	大家可以看到我们只给它输入了前100长度为100的这个字符，而它拿到的这个完整的prom就只是这么一点点内容，是一个小说标题作者他总结出来的，其实没总结多少内容。这个应该大概率是因为他本身有老人与海。因为这两个信息很重要，就是这这两这本小说太有名了，所以他能给出一些这个内容。但是一些其他的小众的文本就不一定了。那现在假设我们给1000个，相当于应该是集美几美分。我们把这个内容传进去，它会给更多的内容，会有一个总结，但这里消耗的时间就会多一点了，还在执行。总这个部分的text才是我们后面输出的这个结果，我们总结的结果是放在这儿的。老人与海是一本海明威著的小说，讲述了一名渔夫很倒霉巴拉巴拉这样的一个结果，我们当然也可以用sequences把这两个编排起来。
	因为这里没法再手动控制第二个的这个结果了。我就简单一点，把前面的这个内容少一点，不然会超过限制。为什么会超过限制？大家应该也能理解对吧？刚刚手动执行的这个过程，因为我们如果在输入这一侧，就相当于在执行transform chain之前。我们如果给了整本小说，那就整本小说按照我们现在这个处理方式，就是这部分内容就都会丢给我们的后面的这个LLM欠，那这个LM欠就拿到内容太多了。第一没必要花这么多钱做demo对吧？给大家演示。
	第二有可能超过限制，而实际上它会超过限制的。所以我这就只给他前100个字符，作为整个sequences券的输入。这里大家发现，因为我们刚刚把这个LM chain给verbal设置为true了。所以在sequential chain里面它也会看到，我实际给它传入的这个内容是这一部分的内容。然后在前面的这个transform前，他没有去把这个内容展示出来。
	这个是我们的transform chain它的一个最重要的价值。不是说它过度抽象和过度定义，而是说通过这样的一种手段，使得我们去处理文本的这些方法，函数模块也能变成一个欠。而当它变成一个欠的时候，它就很好的能够跟其他的欠去做编排和调用。就比如说能变成一个sequential欠当中的一个模块，或者说变成一个rotor chain当中的一个模块。
	好，那我们再看一下rotor chain是如何使用的，这个也很简单，我们再重启一下，让它更干净一点。首先我们仍然是会调用OpenAI和LM chain以及我们的这个prom template作为很基础的内容。然后同时，他还掉了一些别的欠，我们刚刚没有讲到的，但是从名字上应该也能很好的去理解。我们在实际使用中大家就能知道他们干什么的。一个叫conversation chain，一个叫market，prompt the trend。
	首先为什么会出现conversation change？我们刚刚有讲过，不是每一个大模型都支持聊天对话模式的。那么通过conversation chain可以让一些不具备这个模聊天模型聊天对话能力的大模型也类似的拥有这样的能力。有人欠来维护这个聊天记录和状态，这个是一个很常见的一个情况。好，那我们执行一下。
	下面我们定义了两个from template，这两个prom time plate，其实只有俩字符串对吧？我们上节课也讲了，没有什么神奇的prom就是字符串。一个是这个物理老师的非常聪明的物理教授，擅长回答很多物理问题。当你不知道某个问题答案时会坦诚承认。另一个是数学数学家，数学老师擅长回答数学问题。回答数学问题的时候，大家可以看到这句话的这个prom的描述，将难题分解成各个组成部分，先回答组成部分，然后将它们整合起来回答更广泛的问题。
	比如说我们之前讲的这个step by step也好，或者叫这个chain source也好，类似这个prompt这个trick，那好，我们把这两个分配它定义好，定义好了一个prom info。这里面就相当于看这个大家应该很有感觉了，跟这个方向后的搞法很像。大家先别管，反正就这俩对应着他们的像是这个函数一样，已经很像函数了，对吧？
	一个列表，然后我们再去定义一个model，默认使用这个OpenAI的这些参数，然后创建一个空的目标链的一个字典，就有一个destination的欠的一个字典，我们从这儿再细看一下他这个破循环的函数干了什么。第一他去follow了这个prom的input，就是这儿佛洛普的这个其实就只有他们俩被挑出来。第一取了name就取了它，物理取了这个template，那template是什么呢？Template的其实就是这个，对吧？
	是为了好看，我们做了两个两个notebook单元的定义，为了把概念理清楚，这个是模板，这就对应着它创建了一个对象，那这个对象是干嘛的呢？就是模板，就是这里的模板。有一个variable是叫做input。因为这里所有的模板都需要有一个input作为input variables，定义了一个券，那这个券是用我们这儿的这个LLM，然后和这的这个prompt。这个跟我们刚才讲这个simple security chain的时候很像，对吧？
	并不是说每一个LM chain都需要一个大语言模型的实例。当我没有状态的时候，我就用一个实例就好了。为什么？因为其实每一个实例都是在给，尤其是像OpenAI的API调用，都是带给OpenAI的这个API and point给API的这些给OpenAI的这个API服务去做调用的。然后你内部去跟他做管理的这些调用越简单越好啊，他其实就这么一个意思。
	所以大家如果看到这样的一个情况，也不要吃惊，就复用这个LM实例就够了。有一个destination change，我们这儿有一个空的字典，这个空的字典里面塞一个key value进去。Key是什么呢？Key就是物理或者数学，对吧？我们每个老师有自己的学科，这就是物理。
	确认是什么呢？欠就是我们封装好的这个LM券，这个封装好的LM券有一个template，template就对应的这里的这个complete，对吧？那还有一个描述OK然后接着我们创建了一个conversation chain，这个conversation券有一个output key，所有的chain他们的有很多的抽象的好处就在于out of the key什么概念？刚刚已经讲过了对吧？他把这个输出结果放到这个text里面，这我们也不赘述了，我们去去运行它，这个地方的这个defer就是一个conversation change，这就也就不再展开了。
	接着我们做什么事情，我们在下面去导入了这个LM这个线和这个route，or put the other, 我们看看具体做了什么内容。第一从我们刚刚的这个prom info里面取出来这个destination，就这个目标，那取出来结果是怎么取的？就这个地方的name就是我们的物理，对吧？适合回答物理问题。大家还记得这个地方适用于回答物理问题。物理其实就我们这儿的这个结果，这个构造成了一个f stream，就我们python里面的一个f stream。我们可以待会儿执行完了，把destination输出出来给大家看一看就理解了。把两个不同学科的老师，本来是这个destination是一个列表，把这俩列表里面的结果再拼成一个字符串，这个字符串通过这个marty prompt router template的format方法。
	首先这是一个temple ate protected ate，通过封面方法就是真正去生成了我们的一个特定的prom，对吧？就相当于它本身就是一个可以充分复用的一个模型。这个人券框架内置的一个提示词模板，他也有他的封面方法，他也有他输入的要求。输入的要求就是构造出了这么一个结果，这个是造出了一个root的prompt，这个root的prompt，它的这个模板最终需要的也是一个输入而已，跟我们最终连接起来的每一个一致。然后他也给他预置导入了一个output的power。这其实跟上节课的很多内容都已经关联起来了。
	首先他需要有一个模板来做这个ten play，就是具体这个from ten play实例，要去实例化的时候要有一个构造函数，这是一种方法。这个构造函数的方法里面要传这个特定的complex怎么来的？通过类似的一个造字符串，造这个特定字符串的方法来的。但它其实是造了这个模板，就相当于一个模板的原模板。
	大家理解的话有一个meta prom的template叫这个marty prompt rotor tempted它的format方法造出了真正的一个提示词模板。这个提示词模板是root prom的所需要的我们应该有太多次提到了meta这个概念，我们先往下看，这忘了执行这个导入了。对，好，为了让大家理解，我们把这儿的一些中间结果输出出来看一看。
	这个destination就只是一个列表，对吧？没有那么神奇。这个three是可以直接运行，也只是把这个换行符能够打印出，也只是造了一个字符串，中间有一个换行符，用默认方法当然就会把这个显示的好一点。然后这个router complaint，其实也只是为了造一个提示词模板，对吧？大家说不理解内部语句，这个其实就是我们相当于从这个marty prompt router complete这样的一个。大家也可以去看源代码，这个都不复杂。相当于从这个rot的推荐的写这个prompt的方法，就是直接用他自己的这个实现方法。当然如果你能写出更好的那也可以。
	但这我们就会涉及到另一个上节课想要讲的概念，就是format的方法有很多种。你看他其实就用了各种各样的分隔符。大家如果去研究的话，这个是他首先这个是原模板这个玩意儿对吧？这个应该也是可以输出的，我没有理解错了。
	大家细看一下这个嵌套逻辑，包括我们去理解python的一些基础概念。大家看这个是梅塔prom temple ate，这个是prompted plate。然后这个prom template可以接受一个input作为input variable al。但是这个meta prompt the time plate，他接受的是这个destination，对吧？然后他的input被解包了一次，变成了一层化括号。这个一层化括号是这个ten place真正变成prom的时候要填入的参数，这个留在这儿，到时候我们也上传到这个代码库，让大家去理解这个过程。我把这两个顺序换一下，这个是逐渐解码的一个过程。对，很有必要的去理解一下这个过程，这是原模板，这个是。
	一次填充参数之后的一个结果。这个destination就是我们这填写出来的这个destination script，填进去了之后，下一次我们真正要实例化，要实力化这个欠去运行的时候，这个input就是我们要填的这个具体的方法。这是非常常见的一种使用方法。
	给大家去细想一下，sequences券是在券的运行上有一个顺序逻辑，而route chain是在欠的运行上有多层。这个参数需要被多次传入，逐渐的去解码，那就能很好的去用这个多层逻辑，这个就跟这个盗梦空间一样，对吧？你在深沉梦境的时候，当然这个框框就多一层。但是你在浅层梦境的时候，这个深层梦境的你都看不到，对吧？
	大概这个意思，大家玩两下就能理解。然后这里我们把这个market from the chain给定义好之后，然后我们问一些问题，这是你看他也给了一个warning，就是这个predict and pass方法很快要去的了。那大家也可以在我的这个上传之后去看一看，我们应该用哪一个欠来把这个窝里消除掉，使它的这个更新的方法，这其实是output power这边的一些要求。
	那黑体辐射是一个什么问题？黑体辐射是一个物理问题，对吧？然后大家去想它内部是怎么执行的，它内部执行的过程应该是黑体辐射是什么？传到了这样的一个rotor template里面，相当于把它替换成了这个结果。我们把这个结果又传到了后面的具体的2个LM圈里面去实际的运行。他判断出来这个黑体辐射是应该更适合回答物理问题的这个LMT来回答，有点类似于我们的方向框里，对吧？
	大家仔细去想这个地方，我们去定义他的时候，是不是很像我们之前学的function calling。Function calling的很多实现跟南县这个地方要做的事情是一致的。就是由一个大模型判断后面几个大模型的能力是什么。我现在这个问题适合给哪个大模型去处理，差不多这样的一个逻辑。
	还有一个数学问题，比如说大于40的第一个质数是多少，使得这个质数加一能被三整除，43。因为这个43大家自己去看一看就知道43 44能被这个完了，我们这就不在赘述了。时间关系，整个欠的例子就到这为止。
	我们留了一个homework，刚刚粘贴过去的应该就是这个地方的homework。然后mark是说我们把这个LM router chain去再做扩展，再多扩展，其实底层是用的它，对吧？那我们把这个market from change的扩展成还有其他几科老师，比如说有生物、计算机、汉语言文学。
	这几个老师如果我们要做扩展，其实也很简单，大家去想一想我们要做什么事情。第一，我们需要给这几个老师，真正干活的这些老师，这些LMK设计一个template。第二给他们一个name，相当于这个LM券。如果作为一个函数，需要有一个函数名，有一个describe去描述它，然后让我们前面的这个marty from的键能知道他是干啥的。我们的mm process甚至自己本身都不需要去做调整，他只需要把你新的这几个后面的LM券加到这个负循环里面来。其实就这段话都不用改，对吧？
	当然如果扩充了prompt info，那这个地方的负循环自然就会有其他的几个老师，这个destination string也会有其他的老师。这个地方拼出来真正的这个candidate prom也会有有其他的老师。然后最后去执行的时候，自然就会有其他的老师来回答问题了。这个解题思路就是这样，非常简单。那么看看大家现在有什么问题，我们来回答这个五分钟的问题，留20分钟的时间，我们来讲一讲最简单的memory。
	Transform chain仅仅是包装使用自定义转换的函数满足欠的接口吗？在我们的这个事例里主要是想强调这一点，它提供了一个入口。你可以这么理解，首先transform券它是基于最底层的这个券，我们把它放到了每一个。Special chain里面有写，这个transform chain它的鸡肋是我们的这个券，这个券它可以使得其他的券能够来调用它，也就是它的可组合性。首先transform券提升了它的可塑性、可组合性。并且我们可以假设transform券他不他不是一个sequential茜或者router chain的第一个欠的时候，我们希望它能够被观察到。如果你不去做这样的一个封装，不把它变成一个欠的话，你也可以实现类似的功能。
	我更麻烦一点，就相当于你现在有一个乐高玩具，乐高玩具大家都是用同样的接口，一个圆圈圈能拼在一起。那你觉得你现在做了一个外部的工具，这个工具是你给比如说我们刚刚看到的这个孙悟空的这个玩具，你给他做了一个金箍棒，那这个金箍棒是纯外部的，他不需要跟其他的欠交互，那也行，你就直接给他放上去。但他如果需要跟其他的欠交互，那这个时候我们把它变成一个嵌，有一个统一的底座，能跟别的拼在一起，那是不是很好？这个就是transform欠被设计出来的一个很重要的意义，最重要的意义之一对。
	然后我们不可能把所有的券都跟大家讲一遍，今天讲的这些欠是最重要的几个，我认为是最重要几个概念。其他的一些券都会都是更偏功能性的，而不是偏所谓的meta knowledge这个层面上的。我们再来看一下这一幅图就知道了，就是在这幅图里面transform chain它的价值是在于其他的函数，非大模型的函数可以变成一个欠，然后由欠的方式来统一管理茜everything对吧？然后条件判断的这个事情可以通过AM router欠下面的marty from的欠来实欠。
	不同的最小单元的LM券是可以用来调用各种各样的模型的。比如说调用我们的OpenAI，调用我们的GLM，调用我们的lama都可以。然后我们还可以通过sequential change去完成一个链的编排。
	这个输出不稳定这个输出不稳定两个方式。第一是你的prompt要相对来说稳定一点，你要把prompt做好。第二就是说你使用的这个模型本身是有这个temperature的能力的。我们刚刚留了口子，就是想让大家去研究。当然我可以给大家提供一些思路。第一就是那个prom要设计好，让它足够稳定。第二，比如说我们刚刚用的是达芬奇003的temperature设置的0.9，那它本来就是要求它多样性，那就算调到了同样的APIN的point，它也会不一样。这是因为我们的参数就是给的让它不一样，temperature这个参数就是让它不一样的，就是这个参数设置的高一点，它就是会不一样，就是by design。
	第三个就是说我们在比较复杂的嵌的编排的时候，我们可以把这个verbs打开去看看你的这个prompt是不是每一次都不同。如果的不同，首先想想办法，你是本来就要它不同，还是让它相同？相同的是内容还是格式等等，包括我们刚刚看到的这种meta prom template的用法也很重要。对，这个康铭老师也提到了，对，就是这两个关键点。
	然后这个问题是留给大家的，就是我故意留了一些设计，就是希望大家能动手去试。就是这个LM的router chain这个条件判断到底它是怎么实现的，大家可以自己去研究，包括把这个make up from展现出来给大家看，就想让大家去了解它是不是通过大语言模型实现的？好问题，我觉得大家可以去自己动手试试。
	对如何实现处理超长文本内容，这个你可以上网搜一些拍整。首先你要怎么处理它，就是处理超长文本是一个单聊，处理超长文本是一个没有意义的词。对，处理超长文本第一件事情就像这个康老师讲的，要先切断，切切成多段。切成多段之后你要怎么玩，那是你的任务驱动的事儿。然后网上包括GPT4应该也都能生成各种各样去处理这个文本段的这个函数，根据你的需求描述。可以使用root chain封装不同的GLM模型吗？对，首先root chain不是用来封装的，root chain e的prompt temple都给大家打出来了。
	就是router欠的核心是用来判断什么样的输入适合给什么样的下游的输出的券去调用。他是干一个撮合的事儿，干一个条件判断的事儿。然后下游具体要有什么样的能力，第一看你下游的prom写的好不好，第二看你的描述写的好不好。至于你的描述这个root can是怎么样去用的那这个时候就是我希望大家能动手去看看的对里面嵌套了那么多个LLM token的消耗怎么算？第一你需要去知道你的不同的LM掉了什么样的模型。然后第二就是说你的prompt才是真正给到模型去消耗token去计算的。包括你生成的这个输出的这些completion也是还一直有同学在问他怎么做的条件判断，这个大家都动手自己去试一试，这个是最最扎实的掌握方法。
	对，如果是有多个转换函数是在一个里面调用还是需要多个，这个完全看你的需求。你放在一个里面如果能稳定的转换，那当然是没问题的。但如果你转换之后，你需要大语言模型帮你判断你还需要处理什么事情。那你就把它们拆成两个，中间嵌一个别的。对，已经9点42了。
	好，那我们接着再把memory的最基础的部分给大家讲一讲。好memory最核心的是什么？首先大家不要把它想的特别难，有memory system在我们的这个系统里，也就是干两个事儿，跟我们之前讲model IO模块的时候一样，让大家理解清楚。首先我们看这幅图里面，有一个model IO的部分，就是这有一个虚线框，这个虚线框里面其实是model IO，就我们有prom template，有这个model，有off power，是抽象的概念，而不是说这个model IO本身是一个python的模块，或者说南迁的模块。它是把这个跟模型的相关的高度输入输出相关的放到了一个model IO里。但是我们今天讲的这个prompt tempt和model的实例化的对象，可以把它丢到一个嵌里面，由欠来进行管理。让我们把欠放在这个位置的概念就是说，第一，这个欠需要prom tempt也需要model来实例化它。同时我们在讲Facechain，讲这个chain的鸡肋，就class chain的时候，我们有提到它可以有状态，对吧？
	因为他自己可以维护memory，所以你可以理解成这个券和memory通常是一对儿相互协作的一个关系。就跟我们prompt是根据你的任务来的，你有什么样的任务你就写什么样的prompt。那你有什么样的任务，你需要记下什么样的内容，记下什么样的一些之前的。你不管是你说的prompt还是大模型给你的那个结果，你都想要记下来，要去维护这个结果。
	这要去干这件事儿，由memory这个抽象这个模块来干。他要做的事情就是去记录你的结果。所以我们可以看到右边有一条线，这个answer是什么呢？就是通过output power规范化的结果，你希望把它记下来，写到memory里面right对吧？Memory的第一个事情就是要记记忆对吧？先记下来也可以recall，就是把这个memory给召回，或者说想起一个记忆中的事情，怎么想起呢？从这里面读出来，对吧？从这大家能看到这有一个memory，这有一条线往上给券，我们刚刚讲券的输入的时候也说了，券可以是用户输入的，也可以是memory提供的对吧？
	假设我们是一个chat API，那我们就会维护一个message的列表。那这个message的列表，我们之前看到了我们使用这个chat model的时候，model本身要帮你维护。但如果你使用的不是check model，因为你不可能一个圈里面每一个都check model，对吧？那如果你是把这个记录是放在最外围的，就是放在了这个sequential圈或者root这一层的。那他可能就放在memory比较合适了，而不是放在这个model里面比较合适了。
	你从你需要的具体的这个场景里面去取这个memory，他会写一个叫做past message，就过去的一些信其过去的一些聊天记录存在这儿，就是把之前你回答的一些结果，甚至你之前问的一些结果都存在这儿，然后就会组成一个更新的prom。这个problem你就会看到既有我的question，又有我的past message，对吧？就本来question是我没有记忆的情况下就给question就好了。如果我有记忆了，还能给这个test message，就我之前的一些聊天记录放在前面，就是我们一个典型的聊天模型的一个prom的一个模式，对吧？甚至你还可以分角色分肉，那就是一个非常简单的一个模式了，对吧？
	我们把这个prompt就整明白了。Prompt可以是用户给的，也可以是去memory里面找，组合成一个更完整的带记忆的prompt。然后这prompt可以在大模型输出之后，再写回到这个memory里面。
	这个就是一个高度定制化的一个系统，记忆的这个系统就是一个我们叫X圈，就是指你可以为你的任意的一个需求去造一个X圈。就比如说你可以完全把transform change当成一个空盒子，任何transform function都可以组成不同的transform chain，只要你愿意给他取名就好了。不同的transform change，如果假设transform change需要用memory，你也可以给他定义不同的memory。根据你的需求，所以是完全可以搭配着来用的，一个高度定制化的系统。
	假设我们有了memory之后，我们的版图又全了一点，我们蓝线的模块乐高又多了个颜色了，我们现在能用三种颜色的积木了，有模型，有prot，有memory。然后今天我们会涉及到这个conversation相关的memory，就是一句话来总结，就是给那些没有聊天能力的模型和欠付，能让他们变成有记忆力有聊天能力的大模型应用，然后把他们三人串起来用，然后这就至少我能用一个非chat相关的大模型实现chatbot了，是不是？这就是很典型的一个场景。比如说我们一直在这个notebook示例里面用的这个text w7003，它就没有chat的API，但是使用memory它就能记下来，记在我们的券里面。
	好，那我们实际来看看怎么玩的。老规矩，重启一下。刚刚我们讲的这个大的逻辑，在这也有介绍，我这就不再去再讲一遍了。核心就是memory，就干两个事对吧？一个记一个读，然后记就从这结果里面记一些新的新生成的结果以及相关的。然后读就是在要用的时候去读，然后还是要讲一讲这个类的继承关系，这个跟大家去理解南茜，长期的去关注他非常有必要。
	首先它有两条线，两个鸡肋，一个是这个base memory，一个叫base chat message memory。这俩大家可以看到base memory，base chef memory，你可以简单理解成就是base memory，就是一个非常基础的鸡肋。这俩抽象应该大家已经看到很多了，对吧？一个序列化的一个ABC的ABC大家还记得什么含义？上节课专门有讲。然后这个应该是指这里的记忆，我们可以统一叫记忆，叫内存这个翻译问题。还挺多的，待会这个上传之后，大家有热心的同学帮我把这些刷一下。
	这里的记忆指的是就是我们欠当中的一些状态。其实这个状态核心就是指刚才说的生成的结果和我们给他的一些front，包括你任何你想记的内容，你手动去造一些东西让他记下来也是OK的。然后一些常规操作，比如说我们这个clear方法，这是非常关键的，这个清除记忆了对吧？
	可以的方法，然后可以去存一些上下文，就相当于我们的去去right就把我们的这个生成的结果存下来，还可以去加载一些记忆当中的变量，这个是它比较好的一个抽象。我们知道字符串，但是prompt又不只是字符串，因为我们有prompt template，就是这儿。这个时候我们会发现，如果我们有prom time plate的时候，这个字符串里面有的就是写死的，相当于我们写代码的写死的常量，还有一些是变量，它能区分出你记下来的上下文当中哪些是变量，所以它能加载一些变量，就这么一个意思。
	然后在这个适用于聊天模型的这个base chat message memory也是一样的，有适用于聊天模型的积累，这个大家有兴趣可以去看啊，这里维护了这个list message，相当于聊天模型最大的区别是什么？大家应该理解对吧？它能区分角色，这个是一个很常见的一个抽象了，我这就不再赘述了。
	但是这稍微多说一句，为什么聊天模型还需要这个memory的抽象？最最最直接的就是我们下面会讲的，即使是聊天模型它能维护上下文了，你也不可能每次都把历史记录全部给他，对吧？你是不是也得维护一个你想要记下来的聊天记录。这也是我记得在第一周还是第二周讲的时候，很多同学在问的。就是我怎么样去维护一个message记，既不会超过限制，又经济又实惠。那通过这个memory是一种方式，就不再是手动维护一个message列表，而是通过memory来维护。
	好，那我们就实际的看一看这个例子。很简单，举个例子，三个例子。一个是这个conversation的这个buffer memory，对应的就conversation chain，我们赶紧用过。一个是我们的这个conversation buffer window memory，还有一个是下面的这个conversation summary buffer memory。名字越听越长，我们看第一个，这个是用来干嘛的呢？这是最最常用和最简单的一个memory。
	它用来就是用来传消息的，把消息还能提到变量里，具体是怎么执行的，我们看一下，因为我们这一个配套使用的这个conversation change，我们把这个verbs打开，咱们就能看一看。这个memory是欠所有的券都能够去用的一个成员变量。这个是在券的鸡肋里就有，大家刚刚有讲过的，然后我们可以去把这个conversation buffer memory作为这个conversation chain的memory方法，或者说memory的实例，就可以用它的默认的参数。这个时候我们可以用这个predict方法，去实际看看他干了个什么事。
	比较简单，首先我们用的是temperature等于0。刚刚有同学问怎么让他结果稳定，别让他说胡话，temperature降为零就好了，他就不会有什么多样化的结果了，给你的都是相对确定性的结果，即使是达芬奇003。然后我们给他输入了一个hi there，可以看到它内部这个conversation chain里面使用了这个conversation buffer memory之后，内部有变化。它不再是一个LM券，他是一个conversation check。他干了什么事呢？他有一个prompt after formatting，这刚才已经讲过了，就是他实际这样的这个from。所以从这儿来看看，大家要理解，这个跟你直接调API的区别，就是你之前是high there，但他实际上会帮你维护这个上下文，所以这个是他发给tax，达芬奇003的front这里会写这个。The following the friendly conversation, because human and AIAI tecture and provides lots. 
	八两大堆，如果这个AI不知道这个的答案的话，就是说他不知道，就知之为知之不知为不知，对吧？然后下面这个prompt还专门能把这个区分了，分了行。相当于这个像是一个system的一个role的一个prompt。这个是维护了一个当前的message列表，然后这里有human说了hi there，然后给他AI，让他来生成AI应该说什么？AI说的是idea is nice to meet you，how can I help you today? 对吧？接着来再来一下，再运行一下之后，你会看到prompt变多了，他把你刚刚hi there和这个达芬奇003回复你的这个内容，hi there, nice to meet you. 
	How can I help you today? 也放在这儿。所以这是你第二次调用它的时候给的prompt，他帮你把这个维护起来了。即使达芬奇003不能聊天，但是通过这个方式，达芬奇003知道这里有一个conversation，这里有一个对话的语境和上下文，和这个话是谁说的，man说了什么，AI说了什么，human又说了什么。And doing well, 对吧？Just having a conversation with the AI great. 
	我们可以看到它的一些回复结果，我们继续tell me are about yourself。这个聊天记录仍然会被记下来。所有的这些聊天记录的维护，包括这些prompt，这些东西都是通过conversation chain和conversation buffer memory来实现的，就是能欠自己实现的关于对话的这个欠的一些内置的以及预定义的一些实现，非常简单。大家能看到他最后是写了这个show，对吧？然后这个我们就不再赘述了，这个是它的一个最基础的实现的版本，让我们的普通的大语言模型也能对话，然后他也能帮你维护，但是这就有一个巨大的问题，就是好浪费，对吧？我今天做这个课件已经浪费了不少token了，一直在跟你说这些有的没的你都记下来了。
	然后那有没有一些方法是不要这么浪费吗？那那很简单，就是用这个窗口，用window，我们这也是编程里面经常设计的一些做法。就比如说我不用把从出生开始的所有话都记下来，对吧？我能不能就记最近的一些话，就跟这个时间窗口一样，就是我只记最近的几次话。那这个buffer window memory，conversation buffer进化成了conversation buffer，window memory加了一个窗口对吧？那窗口就是说我只记最近的几次对话，这里要有一个参数叫K这个K其实就是用来记最近的两次对话的。如果我们传承二的话，那传承一就只记上一次对话。
	好，那我们来看看他怎么玩的，直接执行到下面哗哗哗的全是头疼是吧？虽然没多少感受是这样的，这有一个区别在哪？大家可以看到我们一开始说的是high there，对吧？High there doing great. 到最后的时候我们最后一次调用他的时候，他只记得最近的两次对话，hi there一开始的这个信息已经没了，没有再给你说这个high there，他只记了最近的两次对话，就是完整的框是这两次，他只记得最近的这两次对话。当然你可以调整这个K的值，让他记得这个不一样，记得更多，甚至这个memory你还可以让它持久化存下来都可以，这儿我们就不再赘述了。
	这个是加了一个窗口，那加窗口有一个好处是说好我token节约了。但是万一他就是比较聊天的时候技术不是很好，他就是这东辽一句西聊一句，这窗口就框不住？那怎么办呢？还有一种方式是，那行，那我前面的我虽然我不再去把它作为token直接丢给大模型了，那我给他总结一下，保存一些摘要，这个就是conversation的summer buffer memory，就是我把之前的一些对话内容给它summary一下，然后存下来，其实是不是也很简单直接对吧？这个就是使用这个conversation summary buff memory的一个方法，它其实就是保留一些最近的交互缓冲区，就相当于他就只保留最近的一些对话。老的一些对话，他就用来通过这个标记长度的方式来决定我到底要留多少对话。我相当于不再是通过这个聊天的轮数来记录我应该存什么，而是通过我的这个，因为我其实最关心的还是token的数量对吧？那么我通过我记下来多少这个token来做这样的一个缓冲区的长度的一个保障。
	这其实是其实到这儿应该就把整个关于memory，就是我们刚好十点，我看对我们关于这个conversation的这个memory，还有一些其他的一些设定。大家可以在我们的南线的文档里面可以去看啊。在memory下面大家可以看到我们刚刚讲到的conversation buffer memory，very conversation的buffer，window的这个memory，conversation的summer这个拉不开了，conversation的这个summary buffer的memory。除了这以外还有其他的，比如说token buffer的和knowledge graft，还有一些其他的，这些都是用来针对不同的场景来做这个memory的一些手段。但是它的核心其实就是我们看到两个鸡肋方法里面的内容，就我们能够存下来，然后能够去加载它，然后能够获取，然后也能够去清除。
	如果是聊天模型的话，我们后面会去讲到聊天模型里面的memory。他们可以去针对不同的角色的信息去做添加分类去存，分类的去取和抽象。分类的去取需要你自己去做一些根据你取得这个场景和方法的一些实现。所以整个memory是一个高度自由的一个你可以认为是一个高度自由的一个维护，跟大模型聊天内容的一个接口的一个方法。它使得我们的券有了更多的有状态的一些保障。就是我们在讲这个券的激烈的时候，这样的一个好处是可观测可组合。现在有了memory之后，它是有状态的那这个状态我们有各种各样的手段去维护它，去保存它，去加载它。接着我们再回答这个问题，到10点10分，看看大家有什么问题。
	大家提提问题，我们到10点10分，老师可以简单总结一下，今天讲的难确吗？挺好，这个问题挺好的。我们来总结一下今天。今天我们其实主要讲的这个两个模块，我们回到目录，我的鼠标需要切过来。今天我们其实主要讲了两个部分，都是以授人以渔的方式在讲。
	欠是大模型应用的最佳实践，因为通过欠我们理解了连线其实就是像乐高一样，把很多好的东西做成了一个的基础的模块。通过线把它连接起来。比如说我们的模型，比如说我们的prompt，比如说我们的memory和我们即将要讲的agent都是一个一个小的模块。这模块通过统一的接口串起来了，那券就是用来定义这个接口的，然后所有的具体的功能都是在这个接口上面，像磊乐高垒积木一样的做成了各种叉叉欠LM茜茜transform键、root键。Recent的欠没欠就你可以造任何欠，你可以造你的欠，造十个你想要的钱。然后在造这个过程当中，有一些很值得有代表性的欠是需要提的。
	AM茜最简单的嵌封装语言模型封装了prom template sequential欠，使得我们去做欠的编排成为了可能做这种串联的、单输入的、多输入的单输出的多输出的transform片，把一些非大模型交互的工作处理也变成了一个欠。这样就可以统一在欠的编排里面去做这个工作了。茜该有的这些memory的能力，call back的能力，可组合可观测的能力，都可以对于这些非大模型的逻辑处理也给他赋能，让他有这个能力统一编排。
	然后我们还想实现一些条件判断。因为我们把语言变成了一个把自然语言变成了一个编程语言。那这个时候用自然语言做条件判断，今天讲到的一个很重要的概念就是meta from the template，就是模板的模板对吧？这个也其实非常常见的一种使用手段了。
	怎么样去造出一个模板的模板？然后我们的参数，我们的input variables是有多层的参数，你是第几层的参数对吧？我们的muli prom temple ate，mui prompt template这样的一个原模板里面，需要让你植入我下游的不同的券的真实的destination的描述。就我们看到的适合回答物理的问题，适合回答数学的问题，就是作为这个candidate的destination。就我们的这个原模板的第一层参数，让原模板真实运行行的时候，会变成这个解包之后的第二层的这个参数，是我们真正需要由上游的这个结果通过root change，然后他通过他的candidate的destination里面去判断要给哪一个具体的欠做一次条件判断。然后把这个输入给到下游，下游就拿着这个input这个具体的问题再去做判断，去做输出，这个是欠。
	Memory是一个高度定制化的，给我们的钱去提供有状态能力的一个设定一个系统。它最重要的就两块，一个是能够从欠从模型的输出结果上记录下来维护状态。另一个就是说在我们要下一次多次去跟模型跟线去做交互的时候，才能把这些内容再读读出来，读取出来，作为我们下一次跟模型交互的时候的prompt。这个时候有两个鸡肋很重要，一个是space memory，一个是space chat message memory。大家可以去稍微看看他们的实现，一个是维护了memory的读和写，一个是对于了模型，我们还没有深入去讲。对于聊天模型，它维护了不同角色的信息，可以通过不同的艾特方法存进去，也可以通过你自定义的方法拿出来。
	然后为了能够给非聊天模型的语言模型提供对话的能力，记忆的能力，那有一些类似的一些memory system能现实现了。比如说我们今天提到了三个典型的conversation buffer memory，conversation的buffer window memory设置一个最近几轮对话的一个，还有一个conversation的summary buff memory。就我不是机械的去记最近几轮，是去记这个max token limit这样的一个限制。还有一些别的参数也可以作为它的限制。简单来说就是不是不因为有可能我只记最后一轮，那最后一轮就是特别长，对吧？那我能不能把最后一轮的信息有一个token的限制，甚至这个token的限制我还能够去做处理，这些都是可以去进一步去展开和扩展的。大家总结一下，对summary memory可以通过大模型，也可以你自己去做处理，这个是留下了口子的。
	就有同学在问summary buffer memory这个max到底怎么玩的？然后memory存数据是在内存还是磁盘？目前memory是存在内存里的，因为大家自己去讲memory是什么？Memories这个欠这个是实例化的实力，这个python实例里面的一个成员变量，这个成员变量你没给他持久化，他自然不会持久化，但你可以持久化。当然有可以当然可以topic summary buffer，这个我们都可以实现。因为我刚才讲了，memory是一个完全基于你自己的业务场景，可以去做定制化的。它只要实现两个最关键的read和right相关的接口就好了。
	Memory与向量数据库怎么结合？首先我们刚刚在文档里应该有看到vector store back memory。大家稍微去看一看，这是vector store retry memory。Store memory in vector DB向量数据库query top key。Most senate dogs every time IT is caught. 
	这就是一个典型，既做了持久化，同时这个memory也是从持久化的向量数据库里面去取出来的。因为比较常见的问题是说，有可能这个要存的内容太多了，内存你也放不下，甚至没有持久化服务崩，那不就没了，对吧？那放在向量数据库是一种手段。会讲的，会结合向量数据库讲的。我们不是有一个实战，是做销售的这个呃实战。
	那个时候就会讲的对，就是大家要理解能欠的模块不多，但是细节很多，我们不可能一下子给大家全部讲完，也接受不了。我们希望通过每一次课让大家逐渐加深理解，同时还能够庖丁解牛似的让大家理解。模块也没有那么晦涩难懂，它有它的设计逻辑，它有它的设计的一些原则和原理，以及它的动机。我们把这些能够庖丁解牛拆解出来，大家再去看他的文档代码就很好理解了。
	下节课讲什么？老师下节课讲什么？你想想我们南茜下节课还剩什么？没讲对吧？这个乐高积木还剩什么？对你想想就会有了，我不剧透。
	看大家最后还有什么问题，我们最后再找三个问题，memory怎么持久化？刚刚讲过了这个vector DB也可以，怎么样都可以。大家不要觉得大模型学了，别的都忘了。对，大模型是也只是一种技术。其他的其他的技术我们其实仍然可以用。原来怎么把内存里的数据导到持久化的系统里，现在仍然可以这么倒，只不过向量数据库天然方便。因为我们现在问的这些结果，其实它都可以变成一不一定的向量存下来。那你直接去存字符串也不是不行的，我没有说不能存字符串是可以的。
	下节课我们不会直接到实战，我们还有连线的下连线的基础有三节课。对，南茜还会去讲agent，我们还没讲对吧？Agent相关的一些第三方的调用，我们现在我们现在的大模型，我们知道怎么让他有记忆力了，我们能不能让他联网？我们下节课会用agent让他联网，连第三方的一些平台。
	最后一个问题，大家问了些什么问题？后面有没有讲怎么切割大文件？切割大文件就是一个函数，今天的split就已经切割了。大家不要把这个切割大文件搞得那么复杂，很简单的，你让GPT回答你，甚至能给你实现的函数，我们text split也切割了这个文件的对特定时间段的检索可以的，我们的这个conversation相关的memory里面可以存时间的。今天没讲，你把时间戳存下来就可以基于时间段来做检索。还有问题吗？我们再挑一个问题。
	没有的话，那我们就回头大家在群里再问，我们今天就先到这儿。对，如果大家有问题我们在群里沟通。今天的这个notebook我现在就会上传到github，大家可以去自己实操一下。对，一定要动手。南茜就是要动手才能有体感的，好吧。然后唯一一个可能token消耗比较大的就是那个transform欠我已经把它拆成两部分了，大家尽可能多自己试一试，也可以自己传一些这个TST文件去读，不是TXT文件，python也能读的。稍微用你去查一查他的API就好了。好，我们就这样，辛苦大家了。