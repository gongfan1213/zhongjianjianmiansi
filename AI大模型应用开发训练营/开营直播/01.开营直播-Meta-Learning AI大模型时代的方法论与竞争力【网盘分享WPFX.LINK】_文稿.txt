	好，我假设你们能听见，ok那我们就直接开始。我看到这个导播有给我回复，感谢大家今天在这个工作日的晚上还加班来听我的这个汇报。我今天准备了一个主题叫做matter learning AI大语言模型时代的方法论与竞争力这么一个主题的汇报。我是名叫彭金田的，是一个google的development expert，一个老程序员了。现在也是南券的一个developer在使用南县开发一些应用。今天其实整个主题想要跟大家分享的是在现在这个大语言模型的时代。其实大家都很焦虑，就是我们在焦虑我们应该学什么？我们应该怎么样去学，怎么样能够快速的学习，我们学习什么样的内容不会被淘汰，这个其实是一个所有人都无法回避的问题。希望通过今天的这个短短的1个小时的分享，能给大家一些启发，让大家知道其实不用那么焦虑，是有一些办法的，有一些方法的。
	简单介绍一下我自己，我是自己正在做一家初创公司，然后现在也有五年多的时间了，我是这家公司的联合创始人，和CTO叫平安。这是一家对标autodesk，但是又在用AIGC的技术去帮助建筑设计师完成建筑设计的一个公司。然后产品是跟autodesk CAD和和remit比较像，不过它是一个sars产品，同时它支持了像非gma一样的多人协同，还能够用AIGC帮助设计师完成楼栋的设计。
	除了在创业以外，其实我自己一直在这个开源社区，包括像大家看到这个tensor floor也好，cuba flow也好，包括这个bo natives这些比较有名的开源项目，我都有深度参与，并且很早期参与。然后同时我自己你在这个开元社区的一些成果，也变成了这个书籍，包括这个极客时间的一些课程。然后也得到了google的认可。所以大家能看到是google的开发者专家，也是他的出海创业加速器导师。
	是啊，我自己是毕业于浙江大学都可能学院，从中学的这个竞赛保送进到了浙大。然后从大三开始创业，然后创业结束之后，去了加州大学做访问学者，回来华为2012实验室，参与了华为深度学习平台的从0到1的建设工作。这个是我的一个个人的一个背景。右边是我的github的一个profile，也有一个简单的介绍。大家感兴趣的话可以关注。我们可以在gift up上面交流，这个都是一个很好的开发者交流的平台了。
	Ok今天其实重点是想告诉大家说，在AI的这个大语言模型时代，我们要怎么样去学习？首先我们要知道前缀AI的大语言模型的时代，这是一个什么样的时代，今天我用google的这个搜索引擎的指数，这个是一个有用的网站，它能够去全面反映各个领域各个区域的热点是什么。今天我会从我看到的一些视角，抛一些我看到的一些很有意思的数据给大家。
	首先我们看到这张趋势图里面是一个从去年10月1号，也就是CHAGPT发布之前的将近两个月的时间，到昨天7月10号的一个数据。这个数据里面我们找到了三个关键词，看看大家对这三个关键词的热度关注度是怎么样的。最底下的这个黄颜色的，其实是一个在中文圈里特别广受关注的一个叫做stable diffusion。就是我们的纹身图这么一个很有意思的模型。他通过diffuse的技术，让我们能够通过一些简单的文本去生成图片，并且stable diffusion。自己也还在不断的迭代。但是大家可以看到它的热度和另外两个词比起来，其实是有天壤之别的。这个搜索指数差了很多，不管是我们看它的平均值也好，还是在关注度里面的这个份额的分配也好。
	另外两个是什么呢？红色的是CHAGPT，而这个蓝颜色的其实是AI这两个词。然后这个搜索范围是美国，在美国这个领域里面，从去年的10月1号到7月10号，也就是昨天，这差不多九个月的时间，三个季度我们能够看到有一个很有意思的曲线变化。就是这个蓝颜色的线条跟这个红颜色的曲线其实趋势上几乎一致。甚至我们可以说因为红色ChatGPT的这个趋势增长，使得AI本身也受到了关注。
	这也是大家常常在讲的我们所谓的A人工智能的第四波的浪潮，大语言模型由cha TGPT打破了这么一个大家对人工智能好像不太行了，深度学习好像并不能完成那么多的工作的一个怪圈。CHIGBT重新让大家关注到了AI并且使它的热度上到了一个新的台阶，以至于现在的学术圈和工业界其实都在思考怎么样能够通过大语言模型，通过类似于cha TGPT这样的技术来提升我们的效率。这个是第一个insights，所以我们可以看到，其实CHIGPT点燃了我们的第四轮的浪潮。同时CHIGPT的热度，就这种大语言模型的这种范式，其实是比纹身图有更高的热度，尤其是在美国。第二个图其实就更有意思了，我们看到还是刚刚这三个关键词，我们把区域就这个搜索的内容不变，我们把区域从美国放到全球有一个什么样的特点呢？我们会发现其实跟大家想象的不太一样的是，或者说至少跟我自己想象不太一样的是，最关注AI技术的，关注这蓝颜色的AI技术的这个国家，越南为主。
	其实最近几年大家一直在讲越南承接了很多中国的制造业，包括经济上的一些点。这个是有很多媒体在讲。但是我没有想到通过这连续九个月的实际的数字，我们反映出来。因为你想越南、印尼、泰国这些国家其实都是用谷歌搜索引擎为主的，他们反而是最关注AI的那这个是非常有意思的一个点。同样的包括像印尼、泰国也都是在高度关注AI的发展。我不知道有没有听众关注到这一点，其实这一点对我们很有启发。就是越是生产力不算，或者说生产力不是很高昂，不是很贵的一个国家，反而他在关注AI的发展，其实这个事情也反映出来，其实AI对于效率的提升，对于生产力的迭代，对于这种经济快速发展的这种发展中国家是有很大的帮助的。
	这里我们就不再展开了，第三个想要抛的这个点是我们换了两个搜索词，一个叫南茜，一个叫tensor floor。如果关注人工智能的话，这两个词应该会比较熟悉。首先我们看到上面这个蓝颜，这个红颜色线条的叫tensor flow。那那tensor flow是google开源的一个深度学习的框架，它同时在他的后期也支持了大量的传统机器学习，包括强化学习。然后也支持工业界的方便部署。比如说我们能从这个服务器端，从云端的部署，未来也可以迁移到这个端侧。这是从15年开源的一个项目，并且他在整个开源社区有非常好的关注度。
	同时这个蓝色的线条大家会看到逐步从去年的10月11月开始，现在已经热度快追赶上我们的这个TENSFOOD是一个名字叫做南券的框架。这个能券的框架其实是一个我们课程也会讲到的一个框架。它是一个用来做大模型应用开发的一个框架。现在有很多的圈内的人把能券和tensor or flow再做一个对比，认为在大模型的时代，我们也需要有一个模型的开发框架，或者说应用的开发框架。南券现在非常好的卡在了这个生态位置上。然后我们也能看到，其实他在目前还没有特别明显的竞争对手。我们需要去关注这么一个很有用并且很有热度的框架，去追赶这个技术的热度，同时也是在拥抱技术的红利。
	除此以外，我们从区域的角度来看，当然这个结果是在中国这个范围内，我们看到其实有点跟大家想象的不太一样。其实杭州市最关心这个TENSFFO的这么一个城市，也是最关心南券的这么一个城市，它的搜索热度非常高。然后除此以外，北京、深圳、上海这三个城市有大量的创业公司，他们的创新氛围也都是非常长期活跃的。如果拉开时间轴大家自己去看的话，也能看得到，北上广深是仍然非常活跃的这四个最关心新技术的城市。
	但是杭州这几年大家会发现有很多的AI公司也开始往杭州慢慢涌现出来。比如说西湖新城，就Albert的作者，他做了一个大模型公司。然后同时其实北京也有很多的人员开始往杭州去发展，这个是一个。第二个数据就是在中国内部，其实除了北上广深以外的话，杭州是一个第五级。并且在大模型这一次我们会看到它的这个热度甚至超过了北上广。
	然后我们再回过头来看nc chan和和sensor flow这两个框架本身，其实我们现在看到这个比较是更细力度的一个比较。就我们看到在google里面去搜索这个南茜和。的时候搜搜的最多的是热门的查询是什么呢？这两个对比非常有意思的点在于，大家如果看热门搜索的话，其实所有人学习一个新东西，第一步都是想知道它是什么，它有什么用，怎么用它。然后这样的一个W4W1H这么一个经典的一个问问题的范式，或者说我们一个了解新问题的范式。在这一点上，我们会看到能线和tensor flow是类似的，都在了解怎么样去安装它，部署它它是一个什么东西。然后像tensor or flow，因为它的生态很成熟，所以大家会问更多的关于相关联的。比如说像PYTOC cross这样一些跟它类似的框架，这个是属于一个关于热搜的这么一个数据。
	所以从这个视角来看，其实我们能第一个发现南区其实它的普及还不够普及，为什么呢？第一是在于我们刚刚提到的像patch watch cross这样的框架，是这个市场做大了，那我们一个经典的话语叫做蛋糕做大了就会有人来分，对吧？但是我们看到南线其实并没有一些类似的框架跟他一起去抢占这个市场。然后第二点在于从左边这个地理分布图大家可以看到，其实这里有颜色的区域表示大家在关心他，因为我们这里只展示了top 5的这个区域。
	但其实南线除了沿海的，比如说我们看到这边的北京、上海、杭州以及深圳，当然还有四川，也是一个对AI非常有热度的一个城市，跟我们国家的这个发展战略也很像，这四个大的区域最先捕捉到了这个新技术，并且开始关注它。但tesla flow经过了这八年来的一个运营，已经相当成熟了，这个我们就不必再展开，这个是我们看到的一个粗的现象，就是大家都关心这两个新技术，北上广深包括四川可能更早的关注。然后同时我们的大语言模型的社区从CHIGBT去年底开始到现在，其实也就半年多的时间，还很早期，还有很多的事情可以去做。
	第二个细致一点的观察是什么呢？我们能看到其实搜索量的上升决定了近期以来大家关于这个问题有什么最急切的想要去问的问题。我们能看到的是南券它的相关查询的这个搜索量飙升的数据几乎没变。大家对于这个框架仍然停留在他是什么的一个状态，而没有这种深度使用的用户。但是TENSF flow大家可以很明显的看到，大家问的都是一些很细致的很深度的问题了。比如说我因为我本身对特色flow比较熟悉，我们我简单解释一下。像这几个热点搜索飙升的词，第一个叫这个矩阵相乘的一个API，然后后面也是跟这个矩阵乘法相关的，就我怎么样去把我的维度去做扩展，包括我怎么样去获取我的这个变这个我们叫向量里面的这个scope，然后去做一些向量的操作，包括embedding的look up。
	这个其实就反映一个很实在的，就我们刚刚上一个关于热搜的佐证，其实两个社区之间都很热，我们看到它的热度已经都追平了。但是他们的时期又完全不同。南县还有很多的工作值得我们去做，值得我们去学习，接着我们再从另一个视角去看这个问题，我相信来听的人应该有一些是使用过github的这个用户。在github上面其实有一个金指标，或者我们叫北极星指标。在大部分的时候它是有效的。就是我们一个开源项目它的star数量，就类似于我点赞了，我收藏了，我认为这个项目很好。
	这幅图里面展现了三个开源项目，我们能从它的时间序列上能看得出来。这个蓝色的是腾讯flow，它相对来说都开源的比较早，在15年的下旬。然后接着是这个排touch，最后是我们的南区。从这个图里面能看得出来，其实tensor flow一直是一个在匀速增长的一个项目。这个项目其实能看得出来，第一他没有死掉，对吧？因为有很多的开源项目他慢慢就不行了，大家就不关注他了，他的也就不会有人持续再给他点赞了。
	排touch也是类似的，就说明其实深度学习并没有像大家想象的那样，好像热度过去就不在了。相反其实深度学习走进了千家万户，我们现在天天手机上都会有无数次的人脸的调用，上班打卡也会有这个类似的调用。其实深度学习已经从一个学术热点变成了一个逐渐行业化落地的一个状态。类似的其实我们看到AIGC的这一波热潮，它其实也是在类似的一个发展路径上。
	不过它又略有不同。第一个不同就在于哪里呢？我们把这个时间线拉回来，就我们看它的纯自然增长。我们把这个时间轴就单看从这个项目的第一天开始的一个增长路线，我们能看得出来，首先这个增长的斜率是不一样的。这也反映出一个什么样的问题呢？就是这一轮我们的大模型，我们的AIGC，其实和上一轮我们讲深度学习，我们讲计算机视觉其实完全不一样。最不一样的一个点就是我相信今天来听的人有很多其实都不算是程序员或者开发者，但他也会关注这件事情。因为AIGC动了很多人的蛋糕，或者说他让很多人觉得原来AI是这样的，AIAI可以干这样的事情。
	以前我们都会认为AI是一个特定领域的事情。所以从这个增长斜率看得出来，这个热度跟以往三波都不太一样。对于我们所有人来说，应该怎么样在这个过程当中参与其中是一个非常重要的事情。这就是一个很有意思的三个关键词，一个叫做这个时代的浪潮，一个叫做技术的红利，最后是个体的选择。为什么要抛这三个词呢？其实是跟刚刚那个问题完全关联起来的。
	我们其实像我的话，今年已经马上要30岁了。我是见证了很多互联网浪潮。从这个1.0、2.0到现在，我们看到AI又重新把移动互联网带到了一个全新的高度。移动互联网造就了数据，但这些数据通过我们的大语言模型焕发出来了更多的价值。在这个时代浪潮过程当中，我们会看到，其实像iphone的出现是一个关键性的节点，它使得我们的移动互联网有了硬件的载体。
	然后向中间我们看到移动互联网有大量的AP就我们在十年前的时候，大家都会发现，我们吃吃饭，我们这个外卖，我们出门打车，用这个饿了么的，用饿了么用滴滴。然后包括像海外的一些公司也到中国来，不包括像uber，这些公司其实都是APP的公司，对吧？那现在我们今天来看，APP公司已经没有那么新鲜了。但是在上一波移动互联网的时候，它是一个全民参与的热潮，非常热。包括我自己也参与其中，在15年的时候，第一次创业跟一个学长做了一个NLP这个技术怎么样去帮人做辅助诊疗的这么一个APP，叫半个医生，这个其实是一个非常大的技术浪潮，我一直在这个浪潮里面努力参与。包括像这个左下角，像这个critical，它是在十年十多年前，由这个很小的一个技术社区逐渐发展起来。这都是浪潮，这些浪潮我们都看到过。
	然后到了移动互联网之后，我们看到tensor flow起来了。通过这个image net，包括我们有这个VGG inception到region net的出现一个里程碑，让我们发现原来人会认这个是苹果，那个是梨。这件事情AI已经可以干的比人还好了，超过了人的水平。一直到我们看到了CHIGPT的出现，其实CHAGPT标志着另一个里程碑。那就是说我们现在在这个语言模型这件事情上，已经出现了跟resnel一样，机器比人干的更好的这么一个状态。我相信大家如果用过HATGPT应该都深有体会。当你让他去干一些日常的这种文书类的、工作总结类的工作的时候，他都干得很好。
	这里就会有两个问题，第一个就是说时代的浪潮跟个人的选择无关，对吧？就无论我们自己做了怎么样的选择，时代的浪潮都会一波又一波的去拍打过去，然后去影响所有人。像吴军老师早期写的一本书浪潮之巅，讲了更早以前的计算机的发展史，包括互联网的发展史。然后每一个行业我相信都有这样的浪潮，这个浪潮我们人影响不了。但是在这个浪潮之中，我们能看见什么东西呢？我们能看见一些机会，能看见一些技术的红利。那就比如说在这个过程当中，我们看到了在上一轮有tensor flow这样的一个技术。这个技术其实使得很多的AI的公司使用它，造就了很多行业的便利。
	这个技术朱红利早期的参与者当然有非常好的回报。就比如说我自己，我从16年初开始参与这个社区，看着他一步一步的成长，然后我自己也通过他学习到了很多的东西。比如说我自己通过城市flow，我变成了他的贡献者。然后也成了谷歌的开发者专家，然后也写了书，然后也认识了更多的优秀的人。这都是你早期参与者能够享受到的技术红利。如果你不是一个开发者，比如说我们刚刚提到的这个移动互联网时代，你是一个早期的用户，你是一个APP的用户。同样的你在那个时候也薅到了很多的羊毛，对吧？
	那类似的这些红利，我们不管是作为开发者还是用户，越早的去拥抱他，我们一定是在这个浪潮里面越早享受到这个红利的人。这个时候对于我们个人来说，这个个体的选择就变得尤为重要了。到底我们是看到了这个浪潮与我无关，我们不去了解它，我们就随着这个浪潮走就好，这样也是ok的那还有一种方式是我们主动的去拥抱，去抓住这个技术的红利。这个是一个更我自己个人认为更优的一个选择。回到现在这个阶段，那大语言模型的时代，我们刚刚也提到有一个框架叫做南泉，它的热度也很高了。他是一个不只是让你成为一个用户，而且是作为一个开发者来说，怎么样能够在今天我们一直这个CCATGPT的这个plug in。
	是现在的iphone时刻。我们看到了iphone造就了移动互联网，造就了很多个几千亿美金的公司。我们在tensor or flow这个年代，也看到有很多的AI的公司。那在南券这个年代会不会有很多的公司？有，我相信大家了解上一周在上海刚开完这个WAIC这个世界人工智能大会，有很多的AI公司。然后我也在网上看到了很多的大语言模型的公司，很多的公司都在拥抱，我们个体也需要去拥抱。但是在拥抱这个过程当中，就会难免有一个很大的问题。
	也是今天的一个很重要的主题，就是我们会发现每一波浪潮都有新东西。那这些新东西对于我们个体来说是不是都能学得会？我觉得可能很难。就有一句庄子的名言叫我的生命是有限的对吧？我要学的东西是无限的。比如说武神有牙，学海无涯吧？那我能怎么样去学呢？
	所以这就又引申到一个很有意思的概念，就是知识焦虑。这个是我自己也深有体会，我今天后面也有一个简单的介绍，去讲我是怎么样去逐步的去解决这个问题的。知识焦虑其实是一个最近几年，尤其是疫情以后，我相信所有人都会感受到的一种症状，或者说你的一种心理体会，我到此时此刻也都会有知识焦虑，我去仔细查了一下，其实它算是一种疾病，往严重了说，就跟这最近这个抑郁症也被大家很多人提了很多。
	为什么呢？其实本质还是在于现在这个时代，信息它的生产的效率太高了。或者说信息就是在爆炸的一个年代。我们每个人都在无数的APP里面去接触信息。但是我们自己又不知道我们在这个过程当中学会了什么，但时间就消耗掉了，这个是一个非常客观存在的现象。我自己其实也是一样，我刚才有讲，我是很很长很多年的编程经验，其实我是从中学开始到现在差不多有。虽然现在30岁，但是我是从15岁开始写代码，所以其实也有将近15年的这么样一个编程经历了。
	我学过很多的编程语言，从中学开始，那个时候老师教这个q bicycle叫帕斯卡，叫pyy。Cle那会儿老师就叫帕斯卡，对吧？后来你知道他其实这里有一个更洋气的英文名字。后来你去学CC加加java pythons。然后到了这个创业的时候，为了做数据分析，还学了这个R语言。后来为了做这个深度学习平台，学了go name语义。
	这么多的编程语言学下来，其实最大的一个困惑就是我为什么要学这么多编程语言，然后我还要学多少年才能学得够？这个其实是对于自己来说是一个非常焦虑的事情。而且最大的原因在哪呢？不在于是说说我可能不想学或者学不动，而是说如果你只会编程语言，是不是你的能力，你的技术战有局限。
	所以你会发现其实很多初级的研发同学，他一直在那学编程语言。但是稍微有一些比如说有五年以上或者5到8年的经验的研发同学，他可能会说我在学习什么算法，我在研究什么框架，我在看一些论文。但是就算是这样，我们也会发现，其实知识是非常多的，是学不过来的。那么怎么办？对吧？怎么样去缓解这个焦虑？
	我觉得这是一个非常困扰我的问题，尤其是刚我有讲，我在15年下旬16年初的时候，投入了大量的精力去研究TECFFW，研究深度学习，但是现在大模型火了，对吧？你要开始从头再来一遍，重复这个八年前的过程去学习南拳，那这个过程你是跟原来一样的那个学习模式吗？你还像22岁的这个小伙儿一样，这么有精力去学习吗？其实这是一个很灵魂的拷问，尤其是如果在八年之后又有新的东西出现了怎么办？所以我觉得有三个很严肃的问题是困扰我也是让我去不断思考怎么去解决的一个困惑。
	就是说嗯第一个点叫做怎么样去获取有效的信息。因为数据已经非常多了，信息也非常多了。那我们要怎么样去学一些？我认为这个信息是值得获取的，是值得去学习的。获取到了有效的信息之后，我们我我自己的一个定义是说，信息是永远都是爆炸的，你是学不完的，然后你也无法处理完。当然可能未来的大语言模型可以，这些信息获取到之后，有一部分信息是知识，但是这些知识非常多，尤其是现在这个状态下。那这么多的知识要怎么样去学？
	然后比如说刚刚的这个例子，就是说我知道了AI发展的很快。在十年前，那么TERFLOW深度学习是一个好的东好的知识我们去学学到了那学到之后，这个知识的保质期有多长，对吧？就是我们花了比如说我花了三年的时间，我掌握了一门框架。然后我发现明年它已经不再流行了。因为有新的框架出现了，新的编程语言出现了。那什么样的知识保质期最长？我们以终为始来看，就是这三个问题其实本质上抽象一下，就是我们到底要学什么？然后我们怎么样能够学的快一点。
	然后我们挑出来的这个我们挑出来的知识我们学的很快了，那他能用多久？这个我认为是三个很重要的问题，也是今天紧扣主题叫meta learning，叫元学习。就是我们到底要学会怎么样去如何学习，是一个非常重要的点。
	那那这里我自己的一个答案是什么呢？就是我自己其实是一个很焦虑的齐国英也快30岁了，按照古人的话讲，这个三十而立，对吧？你应该有点自己的这个成就了，但是我现在回忆的后来好像也没有什么成就。那么怎么样去缓解这个焦虑？这个焦虑有没有人遇到过？然后有人遇到过的话，他是怎么解决的？通常人是这样去解决问题的对吧？那你要找人找有没有人遇到过，找谁呢？
	刚好我就会发现一个很有意思的点，就是我们很幸运，我们都生在中国。中国有非常多的文化历史的积累，有大量的文字记录下来了。这些文化的典籍非常值得学习，尤其是我今年花了一些时间开始去看这些很厉害的先贤他们留下来的这种文化的精华之后，我觉得非常有收获。这个也是今天会跟大家分享，包括待会儿我们会有这个QA的环节，大家也可以提问。
	我先抛出一个问题来，就是今天很有意思的一个问题，叫我们中华文化5000年也好3000年也好，但这个很多人都有争议，但我们不重要。就是你记住了什么？就是我们这个是我相信所有听众应该接受过K12教育，我们可能会有不同背景接受过K12教育都会或多或少读过一些中华文化所谓的书籍。那我们还记得什么呢？我们可能记得孔老夫子之乎者也，对吧？那我们看一下这个行业记得什么呢？
	很有意思的一个点是，最近这一波大模型，今年以来很多公司，不管是老牌的AI公司也好，老牌的互联网公司也好，还是新的初创公司也好，包括各种各样的还活着的公司，都在搞这个大模型。我前天看过一个国产大模型的一个有名有号的一个列表，已经超过100个了。这个也已经接近百团大战的这么一个状态了。但是我们看到有很多老牌公司特别喜欢取这种古时候的名字。对吧？这个盘古日日新，通义千问文心一言混元悟道前缘这东西都或多或少感觉不是那么好理解，对吧？当然我不想说这是中华文化，我只想说这些老公司好像都有一些特定的执念或者说这个共识，他们喜欢取一些有内涵和深度的名字，为什么呢？这个我们不给答案，我只是抛这么一个想法。
	我说说我记住了什么？清华跟浙大跟我们有关系，因为我现在。初创公司我的合伙人有大部分都清华的那我自己是浙大毕业的。我最近这半年来我记住的几个东西我抛出来，然后又跟刚好跟我自己身边相关的。
	第一个就是清华的校训，清华的校训叫自强不息，厚德载物，是一百多年前立校的时候，就一直叫累。这句话其实我相信大部分的人都听过，然后这句话也很有意义，自强不息，厚德载物对吧？人要自强，然后要有德行，你才能够承载很多东西。不管是实际的物理世界的物体，还是你内心的一些东西。这个清华校训的这这句话它取自于哪呢？我相信更多人听的是一个扩展的版本，叫天行健君子以自强不息，地势地势坤，君子以厚德载物。然后我相信大家看到的那个版本，可能天行和剑之间是连在一起的，地势和坤之间也许是连在一起的，这些都不重要但重要的事情是什么呢？
	是说其实这句校训它是很有历史的一句话，它来自于一本书叫易传的象传的上篇。这句话其实它是用来原来是用来解释什么的呢？它是用来解释乾卦和坤卦这两个最重要的，我们叫周易里面的挂的这个卦本身整体的。那么乾卦通常我们讲这个阳至阳对吧？空卦至阴，这里我们就不展开讲周易了。这个当然我最近也在研究，大家有兴趣我们可以在我们这个学员群里去交流，这个都问题不大。
	对，这个是想说其实像清华这样，我们应该算国内最好的高校。他记住了一些内容，来自于很早以前春秋时期的一本书，叫相传。像我的母校这个校歌其实是非常好。到现在为止，我相信大部分一个合格的浙大的毕业生，一定两件事儿记得非常清楚。一件事儿是诸葛亮老校长问的两个问题，还有一个事情就是这个浙大的校歌。因为浙大校歌是一个古语写的校歌，然后里面有大量的引经据典的内容。
	其中有一个我记得非常清楚的词叫形上未到，西形下未起。这个什么意思呢？就是大家都听过一个词叫形而上，对吧？形而下。形而上其实通常就是指我们这个世界上已经看不到的这个宇宙运行的规律叫道，这跟道德经里面的这个道是一样的。形下卫气就是我们实际的这个世界，这两句话其实跟自强不息，厚德载物有一定关联就行。
	上味道就是指这个钱要表达的开万物的这个状态，形象未系就是我们的这些万物，很有意思。这句话其实也来自于易传的戏词传，易传的戏词传里面的原句叫是故形而上者谓之道，形而下者谓之器。那肯定比较较弱的这这一页都在讲一些非常古老的文字，这个文字其实是我在对抗这个知识焦虑的时候，一个很有意思的解决办法。就是我总得学一点好像八年之后还有用的东西，对吧？它不一定是一个我们叫有道有术对吧？不一定是一个具体给你挣钱的东西，但是能让你这个内心抵抗这个知识教育。然后你会发现这个方法论，他是可以引申到你挣钱的技术手段上的。
	我们回过头来看啊，跟我最相关的这两个高校，他们一直在记住了很多中华文化的精华。这两个书也好，或者我们叫文章也好，易传象传和易传细实传，由着这两件事儿我就开始研究这个易传到底是个什么东西，对吧？那我们再稍微花点时间去跟大家分享一下我的一些学习方法和见解。
	首先易传是什么？易传？他是孔子，像当然现在的这个考究是讲孔子和他的弟子，包括这个周公，也叫周公旦，就是我们的周文王的儿子，周武王的兄弟的写的一起写的这个书，这个书一共有十篇，所以又叫10亿。我们刚刚看到的两篇，一个是相传在相传的上篇，一个是这个细瓷钻。
	那这个是孔子写的，写的这十十本书，这十本书非常重要。孔其实大家了解这个人，觉得他是一个儒家的代表，是一个大儒。但是其实他从晚年49岁的时候就开始研究这个。所以这个也是我之前不知道的，我由着这个知识的节点一点一点往上爬，对吧？然后知道了一些所谓的体系化的知识。我们之一mean learning最重要的一个点就是不再重要的是要掌握某一个字或者词，一个知识点有什么样的意义含义。而是说你能不能往根儿上找一些不变的东西我就在找这个中华文化所谓不变的东西往回倒的过程当中，我们发现了，其实孔子他自己除了儒家的造诣以外，他本身还在研究这个玩意儿周易。
	然后同时我们还会发现有两本书也很有名，我相信有的同学可能还读过一本叫道德经。其实他古时候叫这本书叫老子，是老子写的。还有一本叫南华经，又叫庄子。我们刚刚其实提过一句话叫武神也有涯，而知也无涯，以有涯随无涯殆矣。这句话其实就是出自于庄子南华经典里面的内容。那你就会发现其实我们生活当中好多的事情，都来源于这个根儿上的知识，包括我们生活当中的很多成语，乱七八糟对吧？为什么会有乱七八糟？这个东西跟易经周易有关，跟他的挂的这个变化有关，就有很多的词都来自于这。
	我们再整理一下这个知识，你会发现其实道德经、南华经、周易又被称之为三玄之学。那就我们平时讲玄学对吧？我们都只知道玄学。那玄学本身是不是一个真正的在历史上或者说在文化研究上有这么一个称谓？其实有的就我们中华文化是是讲是讲这个玄学的研究的，并且它不是一个显学，是一个隐学，不是大家天天可以学到的。
	你再往回倒，其实这个易经也不只是周易，他还有这个易传，就类似于孔子给周易写的论文报告心得体会一样。易经除了我们现在看到的这个周易以外，据说还有两本丢失的，比如说连山易和归藏易。这些都是你不断的去往根儿上找的时候，那你会发现有很多的知识它是一棵大树的根。然后我们现在学到的很多内容是开枝散叶下去的，这个过程会让人非常的舒服。我不知道大家有没有过类似的体会，当你对很多事情像一个毛线球，你捋不清楚，这里也有知识点，那里也有知识点的时候，你去把它往它更高层次或者说它的来源去捋的时候，会让人豁然开朗，如沐春风。这个是我通过这个，我相信所有人应该都或多或少了解过这些关键词也好，这些名词也好。这个过程其实是一个让人把知识理顺，把你的知识理顺之后，你就知道你要怎么样去分配你的时间和精力去学。
	然后学的时候也就会有重点，比如说这幅图其实已经涵盖了很多的中华文化了，但它的知识内容又没有那么多。比如说老子这本书五千多个字对吧？然后易传你把这十篇加起来，用A4纸打印，可能也就十张纸就能打印完。这个内容是高度凝练和内涵的那怎么样去消化这些精华？这个是另一个技术手段的事儿，我们就不展开。
	但好处是说你会发现很多后来的研究，他都是从前人的很精华的内容里找了一个切片去给他去做扩展。那你如果能把这个切片从这个切片本身找回到原来整个一棵大树的这个样貌，被你复原出来。那你学习东西你会非常的高效。同时你也非常的豁然开朗的状态，不再焦虑了。因为你知道这个知识体系你有了，你知道你现在想要去掌握哪一个领域的内容，哪一个指数的内容，而不再只是说我都没有见过这个森林，对吧？
	这个是一个很有意思的一个分享，也是我自己的一个心得体会。整个这个过程其实是想告诉大家如何去学习一个meta learning的思路。回到我们学大语言模型本身来说，我们现在就是在面对无数个切片，这是一个很有意思的。
	这个阿凯的阿cap是一个免费的让大家可以上传论文的一个网站。这个网站在2022年的时候突破了200万篇论文了。就是这个网站上已经有200万篇论文了，并且是在一年半之前。然后它的创始人其实非常的没有想到这个世界发展这么快，他们是怎么讲的呢？就是说这个网站从他的创立第一天开始，到他获得第100万份论文的这个时间节点用了23.5年。然后第2个100百万用了七年。然后我相信这一轮他当时在2022年的1月3日的时候发了一篇论文，讲刚刚的这个数据。但是他应该没有想到的是说，ChatGPT在2022年的年底就11月30号发布了。
	那么这样的一个AIGC的大语言模型应用，可以让更多的人更快速的去去写论文。我相信经历了这半年的一直在关注AI圈子的这个同学，一定有一个很明显的体会，就是每天都有新论文出来。你也不知道他能不能严格意义上叫做论文，但是会有新的出来。就比如说今天我正在看一些文章的时候，就看到有人在发一篇所谓解读CHAT，解读这个GPT4的架构，包括它的设计，它的模型的这个站相关的一篇文章出现了。这样的事情每天都在发生，所以我相信都不需要四年。因为之前他有预言，可能四年的时间就第111百万了。我觉得可能现在都已经快接近这个数字了，因为大家真的是非常疯狂的在发论文。
	这都是我刚才讲的切片。这些切片对于你来说有什么样的价值，或者说你应该怎么样先过滤一遍获取有效的信息，几百万篇的论文我塞到CS这个赛道也好，再到AI这个赛道也好，怎么着上万篇肯定有的。上万篇的论文对于你来说你这一辈子都看不完，那你应该怎么样去学？刚刚我其实没有提到的一个点，就是虽然那些中华文化的书籍很字数不多，但是还是需要有人带你去看的那我是最近在看南华锦老师的书，所以他是一个很好的老师，能够很通俗的帮你去开启这扇门。
	其实学习大模型也好，学习人工智能也好，我理解也是需要如果有人能够帮你一开始去把这件事捋顺，就是帮你开启这个门，开启这个动作也好，开启这个技术也好，其实我认为就有点类似于我们刚才讲的这个make time learning。它最核心的是让你见到了整个生理，让你见到了整个学术也好，知识也好，它的体系你懂吗？然后完了之后，你知道怎么样由着某一条线去关注你应该关注的内容。
	那么我们就回到大语言模型本身来说，我们应该怎么样去把刚刚类似于所谓的中华文化这条线给捋出来，我们尝试捋一下。首先之前应该也有人看过这张图，我在上一次直播有碰过。这里有两个很重要的论文，一篇叫做attention mechanism相关的一篇论文，是由这个beno，就我们的图灵奖获得者和他的这个博士生，当时还是他的博士生叫banana o，两个人一起，当然还有其他一位作者三个人一起写了这篇文章。这篇文章的代表表现也好，它的价值也好，非常的大，因为他是第一个把这个注意力机制提出来，并且也引入到神经网络里面去解决机器翻译问题这么一个最典型的自然语言处理问题的这么一个论文。它是具有开创性的一个价值。我相信大家如果去关注的话，这篇论文是非常重要，也是值得一读的。
	然后接着我们会看到有一篇论文叫做transformer，就是attention is oil need的，现在都叫它transformer对吧？因为这篇论文内部给他的这个self attention mechanism也好，self attention architecture也好，就这个自注意力机制的整个架构模型架构取名为transformer。然后这篇文章也很有它的价值，他提出了一个非常简单的模型的框架。把什么干掉了呢？把我们的大家如果了解人工智能，把这个RN，把CNN这样的一些非常经典的我们的深度学习里面的网络架构给干掉了。他的整篇论文就我们的transformer这么一个模型，就主要使用了attention这么一个最重要的一个机制。然后这个attention是一个叠加的对战，然后这个堆栈里面有这个encoder，有decoder，attention里面还使用了这个insider的技术这里其实也是我们掌握了整棵树之后，你会发现很多知识是触类旁通的，待会我们再详细讲一下这个逻辑。
	接着我们有transformer之后，我们会发现这个技术的发展到了另一个阶段，就是我们有了注意力机制。我们有了自注意力机制之后，大家发现，大语言模型这事儿是值得搞的。所以在五年前，其实我们现在国内搞大模型很多公司对吧？刚才提到100家公司，你在五年前OPI就已经很执着的开始去投入做这件事情。
	然后那会儿两个大的公司在作为最主要的生力军在搞这个大语言模型。一个就是现在最有名的OpenAI这个团队，他们在18年的时候发表了一篇文章叫improving language understanding by general native pre training。这篇文章就是大名鼎的GPT one的论文。
	然后在19年的时候，google发布了另一篇论文叫做bert，这个bert其实也是用pre training，但是它不同点在于它做了双向的学习。大家理解我们人说话都是或者我们人去阅读的时候，通常都是一个方向来读。就是我从左到右的读，古人可能从右往左的读。Bert这件论文干的最重要的事情就是我既学习了从左往右学，我又学习了从右往左学。这个B就是来源于这儿我们的by directional，就是把这个transformer跟这个双向做了一个结合。这种思路其实也是一脉相承，也是有很多的可借鉴的。我们可以看到，其实不管是bert也好，还是这个GPT one也好，他们都是基于这个transformer，基于这个注意力机制，所以他们都引用了我们的这个bandana的论文。
	中间我们看到这个bubble这个泡沫的这么一个图，它其实表示的是第一颜色越淡，它的年代越久走远。这个泡泡越大饮用量越多。所以我们看到比较大的几个泡泡，其中有一块颜色比较淡的，就是我们刚刚有提到的这个注意力机制。这篇论文被非常多的人引用，我们刚才是有看到大几万个应用。
	除了这些以外，我们再往前倒会发现一些什么内容呢？或者说往这个侧面到我们在捋这个过程？我们会发现其实transformer在中间？Transformer引用了我们的这个attention mechanism，然后大家都在引用这个transformer。所以transformer当然属于一个非常中心的位置。
	但是除了transformer以外，其实我们还会看见旁边有几个很大的泡泡，其中这个LSTM这是一篇非常重要的论文。然后他成功的解决了我们传统的RNN，就我们的这个循环神经网络里面无法解决的长期记忆的问题，它就叫non term对吧？在这个过程当中，其实这个长短期记忆通过这个经典的LSTM的架构被大家广泛应用了。所以当时也有人在为这个图灵奖喊冤，就是这个LSTM的作者应该也获得这个图灵奖，这个是后话。
	LSTM本身是一种神经网络的架构。我们刚刚有提到transformer，其实他提到了attention is all you need的，是吧？所以他不需要神经网络的架构了，他把这个LSTM给抛走了。但是我们的LSTM当时的这个发展，也是经历了一个很有意思的阶段，就是我从左到右去学习。那我能不能从右到左去学习呢？其实就有一波研究人员就提了这个叫by directional LSTM，就是我双向的LSTM。这个逻辑跟bert其实是非常像的。
	我们其实学很多的这个论文也好，你往你看的越多，尤其是你是有体系的去看了之后，你会发现大家的研究路数其实也是有门派的对吧？最大的两个门派就是我们的连接主义和符号主义，对吧？所有的神经网络搞神经网络人都被盖了一个帽子叫连接主义。然后所有搞这个逻辑推理的，符号学的，包括一些其他相关领域的，就叫这个符号主义。现在最新的这个研究方向是这样，我们还是要合并，合并的方式大家都在想有一些成果了。对。然后除此以外，我们还有一个很重要的词，我相信大家天天都听到叫这个embedding，我之前其实也有提过这个embedding，最最也不叫最有名，就是最广泛应用的是一个google的开发的工具，叫world rect。
	就是我怎么样能够把我们的一个自然语言的，就比如说我们现在在屏幕上看到的所有的这些英语的单词变成一个词向量。这个词向量在一个语言模型里面，它是一个统一的向量空间。那么我相同的词就拥有相同的向量，就把一个语言学的问题变成了一个数学问题。那么不同的语言，中文和英文，我都可以变成一个高维的向量空间。向量空间之间就有数学的办法可以去解决问题了，就可以做翻译的问问题，这是一个非常重要的成果。Work react. 
	然后我们还看到这有一篇文章叫glow，其实就global vector for world representation。大家可以理解它是在watch back后面的一个研究成果，在bert里面也有去使用和引用它。Embedding也是一个重要的发展方向。
	整体来看，其实我们在尝试捋就是我们的大语言模型，我们看一个事情，看他的最早期阶段是证人最能看出问题的。因为很多时候你的后面迭代的版本不会有质的飞跃那么你看到早期的版本能看到那个根的脉络，就跟我们刚刚去了解，你去看孔子的东西，然后你去看老子的东西，去看庄子的东西，一定比后面的人的解读更有意思。南怀瑾老师有句话很有意思，是说一本道德经五千多字，你摘出来两三个字都可以写一篇博士毕业论文。我觉得他说的是非常有道理的。包括咱们看到清华的校训，浙大的校哥？也都是其中的只言片语，就能够表达这么多的含义。所以你往这个哲学高度去讲，是有很多东西精华在那的。
	这里也是一样，我们刚刚提到了大语言模型有注意力机制，对吧？那注意力机制它的发现使得我们后面可以有自注意力机制，有marketing head多头的注意力机制。然后我们有神经网络架构，神经网络架构里面RNCN，RN有一个很重要的成果叫ASTM，它它基本上就替代了原始答案。Embedding我们有world vest，有global vector。
	Ok那么从这个视角我们再给大家图形化的去捋一下这个逻辑。就比如说我们看到transformer，transformer其实除了我们刚刚提到的GBT家族以外，除了bert家族以外，还有t five这个家族，他们也在使用transformer在各种魔改。然后他们都在延伸出不同的模型站。这里也只是一个节选，也不代表全部的模型，这些这个也是网上的一个截图。
	那我自己做了一个什么样的梳理呢？就我们刚刚那幅图里面，其实有三个很重要的方向，刚刚我也在用语言的方式跟大家去讲。第一个就是这个tension的发展，它发展出来了transformer，然后发展出来大语言模型，然后有embedding的发展。它使我们把自然语言语言学的问题变成了一个数学问题。然后有这个LSTM，他把我们的这个序列，就怎么样把一堆的预言和一堆的数学向量结合在一起。那么RNNLSTM是一种比较好的结构。
	Transformer也有他的办法，他用attention直接去记录，也是一种办法。但是它中间加了一个前馈网络，就这个feed forward neural network，那它仍然使用了neural network。如果他自己做了一个两层的全连接网络，所以你仔细来看，根儿上是这个newer network，就是我们说的连接主义，对吧？那连接主义其实除了我们的ASTM，这个其实属于neural network architecture的范畴，就是我们神经网络架构的范畴。LSTM是其中一种，它属于RNN对吧？还有CNN，还有全连接，还有各种的东西。
	Embedding是一种嵌入的方法，把我们的原来的这个输入项变成了一个向量。然后在一个统一的向量空间里面，很多原来的输入之间的关联关系就被找出来了。语言模型也大量的使用invading的方法，包括像现在OpenAI的embedding，API应该被调用最多的一个API。因为它的大模型强，它的语言理解能力强，所以你问他相同的问题或者相似的问题，通过embedding就能找出他们是类似的。
	对，然后attention也是一样，其实attention这个机制从14年本就和banana发明以后，现在有非常多不一样的attention机制。比如说它还有不同的分类方式，比如刚刚提到的这个是不是sofa天选，或者是普通的天选。然后你是不是一个hard attention，还是一个soft attention？你是一个market head attention还是一个marketing level attention？
	Attention是一个被玩出了很多花活的一个机制。我们在第一篇里面，这个大模型的理论基础也会花很多时间去就跟大家讲这几块内容。就是希望我们所有的不管是你订阅了这个课程，我们可能会更深入的去讲让你更好的去理解这个过程。更好的去把整个大元模型它的理论到最后实践是怎么关联起来的，有一个全方位的认识。
	也是希望能够授人以渔，对吧？而不只是授人以渔，让让你能够打开这个meta learning的这个方法。这个方法让你不仅是能看到我教给你的这个neural network有这三条线，还有很多条线。除了neural network以外，其实还会有符号主义，然后还会有diffusion。Diffusion跟transformer的结合，就是我们刚刚提到SD stable diffusion和transformer的结合，也是现在非常热的一个研究方向。
	然后像昨天李飞飞老师，就这个image net数据集的贡献者李培培老师也在研究这个embodied的I就生生智能大语言模型。其实在当下这个节点，远远能够做到比现在我们看到的更多的事情。就是因为他第一次让语义理解，让我们的语言表达到了一个全新的高度。这个全新的高度就相当于开了一个门，这个门对于我们来说，第一我们能让AI听懂人话了。第二就是我们能让AI看懂人话了，对吧？看懂人话他就可以学很多的各种各样的数据和知识信息，然后把它总结出来告诉我们。
	然后听懂的话就是我能把我要想要交代的任务告诉他。Embodying AI的这个研究方向，就是说我能够把机器人学，我的这个robotics，我们的各种各样的机器人，不管是人形的还是机械手臂。你看特斯拉的这个人形机器人，现在也花了很多时间在做推广宣传。然后这种各种流水线上面的生产机械手臂，现在也在做进一步的迭代。我们能不能把我们的视觉系统，就是我们十年前研究的这些深度学习，也是李飞飞老师比较擅长的部分。把这些视觉系统看到的信息，我们人其实也是这样的一个无感集合的一个信息处理中心，对吧？那大脑就是一个高级的CPU或者GPU。我们人的眼睛看见了各种各样的信号，信号通过大脑告诉了我们这个画面，然后这个画面里面的信息，我们人能够去做分割、分类、识别，然后基于这些信息我们能去做反馈。
	这反馈你从AI的角度来说，一类是判别式问题，一类是生成式问题，对吧？判别式问题就是假设你的领导问你，你说我今天的这个决定好不好？你说特别好对吧？为什么特别好？你还能讲出123来。那深层次的问题是说，你说下一步工作应该怎么做？你举出了这个一二三有短期的安排，有长期的安排，有细致的规划，也有宏观的战略，对吧？其实人跟AI有很多相似之处，这个事情又上升到一个哲学高度，就是那你学哲学跟学AI有没有什么可以借鉴的东西？我最近看了很多孔子写的这个十一，还真有包括这个很很有意思。
	简单讲一个点，我不想讲太多跟这个大语言模型无关的内容。大家都学过信息论，学过相同的这个信息论。相同的信息论有一个很重要的点就告诉大家是说信息的传递一定是有损失的。就是我在这儿巴拉巴拉讲，听到的每一个人的每一个听到我画的这个这个听众可能他的关注度也好，他自己的一些能耗也好，会消化成不一样的内容，一定跟我想要表达的之间是有差距的。这个是信息的损失。然后他不管是以什么样的载体，他都是有损失的。
	我们还听过一句话叫，一图胜千言，对吧？就是你如果用一个图像的方式来表达，会比你说说出来写出来，用文字纯文字来表达，消除更多的歧义，减少这个损失。就是因为图像可能大家能更多的去达成共识，包括视频等等。但是无论如何，不管你用什么样的载体，它都是有损失的。
	孔子在几千年前也说过言不尽意，这个词大家可以由着这四个字去找。其实本质要解决的问题，要说明的问题就是人跟人之间的交流一定是表达不了自己的含义的。就跟我刚刚说相同的那套理论是完全一样的。
	然后他也有提到用图案都会达成不一样的认知，这些就是你会我说的如沐春风的感觉。就是你今天花了比如说花了5个小时时间在看AI的论文，然后睡前花了2个小时时间在看哲学，你发现他们在很多地方是有相通的地方。包括你再回过头来看这个GPT4，今天出来这篇文章，包括前几天上个月讲这个GPT4的揭秘，对吧？我们是由不八个专家或者说八个不同领域的大模型凑在一起，用instable的方法，相当于整了个智囊团，八个智囊，然后各自有擅长的领域，你来一个问题，八个智囊都告诉你答案，你再看哪个正常回答的好，然后把这个答案甩给我们的用户。
	这种方式ensemble的这个思路，其实在transformer里面，就是在六年前在google的这篇论文里就已经非常好的体现过了。这个我会在我们的第一次课的时候去跟大家分享一下。就在他的transformer的摘要里面就有提到，就transformer本身抛弃了很多的东西，然后只留下了tension，并且用了muti head attention。这个muti head attention的逻辑就是用多个attention mechanism去学习同样一段话，它的不同的含义，你可以理解成每个不同的attention都是一个小专家。其实这个思路由着这个过来是非常成顺理成章的一个事情。
	GPT4 transformer？又隔了六年，但他们的效果达到了完全不一样的阶段。这里又有很多东西值得思考。但是无论如何你会发现你在学习这件事情本身上，你有mate learning，你有知道如何去学习，你能搭建知识体系，都对于你去学习任何新的东西有帮助。
	好，最后留下一点点的时间跟订阅课程的同学讲一下我们的这个课程安排和思路。首先我现在一直在鼓吹的，也被或者说讲的一个。很重要的一个技术战或者说技能站skill的这个stack。就你自己一个人，你在这个工作这方面，你在职场这方面，你应该具有什么样的一些能力，然后跳出工作以外，你自己学习任何一个新东西，你需要有什么样的一个方法论。在大语言模型的时代，我觉得方法论很重要，并且跟以前都会有一些不同。
	也是通过这个比例，我去设置了整个课程的一个时间分配。首先当然这幅图还会有一个B，就我之前考察这个研发员工，他应该会有怎么样的一个技术站，这里我们就暂时不展开。就是说我认为现阶段我们应该怎么样去分配自己的时间来高效学习。首先最重要的事情就是实战，就是我们要用动手的方式去碰这些新技术，去拥抱这些技术红利。刚刚有提到一方面是作为一个用户，作为一个user，我们能去使用新东西。比如说我们能用prom，用prompt engineering的一些手段，然后用prompt template的一些模板去帮我们快速的使用现成的像ChatGPT，像拿马，像cha TGIM这样的大模型，帮我们解决问问题。第二个就是说如果他不够用的时候，我们能不能基于它。因为大模型是一个很底层的，我们讲AI范式，为什么叫第四次的AI的这个浪潮？
	第四次的发展就是因为transformer的出现，因为大语言模型的出现，使得大语言模型本身变成了一个我们叫foundation model，就基础层。然后上面可以做各种各样的事情，就比如说我们刚刚提到的郎茜，它其实是你可以理解成是一个大语言模型的middle wear，大语言模型时代的中间件。它负责跟更上层的应用层和下面的基础模型层之间去做交互。
	中间件干什么事情呢？大家现在做互联网开发知道有什么样的中间件，有这个消息队列对吧？有缓存，redis，包括还有一些其他的，那这些东西都是在中转出处理数据的，有的时候是为了hold data热数据我们要能够临时存下来。有的时候是为了我的处理能力不够的时候，我能够把它存下来。
	其实南倩的定位跟他非常像，这句话大家可以去细品，然后去看这个社区的发展，包括他自己对接的他的抽象和他对接的各种各样的内容。他去接向量数据库对吧？他自己去设定了agent，设定了这个chain这两种不同的抽象。然后他去把这个prompt template这么一个模板做成了一个他自己的很重要的抽象。然后他自己把大语言模型的处理结果，我做成了一个partner，这个是大模型应用实战，我们一定得去实际的去碰它。
	第二点就是我今天的主题就是mean learning。Meta learning其实要掌握的叫meta knowing对吧？就是原知识是什么？原知识和知识点最大的区别和这个具体的knowing最大的区别就在于我们的meta learning是要学how to learn，learn to learn? 就怎么样去学学习本身要怎么样去学。有一本书我前年看过的叫如何阅读一本书，其实也是很有意思的。不过它是从技术层面在讲如何提升自己的ROI去读书，这个是很重要的点，就建立知识框架，然后说这个合作共赢，我们的。
	那我什么时候开声音和我好像。
	听到了那个那个的声音，就我们导播的声音可能需要mute一下。对我这边还有大概五分钟。第三部分就这个合作共共这个合作共赢点很简单，其实就是在刚刚提到的三层，我们的fountain foundation model，然后我们大模型的这个基础模型层，然后中间的南茜就应用层。应用层其实就是说我们要设计各种各样的应用，这些应用就包括。
	一会儿我需要开启视频，需要静音吗？
	Hello，张浩老师可能需要把麦闭一下，我这边能听到你声音。对呃对然后我们最后应用层，刚刚有讲到就是人和AI在交互。人和AI交互的同时，人和人也在交互。然后你有可能跟你交互的那个人其实本身是一个AI的agent对吧？这个是一定会发生的一个事情。那怎么样去更好的去跟AI交互，跟AI的agent交互，跟拥有AI agent的人去做交互，这个是很重要的一个技能。
	最后就是我们的创新的思维，我们的innovative。这个是指我们要关注新的东西。就我们在已经有非常成熟的也好，我们在不断完善的这个知识框架的体系下，我们还能去吸收新东西。然后我们吸收新东西的过程就是一个庖丁解牛的过程，对吧？
	我们看到了GPT4他用的insect boy in inmate l是一个transformer，用过甚至更早，machine learning也用过非常早，这个都用过。这个东西其实就没有那么就太阳下面就没有那么多新鲜事儿了，对吧？就跟我说你看三选也好看，孔孔老也好，那么和你研究现在的这个大模型也好，其实你往根儿上找，大家的根儿上的东西其实并不多，更多的是它的变体，它的演变，它在不同场景的应用。这个是非常值得大家去深度思考和未来学新东西的时候的一个方法论的认知。我觉得这个是我自己的一个体会，希望大家也能够通过这个方法去提升效率。
	然后整个课程我们看得到其实它分成了八周的时间。然后有三个大的篇章，分别是基础篇，进阶篇和最后的这个生态篇。我们的比例就这个分配的比例也是实战最多，大家能看到实战的这个课程的时间是最多的，差不多将近一半。然后同时我们这个大模型基础这个课程可能会实际的话可能会讲三次的课程，或者说两次半的一个课程，因为我们这个内容非常多，这个初探大模型起源与发展，我就已经给大家做了得有八十多页的这个slide PPT了。
	因为确实要把这个大模型一路怎么来的，我们按照刚刚没谈论令的方式，对吧？怎么样从我们根儿上，假设我们只调到这个attention mechanism到现在的我们的GPT4，包括其他的一些大模型，他们之间这个过程有哪些精华的东西，有哪些重要节点。这个知识体系里面的重要节点是应该被拿出来单独讲的。我觉得这个是非常重要，也是让大家能够假设。因为我们大模型一直在快速的迭代，假设我们这个课结束了，又有新的东西出来，怎么样把这些新的东西纳到你自己的体系里面去，这个是很重要的一个点。所以大家会看到一开始会花一些篇幅，两周的时间、两节课的时间，一周的时间去讲大模型的基础。
	然后接着我们每一个新的东西，不管我们讲OpenAI也好，讲ChatGPT也好，包括讲我们的南倩也好，都是理论加实践的方式来讲。然后这个过程当中，希望大家动手和思考能够同步进行。然后也会有这个家庭作业布置下来。大家要是有兴趣的话，我觉得也是值得去看一看的。这个家庭作业既有动手的，也有阅读类的，这个阅读需要去总结，可能会有一些选择题之类的给到大家，让大家去看是不是理解到了一些关键点。包括最后的应用和这个生态发展，我们也会去讲跟应用落地相关的一些隐私问题，以及大模型这个生态。其实除了OpenAI除了南茜这一套技术站以外，每一层里面都还有机会。中间的中间建成南茜目前还没有大的竞争者，但是底层的基础大模型我们看到了无数的玩家，对吧？
	然后除了OpenAI的大模型以外，清华的CIGM资源。CIGM包括我们像开始提到的一些国内的公司都在做。最后会有一些课程的答疑，我们单独有一次课去做完成的课程总结，包括针对这个课程进行的这两个月过程当中，一定会有很多新的东西出来。我们把这些新的东西都统一总结，然后在这一次课里面去跟大家做分享最后有一页是一些感慨，因为前两天终于收到了google部寄过来的谷歌开发者的证书。其实我是中国最早的四位在积极学习这个领域的GDE。
	那会儿是其实整个国内的开源没有现在这么多公司，这么多社区在做，就非常少。然后那会儿我也在华为，然后后来出来去了这个财源科技。见证了国内的开源社区和技术氛围的一个逐步成熟。
	其实今天的开发者和八年前、十年前的开发者比起来已经幸福很多了。他们有很多的渠道，有很多的信息，能有更多的机会接触到一些也相对来说有有一定经验的开发者或者说专家，我觉得这个是非常好的。然后这五年其实也是无证经营，一直都在讲除了这个线上系统以外，线下没有一个证，现在终于有证了，对，很有意思。下一个五年，其实不管如何，是不是订阅了这门课也好，或怎么样也好，线上线下都可以。希望能够跟更多的小伙伴，研发也好，我们的产品经理也好，一起来投身做这个事儿。就我们的AI大模型，我们的AI的基础设施大模型和应用，其实都会有很多的工作需要大家去开展。我今天的这个分享就到这儿，感谢大家。接下来好像是一个感谢大家。
	我可以解除静音，开启视频了，对吧？我可以接受建议。好，感谢彭老师的精彩分享。我们刚才大家听彭老师对这个未来趋势的一些判断，相信大家已经迫不及待了，要开始学习。我们跟着彭老师来学习我们这个AI大模型应用开发实战营的这个课程了。今天我们也除了彭老师的分享了，我们刚才也做了预告。就是说我们一会儿还有马上就是马上就会有另一位专业的老师来和彭老师，还有我一块来去去做一个。我来对两位老师去做一个访谈，去问请两位老师去解答一下招聘相关企业用人单位招聘方对AIGC领域的人才的一些需求。一个是我们的彭庆庆老师，他会来参与我们这个访谈。另一位我们也请到了国内非常专业的人才服务商TCC的一位AIGC领域的专业顾问王宇晨老师来参与我们的访谈。
	接下来我们就进入这，稍等两位老师准备一下，一会儿我们就进入访谈环节。我们的访谈内容也主要是征集了大家此前的一些征集到的一些问题，就是大家关于这个AITC领域方面的一些招聘用人需求，包括很多同学最近也在我们这个学员群里边去反馈说，学完这个课程我们可以去做什么内容？去做什么样的工作呢？相信很多同学都对这些问题有一些需求，想知道这个问题的答案。接下来我们就进入这个访谈环节。
	Ok我看两我已经进来了，彭老师好，还有王老师好。接下来我问两位老师一些问题，就是请两位老师分别来回答一下。Ok大家是可以听到我声音，声音是没问题的。
	可以听到。
	Ok ok那接下来我们访谈就直接开始了。行，今天第一个问题，导播是需要给调一下。好的，稍等导播给我调一下这个镜头的位置。Ok行，可以了是吗？好，我们今天先说第一个问题，随着我先请彭老师来回答一下他的第一个问题是随着今年这个AIGC的爆火，根据两位在行业内的观察，各个企业在今年在这个AIGC领域方面的这个招聘需求大概是一个什么样的情况呢？彭老师先来回答一下。
	好的。
	这样王老师先来回答，然后是王老师来回答，我说一下这个顺序。
	好好，那我这边开始对吧？行，我听懂，那我先抛个砖。是这样，就是AIGC首先这个词比较泛，我相信经过这半年多的这个时间，大家也越来越整明白了。其实这个AIGC有几条路，有几条线路，然后什么样技术方向，像我们公司的话其实会更加注重。这也是为什么要做这个课，也是希望他有没有一些优秀的学员，能够成为未来公司的合作一起合作的共识的同事。
	我们其实更看重两个方面，就跟刚刚分层讲的比较像。第一我们不太会去做底层的基础大模型，这个会太耗时耗力了。我们会在中间层，比如说南茜，就这个大模型的middle are这一层，我们会有大量的这个工作。我自己现在也在做这个事儿，也正在跟公司里面的其他的同事一起去做这个事儿。
	这一层就南券的开发者就会使用南线的研发。会是我觉得会是现在所谓的AIGC开发者里面最有优势的一波人。因为也没有什么别的东西了，就跟十年前你会扩大的开发，会touch的开发，八年前会tensor low开发，五年前会patch的开发一个逻辑。所以这个是有技术红利的那第二点就是说我们可能会关注一些，他不是说这一波火了之后再再投入的，而是说他一直在AI这个领域里面，他有一些其他的经验背景。不管他是做AI的工程，做AI的前端，做AI的产品经理。
	这种同学他的这个转身也好，他的学习也好，会我们认为沟通起来会成本更低，然后更容易聊到一起。可能会这两类人就偏应用层了。对。
	ok好，那也请王老师来回答一下这个问题。也就是因为你做了很多这方面的人才服务，也请你表达一下这方面看法。
	好，没问题。然后谢谢主持人，也谢谢彭老师之前精彩的分享。大家好，我是知名猎奇TTCAIGC方向的专业顾问雨辰。也很荣幸这次能够跟大家一起来聊一聊AIGC行业发生的一些变化，以及企业招聘的一些用人的需求。刚才我们有问到这个问题，说现在AIGC的需求是怎么一样的？其实我非常开心的说，其实是一个非常积极的一个市场，就不明industry就相当于是整个AIGC带来了在行业产业上颠覆性的影响。像今年年初TTC将近接到了30家初创企业的招聘团队搭建的需求。同时大厂内部技术团队搭建的工作，其实也在如火如荼的展开。
	从技术侧，刚才彭老师有分享到就是从算法工程，然后数据再到我们说的产品运营设计前后端。然后其实会有很多不同的岗位需求都涌现出来。然后根据企业的规模的不同，比如说它是初创企业还是大厂，其实也会分为他想要技术高阶的创始团队的成员，还是说主力的年轻的高潜的技术伙伴、产业伙伴。同时根据企业不同的商业模式也有拆分，比如说他是想做to b的企业还是to c的企业，或者说他是想专注在技术导向驱动的大模型公司，还是说做产品和技术双驱动的这种公司，那他的需求也会围绕BC端的产运，然后相当于是技术团队人数的多少，搭不搭建预训练方向的团队等等，都会有一些差异。
	好，刚才我接着问一下于强，刚才你也说到了在这方面一些需求的，你观察了一些招聘需求的概况。你就你观察到的这现象而言，大公司和中型公司以及小公司在这方面需求有哪些不同吗？
	这是个非常有趣的问题。首先可以发现有一个很明显的相同点，就是我们都需要强有力的带队人。谁真正可能像彭老师这样非常有经验技术带队人或者运营产品的带队人来进来在大厂或者创业公司。其实进一步我们再看其中不一样的差异点，可能是在于企业搭建的过程中，大厂它其实对于团队规模和各个细分方向的要求会更加复杂一些。所以可能我们需要除了有非常资深的P9P10 level的人选之外，我们还要有P8左右强带队的技术负责人，以及一些可能毕业2到3年或者五年以内的这样的人选，去作为一个三个方向的梯队搭建。当然还包括一些大厂，还有一些校招项目。
	然后如果是小型的初创公司，可能pre a轮之前的大部分在20到30人的规模。那他其实就会非常的扁平化，就是强有力的负责人。然后再加上一些年轻的主力同学，其实他会非常简单，也非常直接高效一点。
	中型企业位于两者之间，它有可能是新兴的独角兽，或者是一直在B轮附近的精品企业。它的需求会更加的规范化，就是相当于根据企业的业务模式，它会设计不同的岗位和团队搭建。所以其实它是分为梯队来看。
	好的，谢谢王老师。彭老师在这方面有哪些观察吗？还是刚才那个问题，就是大公司、中型公司和小公司在我们这人才需求方面，他们不同的需求。
	明白，确实这个问题非常好啊，王老师刚才讲的也很全面了。对我可能就补充一个小点，就是说因为我们可能算小公司，我们公司也就才正在融这个B轮，也才四才五年多的一个时间。我觉得可能小公司的话，因为没有大公司那么多的业务那么全面，所以除了在AIGC本身以外，我们可能还会考察另一个维度。就是因为它要结合，IGC最终还是要落地的，就跟其他的技术一样。在这个落地的这个视角上，可能小的公司会更多的选择它目前的这个业务上面，你有没有一些弄好？因为AIGC核心还是在于这个基础大模型，你自己没什么机会了。像我们投资人这个朱巧虎？也是我们投资人之一，之前也讲过。更多的机会在哪？在中间和上面，就刚刚从技术的视角也拆了。
	中间和上面那你有什么样的一些背景？你有没有一些行业的know how，或者说你有没有一些项目的经历？这个我觉得可能是另一个点，也是很多大家在焦虑。我之前不是干AI的，我是干前后端的，我做项目的，一样的是有机会的。关键是还是刚刚那个今天分享很重要的逻辑，你做了这么多年的工作，你沉淀下来了什么？5000年你记住了什么？这八年的工作经验你留下来了，是其实这个很重要。所以这个know how和你的沉淀的一些项目经历，行业经验会很重要。对于小公司来说的话。
	好好的，谢谢。刚才我们也谈到了这个招聘需求，就是这个招聘市场一个概况。很多人可能就比较关心他现在自己是做这个传统开发，现在各个公司在这个AIGC领域的人才技术人才方面有更多的需求了。他们怎么去转到这块？根据你们的观察，是从传统开发转到AIGC相关应用开发人多吗？以及你们，特别是王老师，你们给企业提供这方面人才服务的时候，就像比如你们去给企业输送这方面人才，他们之前大概是做什么的呢？王老师可以先回答一下这个问题。
	很多的传统开发的需求现在是逐渐的在增加。就相当于是原来互联网产业一些优秀的伙伴，或者感兴趣转型的伙伴。其实现在在大模型这样的初创公司里面会有很多的需求。然后我们的初创公司也会分为不同细分行业。比如说之前TTC也专门出版了HI相关的行业报告。那在里面比如说代码不像3D文本相关的，其实都可以自动生成。
	所以像彭老师刚才也提到，对于前后端数据架构的伙伴，只要他愿意转行，然后很感兴趣，其实这个市场的需求会非常多。大家如果感兴趣的话，也可以说更多的去读一些行业内的文章，然后学习一些课程，然后更多的去体验一些大模型相关的产品。所以市场是一个非常繁荣，而且有很多新机会的市场。
	好的，彭老师怎么看这个问题呢？
	你看是哪一类的岗位需求对吧？
	对，我再重复一下这个问题。其实就是想说很多同学比较关心他怎么从现在这个IGC领域的需求就已经涨起来了。他比较关心现在企业招这些人是之前做传统开发的，还是说他本身还其实本身就是从AI领域过来的。
	他们比较关心这个。明白，我觉得是我是这么看这个问题的。首先无论如何，不管做什么样的一个新技术，其实它的比例分配也好，它的岗位分配也好，还是服从这个正态分布或者说这个28定律的。所以你会发现真正就是大家我看最近有一些讲法，就跟每一轮AI活起来都会讲说什么好像做AI的或者说AI的的招聘并没有那么多。其实也不是，因为其实真正懂这个底层大模型的，就其实可能全世界也找不到几百个人，可能就那么一两百个人，对吧？那么在大模型上能够会微调的就是可能数量会更多一点。比如说能够有几万人或者说几千人。
	在这个问题当中，我们现在在聊的不再是说我要学一个新技术。而是说我要在一个公司里面一个具体的工作岗位上去承担我的具体的工作了。这个时候你会发现大部分时候他的配比可能是我有一个真正会搞大模型微调的人。然后给他配了十个工程师。这十个工程师帮他去解决这个大模型微调之后，它有可能是一个垂直大模型，有可能是一个project injection的基础大模型，有可能是这个prompt template去配合它生成的一个需要输入输出去做前后处理的一个应用产品。那这个时候首先你能不能跟人家配合，对吧？就是我们还是讲技术稀缺性。
	我为什么讲刚刚说你要有弄号，然后你会一些基础的这个大模型的东西之后，至少你是那十个人对吧？你是AIGC的这个项目组，对项目组很有希望对吧？大家知道AIGC现在很火，你在那个项目组里了，然后你是那个项目组里的那十个人了。然后我们再说你下一步怎么怎么成为那一个人，这个比例是存在的客观存在的。然后那十个人里面一定需要前后端和项目经理和刚刚提到这些角色。
	那你现在是处于一个什么样的岗位，我觉得这个比较关键。就你自己觉得你的技术站需要有比较大的调整吗？如果不是的话，你就会发现其实AI就跟十年前讲软件在吞噬世界一样。
	现在AI其实就是在吞噬世界。它首先吞噬了各种各样的研发工程师，他消解了很多研发工作。同时他未来会消解其他很多行业的工作。那你现在的工作你是要由着他怎么样跟AI去结合呢？结合之后先从自身的角度去找你适合做什么样的事情。
	然后哪一类哪哪一类的岗位需求会比较多，其实是一个具体问题。我觉得可能在像BAT或者华为这样的大公司来说，他们会去做很多技术类产品。那这个时候肯定是我刚刚提到的那个82里面的那个2比较多。它可能不是1比10，他可能是2比5或者1比5。那这个时候你可以选择去试一试，你要不要当那个一或者2，对吧？然后更多时候你成为先进到那个项目组里的懂AI就你是原来有技术加AIGC或原有技术加AI加l am的，这个人会更好一点。我觉得而且这个也是很急迫的对，因为这样落地需要这样的工程化团队。
	所以大家还是要去抓住这个比较难得的机会。就是在我们这个IGC刚兴起的这段时间点，其实你要做一个最早去赶上这波浪潮人，其实你就会有更多的先发优势。接下来还是想问王老师一个问题，就是因为你们在招聘领域方面也有很多的经验。想请你聊一下，就是像你们今年做这个AIGC领域的这些招聘的话，招聘服务的话有哪些比较有趣的洞见可以分享给大家吗？是不是大家听完你这些之后，可以对自己的找工作、职业规划有一些帮助，可以分享一些。
	非常有趣，其实它是一个行业产业波动的过程。最开始初创公司搭建我们找一号位的过程中可以看到大家优先看bat或者是传统研究院里。做技术一号位的人才，以及相应的重点团队的人才。所以这个时候行业线找人其实会非常精的专注这个领域。相应的在NLP算法，AIGC多模态算法或者AI框架侧的人选，我们可以说是炙手可热。所以在这个阶段，其实对于行业线的伙伴来说，技术侧和产运侧其实它是非常集中的一个状态。
	然后我们进入到了第二个状态里面，就是你可以明显的发现在搜索大模型关键词的时候，相应的人选变多了。这是因为现在很多企业和初创公司在进行大模型相关的业务，所以市场也在孵化和培育更多的大模型相关的人才。这个是一个非常好的现象，就是大家已经开始从事相关的研究，然后大家已经去探索相应的产品。所以在这个阶段我们会发现我们顾问侧和人选侧都是一起在认知升级的过程中。就是我们从传统意义上理解的大模型，只是做技术到更多的大模型有这么多有趣的对话类产品，就是文本类产品、笔记类产品，甚至说一些to b类的服务产品。所以它会有各种各样的分支。
	在这个基础上，行业里面的需求在增加，然后人选的经验在积累。所以在这个过程中，我们对企业招聘以及大模型本身这个事情的理解就会发生变化。大家可能更多更广泛的接受了这个概念，然后也在积极的去探索和想办法是不是有可能去转型。所以这是一个在认知和企业需求市场上发生了一个变化。
	另一块我觉得比较有趣的一个观念就是大家都在谈论，原来的我只要最优秀的人选，然后谁最强到现在真正的我们在搭建梯队的过程中，可以根据企业的需求去为他搭建一个完整的技术的梯队。这个梯队对于人才的选择，人才的适配性也会由原来的单一观念变到现在更加多元的一些观念。就什么样是适合这些企业的。所以可以看到企业不仅仅只追求技术最好的人才，更多它是追求适合企业双向奔赴，且它能够为企业带来现阶段赋能的人选。而且也有更多的企业愿意去培育大模型相关的人才。其实相当于是这两点，我觉得是特别有意思的一个现象。
	好的，谢谢王老师。我们现在已经九点半了，我们很多观众也在看两位老师的答疑直播，他们可能现在也有一些新的问题想问老师，那我们就直接去弹幕区里边看看有哪些问题可以两位老师可以帮忙回答一下。技术问题就是彭老师，大家可以问彭老师有很多同学也想在这方面问一些求职，AIGC领域的求职招聘，职业规划方面问题，也可以问问王老师。大家有哪些问题就在弹幕里面发出来，我去挑一些，就直接在这里边给提出来，两位老师回答一下。先看一个技术问题，一个人叫我是豆瓣酱，他问彭老师用long称对于这个高负载有解决方案吗？
	好，非常好的问题。大家可能要看他的这个高负载的一个具体情况了。因为高负载其实是一个在所有的技术人员都会面对的一个问题，尤其是当你这个应用逐渐有更多的人关注的时候。
	首先我从我的理解，因为没法跟他直接交互。首先高负载看，因为南倩他的最大的价值在哪呢？其实作为一个沟通大模型和你最终应用的一个中间载体，人生的价值是可以去跟大模型多轮处理他的逻辑。然后如果在这个问题中，高负载的问题是说这个多轮本身就我同样的一个用户，我现在在问这个大模型，比如说我现在问这个大模型，能不能帮我解答一下明天的出行应该采用什么样的交通工具。
	这个时候他会发现你的这个问题可能不是很确定，因为你并没有讲你要去哪儿，对吧？你只是讲你要出行，那这个时候他可能会先去检索一下上下文里面有没有这个对应的信息。你有没有可能在之前的对话里讲过你要去哪儿，或者说你用过别的方式去表达了你可能未来要去哪。这些都是南倩的倩和agent这两个头像能够帮你去解决的问题。所以这里就会有很多轮的尝试，就跟大家看这个auto GBT的demo一样，它会内部去做多轮的这样的一个处理。这个时候如果这里有很多的多轮，第一很难去直接去给它做变形了。因为它这是一个串行的过程，这里是不太好去做并行的。
	这里唯一能够去做一些比较好的并行场景是相对数据库的引入。这个我们也会在后面去讲，包括最近也在跟一些做国内的这个数据库创业公司的一些方面们在聊。就是向量数据库是另一个中间件，这个中间件对于大模型来说是一个第二大脑。你可以这么理解，他能怎么样解决高负载问题呢？这个就跟互联网的经典架构很像了。就我们做一个网站，我们做一个双十一的抢购。我们通常需要中间件来解决这个消峰填谷这个高并发的问题。
	向量数据库对于我们的AIGC的应用来说就是这么一个定位。对于很多的重复的问题，相似的问题，他可以帮你去做解答。因为他不需要再直接去访问最底层的的基础模型了，而是在向量数据库里存好了这样的一些QA。那这些QA队是能够帮你找到一个相对来说你还比较满意的答案的。即使是像刚刚那样的串行过程当中，如果你不是一个特定定性的一个个性化的问题，那他也能够通过去向量数据库里检索帮你解决这个问题。这就可以去做一些高负载的一些尝试了。这个是我们看到的现阶段。未来可能还会有很多的不同的尝试，就包括我在跟这个向量数据库的一些研发团队去在聊。
	就是我们刚刚举的那个场景是比较相对来说比较难业务的一个场景，就是我有相同的问题或者相似的问题，但是我的问题本身也是可以组合的。我的南线是不是可以针对向量数据库，把向量数据库当成我们的基础模型一样。把把这个问题本身它的答案，就是已经缓存下来的答案，在向量数据库里的答案再去做拆解，再去做representation，然后再去组合。那这个时候其实就所谓的第二大脑的价值才在这儿。他不只是存下来，他还能再思考，把以前已经回答过的问题记下来，像一个学生一样，对吧？我觉得这是我目前想到的一些答案。对，不知道有没有回答这个同学的问题。
	好的，这位同学如果你有更多问题可以继续在这个弹幕里面提问我们来看下一个问题，或许王老师也可以帮忙回答一下，不一定是这个具体的岗位。有一个同学他想问，从传统产品经理怎么成为大模型产品经理？像这些企业在招聘的时候，就是像王老师你碰到的这些企业，他在招聘的时候，对这些想从传统的港传统的这些无论是开发产品经理要转到这个大模型领域的这个开发或者产品经理会有哪些要求吗？哪些具体要求吗？比如说这个学校、学历，还有其他的一些项目方面的要求，这个王老师可以帮忙解答一下吗？
	好，非常新。但是我觉得也是大家比较关做的一个问题，就是如何去找到心仪的相当于转型的一个工作。其实我们也有幸和一些初创企业特别优秀的产品负责人去交流和学习过这样的一些问题。然后有听过他们的一些具体面试的一个情况。
	整体可以看下来，就是在转型的过程中，如果真正感兴趣转到AI产品这个行业，首先其实对于人选的要求是要求他自己有相关的AI产品的经验。如果之前就在做AI相关的一些生成式或者工具类的业务，其实这一点是非常加分的那除了这些硬性的条件之外，一些软性的比如说会积极的去思考大模型的一些变化，关注其中的技术点，具有creative thinking，就是相当于创新的思考以及一些批判性的思考等等一些思考的能力。然后他能够快速的去反映一些在产品设计和功能上，大模型能够带来的一些改变。因为实际上大模型的产品也是在不断迭代的过程中，他没有一个统一的范式。这也造就了他更加的有趣和富有魅力。
	所以在这个基础上，大家感兴趣转型可以从以下几个阶段。比如说我们经常团队的伙伴和leader们也会分享。像是你可以去阅读一些相关的技术文章，公众号文章，去思考其中一些技术的转型点和带来产品一些改变。然后多去体验国内外不同的产品，创业产品、成熟AI产品的一些变化。然后通过这些相应的赋能去理解真正在一家初创企业做大模型的产品需要具备哪些的功能。然后需要去如何的去创作。这是基于如果之前没有经验的伙伴，可以从以下的角度来展开了。我觉得像在创意的过程中，其实他是最体验一个人深度思考，对大模型业务的思考。所以他需要一个全面的去理解技术站，以及相关的一些相应的设置的一个过程。
	好的，谢谢王老师。下一个又是一个技术问题，得请彭老师回答一下。他这个同学叫我，他他问的是掌握朗读和CHATGLM主要需要哪些知识？需要读懂那些transformer bert系列的论文吗？
	好问题。对，我觉得今天讲那个知识体系最重要的一个点就在于告诉大家那个知识点本身你掌握的有多深刻，已经没有那么重要了。首先一定会在第一章就教大家，我为了做第一章的前三个小节，刚刚就说我已经读了有几十篇论文了。但是这个读的过程就是在帮大家筛，对吧？很没有办法，没人帮我筛。
	然后把这个论文筛出来，其实就会发现其实它里面有很多的思想，有它的技术的脉络是没有那么复杂的。所以就大模型本身，包括刚刚提到的transformer，它的注意力机制其实是有很多一脉相承的东西。是这个脉络很重要，一定要把这个脉络把握住。同时至于这个论文你整的有多明白，就每个字都整明白了。因为大家知道知识它像一棵树，对，这个脉络是这个主干。就是我们刚刚有提到一个具体的知识，那个切片的逻辑，怎么从这个校训，怎么从校歌回到易经？那怎么从这个论文当中的一个词回到那个根儿上的attention很重要。但是并没有说他就没有长出其他的知识的脉络，这个枝芽？
	那些没有那么重要的东西，我们可以先放一放，我们把我们现在上手最重要的事情先给整明白，所以这个是回答第一个问题，就是不需要看的那么细。但是至少我讲的东西咱们一定得消化掉，因为我已经塞了，大家觉得这些是很重要的，所以大家一定得整明白。就是刚刚包括刚刚那个分享里面也有粗浅的提到一些，对，是这样的那第二点就是说需要哪些先验知识去学习这个大模型呢？其实我觉得有两个点很重要。
	第一个点是我相信很多人看过姜文的一部电影叫让子弹飞。葛优老师当时面对姜文的老婆说过一句话，就是他想当马匪，但是他不知道怎么当。葛优老师说我也不知道怎么当对吧？我吃着火锅唱着歌被人绑架了，他就成为马匪了，对吧？
	先去试，就跟我们一直讲的40%的比例是实践。你先去试一试，先去玩一些大模型，就是你不要怕，就是你不要有任何的畏惧感，先动手去用。不管是用CHAGPT也好，用这个大模型本身也好，这些开发框架也好，CIGLM也好，它都有部署文档的。它跟以前你学的任何一个前后端的东西，互联网的东西没有本质的区别，你先把它弄起来对吧？你会用了，然后能够部署了这些东西其实是不需要花太多精力，你也能掌握的。
	把这个东西搞好，这是第一步，就是你先迈出去这一步，这个动作很重要，这个动作就把我们的一个滑动的摩擦力变成了一个滚动的摩擦力了，对吧？我们学过初中物理都知道，滚动摩擦力阻力就少了很多，你就走起来了，对吧？那你走起来之后才会知道你需要什么样的先验知识。因为这决定了你要往哪个方向去深入研究。
	你是要去变成一个难看的contributor？变成一个社区的贡献者呢？还是说你想要通过南劝你，你就把课程当中的几个实战整明白了，你可能你就能打造你自己的一些AIGC的小应用了。那这个时候可能你更多的要研究的是你的领域数据应该怎么样去做数据，这些数据怎么样变成一个可以喂给大模型的prompt。所以这个其实更重要，没有那么多先进知识需要去掌握的。因为大模型能写代码对吧？大模型能帮你做文档的工作，其实更多的还是用，对，就直接去用。
	好，我们看下一个问题。下一个问题他有点像关于这个企业的人才建设的阿托。他想问这个AIGC招聘的话，大概是主要是招聘哪些技术岗位，以及对于未来进军AI这些企业，去搭建这个人才梯队有哪些建议吗？王老师应该对这个问题比较擅长，你可以回答一下，一会儿彭老师也可以说一下自己的看法。好的。
	好，从招聘的技术线来讲，其实可以分为几类。比如说在技术领域，就像AI核心的算法，NRP的算法，其中也包括一些传统的做NOP的语音对话，或者一些直接做P大模型预训练等等。在上层的一些模型相关底层开发的一些。算法，然后还有一些多模态AI这些的算法，然后AI info框架，比如说模型的推理训练等等。
	然后进一步从职能线和产品线来讲，它需要有产品经理，可以是B端、P端或者C端。进一步还有像是做如果是面向海外市场，就会有海外运营的负责人，商业的负责人以及他们相应的团队搭建。然后国内市场就是市场运营对整整不同搭建下来。在其中技术梯队和职能梯队也会根据最开始我们分享到的企业现阶段的诉求和他商业模式上的差异去进行一个调整。然后从企业梯队搭建上面有哪些相当于是不同点，或者说是企业搭建上有哪些可以看到的一些常见的方法，然后如何去搭建更好的梯队。我觉得这些核心归下来就是为企业找到优秀的人才，还需要去怎么样帮他去找，以及企业究竟需要什么样的人才。从梯队本身的这个意义来看，它是跟整个企业现阶段的需求和发展方向强相关的。如果他现在需要研究型的梯队，那可能我们去增加一研究型和非常强的技术型人才的比。
	如果他需要产品创新和业务层的梯队，我们就去增加产运和业务上的一些需求，然后去增加相应的人选。其中在搭建的过程中，我们也会去进行一些人才的寻访，人才的摸排。更多的可以在不同专业领域和特长不同的一些人选，专注的一些方。向上去为企业去寻找相应的人选。对。
	好，刚才稍微有点卡顿，王老师回答完了吗？
	我回来了。
	Ok ok好，请彭老师，你也简单谈一下这方方面看法。企业在AIGC方面这个人才梯队建设，或者说是要核心招聘哪些AIGC的技术人才，这方面有哪些建议给到大家？
	你是建议给到招聘者还是。
	给自己要给到招聘者。因为有同学问，因为他可能是去搭建这个技术团队的，所以他想问，比如说我们要去做一个LGC的团队，有哪些技术岗位是要核心去优先招聘的？
	明白，这个问题挺好的，而且也是一个挺实际的问题。不过这个问题可能他没有一招鲜的回答。首先我觉得刚刚王老师回答已经很全面了。我觉得从另一个视角补充一点我的浅见是说，首先如果咱们是招聘者，然后咱们本身又不是一个很对大A大模型非常有深刻认知的技术人员来招聘的话，比如说咱们是一个业务领导，咱们是一个这个项目的负责人来做招聘的话，第一件事情不是想要招几个人，或者要招一个什么样的人，而是要解决什么样的问题。
	大家如果去看这一轮的这个大模型，其实有一个很显著的点。就是说模型的设计，包括大模型的这个研究，大家都在为下游的任务，我们具体的task specific，就这些具体的任务，我们再想象一下，我们应该要怎么样去设定这个任务，才能挖掘出这个大模型的能力。其实是倒过来的，是由任务来驱动的，是我要搭建这个项目团队来解决什么样的问题，由这个点来驱动的那如果从这里出发的话，我觉得问题就变成了一个很简单的ROI的问题了。就是我搭建这个团队要解决的是偏这种纯研发的。比如说你在华为内部的20医药实验室，就我以前带的这个部门，他可能不会直接背数字。那这个时候我要做的是基础能力的建设。基础能力的建设你可以去有这个技术能力，你可能就得分成了。
	刚刚也有提，然后你可以做简单的咨询，先以比较低的成本去了解你做这个事儿大概是一个什么层次的事儿，需要什么样的关键技术。然后下一步再是说这样的关键技术你愿意付出多大的成本去换回什么样的效果。这是对于一个纯研发投入的团队来看的话。如果你是一个要背这个数字，背产值的这么一个团队，那你就要倒过来算，你多少的预算能干这个事儿。然后这个预算又会倒过来，首先那就变成这个预算，比如说够不够？比如说你准备只准备了100万的预算，然后那这个预算可能也就只够招一个项目负责人，就是这个研发的项目负责人。那这一个研发的项目负责人你就去找这样级别的人聊就好了。你也可以很坦白的跟人家去沟通，然后看看别人的一些反馈。
	然后如果你的预算是，比如说大几百万，你要招一个5到10个人的团队。那这个时候其实跟刚刚那个路径是一样的，你仍然可以找到一个这样级别的负责人跟他们去多沟通。先让自己的这一块的know how，就是补充一下。然后补充好之后，其实你大概也就明白这些路数了。因为你现在最大的问题是你的信息缺失，信息不对称的对，所以我觉得可能是这样的一个视角，从具体问题出发，从你要不要背数字，然后你有多少的预算，然后优先找那些比较懂的人，而不是找那个junior的人去做咨询。
	好的，接下来有一个非常实际的问题，就是一个同学问说AIGC领域这个岗位会比传统开发这些薪资更高吗？两位老师可以简单回答一下。
	这个王老师比较了解。
	我觉得首先是在传统互联网的时代的时候，大家每个企业的招聘和不同岗位，大家的薪资是有不同的宽带的那在跳槽的过程中，其实涨幅大概的差异本身在不同的年份也不会有太大的波动。可能在原来互联网经济比较蓬勃发展的时候，我们会看到一些潜在上市的企业会给到大家比较多的福利。那可能是在当时的一个情况。
	现在来看大模型的企业机会，我想说的是有更多的机会。但是薪资涨幅这个事情永远是和价值相关。就是你是否能够为企业下一阶段发展带来相应的人才才的价值，是否你在同行业领域内是顶尖的人才。然后你的稀缺性和你能为企业去解决什么问题。在传统开发的伙伴来看，比如说大家的技术站，然后技术的全面性，管理的成熟度以及技术的领先性。这些都是企业在衡量人才整个标准过程中会考虑的一些因素。
	所以进而是不是比传统的企业薪资更高，其实很难评判，永远是因人而异的一个过程。但是可以知道的是现在更多的机会，更多的选择。所以当大家选择面变广的时候，评判机会的标准不仅仅是因为薪资了，更多的可能是你真的感兴趣大模型。你感谢你这个行业和企业，你加入到这样的公司，是能够让你和企业都有双向成长的这个过程。然后我们再看薪资，是能够cover住大家一些基本诉求。我觉得可能这样的话是现在在大模型企业中，大家会更加充实，以及更加愿意去加入大模型企业的一个原动力。
	好的，谢谢王老师。最后我们就再来问彭老师一个技术方面的问题，我们就结束今天的访谈环节。是我们就随便挑一个，这个是同学是这么问的，他说我是在做金融的，想问一下trend TPPT在GPT在金融领域有哪些比较主流的应用？
	王老师能帮到明白，首先金融很大，我去年看了曼昆的两本著作，就是微观和宏观对金融很大的一个领域。然后我自己也曾经开发过一些量化的小程序，不是微信小程序，一些小的side project。我觉得首先金融这个领域已经有一个很有名的，就彭博社他们搞了一个GPT，我不知道大家问这个问题的同学有没有了解过，就是金融离钱最近，就所有离钱最近的地方一定是新技术合法合规的，离钱最近的地方一定是新技术蓬勃发展的地方，这个是没毛病的。因为它的高周转，它的效率更高，所以金融一定有应用。
	然后据我了解的话，现在有很多的人在尝试，一方面是金融的报道，吧，这个可能是就布伦贝尔他们做GPT第一件事儿就干这事。就是我大量的金融报道我能让GPPT来帮我写了，包括写研报，写分析。如果你是做卖方机构的那这些东西肯定能用这种GPT类似的语言模型去帮你做的。因为这事儿就是一个做总结，做摘要，然后不断去输出特定格式文档的这么一个工作，所以这个肯定是能做的。第一个点。第二点我不知道它是指这个，如果是指这个trading，指交易这个部分的话，我理解的是也有很多人在尝试，但我自己不知道有哪家公司成功的跑出来了，因为量化公司其实通常自己都有团队的。比如说我知道这个杭州的换方，对吧？
	他们从我知道我一个直系学长去他们那的时候，他们管理规模才几十个亿，到现在已经是上千亿的管理规模了。那他们自己就能搭建一个自己的AI团队。这个时候是倒过来的，就是我金融很强了，然后我有钱，我有资源，我有卡，我自己就搞一个团队了。所以他不一定会在公开渠道上去碰很多东西，因为挣钱的这个金产值他是不愿意分享的。对。
	好的，非常感谢两位老师的精彩回答。因为我们时间原因，我们今天访谈环节就先到这儿。后面大家有哪些更多的问题可以报名我们这个课程。有可以在和这个课程互动过程中去向彭老师提问，包括我们有专业的助教。再次就感谢大家的参与，也感谢黄老师和王老师专业的回答。接下来我会再给继续去给大家去介绍一下我们课程的内容和我们课程的未来一些规划。好，我们访谈环节就先到这里。