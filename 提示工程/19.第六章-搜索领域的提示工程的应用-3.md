
### 提示工程：方法、技巧与行业应用

大的候选答案。

线性加权推断通过线性加权的方式综合上述两种概率打分，权值的选定由验证集中得出。

#### （4）评估 开放域问答任务上的评估

![image](https://github.com/user-attachments/assets/2becef5b-5068-4d99-935e-ccca7382d32c)

![image](https://github.com/user-attachments/assets/dd0e4957-1f02-4fe6-8336-fba350855a9d)


为了评估检索增强型大语言模型在开放域问答任务上的性能，谷歌研究员设定了以下两组参照模型作为对比。

- **CB**：大语言模型用于封闭域（close - book）的问答，即大语言模型在不依赖任何外部知识源的情况下生成答案。这种情况下，大语言模型只能根据其模型权重中编码的知识来回答问题。

- **OB<sub>gold</sub>**：假设大语言模型拥有一个神谕检索系统（oracle retrieval system），它可以为每个问题提供真实且最相关的事实段落（ground - truth evidence paragraph）来辅助大语言模型生成答案。
- **OB<sub>noranking - google</sub>**：在上述提出的方法上仅采用单采样方法，即去除多采样步骤而直接使用$P_{tfidf}(p_{i}|q)$值最高的事实段落作为生成回答的证据。

谷歌研究员使用的大语言模型均为GOPHER - 280B，评估集均为开放域问答任务公开的数据集。表6 - 6列出了不同的大型语言模型的评估结果。

**表6 - 6 检索增强型大语言模型在开放域问答任务上的效果**


|数据集|单采样方法|  |  |多采样方法|  |
| ---- | ---- | ---- | ---- | ---- | ---- |
|  | CB | OB<sub>gold</sub> | OB<sub>noranking_google</sub> | OB<sub>直接推断</sub> | OB<sub>线性加权推断</sub> |
| FEVER | 44.5 | 66.6 | 52.2 | 52 | 57.2 |
| STRATEGYQA | 61 | 80.4 | 61.1 | 64.6 | 66.2 |

从表6 - 6中可以看到：CB与所有OB模型相比，准确率有明显下降，说明引入互联网检索对于提高开放域问答任务的效果至关重要；单采样OB<sub>noranking_google</sub>模型与多候选答案采样与概率打分的OB<sub>直接推断</sub>和OB<sub>线性加权推断</sub>模型相比，准确率也有显著降低，说明使用少样本提示和多候选答案采样能够进一步提升大语言模型在利用外部知识进行推断和生成的能力。

以上结果表明，检索增强型大语言模型能通过利用外部知识库，给出更准确、更可靠的回答。同时，通过设计少样本提示，并结合多候选答案采样和概率打分的方法，能进一步提高大语言模型在解决特定任务时候的适应性和稳健性。

### 2. 开放域对话中通过外部知识和自动反馈增强大语言模型
本小节介绍的第二个开源实例是由微软MSRA的研究员提出的大语言模型增强器（LLM - Augmenter），可以为开放领域的对话系统增加外部知识和自动反馈机制，从而提升回答问题的准确率。微软研究员提出的LLM - Augmenter不仅能利用外部知识库作为回答问题的依据，更重要的是使用效用函数生成的反馈来迭代地修改大语言模型的提示，以改善模型最终的回答。

举例来说，给定一个用户查询如“关于2019年洛杉矶湖人队球员交易”，LLM - Augmenter首先从外部知识库中检索相关证据，并将检索到的证据与相关实体信息进行链接和推理来进一步整合证据，形成一个完整且有逻辑的证据链。其次，LLM - Augmenter使用包含整合后证据的提示来向ChatGPT查询，让ChatGPT生成一个基于外部知识的候选回复。然后，LLM - Augmenter会验证候选回复是否符合效用函数设定好了质量标准，例如，检查它是否虚构了证据。如果没有通过验证，LLM - Augmenter生成一个反馈信息来修订提示，并再次查询ChatGPT。这个过程重复进行，直到一个候选回复通过验证，并发送给用户。

LLM - Augmenter由工作记忆模块（Working Memory）、策略模块（Policy）、动作执行器（Action Executor）和效用器（Utility）组成。下面介绍各个模块的详细工作原理。
#### （1）工作记忆模块
工作记忆模块跟踪对话状态，记录到目前为止对话中所有必要的信息：
- 当前的用户查询q；
- 根据q检索或整合得到的外部知识源证据e；
- 由大语言模型根据提示生成的候选回答o；
- 评估o中每个元素是否符合任务需求或者用户期望的效用分数u，并根据u产生指导大语言模型修正其输出结果的反馈f，u和f都由效用模块生成；
- q之前所有的用户输入问题及大语言模型输出结果组成历史会话hq。

#### （2）策略模块

策略模块选择下一个系统动作a，使得在当前状态s下能够带来最佳期望奖励r。这些动作包括：
- 根据q和hq从外部知识库中获取支撑性证据e；
- 根据e、q和hq调用ChatGPT生成候选回复；
- 如果候选回复通过了效用模块设置的质量标准，则向用户发送最优回复。

策略可以使用人工编写规则或者模型学习两种方法实现。微软研究员采取模型学习方法，在对话数据上训练策略模块，并使用强化学习方法更新预训练模型参数以最大化期望奖励。这种方法不仅可以利用预训练模型的强大能力，而且还可以通过微调来适应不同的任务需求和用户偏好。

#### （3）动作执行器
动作执行器执行由策略模块选择的动作，由两个部分组成：知识整合器（knowledge consolidator）和提示引擎（prompt engine）。
- **知识整合器**：是一种增强大语言模型能力的方法，可以减少虚构或不准确信息的生成。知识整合器包括知识检索器、实体链接器和证据串联器。知识检索器首先根据q和hq生成一组搜索查询，并调用一系列API从各种外部知识源检索原始证据。实体链接器用相关实体信息来丰富原始证据，并形成证据图。然后，证据串联器从图中剪除不相关或重复的证据，并形成一个最相关且连贯的证据链候选列表。经过整合后的最优证据e被发送到工作记忆模块。
- **提示引擎**：生成一个提示，用来向ChatGPT查询，让ChatGPT生成候选回答o给问题q。提示是一个文本字符串，由任务指示、用户问题q、对话历史hq、证据e和反馈f组成。表6 - 7展示了一个微软研究员给出的提示模板示例。

**表6 - 7 提示引擎的模板示例**

|提示模板|希望你扮演一个聊天机器人AI，来帮助用户规划旅行。你会看到一些知识片段。请你根据这些知识片段，友好而准确地回答用户的问题。<br>工作记忆：<内容>…<br>上下文：<br>用户：<内容>…<br>助理：<内容>…<br>…<br>用户：<内容>…<br>助理：|
| ---- | ---- |

![image](https://github.com/user-attachments/assets/fbf1d8f2-1e08-431a-830b-42f9bb28e098)


#### （4）效用模块
给定一个候选回复o，效用模块使用一组任务相关的效用函数生成效用分数u和相应的反馈f。例如，在一个火车票预订对话中，ChatGPT回复应该是对话式的，并专注于引导用户完成预订过程。

同样地，微软研究员利用ChatGPT作为效用函数，即通过提示ChatGPT来评估候选回复并给出改进意见，从而实现自我评估以收集反馈。

#### （5）评估
为了评估LLM - Augmenter在开放领域对话任务上的表现，微软研究员使用了一个对话式客服场景的数据集进行实验。该数据集包含了除常见问题外，用户评论等多种类型的外部知识源，可以用于测试模型理解和使用相关用户评论帖子和常见问题片段生成回应的能力。

微软研究员通过人工评估了LLM - Augmenter在可用性（usefulness）和人性化（humanness）方面的能力。如表6 - 8所示，LLM - Augmenter在可用性和人性化这两个方面都显著地优于ChatGPT。

**表6 - 8 LLM - Augmenter和ChatGPT的比较**

|模型|可用性|人性化|
| ---- | ---- | ---- |
|ChatGPT|34.07|30.92|
|LLM - Augmenter|45.07|35.22|

### 6.3 大语言模型增强检索
上一节介绍了如何通过检索来增强大语言模型的生成能力，以缓解模型在开放领域问答和对话任务中存在的幻觉问题，提高输出的质量和可靠性。本节将从另一个角度阐述大语言模型如何反过来增强检索的效果。

搜索引擎是自然语言处理在工业界最具影响力和价值的应用之一，已经发展了二十多年。随着用户需求和信息量的不断增长，传统的基于关键词匹配和启发式排序的方法已经难以满足复杂多样的搜索场景。因此，在大语言模型时代，有必要重新审视搜索引擎中涉及的各种自然语言理解任务，并借助大语言模型强大而灵活的表示学习和推断能力，来构建更为智能、精准和友好的搜索体验。本节将以3个典型案例来说明大语言模型可以如何增强检索。

### 6.3.1 神经向量检索
#### 1. 神经向量检索概述
过去几十年，工业界主要依赖于基于关键词匹配和排名函数（如BM25）来实现文档检索。这种方法虽然简单高效，但也存在着明显的缺陷：它忽略了文档和查询之间更深层次、更细粒度、更丰富多样的语义联系，并且无法很好地处理词汇失配（如同义词、多义词等）和复杂查询（如自然语言问题等）等问题。为了突破这些局限，近年来研究人员开始探索基于神经网络模型来实现语义检索（semantic retrieval）的方法。

神经向量检索（neural vector retrieval）是一种基于神经网络模型实现语义检索的技术。其核心思想是利用神经网络模型将文档和查询分别映射为低维稠密向量（也称为嵌入或编码），这些向量可以有效地捕获文档或查询中隐含的语义信息、结构信息和上下文信息，并且可以很好地保持相似内容之间距离较近、不相似内容之间距离较远的特性。因此，在进行文档检索时，只需要计算候选文档与查询之间向量表示的距离或相似度，并按照由近及远或由高至低的顺序返回结果即可。

#### 2. 大语言模型作为编码器
在神经向量检索技术中，编码器是决定向量表示质量的关键部分。编码器需要具有强大的非线性和抽象能力，以便从原始文本中提取出高层次和丰富多样的特征，并压缩到低维度空间中。如图6 - 7所示，在同一维度空间上，编码器越优秀，则相似内容之间的距离越近，不相似内容之间距离越远，在给定查询时能够更精确地找到相关联的文档。

![image](https://github.com/user-attachments/assets/923d53db-48b9-4254-9cad-62120b815cf8)


**图6 - 7 向量化后文档相关性**
（图中展示相关文档和查询在二维坐标上的分布，相关文档围绕查询分布）

大语言模型可以作为优秀的编码器来实现神经向量检索，具备以下优势：
- 大语言模型能够利用其深层次和丰富的知识表示，捕捉文本和查询之间更深层次、更细粒度、更丰富多样的语义联系，提高检索的准确率和召回率。
- 大语言模型能够利用其强大的泛化能力，处理不同领域、风格、话题等方面的文本和查询，增强检索的稳健性和覆盖度。
- 大语言模型能够利用其巨大的预训练数据规模，缓解检索任务中的数据稀疏性问题，提升编码器的表示能力和适应性。

为了评估不同编码器在神经向量检索中的性能，可以参考大文本嵌入基准（Massive Text Embedding Benchmark，MTEB）测试集。MTEB测试集涵盖了8个文本嵌入相关任务（如分类、聚类、检索和重排等），共58个数据集。图6 - 8是MTEB测试集中检索任务的榜单截图，可以看到目前业界最先进的大语言模型在此任务上均有出色的表现。

![image](https://github.com/user-attachments/assets/4dd5c839-03c9-4d18-bdd0-7a2116f3a059)


**图6 - 8 MTEB的检索任务榜单**
（图中展示不同模型在各项任务上的测试结果表格）

尽管大语言模型在神经向量检索中有很多优势，但也面临着一个主要挑战，即编码的效率问题。由于大语言模型通常参数量巨大，推断时间长，直接运用于对时延要求高的搜索引擎中是不切实际的。

为了解决这个问题，有多种可能的做法：一是对大语言模型进行小型化，减少其参数量和计算复杂度，例如使用知识蒸馏（knowledge distillation）、模型压缩或模型剪枝等技术；二是将大语言模型仅用于搜索栈的最上层做重排（re - ranking），以减少计算输入的复杂度；三是利用大语言模型标注搜索引擎里机器学习模型的训练数据。在6.3.2和6.3.3两小节将介绍后两种方法的应用实例。

#### 3. Vectara
Vectara是近年来推出的一个由大语言模型驱动的对话式搜索引擎，它可以实现自然语言的交互和信息检索。Vectara首先可以通过大语言模型对网页、文件、应用程序等的文本内容进行高效的编码和表示，提高检索的相关性。同时，Vectara采用了神经网络模型进行召回和粗排，提高检索的准确性。图6 - 9是Vectara的简要流程图。

![image](https://github.com/user-attachments/assets/5835945b-0b31-478d-8429-e7bce509d520)


**图6 - 9 Vectara的简要流程图**
（图中展示Vectara从Extract、Encode、Index、Retrieve、Rerank到Calibrate的流程）

### 6.3.2 相关性重排
大语言模型具有强大的零样本学习能力，能够在没有专门训练的情况下，适应各种自然语言处理任务。对于搜索引擎里的关键问题——相关性排序是否也可以利用大语言模型？相关性排序是指根据用户输入的查询，从索引库中检索出若干候选文档，并按照与查询的相关程度进行排序。如何利用大语言模型来提升相关性排序的效果呢？

百度团队的研究表明，通过合理地设计提示，可以让大语言模型在相关性排序任务上，达到甚至超过基于监督学习方法的水平。具体来说，百度团队在段落重排（passage reranking）任务上，探索了3种不同类型的提示方法。
- **查询生成（query generation）**：查询q与段落$p_{i}$的相关性得分是模型基于段落生成查询的负对数似然（即查询词每个字符上的负对数似然加和去平均），然后根据相关性得分对段落进行排序。
- **相关性生成（relevance generation）**：相关性得分是大语言模型在提示下生成是或者否的概率值。
- **排序生成（permutation generation）**：不同于以上两种获得大语言模型对数概率值的方法，排序生成方式直接提示大语言模型对所有的段落基于相关性进行排序。

表6 - 9列出了百度研究员提出的3种用于段落重排的提示模板。

![image](https://github.com/user-attachments/assets/524748d7-8e1b-435b-912f-9f351bf7b005)


**表6 - 9 段落重排的3种提示模板**



|指令类型|提示|
| ---- | ---- |
|查询生成|请写出一个基于以下段落的查询问题。<br>段落：{{段落内容}}<br>查询：{{查询内容}}|
|相关性生成|给定一段段落和一个问题，输出“是”或“否”来判断段落中是否包含对问题的回答。<br>段落：段落内容例子1<br>查询：查询内容例子1<br>以上段落能回答对应的查询吗？<br>回答：是<br>(更多的例子)<br>段落：{{段落内容}}<br>查询：{{查询内容}}<br>以上段落能回答对应的查询吗？<br>回答：|
|排序生成|这是RankGPT，一个智能助理，我可以根据查询与文章的相关性对段落进行排序。<br>以下是{{num}}个段落，每个段落用数字标识符[]表示。我可以根据它们与查询的相关性对它们进行排序：{{query}}<br>[1]{{段落1}}<br>[2]{{段落2}}<br>(更多的段落)…<br>搜索查询是：{{query}}<br>我将根据搜索查询的相关性对上面的{{num}}个段落进行排序。段落将使用标识符按降序列出，最相关的段落应该排在前面，输出格式应该是[] > [] >等，例如，[1] > [2] >等。<br>{{num}}个段落的排序结果是：|

表6 - 10展示了百度研究员将不同大小和提示类型的大语言模型在两个排序数据集上进行无监督段落重排的效果，并与当前最先进（SOTA）的有监督和无监督方法进行了比较。

**表6 - 10 不同模型在相关性重排上的性能**

![image](https://github.com/user-attachments/assets/83c3bde4-5da0-48ae-aed1-7504ddbdcc73)


|方法|TREC - DL19|  |TREC - DL20|  |
| ---- | ---- | ---- | ---- | ---- |
|  | nDCG@1 | nDCG@10 | nDCG@1 | nDCG@10 |
|BM25|54.26|50.58|57.72|47.96|
|监督方式<br>monoT5(3B)|79.07|71.83|80.25|68.89|
|非监督方式|提示类型|  |  |  |
|text - curie - 001|相关性生成|39.53|41.53|41.98|34.91|
|text - curie - 001|查询生产|50.78|49.76|50.00|48.73|
|text - davinci - 003|查询生产|37.60|45.37|51.25|45.93|
|text - davinci - 003|排序生成|69.77|61.50|69.75|57.05|
|ChatGPT|排序生成|82.17|65.80|79.32|62.91|
|GPT - 4|排序生成|82.56|75.59|78.40|70.56|

从表6 - 10的结果可以看到以下结论：
- GPT - 4使用排序生成提示方法在两个数据集中都取得了最好的效果。作为一种无监督方法，它在DL19和DL20上的nDCG@10分别比当前最佳有监督系统monoT5(3B)高出3.76和1.67。
- GPT - 5（ChatGPT）在nDCG@1上与GPT - 4表现相当，但是在nDCG@10上落后于GPT - 4。 
- 相比于查询生成或相关性生成方法，排列生成方法能够更有效地指导大语言模型进行段落重排。

### 6.3.3 数据标注
在检索系统中，有很多自然语言处理任务需要大量高质量的标注数据来训练和评估机器学习模型，如文本分类、命名实体识别、关系抽取等。但是人工标注是一项代价高昂和耗时的工作，并且标注结果可能受到不同标注者的主观偏差和水平差异的影响。 

ChatGPT这样的大语言模型能否有效地替代人类标注者在自然语言处理任务中的作用？

近年来，已有研究报告和产业界案例表明，在有些自然语言处理任务中，使用大语言模型进行数据标注可以达到或超过人工众包（或专业标注员）的水平，同时能显著降低标注成本。这些任务通常涉及对文本内容进行审核、分类、抽取或生成等操作。为了使大语言模型能够正确地完成这些任务，通常需要为其设计合适的输入、输出信息和精巧的提示。

本小节将介绍瑞士苏黎世大学Fabrizio Gilardi等研究员提出的使用大语言模型进行数据标注的实例，并简要展示其所设计的提示和取得的对比结果。表6 - 11展示了研究员们设计的一些用于ChatGPT进行数据标注的提示。

评测方法为：ChatGPT在这些提示下生成标签，同时将相应的任务派发给经过训练的标注员和众包标注员。最终的数据标注效果，ChatGPT在零样本情况下：

 - ChatGPT在5个有关内容审核的任务中有4个超过了众包的表现；
 
 - ChatGPT的内部标注一致性在所有任务中都优于众包和训练过的标注员；
 
 - ChatGPT的每条数据的标注成本大约是0.003美元，比众包便宜20倍，而且质量更高。
由
此可以看到，大语言模型进行数据标注可以达到或超过人工众包（或专业标注员）的水平，同时能显著降低标注成本。


# 6.4 搜索新场景
## 6.4.1 必应故事
必应故事（Story）是必应在搜索里新推出的场景。在必应搜索框中，一些用户查询词会触发Story，触发后的搜索结果顶部将呈现文字、图片、语音或者视频的介绍内容，提供更加丰富的搜索体验。
图6 - 10展示了必应故事的体验界面。

### 图6 - 10 必应故事
| Microsoft Bing | welsh corgi |
| ---- | ---- |
| SEARCH | CHAT | WORK | IMAGES | VIDEOS | MAPS | NEWS | MORE |
| Welsh Corgi Dog breed | Breeders | Health | Grooming | Training | Facts | Diet |
| **The Pembroke is a lively, Intelligent, and loyal companion, but also needs regular exercise, training, and grooming to stay healthy and happy** |  |
| Story is an experiment. Sources: <br> Pembroke Welsh Corgi Dog Breed Infor - <br> Pembroke Welsh Corgi Dog Breed Profil - <br> Pembroke Welsh Corgi Information & D_ |  |
| Feedback |  |

![image](https://github.com/user-attachments/assets/f34d9c75-e189-4356-ad07-8ee2bc2fca8e)

![image](https://github.com/user-attachments/assets/15f46516-c375-4617-83f0-168023bfa958)



## 6.4.2 必应知识卡片2.0
必应知识卡片2.0（Knowledge Cards 2.0）是必应在原先版本基础上的升级，包括以下方面的创新：
 - 技术方面，由全新的GPT - 4驱动；
 - 内容方面，能提供更加趣味性的知识以及更加准确的关键信息；
 - 展现方面，丰富的多模态体验，如包括图表、时间线和视觉故事等多方面的视觉呈现。
图6 - 11展示了必应知识卡片2.0的体验界面。

![image](https://github.com/user-attachments/assets/d50fe26a-c0cd-4051-91db-21103057edc6)


### 图6 - 11 必应知识卡片2.0
| **里约热内卢** <br> 巴西城市 | **Compare** |
| ---- | ---- |
| 里约热内卢，有时简称为里约，位于巴西东南部，为里约热内卢州首府，也是巴西人口第二多的城市，仅次于圣保罗。面积1256平方公里，人口674.7万人，整个都会区人口达1229万。里约热内卢由→ 维基百科 | 人口（百万）：6.9 <br> 面积（平方公里）：1,256 <br> 海拔（米）：62 (209 ft) <br> （数据截至2020年或2021年，取决于城市或都会区的定义） <br> 最湿季：(160, 960) <br> （2011年数据） |
| 社交媒体图标（维基百科、Facebook、YouTube） | 1897年，一群参加过卡努多斯战争的士兵在里约热内卢市中心附近的一座山上定居，创建了第一个贫民窟。这座山被称为普罗维登萨山，贫民窟的名字叫法维拉，源自战争发生地区生长的一种植物。 |
| 地图（标注Rio、Volta Redonda、Macae等地点） | 科帕卡巴纳宫酒店，于1923年开业，是世界上最著名和豪华的酒店之一。它曾接待过名人、王室和总统，例如弗雷德里克·福赛斯、保罗·罗伯逊、利利亚娜·蒙泰罗、戴安娜王妃、费利佩王子和莱蒂齐亚王后。 |
| **时间趋势线** | 里约热内卢的葡萄牙语意思是“一月的河流”，但那里并没有河流。这个名字是1562年1月到达的探险家的一个错误，他们以为那是河口。 |
| 1565 里约热内卢由葡萄牙人建立 <br> 1763 里约热内卢成为巴西的首都 <br> 1808 里约热内卢获得拿破仑的葡萄牙王室 | 大区：东南 <br> 州：里约热内卢州 <br> 建立：1565年3月1日 <br> 海拔：0米/1,021米（0英尺 - ） <br> 查看更多内容 |
|  | **预订航班** **预订酒店** |
|  | **最佳的旅游季节** <br> （以柱状图展示1 - 12月情况） |

### 表6 - 11 数据标注的ChatGPT提示
| 任务 | 提示 |
| ---- | ---- |
| **相关内容审核** | 对于样本中的每一条推文，请按照以下步骤操作。<br>1）仔细阅读推文的文本，注意细节。<br>2）判断推文为相关（1）或者不相关（0）。<br>当推文与内容审核直接相关时，应将其标为相关。这包括讨论以下内容的推文：社交媒体平台的内容审核规则和做法、政府对在线内容审核的监管，以及/或者像标记这样的温和形式的内容审核。<br>如果推文没有提到内容审核，或者它们本身就是被审核过的内容，那么应将其标为无关。例如，推特上被标记为有争议的唐纳德·特朗普的推文，声称某事是假的推文，或者包含敏感内容的推文。这些推文可能会受到内容审核，但是它们并没有讨论内容审核。因此，对于我们的目的来说，它们应该被编码为无关。 |
| **主题检测** | 关于内容审核的推文也可能涉及其他相关话题，例如：<br>1）第230条，这是一项美国法律，保护网站和其他在线平台免于对其用户发布的内容承担法律责任（第230条）；<br>2）许多社交媒体平台，如推特和脸书，决定暂停唐纳德·特朗普的账号（特朗普禁令）；<br>3）针对推特支持账号或帮助中心的请求（推特支持）；<br>4）社交媒体平台的政策和做法，如社区准则或服务条款（平台政策）；<br>5）对平台在取消平台资格和内容审核方面的政策和做法的投诉或建议暂停某些账号，或对账号被暂停或举报的投诉（投诉）；<br>6）如果一段文本不属于第230条、投诉、特朗普禁令、推特支持和平台政策这些类别，那么它应该被归类为其他类别（其他）。<br>对于样本中的每一条推文，请按照以下说明操作。<br>1）仔细阅读推文的文本，注意细节。<br>2）请根据话题（由文本的功能、作者目的和文本形式定义）对以下文本进行分类。你可以从以下类别中选择：第230条、特朗普禁令、投诉、推特支持、平台政策和其他。 |
| **立场检测** | 在内容审核的背景下，第230条是美国的一项法律，它保护了网站和其他在线平台不因为其用户发布的内容而承担法律责任。这意味着如果有人在网站上发布了一些非法或有害的内容，网站本身不能因为允许发布而被起诉。但是，网站仍然可以选择审核内容，并删除任何违反其自身政策的内容。<br>对于样本中的每一条推文，请按照以下说明操作：<br>1）仔细阅读推文的文本，注意细节；<br>2）将推文分类为对第230条持有积极态度、消极态度或中立态度。 | 
